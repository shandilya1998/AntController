/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
usage: ddpg.py [-h] [--experiment EXPERIMENT] [--out_path OUT_PATH]
               [--env ENV] [--env_version ENV_VERSION] [--model_dir MODEL_DIR]
               [--test_env [TEST_ENV]] [--her [HER]]
ddpg.py: error: unrecognized arguments: -- her
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Traceback (most recent call last):
  File "ddpg.py", line 198, in <module>
    env = stable_baselines3.common.env_util.make_vec_env(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 102, in make_vec_env
    return vec_env_cls([make_env(i + start_index) for i in range(n_envs)], **vec_env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 77, in _init
    env = gym.make(env_id, **env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/usr/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 916, in get_code
  File "<frozen importlib._bootstrap_external>", line 846, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 256
    self.desired_motions.append(np.array([self.xpos[i], self.ypos[i], self.h]. dtype = np.float32))
                                         ^
SyntaxError: expression cannot contain assignment, perhaps you meant "=="?
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Traceback (most recent call last):
  File "ddpg.py", line 198, in <module>
    env = stable_baselines3.common.env_util.make_vec_env(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 102, in make_vec_env
    return vec_env_cls([make_env(i + start_index) for i in range(n_envs)], **vec_env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 77, in _init
    env = gym.make(env_id, **env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 60, in make
    env = cls(**_kwargs)
TypeError: AntEnvV2() missing 1 required positional argument: 'AntEnvV1'
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Traceback (most recent call last):
  File "ddpg.py", line 198, in <module>
    env = stable_baselines3.common.env_util.make_vec_env(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 102, in make_vec_env
    return vec_env_cls([make_env(i + start_index) for i in range(n_envs)], **vec_env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 77, in _init
    env = gym.make(env_id, **env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 60, in make
    env = cls(**_kwargs)
TypeError: AntEnvV2() missing 1 required positional argument: 'AntEnvV1'
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Traceback (most recent call last):
  File "ddpg.py", line 198, in <module>
    env = stable_baselines3.common.env_util.make_vec_env(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 102, in make_vec_env
    return vec_env_cls([make_env(i + start_index) for i in range(n_envs)], **vec_env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 77, in _init
    env = gym.make(env_id, **env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 60, in make
    env = cls(**_kwargs)
TypeError: AntEnvV2() missing 1 required positional argument: 'AntEnvV1'
2021-05-27 08:41:48.194181: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 08:41:48.194238: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_1
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Traceback (most recent call last):
  File "ddpg.py", line 267, in <module>
    model.learn(total_timesteps=int(2e6), callback=callback)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/td3/td3.py", line 203, in learn
    return super(TD3, self).learn(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 353, in learn
    rollout = self.collect_rollouts(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 567, in collect_rollouts
    new_obs, reward, done, infos = env.step(action)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 163, in step
    return self.step_wait()
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 43, in step_wait
    obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/monitor.py", line 98, in step
    ep_info[key] = info[key]
KeyError: 'reward_forward'
2021-05-27 08:45:02.021465: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 08:45:02.021525: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_2
Num timesteps: 2000
Best mean reward: -inf - Last mean reward per episode: -448.68
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(-1305.1580912, 324.4598109705209)
---------------------------------
| forward_vel        | 0.0638   |
| reward             | -1.31    |
| reward_contact     | -0.00387 |
| reward_ctrl        | -2.31    |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 533      |
|    ep_rew_mean     | -234     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 5        |
|    time_elapsed    | 358      |
|    total timesteps | 2132     |
---------------------------------
---------------------------------
| forward_vel        | 0.621    |
| reward             | -0.974   |
| reward_contact     | -0.0029  |
| reward_ctrl        | -1.97    |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 317      |
|    ep_rew_mean     | -137     |
| time/              |          |
|    episodes        | 8        |
|    fps             | 6        |
|    time_elapsed    | 364      |
|    total timesteps | 2534     |
---------------------------------
---------------------------------
| forward_vel        | 1.36     |
| reward             | -0.854   |
| reward_contact     | -0.00232 |
| reward_ctrl        | -1.85    |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 239      |
|    ep_rew_mean     | -102     |
| time/              |          |
|    episodes        | 12       |
|    fps             | 7        |
|    time_elapsed    | 368      |
|    total timesteps | 2873     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | -80.3    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 8        |
|    time_elapsed    | 371      |
|    total timesteps | 3057     |
---------------------------------
---------------------------------
| forward_vel        | 1.96     |
| reward             | -0.696   |
| reward_contact     | -0.0016  |
| reward_ctrl        | -1.69    |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 181      |
|    ep_rew_mean     | -75.3    |
| time/              |          |
|    episodes        | 20       |
|    fps             | 9        |
|    time_elapsed    | 378      |
|    total timesteps | 3619     |
---------------------------------
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Num timesteps: 4000
Best mean reward: -448.68 - Last mean reward per episode: -471.99
Traceback (most recent call last):
  File "ddpg.py", line 268, in <module>
    model.learn(total_timesteps=int(2e6), callback=callback)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/td3/td3.py", line 203, in learn
    return super(TD3, self).learn(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 370, in learn
    self.train(batch_size=self.batch_size, gradient_steps=gradient_steps)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/td3/td3.py", line 146, in train
    replay_data = self.replay_buffer.sample(batch_size, env=self._vec_normalize_env)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/her/her_replay_buffer.py", line 212, in sample
    return self._sample_transitions(batch_size, maybe_vec_env=env, online_sampling=True)  # pytype: disable=bad-return-type
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/her/her_replay_buffer.py", line 354, in _sample_transitions
    transitions["reward"][her_indices, 0] = self.env.env_method(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 113, in env_method
    return [getattr(env_i, method_name)(*method_args, **method_kwargs) for env_i in target_envs]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 113, in <listcomp>
    return [getattr(env_i, method_name)(*method_args, **method_kwargs) for env_i in target_envs]
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/core.py", line 249, in compute_reward
    return self.env.compute_reward(achieved_goal, desired_goal, info)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/core.py", line 249, in compute_reward
    return self.env.compute_reward(achieved_goal, desired_goal, info)
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 313, in compute_reward
    reward = np.concatenate([
  File "<__array_function__ internals>", line 5, in concatenate
ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)
2021-05-27 08:53:28.793156: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 08:53:28.793226: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_3
---------------------------------
| forward_vel        | 2.52     |
| reward             | -0.794   |
| reward_contact     | 0        |
| reward_ctrl        | -1.79    |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 282      |
|    ep_rew_mean     | -116     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 65       |
|    time_elapsed    | 17       |
|    total timesteps | 1130     |
---------------------------------
Num timesteps: 2000
Best mean reward: -inf - Last mean reward per episode: -94.53
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(-1035.207211, 334.77709989956224)
---------------------------------
| forward_vel        | 0.779    |
| reward             | -0.913   |
| reward_contact     | -0.00264 |
| reward_ctrl        | -1.91    |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 285      |
|    ep_rew_mean     | -137     |
| time/              |          |
|    episodes        | 8        |
|    fps             | 9        |
|    time_elapsed    | 336      |
|    total timesteps | 3123     |
---------------------------------
---------------------------------
| forward_vel        | 1.33     |
| reward             | -0.786   |
| reward_contact     | -0.00208 |
| reward_ctrl        | -1.78    |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | -96.9    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 9        |
|    time_elapsed    | 338      |
|    total timesteps | 3283     |
---------------------------------
Num timesteps: 4000
Best mean reward: -94.53 - Last mean reward per episode: -503.98
---------------------------------
| forward_vel        | 1.58     |
| reward             | -0.673   |
| reward_contact     | -0.00163 |
| reward_ctrl        | -1.67    |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -118     |
| time/              |          |
|    episodes        | 16       |
|    fps             | 13       |
|    time_elapsed    | 358      |
|    total timesteps | 4814     |
---------------------------------
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
()
Traceback (most recent call last):
  File "ddpg.py", line 268, in <module>
    model.learn(total_timesteps=int(2e6), callback=callback)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/td3/td3.py", line 203, in learn
    return super(TD3, self).learn(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 370, in learn
    self.train(batch_size=self.batch_size, gradient_steps=gradient_steps)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/td3/td3.py", line 146, in train
    replay_data = self.replay_buffer.sample(batch_size, env=self._vec_normalize_env)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/her/her_replay_buffer.py", line 212, in sample
    return self._sample_transitions(batch_size, maybe_vec_env=env, online_sampling=True)  # pytype: disable=bad-return-type
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/her/her_replay_buffer.py", line 354, in _sample_transitions
    transitions["reward"][her_indices, 0] = self.env.env_method(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 113, in env_method
    return [getattr(env_i, method_name)(*method_args, **method_kwargs) for env_i in target_envs]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 113, in <listcomp>
    return [getattr(env_i, method_name)(*method_args, **method_kwargs) for env_i in target_envs]
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/core.py", line 249, in compute_reward
    return self.env.compute_reward(achieved_goal, desired_goal, info)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/core.py", line 249, in compute_reward
    return self.env.compute_reward(achieved_goal, desired_goal, info)
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 314, in compute_reward
    reward = np.concatenate([
  File "<__array_function__ internals>", line 5, in concatenate
ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)
2021-05-27 09:21:50.460809: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 09:21:50.460874: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_4
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 85.5     |
|    ep_rew_mean     | -34.9    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 50       |
|    time_elapsed    | 6        |
|    total timesteps | 342      |
---------------------------------
----------------------------------
| forward_vel        | 2.86      |
| reward             | -0.399    |
| reward_contact     | -0.000648 |
| reward_ctrl        | -1.4      |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | -87.3     |
| time/              |           |
|    episodes        | 8         |
|    fps             | 66        |
|    time_elapsed    | 23        |
|    total timesteps | 1605      |
----------------------------------
2021-05-27 09:26:32.646401: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 09:26:32.646476: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_5
----------------------------------
| forward_vel        | 1.75      |
| reward             | -0.46     |
| reward_contact     | 0         |
| reward_ctrl        | -1.46     |
| reward_position    | 3.63e-179 |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 133       |
|    ep_rew_mean     | -48.9     |
| time/              |           |
|    episodes        | 4         |
|    fps             | 56        |
|    time_elapsed    | 9         |
|    total timesteps | 532       |
----------------------------------
---------------------------------
| forward_vel        | 2.61     |
| reward             | -0.315   |
| reward_contact     | 0        |
| reward_ctrl        | -1.31    |
| reward_position    | 4.19e-87 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 241      |
|    ep_rew_mean     | -106     |
| time/              |          |
|    episodes        | 8        |
|    fps             | 65       |
|    time_elapsed    | 29       |
|    total timesteps | 1927     |
---------------------------------
Num timesteps: 2000
Best mean reward: -inf - Last mean reward per episode: -105.99
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(-478.8511709999999, 521.3427320934238)
---------------------------------
| forward_vel        | 1.43     |
| reward             | -0.341   |
| reward_contact     | -0.00229 |
| reward_ctrl        | -1.34    |
| reward_position    | 1.09e-18 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 264      |
|    ep_rew_mean     | -120     |
| time/              |          |
|    episodes        | 12       |
|    fps             | 8        |
|    time_elapsed    | 360      |
|    total timesteps | 3239     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 214      |
|    ep_rew_mean     | -95.9    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 9        |
|    time_elapsed    | 364      |
|    total timesteps | 3489     |
---------------------------------
---------------------------------
| forward_vel        | 1.76     |
| reward             | -0.347   |
| reward_contact     | -0.00181 |
| reward_ctrl        | -1.34    |
| reward_position    | 4.4e-10  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 184      |
|    ep_rew_mean     | -81.5    |
| time/              |          |
|    episodes        | 20       |
|    fps             | 10       |
|    time_elapsed    | 367      |
|    total timesteps | 3752     |
---------------------------------
Num timesteps: 4000
Best mean reward: -105.99 - Last mean reward per episode: -196.41
---------------------------------
| forward_vel        | 2        |
| reward             | -0.377   |
| reward_contact     | -0.00154 |
| reward_ctrl        | -1.38    |
| reward_position    | 3.73e-10 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 168      |
|    ep_rew_mean     | -73.4    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 11       |
|    time_elapsed    | 372      |
|    total timesteps | 4103     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 154      |
|    ep_rew_mean     | -66.9    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 11       |
|    time_elapsed    | 376      |
|    total timesteps | 4390     |
---------------------------------
---------------------------------
| forward_vel        | 2.17     |
| reward             | -0.398   |
| reward_contact     | -0.00142 |
| reward_ctrl        | -1.4     |
| reward_position    | 3.24e-10 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -62.9    |
| time/              |          |
|    episodes        | 32       |
|    fps             | 12       |
|    time_elapsed    | 380      |
|    total timesteps | 4740     |
---------------------------------
---------------------------------
| forward_vel        | 2.33     |
| reward             | -0.403   |
| reward_contact     | -0.00125 |
| reward_ctrl        | -1.4     |
| reward_position    | 2.86e-10 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | -60.8    |
| time/              |          |
|    episodes        | 36       |
|    fps             | 13       |
|    time_elapsed    | 387      |
|    total timesteps | 5057     |
| train/             |          |
|    actor_loss      | 1.39     |
|    critic_loss     | 23.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 55       |
---------------------------------
Num timesteps: 6000
Best mean reward: -105.99 - Last mean reward per episode: -151.70
Num timesteps: 8000
Best mean reward: -105.99 - Last mean reward per episode: -235.53
---------------------------------
| forward_vel        | 2.23     |
| reward             | -0.558   |
| reward_contact     | -0.00129 |
| reward_ctrl        | -1.56    |
| reward_position    | 2.51e-10 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 225      |
|    ep_rew_mean     | -269     |
| time/              |          |
|    episodes        | 40       |
|    fps             | 14       |
|    time_elapsed    | 626      |
|    total timesteps | 9057     |
| train/             |          |
|    actor_loss      | -34.6    |
|    critic_loss     | 26.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 4055     |
---------------------------------
Num timesteps: 10000
Best mean reward: -105.99 - Last mean reward per episode: -311.34
---------------------------------
| forward_vel        | 2.16     |
| reward             | -0.638   |
| reward_contact     | -0.00136 |
| reward_ctrl        | -1.64    |
| reward_position    | 2.37e-10 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -321     |
| time/              |          |
|    episodes        | 44       |
|    fps             | 14       |
|    time_elapsed    | 750      |
|    total timesteps | 11108    |
| train/             |          |
|    actor_loss      | -67.7    |
|    critic_loss     | 36.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 6105     |
---------------------------------
Num timesteps: 12000
Best mean reward: -105.99 - Last mean reward per episode: -350.43
Num timesteps: 14000
Best mean reward: -105.99 - Last mean reward per episode: -372.90
---------------------------------
| forward_vel        | 2.21     |
| reward             | -0.701   |
| reward_contact     | -0.00145 |
| reward_ctrl        | -1.7     |
| reward_position    | 2.16e-10 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 313      |
|    ep_rew_mean     | -398     |
| time/              |          |
|    episodes        | 48       |
|    fps             | 15       |
|    time_elapsed    | 990      |
|    total timesteps | 15108    |
| train/             |          |
|    actor_loss      | -80.6    |
|    critic_loss     | 5.83     |
|    learning_rate   | 0.001    |
|    n_updates       | 10105    |
---------------------------------
Num timesteps: 16000
Best mean reward: -105.99 - Last mean reward per episode: -412.06
Num timesteps: 18000
Best mean reward: -105.99 - Last mean reward per episode: -451.07
---------------------------------
| forward_vel        | 2.07     |
| reward             | -0.722   |
| reward_contact     | -0.00159 |
| reward_ctrl        | -1.72    |
| reward_position    | 2.02e-10 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 366      |
|    ep_rew_mean     | -470     |
| time/              |          |
|    episodes        | 52       |
|    fps             | 15       |
|    time_elapsed    | 1235     |
|    total timesteps | 19108    |
| train/             |          |
|    actor_loss      | -89.2    |
|    critic_loss     | 4.59     |
|    learning_rate   | 0.001    |
|    n_updates       | 14105    |
---------------------------------
2021-05-27 09:50:21.934230: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 09:50:21.934294: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
MultiInputPolicy
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_6
----------------------------------
| forward_vel        | 4.06      |
| reward             | -0.17     |
| reward_contact     | 0         |
| reward_ctrl        | -1.17     |
| reward_position    | 4.34e-160 |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 105       |
|    ep_rew_mean     | -37.8     |
| time/              |           |
|    episodes        | 4         |
|    fps             | 52        |
|    time_elapsed    | 7         |
|    total timesteps | 420       |
----------------------------------
2021-05-27 09:53:08.841712: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 09:53:08.841772: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
MultiInputPolicy
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_7
----------------------------------
| forward_vel        | 1.96      |
| reward             | 1.14      |
| reward_contact     | 0         |
| reward_ctrl        | -1.82     |
| reward_position    | 8.98e-225 |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 298       |
|    ep_rew_mean     | 29.9      |
| time/              |           |
|    episodes        | 4         |
|    fps             | 67        |
|    time_elapsed    | 17        |
|    total timesteps | 1192      |
----------------------------------
Num timesteps: 2000
Best mean reward: -inf - Last mean reward per episode: 43.28
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(-1520.3894335, 200.68703479187522)
---------------------------------
| forward_vel        | 0.567    |
| reward             | -0.538   |
| reward_contact     | -0.00257 |
| reward_ctrl        | -2.1     |
| reward_position    | 4.47e-08 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 53.3     |
| time/              |          |
|    episodes        | 8        |
|    fps             | 7        |
|    time_elapsed    | 318      |
|    total timesteps | 2322     |
---------------------------------
---------------------------------
| forward_vel        | 0.813    |
| reward             | -0.141   |
| reward_contact     | -0.00203 |
| reward_ctrl        | -1.95    |
| reward_position    | 3.53e-08 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 162      |
|    ep_rew_mean     | 58.7     |
| time/              |          |
|    episodes        | 12       |
|    fps             | 8        |
|    time_elapsed    | 322      |
|    total timesteps | 2655     |
---------------------------------
Num timesteps: 4000
Best mean reward: 43.28 - Last mean reward per episode: -590.46
---------------------------------
| forward_vel        | 0.943    |
| reward             | 0.0752   |
| reward_contact     | -0.00161 |
| reward_ctrl        | -1.87    |
| reward_position    | 2.79e-08 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 215      |
|    ep_rew_mean     | 86.8     |
| time/              |          |
|    episodes        | 16       |
|    fps             | 12       |
|    time_elapsed    | 341      |
|    total timesteps | 4148     |
---------------------------------
---------------------------------
| forward_vel        | 1.07     |
| reward             | 0.328    |
| reward_contact     | -0.00142 |
| reward_ctrl        | -1.74    |
| reward_position    | 2.31e-08 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 185      |
|    ep_rew_mean     | 82.6     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 12       |
|    time_elapsed    | 345      |
|    total timesteps | 4407     |
---------------------------------
2021-05-27 10:00:42.285685: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 10:00:42.285746: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
MultiInputPolicy
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_8
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.8     |
|    ep_rew_mean     | 44.5     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 47       |
|    time_elapsed    | 6        |
|    total timesteps | 319      |
---------------------------------
----------------------------------
| forward_vel        | 0.882     |
| reward             | 0.324     |
| reward_contact     | -0.000429 |
| reward_ctrl        | -1.56     |
| reward_position    | 6.67e-41  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 104       |
|    ep_rew_mean     | 56.8      |
| time/              |           |
|    episodes        | 8         |
|    fps             | 60        |
|    time_elapsed    | 13        |
|    total timesteps | 834       |
----------------------------------
Num timesteps: 2000
Best mean reward: -inf - Last mean reward per episode: 46.73
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(-1108.4300807, 330.7187395937052)
---------------------------------
| forward_vel        | 0.39     |
| reward             | -0.524   |
| reward_contact     | -0.0024  |
| reward_ctrl        | -1.91    |
| reward_position    | 3.48e-11 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 175      |
|    ep_rew_mean     | 45.6     |
| time/              |          |
|    episodes        | 12       |
|    fps             | 6        |
|    time_elapsed    | 344      |
|    total timesteps | 2270     |
---------------------------------
---------------------------------
| forward_vel        | 0.729    |
| reward             | -0.106   |
| reward_contact     | -0.0019  |
| reward_ctrl        | -1.83    |
| reward_position    | 2.76e-11 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | 46.1     |
| time/              |          |
|    episodes        | 16       |
|    fps             | 7        |
|    time_elapsed    | 348      |
|    total timesteps | 2562     |
---------------------------------
---------------------------------
| forward_vel        | 0.737    |
| reward             | -0.0271  |
| reward_contact     | -0.00163 |
| reward_ctrl        | -1.76    |
| reward_position    | 2.36e-11 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 40.6     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 10       |
|    time_elapsed    | 366      |
|    total timesteps | 3877     |
---------------------------------
Num timesteps: 4000
Best mean reward: 46.73 - Last mean reward per episode: -330.14
---------------------------------
| forward_vel        | 0.737    |
| reward             | -0.0126  |
| reward_contact     | -0.00152 |
| reward_ctrl        | -1.75    |
| reward_position    | 2.13e-11 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 202      |
|    ep_rew_mean     | 27.4     |
| time/              |          |
|    episodes        | 24       |
|    fps             | 13       |
|    time_elapsed    | 381      |
|    total timesteps | 5016     |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 3.85e+03 |
|    learning_rate   | 0.001    |
|    n_updates       | 15       |
---------------------------------
Num timesteps: 6000
Best mean reward: 46.73 - Last mean reward per episode: -306.68
Num timesteps: 8000
Best mean reward: 46.73 - Last mean reward per episode: -341.87
---------------------------------
| forward_vel        | 0.718    |
| reward             | -0.113   |
| reward_contact     | -0.00151 |
| reward_ctrl        | -1.83    |
| reward_position    | 1.79e-11 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 281      |
|    ep_rew_mean     | -88.4    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 14       |
|    time_elapsed    | 564      |
|    total timesteps | 8024     |
| train/             |          |
|    actor_loss      | -23.1    |
|    critic_loss     | 21       |
|    learning_rate   | 0.001    |
|    n_updates       | 3020     |
---------------------------------
Num timesteps: 10000
Best mean reward: 46.73 - Last mean reward per episode: -350.85
---------------------------------
| forward_vel        | 0.773    |
| reward             | -0.0754  |
| reward_contact     | -0.00137 |
| reward_ctrl        | -1.85    |
| reward_position    | 1.61e-11 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 316      |
|    ep_rew_mean     | -113     |
| time/              |          |
|    episodes        | 32       |
|    fps             | 14       |
|    time_elapsed    | 696      |
|    total timesteps | 10288    |
| train/             |          |
|    actor_loss      | -22.1    |
|    critic_loss     | 3.88     |
|    learning_rate   | 0.001    |
|    n_updates       | 5285     |
---------------------------------
Num timesteps: 12000
Best mean reward: 46.73 - Last mean reward per episode: -327.71
---------------------------------
| forward_vel        | 0.75     |
| reward             | -0.111   |
| reward_contact     | -0.00138 |
| reward_ctrl        | -1.86    |
| reward_position    | 1.47e-11 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 342      |
|    ep_rew_mean     | -90.7    |
| time/              |          |
|    episodes        | 36       |
|    fps             | 15       |
|    time_elapsed    | 827      |
|    total timesteps | 12491    |
| train/             |          |
|    actor_loss      | -24.6    |
|    critic_loss     | 1.76     |
|    learning_rate   | 0.001    |
|    n_updates       | 7490     |
---------------------------------
2021-05-27 10:15:41.267299: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 10:15:41.267468: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
MultiInputPolicy
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_9
----------------------------------
| forward_vel        | 0.957     |
| reward             | -4.73e+05 |
| reward_contact     | -0.000391 |
| reward_ctrl        | -1.35     |
| reward_position    | -4.73e+05 |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 414       |
|    ep_rew_mean     | -4.02e+07 |
| time/              |           |
|    episodes        | 4         |
|    fps             | 67        |
|    time_elapsed    | 24        |
|    total timesteps | 1657      |
----------------------------------
2021-05-27 10:17:29.627974: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 10:17:29.628037: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
[-0.0054514   0.01457597  0.77124632]
[9.2e+02 9.2e+02 7.5e-01]
MultiInputPolicy
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_10
[-0.08684789 -0.0760027   0.81926734]
[318.   318.     0.75]
[-0.08556323 -0.08147482  0.81893224]
[318.   318.     0.75]
[-0.08671496 -0.09518668  0.76512818]
[318.   318.     0.75]
[-0.09711481 -0.10304992  0.67906371]
[318.   318.     0.75]
[-0.01688217 -0.0643011   0.62311752]
[318.   318.     0.75]
[ 0.06901927 -0.00801678  0.58682483]
[318.   318.     0.75]
[0.13114548 0.03874249 0.5594654 ]
[318.   318.     0.75]
[0.16530962 0.05115693 0.60157221]
[318.   318.     0.75]
[0.19102357 0.0748649  0.65823976]
[318.   318.     0.75]
[0.21110538 0.11691255 0.7038165 ]
[318.   318.     0.75]
[0.22271347 0.16791485 0.75884917]
[318.   318.     0.75]
[0.23428088 0.20202926 0.79377824]
[318.   318.     0.75]
[0.24998227 0.21696667 0.80440887]
[318.   318.     0.75]
[0.25811216 0.24987244 0.80870804]
[318.   318.     0.75]
[0.22619946 0.32823009 0.85724426]
[318.   318.     0.75]
[0.19995507 0.40909772 0.88154835]
[318.   318.     0.75]
[0.18856523 0.48589809 0.87906347]
[318.   318.     0.75]
[0.18101966 0.56393792 0.8485318 ]
[318.   318.     0.75]
[0.17331431 0.66313214 0.80228064]
[318.   318.     0.75]
[0.16706    0.76826749 0.7455254 ]
[318.   318.     0.75]
[0.18020407 0.87816123 0.71490343]
[318.   318.     0.75]
[0.22177708 0.97730437 0.70480178]
[318.   318.     0.75]
[0.25708015 1.07736734 0.67334439]
[318.   318.     0.75]
[0.28957568 1.17526037 0.62954748]
[318.   318.     0.75]
[0.32418476 1.2434152  0.59031598]
[318.   318.     0.75]
[0.35350216 1.30276742 0.62722681]
[318.   318.     0.75]
[0.379387   1.37057557 0.64837302]
[318.   318.     0.75]
[0.40822664 1.44154073 0.64539505]
[318.   318.     0.75]
[0.43838941 1.51462858 0.6231259 ]
[318.   318.     0.75]
[0.46783973 1.58453357 0.58389914]
[318.   318.     0.75]
[0.50678248 1.64296414 0.53551575]
[318.   318.     0.75]
[0.55240902 1.663449   0.5363975 ]
[318.   318.     0.75]
[0.57725601 1.63729894 0.60796161]
[318.   318.     0.75]
[0.58355101 1.61163526 0.66921825]
[318.   318.     0.75]
[0.58008859 1.59623755 0.70463556]
[318.   318.     0.75]
[0.59046785 1.57161516 0.71769767]
[318.   318.     0.75]
[0.59484917 1.55161761 0.70865912]
[318.   318.     0.75]
[0.59109489 1.53160605 0.69763674]
[318.   318.     0.75]
[0.5913842  1.50314884 0.66035667]
[318.   318.     0.75]
[0.5977249  1.46581453 0.62703564]
[318.   318.     0.75]
[0.5719724  1.44887129 0.63338382]
[318.   318.     0.75]
[0.53648588 1.43567393 0.61736906]
[318.   318.     0.75]
[0.50122607 1.41926196 0.590968  ]
[318.   318.     0.75]
[0.50450678 1.4132542  0.6017368 ]
[318.   318.     0.75]
[0.52159035 1.41540576 0.59426464]
[318.   318.     0.75]
[0.53355344 1.40265588 0.56748571]
[318.   318.     0.75]
[0.54927053 1.36719901 0.55129505]
[318.   318.     0.75]
[0.54371288 1.34378387 0.54747059]
[318.   318.     0.75]
[0.55342016 1.30883637 0.58310344]
[318.   318.     0.75]
[0.56635024 1.28622614 0.6113165 ]
[318.   318.     0.75]
[0.58079395 1.27436898 0.62881206]
[318.   318.     0.75]
[0.60796538 1.27529902 0.63053018]
[318.   318.     0.75]
[0.64222327 1.26649628 0.62400628]
[318.   318.     0.75]
[0.69331941 1.26141718 0.62834319]
[318.   318.     0.75]
[0.74218164 1.25152957 0.61726757]
[318.   318.     0.75]
[0.77255774 1.26014599 0.59088036]
[318.   318.     0.75]
[0.79210829 1.27024726 0.54557028]
[318.   318.     0.75]
[0.78463923 1.26444534 0.54551546]
[318.   318.     0.75]
[0.74555898 1.26350593 0.54390612]
[318.   318.     0.75]
[0.70591398 1.26296627 0.50739039]
[318.   318.     0.75]
[0.70934915 1.27363923 0.52936182]
[318.   318.     0.75]
[0.74848713 1.28515347 0.60743481]
[318.   318.     0.75]
[0.77974966 1.298146   0.6608613 ]
[318.   318.     0.75]
[0.80970184 1.30898525 0.69487816]
[318.   318.     0.75]
[0.83504963 1.31055237 0.7107957 ]
[318.   318.     0.75]
[0.83015696 1.30816534 0.72730614]
[318.   318.     0.75]
[0.83559103 1.31756724 0.72300759]
[318.   318.     0.75]
[0.83338212 1.32491773 0.73988812]
[318.   318.     0.75]
[0.82131326 1.33344605 0.79098633]
[318.   318.     0.75]
[0.80973935 1.3317172  0.8100843 ]
[318.   318.     0.75]
[0.7967092  1.32209034 0.79978068]
[318.   318.     0.75]
[0.78938699 1.31435356 0.7664086 ]
[318.   318.     0.75]
[0.79395335 1.31188939 0.7297379 ]
[318.   318.     0.75]
[0.84521379 1.34278926 0.73928688]
[318.   318.     0.75]
[0.89975954 1.38502169 0.72022287]
[318.   318.     0.75]
[0.96620983 1.40814599 0.67301779]
[318.   318.     0.75]
[1.02797147 1.41586528 0.64342581]
[318.   318.     0.75]
[1.0810298  1.3892985  0.63433065]
[318.   318.     0.75]
[1.120044   1.3620952  0.60242186]
[318.   318.     0.75]
[1.12048302 1.33109106 0.57611369]
[318.   318.     0.75]
[1.1307475  1.31620411 0.53093659]
[318.   318.     0.75]
[1.1455028  1.31732897 0.56166282]
[318.   318.     0.75]
[1.16118071 1.30483931 0.66911684]
[318.   318.     0.75]
[1.17455807 1.3024713  0.75043472]
[318.   318.     0.75]
[1.19987315 1.3108835  0.79876649]
[318.   318.     0.75]
[1.23127849 1.31657984 0.81387133]
[318.   318.     0.75]
[1.247518   1.31311521 0.8020076 ]
[318.   318.     0.75]
[1.26072227 1.30523662 0.77135954]
[318.   318.     0.75]
[1.27050216 1.3056378  0.75097365]
[318.   318.     0.75]
[1.26687121 1.32104811 0.76004256]
[318.   318.     0.75]
[1.26558573 1.32953817 0.83220476]
[318.   318.     0.75]
[1.26115973 1.33804129 0.90077131]
[318.   318.     0.75]
[1.25851346 1.35025333 0.95084146]
[318.   318.     0.75]
[1.25558988 1.35162595 0.98389087]
[318.   318.     0.75]
[1.24726264 1.35495442 0.99328172]
[318.   318.     0.75]
[1.23285651 1.35836801 1.00044188]
[318.   318.     0.75]
[ 0.061066   -0.04692976  0.73289473]
[364.   364.     0.75]
[ 0.06383886 -0.02967225  0.73511942]
[364.   364.     0.75]
[ 0.06116682 -0.02904362  0.68601964]
[364.   364.     0.75]
[ 0.03626663 -0.02764142  0.61940498]
[364.   364.     0.75]
[ 0.05554674 -0.05355368  0.58389616]
[364.   364.     0.75]
[ 0.07102055 -0.10359769  0.55875518]
[364.   364.     0.75]
[ 0.08710668 -0.15629681  0.53477961]
[364.   364.     0.75]
[ 0.12479041 -0.20503048  0.50644275]
[364.   364.     0.75]
[ 0.15153545 -0.25345315  0.48647807]
[364.   364.     0.75]
[ 0.1822056  -0.22938861  0.5541122 ]
[364.   364.     0.75]
[ 0.20432489 -0.1726555   0.61598233]
[364.   364.     0.75]
[ 0.21569536 -0.12026464  0.64754978]
[364.   364.     0.75]
[ 0.22620569 -0.07287827  0.65283148]
[364.   364.     0.75]
[ 0.24680839 -0.02171792  0.62813666]
[364.   364.     0.75]
[0.27289598 0.03311027 0.58208521]
[364.   364.     0.75]
[0.26794359 0.07634145 0.54892995]
[364.   364.     0.75]
[0.24771695 0.09665783 0.51655565]
[364.   364.     0.75]
[0.23501178 0.06704719 0.54756649]
[364.   364.     0.75]
[0.20751122 0.05420291 0.60785242]
[364.   364.     0.75]
[0.16847743 0.049562   0.68482815]
[364.   364.     0.75]
[0.13472108 0.0254163  0.73702483]
[364.   364.     0.75]
[0.11519125 0.00471644 0.77172013]
[364.   364.     0.75]
[ 0.10625758 -0.00709694  0.79332364]
[364.   364.     0.75]
[ 0.1019185  -0.02915312  0.84300908]
[364.   364.     0.75]
[ 0.08496962 -0.0596393   0.89541003]
[364.   364.     0.75]
[ 0.07022302 -0.10502706  0.95855125]
[364.   364.     0.75]
[ 0.04597637 -0.16378085  1.094846  ]
[364.   364.     0.75]
[-0.03711483  0.00427653  0.86240137]
[370.   370.     0.75]
[-3.36683385e-02  3.40651542e-04  8.53892603e-01]
[370.   370.     0.75]
[-0.02666662 -0.00290781  0.79062304]
[370.   370.     0.75]
[-0.02086891  0.00661281  0.70299063]
[370.   370.     0.75]
[-0.03739853  0.06896528  0.65978365]
[370.   370.     0.75]
[-0.04245751  0.16364171  0.63960789]
[370.   370.     0.75]
[-0.05521502  0.25778341  0.60135874]
[370.   370.     0.75]
[-0.06152974  0.31294844  0.57547649]
[370.   370.     0.75]
[-0.07219467  0.33807238  0.56616215]
[370.   370.     0.75]
[-0.07090685  0.37253087  0.54829366]
[370.   370.     0.75]
[-0.00510648  0.39782904  0.57915269]
[370.   370.     0.75]
[0.0677323  0.41849838 0.61240175]
[370.   370.     0.75]
[0.12700956 0.4208771  0.64344   ]
[370.   370.     0.75]
[0.17611717 0.41131142 0.65535387]
[370.   370.     0.75]
[0.21462778 0.40340101 0.64428639]
[370.   370.     0.75]
[0.26451154 0.40765941 0.60329021]
[370.   370.     0.75]
[0.31156744 0.43134053 0.53609898]
[370.   370.     0.75]
[0.3343783  0.46096242 0.50245449]
[370.   370.     0.75]
[0.31448225 0.47217843 0.5478457 ]
[370.   370.     0.75]
[0.30263322 0.4771099  0.57279312]
[370.   370.     0.75]
[0.30426193 0.49066574 0.57457814]
[370.   370.     0.75]
[0.30953686 0.50236656 0.54471316]
[370.   370.     0.75]
[0.31065603 0.48247365 0.54197142]
[370.   370.     0.75]
[0.31718809 0.454229   0.57096045]
[370.   370.     0.75]
[0.32488792 0.42672397 0.57846734]
[370.   370.     0.75]
[0.32698305 0.40239626 0.59288198]
[370.   370.     0.75]
[0.31954637 0.42121187 0.65646837]
[370.   370.     0.75]
[0.29320072 0.44890752 0.71763629]
[370.   370.     0.75]
[0.26345493 0.46142795 0.74618058]
[370.   370.     0.75]
[0.25399096 0.47394931 0.74289187]
[370.   370.     0.75]
[0.25007654 0.48558217 0.72199948]
[370.   370.     0.75]
[0.26219334 0.5066811  0.743073  ]
[370.   370.     0.75]
[0.28055901 0.54853214 0.76788408]
[370.   370.     0.75]
[0.30146785 0.5959008  0.76321068]
[370.   370.     0.75]
[0.31481727 0.63532475 0.72810041]
[370.   370.     0.75]
[0.33205062 0.65343613 0.68966357]
[370.   370.     0.75]
[0.33906412 0.59874418 0.76087758]
[370.   370.     0.75]
[0.32099758 0.54685968 0.83691696]
[370.   370.     0.75]
[0.31220848 0.51379409 0.90185742]
[370.   370.     0.75]
[0.30712613 0.51036932 0.9843219 ]
[370.   370.     0.75]
[0.27910695 0.5209192  1.09925484]
[370.   370.     0.75]
[0.00340487 0.07172495 0.8507034 ]
[552.   552.     0.75]
[0.01095648 0.0603333  0.83885846]
[552.   552.     0.75]
[0.01098517 0.05066401 0.7872554 ]
[552.   552.     0.75]
[-0.00293048  0.04392555  0.69674253]
[552.   552.     0.75]
[0.00844747 0.06151328 0.62886584]
[552.   552.     0.75]
[-5.99178370e-05  5.89434610e-02  6.16042054e-01]
[552.   552.     0.75]
[-0.00682517  0.04878862  0.63038625]
[552.   552.     0.75]
[-0.01886408  0.0466777   0.62417662]
[552.   552.     0.75]
[-0.02339388  0.03929517  0.62049364]
[552.   552.     0.75]
[-0.02571723  0.02111912  0.59584003]
[552.   552.     0.75]
[-0.03642675 -0.01008764  0.54494995]
[552.   552.     0.75]
[-0.03763975 -0.04748398  0.46524295]
[552.   552.     0.75]
[-0.02538442 -0.07399658  0.37932115]
[552.   552.     0.75]
[ 0.0332714  -0.08647215  0.44342104]
[552.   552.     0.75]
[ 0.11118581 -0.08530788  0.58012332]
[552.   552.     0.75]
[ 0.17332835 -0.08540364  0.68837203]
[552.   552.     0.75]
[ 0.23584483 -0.09621759  0.76419658]
[552.   552.     0.75]
[ 0.28881246 -0.1179195   0.81020673]
[552.   552.     0.75]
[ 0.35072384 -0.14309342  0.82966261]
[552.   552.     0.75]
[ 0.42153226 -0.18188391  0.82552748]
[552.   552.     0.75]
[ 0.49722695 -0.21030927  0.799065  ]
[552.   552.     0.75]
[ 0.57485353 -0.22205332  0.75621944]
[552.   552.     0.75]
[ 0.66394135 -0.22855458  0.71094658]
[552.   552.     0.75]
[ 0.74928459 -0.2229748   0.64095608]
[552.   552.     0.75]
[ 0.82901219 -0.21614473  0.56312048]
[552.   552.     0.75]
[ 0.92548875 -0.21222879  0.50548738]
[552.   552.     0.75]
[ 1.02780328 -0.30303041  0.51359997]
[552.   552.     0.75]
[ 1.12641727 -0.39963967  0.52562614]
[552.   552.     0.75]
[ 1.18871778 -0.4873479   0.54887265]
[552.   552.     0.75]
[ 1.23219445 -0.57623566  0.55970557]
[552.   552.     0.75]
[ 1.23295031 -0.65610565  0.5904134 ]
[552.   552.     0.75]
[ 1.23907037 -0.72531383  0.61567692]
[552.   552.     0.75]
[ 1.24334538 -0.78953002  0.62148369]
[552.   552.     0.75]
[ 1.23574298 -0.8493968   0.62192349]
[552.   552.     0.75]
[ 1.22205046 -0.88028997  0.6566551 ]
[552.   552.     0.75]
[ 1.22049193 -0.88776057  0.6824383 ]
[552.   552.     0.75]
[ 1.21537234 -0.88683828  0.68123894]
[552.   552.     0.75]
[ 1.18984746 -0.89943358  0.65834807]
[552.   552.     0.75]
[ 1.13316531 -0.93157234  0.65233213]
[552.   552.     0.75]
[ 1.09110545 -0.96421963  0.62671872]
[552.   552.     0.75]
[ 1.09849274 -0.9518387   0.65063393]
[552.   552.     0.75]
[ 1.11668291 -0.9269001   0.66906926]
[552.   552.     0.75]
[ 1.13282726 -0.90083424  0.66477929]
[552.   552.     0.75]
[ 1.15819802 -0.88959048  0.64927374]
[552.   552.     0.75]
[ 1.19721521 -0.90171452  0.63592434]
[552.   552.     0.75]
[ 1.24468813 -0.90025747  0.60234151]
[552.   552.     0.75]
[ 1.25821003 -0.83526111  0.60623207]
[552.   552.     0.75]
[ 1.25253829 -0.76110705  0.59623358]
[552.   552.     0.75]
[ 1.2494729  -0.70948183  0.57208898]
[552.   552.     0.75]
[ 1.25882914 -0.68691516  0.56350638]
[552.   552.     0.75]
[ 1.23874588 -0.6833414   0.59657239]
[552.   552.     0.75]
[ 1.1980389  -0.67692582  0.64060779]
[552.   552.     0.75]
[ 1.16697425 -0.66891457  0.66671452]
[552.   552.     0.75]
[ 1.13153095 -0.64327983  0.67425651]
[552.   552.     0.75]
[ 1.10147225 -0.61931481  0.65722342]
[552.   552.     0.75]
[ 1.08717476 -0.62070295  0.6497175 ]
[552.   552.     0.75]
[ 1.09971255 -0.6307339   0.67930353]
[552.   552.     0.75]
[ 1.11154661 -0.62729628  0.68597232]
[552.   552.     0.75]
[ 1.11724617 -0.62584761  0.66916242]
[552.   552.     0.75]
[ 1.12871011 -0.64376097  0.62967739]
[552.   552.     0.75]
[ 1.13726789 -0.65850551  0.56681131]
[552.   552.     0.75]
[ 1.15523939 -0.6318794   0.55414194]
[552.   552.     0.75]
[ 1.1572655  -0.5900724   0.54680336]
[552.   552.     0.75]
[ 1.15278201 -0.58382065  0.52905029]
[552.   552.     0.75]
[ 1.14883679 -0.58150165  0.49288236]
[552.   552.     0.75]
[ 1.15669862 -0.59753706  0.5137021 ]
[552.   552.     0.75]
[ 1.17806453 -0.61304147  0.57007796]
[552.   552.     0.75]
[ 1.21261292 -0.6029951   0.62579523]
[552.   552.     0.75]
[ 1.24413856 -0.58704475  0.68584379]
[552.   552.     0.75]
[ 1.26703268 -0.57401256  0.72010443]
[552.   552.     0.75]
[ 1.28029368 -0.57350164  0.71818449]
[552.   552.     0.75]
[ 1.29208965 -0.58865016  0.69765671]
[552.   552.     0.75]
[ 1.29447115 -0.6080898   0.66205744]
[552.   552.     0.75]
[ 1.29875691 -0.63758429  0.60995573]
[552.   552.     0.75]
[ 1.3237184  -0.63566363  0.59993964]
[552.   552.     0.75]
[ 1.33393444 -0.60250088  0.68524532]
[552.   552.     0.75]
[ 1.34210513 -0.56650405  0.74783325]
[552.   552.     0.75]
[ 1.35436495 -0.52770158  0.79521649]
[552.   552.     0.75]
[ 1.37002482 -0.49312225  0.81824068]
[552.   552.     0.75]
[ 1.38432457 -0.46000575  0.80739582]
[552.   552.     0.75]
[ 1.39503285 -0.42378421  0.80170073]
[552.   552.     0.75]
[ 1.40431967 -0.39848039  0.86006628]
[552.   552.     0.75]
[ 1.41135872 -0.40439598  0.95479232]
[552.   552.     0.75]
[ 1.41031991 -0.40664018  1.02184898]
[552.   552.     0.75]
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 62        |
|    ep_rew_mean     | -2.22e+07 |
| time/              |           |
|    episodes        | 4         |
|    fps             | 43        |
|    time_elapsed    | 5         |
|    total timesteps | 248       |
----------------------------------
[-0.07460887 -0.0387538   0.74120583]
[268.   268.     0.75]
[-0.10447267 -0.0540252   0.72453655]
[268.   268.     0.75]
[-0.11067166 -0.06849448  0.67014796]
[268.   268.     0.75]
[-0.09631678 -0.06243527  0.61698004]
[268.   268.     0.75]
[-0.068046   -0.03782945  0.65557566]
[268.   268.     0.75]
[-0.05699059 -0.00576977  0.67916466]
[268.   268.     0.75]
[-0.06001347  0.03065152  0.68047647]
[268.   268.     0.75]
[-0.05048075  0.07396151  0.65606275]
[268.   268.     0.75]
[-0.06942546  0.11682011  0.64331378]
[268.   268.     0.75]
[-0.13868353  0.1468519   0.66561942]
[268.   268.     0.75]
[-0.21627226  0.15286016  0.66205632]
[268.   268.     0.75]
[-0.29102243  0.13756515  0.64277599]
[268.   268.     0.75]
[-0.33811284  0.10128227  0.64138995]
[268.   268.     0.75]
[-0.32124241  0.03857899  0.74053735]
[268.   268.     0.75]
[-0.28325489 -0.02621072  0.86607931]
[268.   268.     0.75]
[-0.26652508 -0.09708245  0.97182203]
[268.   268.     0.75]
[-0.25364272 -0.1777895   1.05321613]
[268.   268.     0.75]
[0.09281386 0.07414172 0.83181491]
[22.   22.    0.75]
[0.09611997 0.08187783 0.82866792]
[22.   22.    0.75]
[0.09732579 0.08783763 0.78304769]
[22.   22.    0.75]
[0.10855739 0.09640497 0.70088223]
[22.   22.    0.75]
[0.11665754 0.1514241  0.6462168 ]
[22.   22.    0.75]
[0.13373425 0.20009976 0.61195933]
[22.   22.    0.75]
[0.17823894 0.21103067 0.60380827]
[22.   22.    0.75]
[0.21600498 0.22867715 0.58581518]
[22.   22.    0.75]
[0.22043735 0.2466272  0.5844462 ]
[22.   22.    0.75]
[0.20689409 0.25705119 0.56740335]
[22.   22.    0.75]
[0.18861559 0.23974066 0.56820649]
[22.   22.    0.75]
[0.16104011 0.21270522 0.58731158]
[22.   22.    0.75]
[0.12318917 0.20501803 0.63002512]
[22.   22.    0.75]
[0.10082346 0.20433748 0.66186772]
[22.   22.    0.75]
[0.09215278 0.2023817  0.67138902]
[22.   22.    0.75]
[0.09510358 0.19301777 0.66395623]
[22.   22.    0.75]
[0.09756681 0.18691604 0.64630723]
[22.   22.    0.75]
[0.09587411 0.23509685 0.65861129]
[22.   22.    0.75]
[0.09798741 0.30072598 0.65383013]
[22.   22.    0.75]
[0.09546354 0.37761437 0.62612111]
[22.   22.    0.75]
[0.06348866 0.47348918 0.63404284]
[22.   22.    0.75]
[0.027417   0.57482518 0.67275285]
[22.   22.    0.75]
[0.00433925 0.66100337 0.68452237]
[22.   22.    0.75]
[-0.01037087  0.74025937  0.66157416]
[22.   22.    0.75]
[-0.04448562  0.79430445  0.61579214]
[22.   22.    0.75]
[-0.08849355  0.84440996  0.55077009]
[22.   22.    0.75]
[-0.10224297  0.91771723  0.49408256]
[22.   22.    0.75]
[-0.12143283  0.97710072  0.50200906]
[22.   22.    0.75]
[-0.12965705  1.03697898  0.56439327]
[22.   22.    0.75]
[-0.13795066  1.09424947  0.60380496]
[22.   22.    0.75]
[-0.12890998  1.15448334  0.62084147]
[22.   22.    0.75]
[-0.11434004  1.21124661  0.61860949]
[22.   22.    0.75]
[-0.10896515  1.28412218  0.59414663]
[22.   22.    0.75]
[-0.13604612  1.35023053  0.61159545]
[22.   22.    0.75]
[-0.1841313   1.41211787  0.64036588]
[22.   22.    0.75]
[-0.24356877  1.48915301  0.67497613]
[22.   22.    0.75]
[-0.31232544  1.57279376  0.7074041 ]
[22.   22.    0.75]
[-0.3815599   1.63548645  0.71198231]
[22.   22.    0.75]
[-0.43986503  1.6998315   0.70336528]
[22.   22.    0.75]
[-0.50031617  1.7684326   0.67199157]
[22.   22.    0.75]
[-0.55374247  1.84109158  0.62255799]
[22.   22.    0.75]
[-0.60812002  1.88172489  0.58274596]
[22.   22.    0.75]
[-0.63594544  1.90778041  0.58916238]
[22.   22.    0.75]
[-0.63529413  1.94445585  0.6159419 ]
[22.   22.    0.75]
[-0.63101891  1.98194963  0.62401448]
[22.   22.    0.75]
[-0.60829073  2.00245692  0.63098588]
[22.   22.    0.75]
[-0.58514252  2.01734245  0.61083542]
[22.   22.    0.75]
[-0.54227039  2.03346036  0.58170709]
[22.   22.    0.75]
[-0.5127986   2.05700081  0.5329859 ]
[22.   22.    0.75]
[-0.49467895  2.09629921  0.50049014]
[22.   22.    0.75]
[-0.49229959  2.16089051  0.55364288]
[22.   22.    0.75]
[-0.49760042  2.22211117  0.59236857]
[22.   22.    0.75]
[-0.50069616  2.28813388  0.61547848]
[22.   22.    0.75]
[-0.50418776  2.3403756   0.64707882]
[22.   22.    0.75]
[-0.50625258  2.37230797  0.67558649]
[22.   22.    0.75]
[-0.49474648  2.40501514  0.67538349]
[22.   22.    0.75]
[-0.49082391  2.44248733  0.65250174]
[22.   22.    0.75]
[-0.48487537  2.48540179  0.61420366]
[22.   22.    0.75]
[-0.49200718  2.49271731  0.58141714]
[22.   22.    0.75]
[-0.50241773  2.4576298   0.58819888]
[22.   22.    0.75]
[-0.50905609  2.40002403  0.60976588]
[22.   22.    0.75]
[-0.52159998  2.34975969  0.61384461]
[22.   22.    0.75]
[-0.53796304  2.31286343  0.62329515]
[22.   22.    0.75]
[-0.54101874  2.28157143  0.61044871]
[22.   22.    0.75]
[-0.54047298  2.24887128  0.57032879]
[22.   22.    0.75]
[-0.5387393   2.22657731  0.55036519]
[22.   22.    0.75]
[-0.52628731  2.22480837  0.60683532]
[22.   22.    0.75]
[-0.51754113  2.22564025  0.63686557]
[22.   22.    0.75]
[-0.50871311  2.23602281  0.64182609]
[22.   22.    0.75]
[-0.48879389  2.22209071  0.61748693]
[22.   22.    0.75]
[-0.43594479  2.19771859  0.59158102]
[22.   22.    0.75]
[-0.37919972  2.16657815  0.54298968]
[22.   22.    0.75]
[-0.34164748  2.13877453  0.4981982 ]
[22.   22.    0.75]
[-0.31822375  2.13769635  0.53841708]
[22.   22.    0.75]
[-0.31364402  2.17627979  0.64757652]
[22.   22.    0.75]
[-0.3211384   2.21909226  0.7219713 ]
[22.   22.    0.75]
[-0.33456787  2.25807323  0.76663897]
[22.   22.    0.75]
[-0.33496576  2.28622465  0.78786062]
[22.   22.    0.75]
[-0.3163141   2.31461023  0.79574052]
[22.   22.    0.75]
[-0.27043626  2.33702589  0.82311039]
[22.   22.    0.75]
[-0.18597563  2.36038993  0.88148465]
[22.   22.    0.75]
[-0.10646262  2.38281214  0.91964459]
[22.   22.    0.75]
[-0.03656898  2.39933348  0.93584937]
[22.   22.    0.75]
[0.03269708 2.39244516 0.93113653]
[22.   22.    0.75]
[0.10600253 2.37737638 0.89724908]
[22.   22.    0.75]
[0.1781169  2.38104221 0.82861889]
[22.   22.    0.75]
[0.26156554 2.39039391 0.74418973]
[22.   22.    0.75]
[0.34017785 2.38341964 0.66290891]
[22.   22.    0.75]
[0.42614938 2.35390884 0.65115958]
[22.   22.    0.75]
[0.53779902 2.3303327  0.68714302]
[22.   22.    0.75]
[0.67571004 2.30732058 0.71636507]
[22.   22.    0.75]
[0.83464056 2.26669966 0.73774815]
[22.   22.    0.75]
[0.98371791 2.19641248 0.7331587 ]
[22.   22.    0.75]
[1.12858492 2.15801054 0.69100405]
[22.   22.    0.75]
[1.25679937 2.13051255 0.63109845]
[22.   22.    0.75]
[1.34339856 2.09410478 0.59042792]
[22.   22.    0.75]
[1.43481461 2.0556621  0.54338276]
[22.   22.    0.75]
[1.53907963 2.03680872 0.66357595]
[22.   22.    0.75]
[1.65012934 2.00764549 0.75331847]
[22.   22.    0.75]
[1.75991459 1.97667018 0.81629779]
[22.   22.    0.75]
[1.86566259 1.95527822 0.85937462]
[22.   22.    0.75]
[1.97546951 1.95510905 0.88689826]
[22.   22.    0.75]
[2.05469788 1.96187037 0.92411547]
[22.   22.    0.75]
[2.13093912 1.94216873 0.94113166]
[22.   22.    0.75]
[2.20379827 1.90712516 0.92347336]
[22.   22.    0.75]
[2.26087296 1.87177175 0.89506604]
[22.   22.    0.75]
[2.32412227 1.8203703  0.92187082]
[22.   22.    0.75]
[2.3737018  1.73731363 1.00381969]
[22.   22.    0.75]
[-0.03678205  0.08658504  0.7133998 ]
[114.   114.     0.75]
[-0.04218284  0.0994732   0.70639681]
[114.   114.     0.75]
[-0.04663447  0.09319999  0.67751745]
[114.   114.     0.75]
[-0.06775301  0.10583113  0.65974499]
[114.   114.     0.75]
[-0.10359562  0.16717023  0.66721818]
[114.   114.     0.75]
[-0.12514877  0.24427068  0.67532891]
[114.   114.     0.75]
[-0.13784738  0.3450539   0.68449173]
[114.   114.     0.75]
[-0.14648931  0.46448391  0.68391137]
[114.   114.     0.75]
[-0.15882821  0.58511511  0.65983634]
[114.   114.     0.75]
[-0.16897058  0.6789687   0.60474688]
[114.   114.     0.75]
[-0.17410932  0.75206426  0.54487633]
[114.   114.     0.75]
[-0.19412361  0.75162758  0.58489438]
[114.   114.     0.75]
[-0.22205239  0.73911693  0.60746822]
[114.   114.     0.75]
[-0.25445902  0.7205777   0.61464191]
[114.   114.     0.75]
[-0.27967862  0.71089775  0.61199565]
[114.   114.     0.75]
[-0.28828389  0.70568709  0.61002985]
[114.   114.     0.75]
[-0.29186165  0.7049685   0.59051795]
[114.   114.     0.75]
[-0.31764093  0.70643519  0.61422608]
[114.   114.     0.75]
[-0.3480879   0.69941813  0.63607717]
[114.   114.     0.75]
[-0.39195141  0.6917276   0.6356958 ]
[114.   114.     0.75]
[-0.43554908  0.68507667  0.62268627]
[114.   114.     0.75]
[-0.4797511   0.67003862  0.61532976]
[114.   114.     0.75]
[-0.52210535  0.6516555   0.59589206]
[114.   114.     0.75]
[-0.56225813  0.63405596  0.55951676]
[114.   114.     0.75]
[-0.578409    0.62691545  0.5268719 ]
[114.   114.     0.75]
[-0.55184804  0.62689855  0.52135072]
[114.   114.     0.75]
[-0.4717557   0.61906837  0.59646216]
[114.   114.     0.75]
[-0.4000589   0.61999698  0.65302534]
[114.   114.     0.75]
[-0.35019752  0.60273518  0.68602104]
[114.   114.     0.75]
[-0.31027889  0.59042735  0.70241644]
[114.   114.     0.75]
[-0.27169397  0.57484141  0.69610812]
[114.   114.     0.75]
[-0.22777123  0.54728131  0.66504033]
[114.   114.     0.75]
[-0.18948497  0.51941636  0.62930928]
[114.   114.     0.75]
[-0.15617006  0.50036918  0.59701584]
[114.   114.     0.75]
[-0.13345772  0.49698139  0.5573258 ]
[114.   114.     0.75]
[-0.10009495  0.49985094  0.60631819]
[114.   114.     0.75]
[-0.06453959  0.50438846  0.62897065]
[114.   114.     0.75]
[-0.05207356  0.492742    0.64644364]
[114.   114.     0.75]
[-0.06198194  0.4928813   0.66080148]
[114.   114.     0.75]
[-0.07300704  0.50910587  0.65413223]
[114.   114.     0.75]
[-0.09192142  0.49998974  0.63413486]
[114.   114.     0.75]
[-0.10522461  0.48324936  0.60661187]
[114.   114.     0.75]
[-0.11426723  0.47413449  0.55687358]
[114.   114.     0.75]
[-0.08083352  0.42712503  0.57460411]
[114.   114.     0.75]
[-0.02914203  0.34470101  0.61124372]
[114.   114.     0.75]
[-0.00760815  0.26144274  0.62930173]
[114.   114.     0.75]
[0.01052324 0.18136286 0.62369766]
[114.   114.     0.75]
[0.03013108 0.11244124 0.59279275]
[114.   114.     0.75]
[0.05913749 0.06924132 0.56768504]
[114.   114.     0.75]
[0.06411389 0.03498537 0.58555265]
[114.   114.     0.75]
[0.05115618 0.01327812 0.63946283]
[114.   114.     0.75]
[ 3.54466027e-02 -3.84293035e-04  6.72962143e-01]
[114.   114.     0.75]
[ 0.01857083 -0.00600265  0.69200108]
[114.   114.     0.75]
[ 0.0069231  -0.01481279  0.69471619]
[114.   114.     0.75]
[-6.97718082e-03 -2.34304839e-04  7.11672125e-01]
[114.   114.     0.75]
[0.00529473 0.0466445  0.76497854]
[114.   114.     0.75]
[0.02418472 0.08145348 0.7941044 ]
[114.   114.     0.75]
[0.01851903 0.10114822 0.83092907]
[114.   114.     0.75]
[0.00833888 0.12271657 0.8476039 ]
[114.   114.     0.75]
[-0.00243264  0.14581009  0.84280288]
[114.   114.     0.75]
[-0.00232645  0.16898182  0.80528653]
[114.   114.     0.75]
[-0.00547942  0.19706815  0.76821847]
[114.   114.     0.75]
[-0.00944318  0.23953482  0.71587479]
[114.   114.     0.75]
[-0.03310169  0.29235304  0.67628098]
[114.   114.     0.75]
[-0.07323022  0.32845854  0.61711133]
[114.   114.     0.75]
[-0.10546678  0.36670297  0.53770157]
[114.   114.     0.75]
[-0.07961732  0.42499687  0.48397163]
[114.   114.     0.75]
[-0.04130827  0.48175193  0.45257544]
[114.   114.     0.75]
[-0.01071102  0.48433108  0.49942018]
[114.   114.     0.75]
[-0.00218626  0.48223509  0.54042913]
[114.   114.     0.75]
[0.01660498 0.4814324  0.56949955]
[114.   114.     0.75]
[0.040339   0.47614154 0.58581112]
[114.   114.     0.75]
[0.080901   0.46907812 0.64850856]
[114.   114.     0.75]
[0.12197821 0.46698981 0.71492704]
[114.   114.     0.75]
[0.16299587 0.46500133 0.75772197]
[114.   114.     0.75]
[0.20733068 0.47894506 0.77509056]
[114.   114.     0.75]
[0.26525923 0.48840374 0.77544804]
[114.   114.     0.75]
[0.31040272 0.48419687 0.75114712]
[114.   114.     0.75]
[0.34749151 0.48621927 0.69463347]
[114.   114.     0.75]
[0.39738862 0.47072635 0.64583999]
[114.   114.     0.75]
[0.45351263 0.43440513 0.65046555]
[114.   114.     0.75]
[0.51997872 0.36343825 0.76287002]
[114.   114.     0.75]
[0.5709313  0.282476   0.85569425]
[114.   114.     0.75]
[0.63170198 0.20644992 0.9190012 ]
[114.   114.     0.75]
[0.702603   0.14356856 0.94746287]
[114.   114.     0.75]
[0.77635848 0.07482301 0.93804714]
[114.   114.     0.75]
[ 0.84719681 -0.00902837  0.90370148]
[114.   114.     0.75]
[ 0.88982421 -0.08609043  0.93379053]
[114.   114.     0.75]
[ 0.92783096 -0.14768894  0.97605708]
[114.   114.     0.75]
[ 0.95461119 -0.19920172  0.98241489]
[114.   114.     0.75]
[ 0.98478835 -0.25552998  0.96027724]
[114.   114.     0.75]
[ 1.0006103  -0.31421471  0.92857974]
[114.   114.     0.75]
[ 0.98308437 -0.36214962  0.92344424]
[114.   114.     0.75]
[ 0.99956425 -0.41512585  0.93365627]
[114.   114.     0.75]
[ 1.02078796 -0.47886724  0.9624305 ]
[114.   114.     0.75]
[ 1.04747907 -0.54625133  0.96475393]
[114.   114.     0.75]
[ 1.07188779 -0.60317738  0.93621919]
[114.   114.     0.75]
[ 1.06701879 -0.66042644  0.88913586]
[114.   114.     0.75]
[ 1.0718222  -0.72164604  0.8205341 ]
[114.   114.     0.75]
[ 1.08135655 -0.78315462  0.72831034]
[114.   114.     0.75]
[ 1.05335612 -0.85711423  0.67040515]
[114.   114.     0.75]
[ 1.05441113 -0.94206732  0.6904388 ]
[114.   114.     0.75]
[ 1.05434859 -1.03091613  0.69103004]
[114.   114.     0.75]
[ 1.05981175 -1.11824957  0.66259247]
[114.   114.     0.75]
[ 1.06515092 -1.20478976  0.60669164]
[114.   114.     0.75]
[ 1.06674342 -1.29467179  0.53216759]
[114.   114.     0.75]
[ 1.04979178 -1.36946656  0.5107254 ]
[114.   114.     0.75]
[ 1.02958661 -1.45686981  0.53146567]
[114.   114.     0.75]
[ 1.01494488 -1.52878938  0.53978129]
[114.   114.     0.75]
[ 0.98677746 -1.58621462  0.64295066]
[114.   114.     0.75]
[ 0.95112436 -1.65262225  0.72725008]
[114.   114.     0.75]
[ 0.92164894 -1.7168311   0.7879762 ]
[114.   114.     0.75]
[ 0.90417489 -1.76636497  0.82055464]
[114.   114.     0.75]
[ 0.89177837 -1.82229412  0.83129202]
[114.   114.     0.75]
[ 0.88391227 -1.88985021  0.82399608]
[114.   114.     0.75]
[ 0.87662355 -1.95994753  0.7922283 ]
[114.   114.     0.75]
[ 0.85385696 -2.00745932  0.72416028]
[114.   114.     0.75]
[ 0.83595275 -2.03294758  0.63218115]
[114.   114.     0.75]
[ 0.81787412 -2.07753963  0.54380293]
[114.   114.     0.75]
[ 0.76754196 -2.10611546  0.49649656]
[114.   114.     0.75]
[ 0.71393456 -2.09939734  0.59858033]
[114.   114.     0.75]
[ 0.66432455 -2.10133705  0.70655371]
[114.   114.     0.75]
[ 0.61103784 -2.10227997  0.78494252]
[114.   114.     0.75]
[ 0.55781273 -2.1075679   0.82979184]
[114.   114.     0.75]
[ 0.50677949 -2.11946213  0.85996745]
[114.   114.     0.75]
[ 0.4697726  -2.13639438  0.88095739]
[114.   114.     0.75]
[ 0.43497948 -2.15577433  0.89140728]
[114.   114.     0.75]
[ 0.39232026 -2.18494309  0.8996219 ]
[114.   114.     0.75]
[ 0.39040009 -2.21280843  0.92760513]
[114.   114.     0.75]
[ 0.43170329 -2.24690565  0.97904416]
[114.   114.     0.75]
[ 0.48482207 -2.27516138  1.01120768]
[114.   114.     0.75]
[ 0.01820784 -0.04277783  0.85774207]
[386.   386.     0.75]
[ 0.01034082 -0.02885245  0.85565051]
[386.   386.     0.75]
[ 0.0098244  -0.02587682  0.80816446]
[386.   386.     0.75]
[ 0.01738382 -0.01744267  0.7414374 ]
[386.   386.     0.75]
[0.06419225 0.02180762 0.70696545]
[386.   386.     0.75]
[0.11464261 0.06047715 0.64693932]
[386.   386.     0.75]
[0.1626146  0.11314339 0.58027955]
[386.   386.     0.75]
[0.20284109 0.13487066 0.55744097]
[386.   386.     0.75]
[0.22420452 0.1598644  0.53181576]
[386.   386.     0.75]
[0.20283521 0.20093374 0.65078039]
[386.   386.     0.75]
[0.18801718 0.22188692 0.81696994]
[386.   386.     0.75]
[0.17961569 0.23603629 0.94840175]
[386.   386.     0.75]
[0.16563343 0.24872445 1.05152453]
[386.   386.     0.75]
----------------------------------
| forward_vel        | 0.964     |
| reward             | -2.49e+05 |
| reward_contact     | -0.0005   |
| reward_ctrl        | -1.3      |
| reward_position    | -2.49e+05 |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 64.6      |
|    ep_rew_mean     | -1.23e+07 |
| time/              |           |
|    episodes        | 8         |
|    fps             | 55        |
|    time_elapsed    | 9         |
|    total timesteps | 517       |
----------------------------------
[-0.01708228 -0.01656235  0.81485172]
[166.   166.     0.75]
[-0.01262558 -0.01275014  0.80546981]
[166.   166.     0.75]
[-0.01917958 -0.02615859  0.76133142]
[166.   166.     0.75]
[-0.05716901 -0.08301768  0.74655471]
[166.   166.     0.75]
[-0.10117674 -0.14436872  0.70786362]
[166.   166.     0.75]
[-0.14118313 -0.21681789  0.63962358]
[166.   166.     0.75]
[-0.18165313 -0.28479374  0.55167614]
[166.   166.     0.75]
[-0.23202675 -0.33683448  0.45354902]
[166.   166.     0.75]
[-0.26028722 -0.34259672  0.40757093]
[166.   166.     0.75]
[-0.27928613 -0.33493502  0.46341638]
[166.   166.     0.75]
[-0.30798427 -0.31749736  0.52062606]
[166.   166.     0.75]
[-0.31653936 -0.30678229  0.55760606]
[166.   166.     0.75]
[-0.31349081 -0.30886367  0.59183048]
[166.   166.     0.75]
[-0.31793099 -0.30911514  0.60130594]
[166.   166.     0.75]
[-0.31183708 -0.30262029  0.59990283]
[166.   166.     0.75]
[-0.28427375 -0.30135435  0.60658722]
[166.   166.     0.75]
[-0.25376848 -0.32977117  0.62635722]
[166.   166.     0.75]
[-0.20567253 -0.38110437  0.64176669]
[166.   166.     0.75]
[-0.16619509 -0.43211176  0.64309958]
[166.   166.     0.75]
[-0.13966748 -0.45962629  0.62907219]
[166.   166.     0.75]
[-0.1272327  -0.45077402  0.62832751]
[166.   166.     0.75]
[-0.11234109 -0.44056533  0.60853831]
[166.   166.     0.75]
[-0.08900641 -0.43991523  0.56418093]
[166.   166.     0.75]
[-0.05417129 -0.43888762  0.55898343]
[166.   166.     0.75]
[-0.03419206 -0.43522788  0.57820894]
[166.   166.     0.75]
[-0.02697714 -0.42498972  0.58268518]
[166.   166.     0.75]
[-0.06766089 -0.40873309  0.64006326]
[166.   166.     0.75]
[-0.11444739 -0.38968098  0.7032257 ]
[166.   166.     0.75]
[-0.16425574 -0.38595029  0.73449801]
[166.   166.     0.75]
[-0.20287093 -0.40299207  0.7346512 ]
[166.   166.     0.75]
[-0.24950773 -0.41939012  0.72211015]
[166.   166.     0.75]
[-0.30559166 -0.44387548  0.72278325]
[166.   166.     0.75]
[-0.34967449 -0.49356071  0.7208173 ]
[166.   166.     0.75]
[-0.39210458 -0.54809193  0.69870906]
[166.   166.     0.75]
[-0.43616846 -0.60362504  0.6610552 ]
[166.   166.     0.75]
[-0.48921901 -0.64574143  0.60802843]
[166.   166.     0.75]
[-0.50198209 -0.7016698   0.588158  ]
[166.   166.     0.75]
[-0.50300939 -0.76986245  0.56876924]
[166.   166.     0.75]
[-0.51016831 -0.82792118  0.53967721]
[166.   166.     0.75]
[-0.53240318 -0.84366327  0.53929694]
[166.   166.     0.75]
[-0.60451776 -0.80378339  0.60851945]
[166.   166.     0.75]
[-0.69343533 -0.76194772  0.66858884]
[166.   166.     0.75]
[-0.75033989 -0.71854064  0.72455469]
[166.   166.     0.75]
[-0.79035409 -0.6755471   0.78424899]
[166.   166.     0.75]
[-0.83803428 -0.63478922  0.81525785]
[166.   166.     0.75]
[-0.874204   -0.60126669  0.81951641]
[166.   166.     0.75]
[-0.88539708 -0.57517739  0.82586228]
[166.   166.     0.75]
[-0.88238824 -0.5437523   0.82346025]
[166.   166.     0.75]
[-0.88112559 -0.50733853  0.80817906]
[166.   166.     0.75]
[-0.90165578 -0.48972954  0.75791937]
[166.   166.     0.75]
[-0.93501743 -0.4673648   0.6825546 ]
[166.   166.     0.75]
[-0.96005559 -0.43494648  0.62835431]
[166.   166.     0.75]
[-0.98179646 -0.39078225  0.6296919 ]
[166.   166.     0.75]
[-1.01958423 -0.33673221  0.67326046]
[166.   166.     0.75]
[-1.04005716 -0.28695123  0.69052343]
[166.   166.     0.75]
[-1.06336614 -0.24216722  0.68655474]
[166.   166.     0.75]
[-1.09088366 -0.18395553  0.67222472]
[166.   166.     0.75]
[-1.11142345 -0.12799817  0.6360238 ]
[166.   166.     0.75]
[-1.13153271 -0.07322985  0.59239778]
[166.   166.     0.75]
[-1.13556148 -0.02807741  0.55549238]
[166.   166.     0.75]
[-1.1746057  -0.00899576  0.54032609]
[166.   166.     0.75]
[-1.21344628  0.00676422  0.56766196]
[166.   166.     0.75]
[-1.25500929  0.02662934  0.61883848]
[166.   166.     0.75]
[-1.29893604  0.04518861  0.64487912]
[166.   166.     0.75]
[-1.34584373  0.07469066  0.646378  ]
[166.   166.     0.75]
[-1.36260543  0.09744535  0.66280406]
[166.   166.     0.75]
[-1.35630069  0.10005791  0.65171564]
[166.   166.     0.75]
[-1.3431479   0.10230788  0.61859819]
[166.   166.     0.75]
[-1.31146171  0.09451622  0.57864053]
[166.   166.     0.75]
[-1.30516457  0.07073113  0.57308978]
[166.   166.     0.75]
[-1.31739187  0.05973644  0.55705349]
[166.   166.     0.75]
[-1.32181136  0.06302515  0.54642011]
[166.   166.     0.75]
[-1.31090093  0.07616649  0.54926412]
[166.   166.     0.75]
[-1.30291777  0.08955182  0.53363437]
[166.   166.     0.75]
[-1.31006099  0.10182752  0.51061128]
[166.   166.     0.75]
[-1.33463448  0.14418155  0.5158464 ]
[166.   166.     0.75]
[-1.38797139  0.18818575  0.58747162]
[166.   166.     0.75]
[-1.44394372  0.22533165  0.70502659]
[166.   166.     0.75]
[-1.49038863  0.2726001   0.79768925]
[166.   166.     0.75]
[-1.5299979   0.31736504  0.86249796]
[166.   166.     0.75]
[-1.57313849  0.35605284  0.89798854]
[166.   166.     0.75]
[-1.62554445  0.39873392  0.91756398]
[166.   166.     0.75]
[-1.66914766  0.44016911  0.91184466]
[166.   166.     0.75]
[-1.70900906  0.47799258  0.87982816]
[166.   166.     0.75]
[-1.74623873  0.51073019  0.82200968]
[166.   166.     0.75]
[-1.73713902  0.5465679   0.79932925]
[166.   166.     0.75]
[-1.73171837  0.5581234   0.80564942]
[166.   166.     0.75]
[-1.72870513  0.5397691   0.85441775]
[166.   166.     0.75]
[-1.72451055  0.52475282  0.8964881 ]
[166.   166.     0.75]
[-1.7293137   0.5226076   0.90652006]
[166.   166.     0.75]
[-1.72523632  0.52959426  0.87764825]
[166.   166.     0.75]
[-1.71967875  0.52315464  0.82746065]
[166.   166.     0.75]
[-1.72723819  0.50825978  0.75612133]
[166.   166.     0.75]
[-1.74531017  0.5033403   0.71882883]
[166.   166.     0.75]
[-1.79011015  0.50837572  0.73546167]
[166.   166.     0.75]
[-1.82285008  0.49853526  0.75485513]
[166.   166.     0.75]
[-1.88141315  0.47767293  0.80847606]
[166.   166.     0.75]
[-1.93676586  0.46638842  0.83607203]
[166.   166.     0.75]
[-1.9917545   0.45150589  0.84260003]
[166.   166.     0.75]
[-2.05392012  0.43856973  0.84137706]
[166.   166.     0.75]
[-2.11468202  0.43758989  0.82594463]
[166.   166.     0.75]
[-2.17305417  0.44036439  0.76247393]
[166.   166.     0.75]
[-2.23763634  0.43400462  0.65525534]
[166.   166.     0.75]
[-2.29808849  0.41989546  0.52020699]
[166.   166.     0.75]
[-2.34501353  0.41607743  0.3996438 ]
[166.   166.     0.75]
[-2.3523166   0.4627247   0.37577939]
[166.   166.     0.75]
[-2.34243022  0.51208072  0.33782606]
[166.   166.     0.75]
[-2.32669955  0.57377752  0.28965343]
[166.   166.     0.75]
[-2.31158509  0.65171864  0.25224914]
[166.   166.     0.75]
[-2.31294037  0.70294345  0.25721452]
[166.   166.     0.75]
[-2.31468917  0.76428142  0.26078018]
[166.   166.     0.75]
[-2.3153062   0.81364915  0.27833189]
[166.   166.     0.75]
[-2.32864018  0.8452649   0.32031079]
[166.   166.     0.75]
[-2.34435898  0.88130494  0.34734852]
[166.   166.     0.75]
[-2.36567375  0.92635862  0.36382072]
[166.   166.     0.75]
[-2.37342269  0.97987513  0.40516594]
[166.   166.     0.75]
[-2.40167382  1.01653802  0.45755787]
[166.   166.     0.75]
[-2.42584344  1.03888929  0.51722526]
[166.   166.     0.75]
[-2.42375672  1.06143586  0.5669013 ]
[166.   166.     0.75]
[-2.42228438  1.08218851  0.59679575]
[166.   166.     0.75]
[-2.43361445  1.10796707  0.59475155]
[166.   166.     0.75]
[-2.43386186  1.13442749  0.57253742]
[166.   166.     0.75]
[-2.4211022   1.12423616  0.56398822]
[166.   166.     0.75]
[-2.39488843  1.10933694  0.52984499]
[166.   166.     0.75]
[-2.36385912  1.09872556  0.46712281]
[166.   166.     0.75]
[-2.34431548  1.08893734  0.39545684]
[166.   166.     0.75]
[-2.35244861  1.0680472   0.33337632]
[166.   166.     0.75]
[-2.40484011  1.01945345  0.33216036]
[166.   166.     0.75]
[-2.46725031  0.96351729  0.32298869]
[166.   166.     0.75]
[-2.51843772  0.90373969  0.29114637]
[166.   166.     0.75]
[-2.54844731  0.84815614  0.24765739]
[166.   166.     0.75]
[-2.53951479  0.79021253  0.25676502]
[166.   166.     0.75]
[-2.53083414  0.73725585  0.26027758]
[166.   166.     0.75]
[-2.53792772  0.69200917  0.26522878]
[166.   166.     0.75]
[-2.54043967  0.6646436   0.29933311]
[166.   166.     0.75]
[-2.54007911  0.64582172  0.31546188]
[166.   166.     0.75]
[-2.54529418  0.63021923  0.31493429]
[166.   166.     0.75]
[-2.54790844  0.62350346  0.30800154]
[166.   166.     0.75]
[-2.55002738  0.62743565  0.29670571]
[166.   166.     0.75]
[-2.5601831   0.63206261  0.29402688]
[166.   166.     0.75]
[-2.5703967   0.63915357  0.28208039]
[166.   166.     0.75]
[-2.5802258   0.64401802  0.25824266]
[166.   166.     0.75]
[-2.59499571  0.65628455  0.25776621]
[166.   166.     0.75]
[-2.60044467  0.67099009  0.25947556]
[166.   166.     0.75]
[-2.60152694  0.68933983  0.25962971]
[166.   166.     0.75]
[-2.60723946  0.71091139  0.2596301 ]
[166.   166.     0.75]
[-2.61502881  0.73700363  0.25961619]
[166.   166.     0.75]
[-2.62453137  0.7619893   0.25991769]
[166.   166.     0.75]
[-2.6433622   0.77178453  0.25982933]
[166.   166.     0.75]
[-2.64855463  0.77122461  0.25981703]
[166.   166.     0.75]
[-2.64507645  0.78880461  0.25962923]
[166.   166.     0.75]
[-2.64854106  0.80525214  0.27445747]
[166.   166.     0.75]
[-2.64882564  0.81954981  0.27410811]
[166.   166.     0.75]
[-2.64870218  0.81615545  0.27876708]
[166.   166.     0.75]
[-2.66622876  0.79653462  0.29124917]
[166.   166.     0.75]
[-2.68312889  0.75873156  0.29237759]
[166.   166.     0.75]
[-2.70082404  0.7145176   0.27238775]
[166.   166.     0.75]
[-2.71200094  0.69364077  0.25344431]
[166.   166.     0.75]
[-2.70690249  0.68402678  0.25854439]
[166.   166.     0.75]
[-2.69394645  0.67236284  0.25994476]
[166.   166.     0.75]
[-2.6691204   0.67219722  0.25942951]
[166.   166.     0.75]
[-2.67059282  0.67081892  0.26025836]
[166.   166.     0.75]
[-2.68172694  0.6584593   0.25966136]
[166.   166.     0.75]
[-2.69356449  0.63680835  0.25951516]
[166.   166.     0.75]
[-2.70799618  0.61448496  0.25970785]
[166.   166.     0.75]
[-2.71899815  0.58755057  0.2596621 ]
[166.   166.     0.75]
[-2.71709424  0.58285107  0.25921393]
[166.   166.     0.75]
[-2.70582365  0.58010067  0.25954937]
[166.   166.     0.75]
[-2.68168303  0.57206388  0.25966451]
[166.   166.     0.75]
[-2.65657322  0.55156417  0.25966099]
[166.   166.     0.75]
[-2.64251648  0.52891733  0.25960707]
[166.   166.     0.75]
[-2.64296722  0.517227    0.2596038 ]
[166.   166.     0.75]
[-2.63498878  0.50735396  0.26020306]
[166.   166.     0.75]
[-2.621909    0.49965735  0.25941838]
[166.   166.     0.75]
[-2.61629845  0.49397429  0.26697256]
[166.   166.     0.75]
[-2.63099963  0.50152779  0.30550661]
[166.   166.     0.75]
[-2.6589067   0.50988548  0.35763001]
[166.   166.     0.75]
[-2.67979388  0.51966193  0.37800614]
[166.   166.     0.75]
[-2.71108383  0.52907957  0.37182615]
[166.   166.     0.75]
[-2.74721881  0.54278517  0.33694115]
[166.   166.     0.75]
[-2.76200882  0.57212252  0.30481845]
[166.   166.     0.75]
[-2.77203568  0.61454489  0.28635838]
[166.   166.     0.75]
[-2.78928257  0.65916556  0.25518552]
[166.   166.     0.75]
[-2.8038083   0.70130467  0.25789782]
[166.   166.     0.75]
[-2.81482226  0.73415659  0.25947104]
[166.   166.     0.75]
[-2.82373363  0.75737565  0.2596149 ]
[166.   166.     0.75]
[-2.82349427  0.77375869  0.25993412]
[166.   166.     0.75]
[-2.81172295  0.79429426  0.27476688]
[166.   166.     0.75]
[-2.82241129  0.8018027   0.28969361]
[166.   166.     0.75]
[-2.85368511  0.81712164  0.28914328]
[166.   166.     0.75]
[-2.89025897  0.84284598  0.26189974]
[166.   166.     0.75]
[-2.91159993  0.85097193  0.25950329]
[166.   166.     0.75]
[-2.92358318  0.84238248  0.26632391]
[166.   166.     0.75]
[-2.9253016   0.83410879  0.26163777]
[166.   166.     0.75]
[-2.92956175  0.81204524  0.26492516]
[166.   166.     0.75]
[-2.93757934  0.77757577  0.25882843]
[166.   166.     0.75]
[-2.94321703  0.75482884  0.25867737]
[166.   166.     0.75]
[-2.94647831  0.73489121  0.25996325]
[166.   166.     0.75]
[-2.93878734  0.71254189  0.25964455]
[166.   166.     0.75]
[-2.92920941  0.69215433  0.25997694]
[166.   166.     0.75]
[-2.92585177  0.67673115  0.25952146]
[166.   166.     0.75]
[-2.91079805  0.66341776  0.26015375]
[166.   166.     0.75]
[-2.88870305  0.65090646  0.25928293]
[166.   166.     0.75]
[-2.87366324  0.63816181  0.25969596]
[166.   166.     0.75]
[-2.86272682  0.62909743  0.26687244]
[166.   166.     0.75]
[-2.84495852  0.62757851  0.26341984]
[166.   166.     0.75]
[-2.81769712  0.63271839  0.25856507]
[166.   166.     0.75]
[-2.79672095  0.64872794  0.25964909]
[166.   166.     0.75]
[-2.78708538  0.65847443  0.25970131]
[166.   166.     0.75]
[-2.7759178   0.66031491  0.26190986]
[166.   166.     0.75]
[-2.76835828  0.64155236  0.25990641]
[166.   166.     0.75]
[-2.74747143  0.64806318  0.26272059]
[166.   166.     0.75]
[-2.73793731  0.65801317  0.25814915]
[166.   166.     0.75]
[-2.73905006  0.66634132  0.25950322]
[166.   166.     0.75]
[-2.74086614  0.67336274  0.25991081]
[166.   166.     0.75]
[-2.73047504  0.68597472  0.25972102]
[166.   166.     0.75]
[-2.71236814  0.69783704  0.26211433]
[166.   166.     0.75]
[-2.71680836  0.70217694  0.28683871]
[166.   166.     0.75]
[-2.72558189  0.69648185  0.30938082]
[166.   166.     0.75]
[-2.72820748  0.69633583  0.30074426]
[166.   166.     0.75]
[-2.72125364  0.70158293  0.25645059]
[166.   166.     0.75]
[-2.7295146   0.70640636  0.25582157]
[166.   166.     0.75]
[-2.75745391  0.69719334  0.25912796]
[166.   166.     0.75]
[-2.77108077  0.68274261  0.25951588]
[166.   166.     0.75]
[-2.77980672  0.66201739  0.25982836]
[166.   166.     0.75]
[-2.78645356  0.6618578   0.25999964]
[166.   166.     0.75]
[-2.80300484  0.66502319  0.25920743]
[166.   166.     0.75]
[-2.81943458  0.67579104  0.25962104]
[166.   166.     0.75]
[-2.83483793  0.68447302  0.26010712]
[166.   166.     0.75]
[-2.84006285  0.67927642  0.25984158]
[166.   166.     0.75]
[-2.83789662  0.68436188  0.25967956]
[166.   166.     0.75]
[-2.818716    0.68751017  0.25956971]
[166.   166.     0.75]
[-2.80783013  0.67824539  0.25957062]
[166.   166.     0.75]
[-2.81762551  0.67109944  0.25965496]
[166.   166.     0.75]
[-2.831942    0.65896768  0.25958281]
[166.   166.     0.75]
[-2.83799507  0.64278349  0.26906051]
[166.   166.     0.75]
[-2.81849009  0.64525854  0.29144218]
[166.   166.     0.75]
[-2.78346481  0.65386748  0.29766987]
[166.   166.     0.75]
[-2.74216042  0.66244896  0.27913031]
[166.   166.     0.75]
[-2.70913521  0.6725016   0.25196404]
[166.   166.     0.75]
[-2.69629513  0.67583108  0.25787075]
[166.   166.     0.75]
[-2.67218995  0.67740699  0.26297369]
[166.   166.     0.75]
[-2.63850185  0.68258475  0.25934556]
[166.   166.     0.75]
[-2.62596012  0.68893384  0.2602695 ]
[166.   166.     0.75]
[-2.61580528  0.69936994  0.25950877]
[166.   166.     0.75]
[-2.60664068  0.71058029  0.25957552]
[166.   166.     0.75]
[-2.60927512  0.72697363  0.25964846]
[166.   166.     0.75]
[-2.63233551  0.74690487  0.27783477]
[166.   166.     0.75]
[-2.66073496  0.75244583  0.29716397]
[166.   166.     0.75]
[-2.6757818   0.75866897  0.29003717]
[166.   166.     0.75]
[-2.68839625  0.76493376  0.26044851]
[166.   166.     0.75]
[-2.70283527  0.77090116  0.25744603]
[166.   166.     0.75]
[-2.71288218  0.77036334  0.25941832]
[166.   166.     0.75]
[-2.71753521  0.76509451  0.25961953]
[166.   166.     0.75]
[-2.72235686  0.76346506  0.25962837]
[166.   166.     0.75]
[-2.73377894  0.76190952  0.25975366]
[166.   166.     0.75]
[-2.74468071  0.75827751  0.25963842]
[166.   166.     0.75]
[-2.76458619  0.75098375  0.2596015 ]
[166.   166.     0.75]
[-2.78563341  0.7358873   0.25997955]
[166.   166.     0.75]
[-2.79134141  0.73506373  0.25947899]
[166.   166.     0.75]
[-2.79746199  0.7414734   0.2596094 ]
[166.   166.     0.75]
[-2.80401479  0.75342489  0.25960152]
[166.   166.     0.75]
[-2.81088753  0.76511249  0.25965973]
[166.   166.     0.75]
[-2.81171566  0.77626037  0.25962535]
[166.   166.     0.75]
[-2.81971911  0.76924216  0.25967723]
[166.   166.     0.75]
[-2.82048609  0.76146821  0.25970879]
[166.   166.     0.75]
[-2.81265334  0.75287036  0.25967633]
[166.   166.     0.75]
[-2.80736422  0.74489783  0.25955802]
[166.   166.     0.75]
[-2.80940481  0.72996151  0.25945156]
[166.   166.     0.75]
[-2.81645237  0.71853782  0.25955076]
[166.   166.     0.75]
[-2.82449565  0.71494697  0.26914832]
[166.   166.     0.75]
[-2.79384725  0.7250658   0.29950568]
[166.   166.     0.75]
[-2.75425471  0.73152713  0.30796015]
[166.   166.     0.75]
[-2.72581196  0.72494121  0.29394992]
[166.   166.     0.75]
[-2.7029365   0.70384212  0.25780216]
[166.   166.     0.75]
[-2.68723173  0.70570793  0.25675674]
[166.   166.     0.75]
[-2.66588681  0.72753525  0.25953081]
[166.   166.     0.75]
[-2.64482582  0.74540616  0.25973734]
[166.   166.     0.75]
[-2.62341568  0.76261493  0.25964607]
[166.   166.     0.75]
[-2.62000918  0.78319474  0.27494982]
[166.   166.     0.75]
[-2.60738956  0.78609679  0.2799397 ]
[166.   166.     0.75]
[-2.5831103   0.77742678  0.26973572]
[166.   166.     0.75]
[-2.57952424  0.77188797  0.25729744]
[166.   166.     0.75]
[-2.6015126   0.76181917  0.25909129]
[166.   166.     0.75]
[-2.62254402  0.75034675  0.25964083]
[166.   166.     0.75]
[-2.63393606  0.74217614  0.25961427]
[166.   166.     0.75]
[-2.64033111  0.7330112   0.25955551]
[166.   166.     0.75]
[-2.65007775  0.71955121  0.25953896]
[166.   166.     0.75]
[-2.66492362  0.71352276  0.25979986]
[166.   166.     0.75]
[-2.68040525  0.70512816  0.25988647]
[166.   166.     0.75]
[-2.68995429  0.69319127  0.25985837]
[166.   166.     0.75]
[-2.69146123  0.68391072  0.2596878 ]
[166.   166.     0.75]
[-2.6865488   0.67869099  0.25962698]
[166.   166.     0.75]
[-2.69099789  0.67475362  0.26010216]
[166.   166.     0.75]
[-2.69296418  0.67106452  0.259759  ]
[166.   166.     0.75]
[-2.69957116  0.6717934   0.25959585]
[166.   166.     0.75]
[-2.69561171  0.67517826  0.26889797]
[166.   166.     0.75]
[-2.68496195  0.67059841  0.27612335]
[166.   166.     0.75]
[-2.66359405  0.67202367  0.2743701 ]
[166.   166.     0.75]
[-2.62783184  0.69003123  0.25706403]
[166.   166.     0.75]
[-2.60828037  0.72066051  0.25775732]
[166.   166.     0.75]
[-2.59307016  0.75476349  0.25950181]
[166.   166.     0.75]
[-2.58340285  0.78656509  0.25978333]
[166.   166.     0.75]
[-2.55734436  0.80794607  0.27811141]
[166.   166.     0.75]
[-2.53834045  0.8261067   0.29078541]
[166.   166.     0.75]
[-2.53814889  0.81335426  0.3122183 ]
[166.   166.     0.75]
[-2.53599935  0.79332585  0.31645721]
[166.   166.     0.75]
[-2.51097887  0.77816813  0.30595075]
[166.   166.     0.75]
[-2.49236607  0.76767694  0.2854916 ]
[166.   166.     0.75]
[-2.47135561  0.75159541  0.25930218]
[166.   166.     0.75]
[-2.45990635  0.73761662  0.25813401]
[166.   166.     0.75]
[-2.46159826  0.72358153  0.25954753]
[166.   166.     0.75]
[-2.46280402  0.70132286  0.25962122]
[166.   166.     0.75]
[-2.46191008  0.67975378  0.25960637]
[166.   166.     0.75]
[-2.45792536  0.66090504  0.25996205]
[166.   166.     0.75]
[-2.45601743  0.63872755  0.25961574]
[166.   166.     0.75]
[-2.44843496  0.61404418  0.25953633]
[166.   166.     0.75]
[-2.45521603  0.58987665  0.26778119]
[166.   166.     0.75]
[-2.4595661   0.56926637  0.26401877]
[166.   166.     0.75]
[-2.46817866  0.55866685  0.25841392]
[166.   166.     0.75]
[-2.48366203  0.54799852  0.25948652]
[166.   166.     0.75]
[-2.50786209  0.53662758  0.25957897]
[166.   166.     0.75]
[-2.53810746  0.5400504   0.27655824]
[166.   166.     0.75]
[-2.56075704  0.56408629  0.30802155]
[166.   166.     0.75]
[-2.56625091  0.58606874  0.31836136]
[166.   166.     0.75]
[-2.55713437  0.60883244  0.30935236]
[166.   166.     0.75]
[-2.55105202  0.63025987  0.27343246]
[166.   166.     0.75]
[-2.54277414  0.64259778  0.25423997]
[166.   166.     0.75]
[-2.52857798  0.65036893  0.25937549]
[166.   166.     0.75]
[-2.5194427   0.66427731  0.25966024]
[166.   166.     0.75]
[-2.51468594  0.68182459  0.25965231]
[166.   166.     0.75]
[-2.51061119  0.69842567  0.25962751]
[166.   166.     0.75]
[-2.50605747  0.7135795   0.25961306]
[166.   166.     0.75]
[-2.50257733  0.73448483  0.25972244]
[166.   166.     0.75]
[-2.49560741  0.75655709  0.25968556]
[166.   166.     0.75]
[-2.48980694  0.77562316  0.25965851]
[166.   166.     0.75]
[-2.48254812  0.78498474  0.26322002]
[166.   166.     0.75]
[-2.47451841  0.7774507   0.27175934]
[166.   166.     0.75]
[-2.46435915  0.77925529  0.25682463]
[166.   166.     0.75]
[-2.46343111  0.79173156  0.2585042 ]
[166.   166.     0.75]
[-2.46294869  0.80228274  0.25957389]
[166.   166.     0.75]
[-2.45537508  0.81104395  0.25969508]
[166.   166.     0.75]
[-2.44604395  0.81210658  0.26778498]
[166.   166.     0.75]
[-2.44947421  0.80204056  0.27296959]
[166.   166.     0.75]
[-2.46247607  0.78964382  0.27634144]
[166.   166.     0.75]
[-2.46799185  0.78165426  0.26869052]
[166.   166.     0.75]
[-2.47991643  0.77567133  0.25750414]
[166.   166.     0.75]
[-2.4955133   0.77144669  0.25929461]
[166.   166.     0.75]
[-2.51119664  0.76872422  0.25964638]
[166.   166.     0.75]
[-2.52533222  0.77352277  0.260711  ]
[166.   166.     0.75]
[-2.54118613  0.7763191   0.25889911]
[166.   166.     0.75]
[-2.56023042  0.76825386  0.25963384]
[166.   166.     0.75]
[-2.57842796  0.75283639  0.25963951]
[166.   166.     0.75]
[-2.58256223  0.7286817   0.25958611]
[166.   166.     0.75]
[-2.58182676  0.71252517  0.25987096]
[166.   166.     0.75]
[-2.58879885  0.7175095   0.25954424]
[166.   166.     0.75]
[-2.6008022   0.71940017  0.25974312]
[166.   166.     0.75]
[-2.60623333  0.72051938  0.25966951]
[166.   166.     0.75]
[-2.60782293  0.72262444  0.25954699]
[166.   166.     0.75]
[-2.61713483  0.71573908  0.25966812]
[166.   166.     0.75]
[-2.62005384  0.70201038  0.2594597 ]
[166.   166.     0.75]
[-2.62973355  0.67823312  0.25947982]
[166.   166.     0.75]
[-2.62961088  0.66274844  0.25992214]
[166.   166.     0.75]
[-2.62344159  0.65003521  0.25962687]
[166.   166.     0.75]
[-2.62300661  0.63495453  0.25978432]
[166.   166.     0.75]
[-2.60973839  0.62383045  0.26053132]
[166.   166.     0.75]
[-2.59102915  0.63367118  0.25980086]
[166.   166.     0.75]
[-2.59449169  0.64142288  0.25906012]
[166.   166.     0.75]
[-2.59217918  0.64835505  0.25967025]
[166.   166.     0.75]
[-2.58688143  0.64461406  0.25967834]
[166.   166.     0.75]
[-2.590442    0.63655207  0.26002735]
[166.   166.     0.75]
[-2.59488974  0.63929802  0.25946061]
[166.   166.     0.75]
[-2.60210838  0.64102859  0.25952829]
[166.   166.     0.75]
[-2.62247194  0.64711941  0.26042908]
[166.   166.     0.75]
[-2.62784386  0.67382425  0.27472786]
[166.   166.     0.75]
[-2.62351122  0.69004886  0.2738019 ]
[166.   166.     0.75]
[-2.62785486  0.69114918  0.2571917 ]
[166.   166.     0.75]
[-2.64710503  0.70975119  0.25965369]
[166.   166.     0.75]
[-2.65709928  0.74170105  0.26017997]
[166.   166.     0.75]
[-2.66068532  0.78297089  0.25921687]
[166.   166.     0.75]
[-2.66701829  0.81352326  0.25978749]
[166.   166.     0.75]
[-2.67665063  0.83477711  0.25962866]
[166.   166.     0.75]
[-2.6884313   0.85264379  0.25968323]
[166.   166.     0.75]
[-2.70241426  0.86766467  0.25960516]
[166.   166.     0.75]
[-2.7172576   0.88405555  0.25962598]
[166.   166.     0.75]
[-2.73548892  0.89913066  0.2710584 ]
[166.   166.     0.75]
[-2.73660376  0.90619474  0.28024084]
[166.   166.     0.75]
[-2.73115089  0.90235362  0.27649417]
[166.   166.     0.75]
[-2.71800047  0.89252711  0.25454916]
[166.   166.     0.75]
[-2.69756731  0.88843232  0.25793448]
[166.   166.     0.75]
[-2.68378908  0.90221915  0.25968628]
[166.   166.     0.75]
[-2.67435962  0.91126692  0.2657386 ]
[166.   166.     0.75]
[-2.66069716  0.90247479  0.2599032 ]
[166.   166.     0.75]
[-2.65272874  0.89592009  0.25860389]
[166.   166.     0.75]
[-2.64708108  0.89230949  0.2595462 ]
[166.   166.     0.75]
[-2.64235754  0.89379598  0.25963464]
[166.   166.     0.75]
[-2.63940013  0.89715575  0.25989987]
[166.   166.     0.75]
[-2.64160711  0.88898176  0.25965931]
[166.   166.     0.75]
[-2.6391561   0.86815769  0.25979905]
[166.   166.     0.75]
[-2.62740916  0.85743657  0.25964651]
[166.   166.     0.75]
[-2.61162325  0.84040587  0.2596695 ]
[166.   166.     0.75]
[-2.59649752  0.83562581  0.25963627]
[166.   166.     0.75]
[-2.58680705  0.83944793  0.25958415]
[166.   166.     0.75]
[-2.58492391  0.83756296  0.26031824]
[166.   166.     0.75]
[-2.57779248  0.83196298  0.25951897]
[166.   166.     0.75]
[-2.56294934  0.82579131  0.2596231 ]
[166.   166.     0.75]
[-2.54971096  0.81261388  0.25960046]
[166.   166.     0.75]
[-2.5461571   0.79691249  0.26138121]
[166.   166.     0.75]
[-2.54364264  0.7846774   0.25899527]
[166.   166.     0.75]
[-2.53026697  0.77336455  0.25957175]
[166.   166.     0.75]
[-2.52132822  0.75777908  0.25992053]
[166.   166.     0.75]
[-2.51902251  0.77204076  0.26314296]
[166.   166.     0.75]
[-2.5146098   0.81108152  0.26580449]
[166.   166.     0.75]
[-2.50812493  0.85716772  0.28098444]
[166.   166.     0.75]
[-2.51965665  0.90083899  0.30491088]
[166.   166.     0.75]
[-2.54947569  0.92821607  0.29921203]
[166.   166.     0.75]
[-2.59508237  0.96018841  0.27243177]
[166.   166.     0.75]
[-2.63908908  0.98392823  0.25490494]
[166.   166.     0.75]
[-2.6734456   1.00529577  0.25882745]
[166.   166.     0.75]
[-2.69965355  1.01318429  0.25954354]
[166.   166.     0.75]
[-2.72411568  1.00961028  0.26175582]
[166.   166.     0.75]
[-2.74831521  1.02759635  0.27486682]
[166.   166.     0.75]
[-2.76836589  1.05069267  0.27240008]
[166.   166.     0.75]
[-2.77763347  1.07816444  0.25761969]
[166.   166.     0.75]
[-2.77138395  1.09664169  0.25888171]
[166.   166.     0.75]
[-2.76561068  1.11410475  0.25960326]
[166.   166.     0.75]
[-2.76172487  1.13488934  0.25965945]
[166.   166.     0.75]
[-2.75860168  1.15425897  0.25958739]
[166.   166.     0.75]
[-2.7542263   1.16793117  0.2596422 ]
[166.   166.     0.75]
[-2.74837092  1.18514073  0.25986431]
[166.   166.     0.75]
[-2.74215571  1.20398818  0.25969219]
[166.   166.     0.75]
[-2.73893812  1.22823289  0.26151851]
[166.   166.     0.75]
[-2.73417165  1.25002087  0.26005469]
[166.   166.     0.75]
[-2.73013277  1.25183323  0.26190719]
[166.   166.     0.75]
[-2.73122877  1.22006238  0.2656699 ]
[166.   166.     0.75]
[-2.72754337  1.18241932  0.2605119 ]
[166.   166.     0.75]
[-2.68957689  1.16207791  0.27035451]
[166.   166.     0.75]
[-2.66170711  1.15595526  0.26787472]
[166.   166.     0.75]
[-2.65189583  1.15540349  0.25649435]
[166.   166.     0.75]
[-2.64244522  1.13638138  0.25896799]
[166.   166.     0.75]
[-2.63228588  1.11480477  0.25966613]
[166.   166.     0.75]
[-2.60666587  1.09324205  0.25982636]
[166.   166.     0.75]
[-2.58059525  1.06518982  0.259524  ]
[166.   166.     0.75]
[-2.5663186   1.04597275  0.26506047]
[166.   166.     0.75]
[-2.57435231  1.03958065  0.28223625]
[166.   166.     0.75]
[-2.59038161  1.0284621   0.27570953]
[166.   166.     0.75]
[-2.62592523  1.00422815  0.26269157]
[166.   166.     0.75]
[-2.64045852  0.98366962  0.26497241]
[166.   166.     0.75]
[-2.65585151  0.96653016  0.2583528 ]
[166.   166.     0.75]
[-2.66791643  0.96663843  0.25950922]
[166.   166.     0.75]
[-2.67345549  0.97429931  0.25961266]
[166.   166.     0.75]
[-2.67427135  0.98461677  0.25985936]
[166.   166.     0.75]
[-2.67259794  0.9906849   0.2595987 ]
[166.   166.     0.75]
[-2.67740854  0.98718174  0.25953576]
[166.   166.     0.75]
[-2.6814033   0.98329403  0.25963547]
[166.   166.     0.75]
[-2.69475799  0.98060051  0.25905135]
[166.   166.     0.75]
[-2.70291432  0.98751196  0.25939496]
[166.   166.     0.75]
[-2.69712497  0.99533035  0.25960091]
[166.   166.     0.75]
[-2.69295442  1.00750827  0.25996781]
[166.   166.     0.75]
[-2.69411592  1.02514339  0.25951386]
[166.   166.     0.75]
[-2.70554063  1.03622408  0.25965996]
[166.   166.     0.75]
[-2.72037998  1.04408236  0.25966479]
[166.   166.     0.75]
[-2.73575549  1.05742406  0.25973872]
[166.   166.     0.75]
[-2.75857335  1.08399027  0.2601102 ]
[166.   166.     0.75]
[-2.75631598  1.0962741   0.27272849]
[166.   166.     0.75]
[-2.75064482  1.08961223  0.28688021]
[166.   166.     0.75]
[-2.74031775  1.08609783  0.30357335]
[166.   166.     0.75]
[-2.72688947  1.08219475  0.31896407]
[166.   166.     0.75]
[-2.71426795  1.07112241  0.31973275]
[166.   166.     0.75]
[-2.70563034  1.06471167  0.30014431]
[166.   166.     0.75]
[-2.70297477  1.03687681  0.27734234]
[166.   166.     0.75]
[-2.68560343  1.01624942  0.25488684]
[166.   166.     0.75]
[-2.65128537  1.00270044  0.25862457]
[166.   166.     0.75]
[-2.61765785  0.99115977  0.259635  ]
[166.   166.     0.75]
[-2.58539762  0.97520724  0.25969968]
[166.   166.     0.75]
[-2.56536902  0.96710369  0.28277061]
[166.   166.     0.75]
[-2.55561627  0.97364949  0.30448141]
[166.   166.     0.75]
[-2.54534447  0.97459379  0.30619294]
[166.   166.     0.75]
[-2.53366048  0.96500145  0.28159855]
[166.   166.     0.75]
[-2.53498897  0.94908808  0.25610831]
[166.   166.     0.75]
[-2.54125281  0.92939643  0.25861213]
[166.   166.     0.75]
[-2.55011652  0.89978684  0.2595717 ]
[166.   166.     0.75]
[-2.59303302  0.88027325  0.27520797]
[166.   166.     0.75]
[-2.65854247  0.89458972  0.29830519]
[166.   166.     0.75]
[-2.71904662  0.9140588   0.29652421]
[166.   166.     0.75]
[-2.78891949  0.93063612  0.26867375]
[166.   166.     0.75]
[-2.83788871  0.94552333  0.25427375]
[166.   166.     0.75]
[-2.85116976  0.95409775  0.25973578]
[166.   166.     0.75]
[-2.85790277  0.96795412  0.2594113 ]
[166.   166.     0.75]
[-2.86641048  0.97714238  0.25959832]
[166.   166.     0.75]
[-2.87894841  0.99121273  0.25974388]
[166.   166.     0.75]
[-2.89294368  1.00639919  0.26724043]
[166.   166.     0.75]
[-2.90158754  1.00713074  0.28025316]
[166.   166.     0.75]
[-2.90652393  1.01055735  0.27047685]
[166.   166.     0.75]
[-2.88964927  1.01264763  0.25647505]
[166.   166.     0.75]
[-2.87250634  1.00864845  0.27135056]
[166.   166.     0.75]
[-2.8698565   1.00397593  0.25855954]
[166.   166.     0.75]
[-2.87684315  1.00338708  0.2577569 ]
[166.   166.     0.75]
[-2.88390706  0.99683096  0.25966292]
[166.   166.     0.75]
[-2.88294531  0.98536224  0.25975149]
[166.   166.     0.75]
[-2.87690924  0.98222697  0.2596216 ]
[166.   166.     0.75]
[-2.87824758  0.98337605  0.25957608]
[166.   166.     0.75]
[-2.88680766  0.99397548  0.25965382]
[166.   166.     0.75]
[-2.89565163  1.00240009  0.2596929 ]
[166.   166.     0.75]
[-2.90669723  1.01046565  0.25958834]
[166.   166.     0.75]
[-2.92039404  1.01267467  0.26204651]
[166.   166.     0.75]
[-2.92667623  0.99626059  0.26394099]
[166.   166.     0.75]
[-2.93040777  0.9716483   0.2605027 ]
[166.   166.     0.75]
[-2.92533812  0.95793585  0.25921473]
[166.   166.     0.75]
[-2.91382967  0.95024748  0.25966576]
[166.   166.     0.75]
[-2.89970381  0.9445537   0.26168381]
[166.   166.     0.75]
[-2.89930487  0.93566076  0.25741153]
[166.   166.     0.75]
[-2.89978238  0.92124756  0.25926898]
[166.   166.     0.75]
[-2.91165505  0.91325179  0.25965347]
[166.   166.     0.75]
[-2.92023491  0.90020957  0.25961039]
[166.   166.     0.75]
[-2.91536273  0.88550112  0.2598523 ]
[166.   166.     0.75]
[-2.89521758  0.87231002  0.25963237]
[166.   166.     0.75]
[-2.8742308   0.86262413  0.25968411]
[166.   166.     0.75]
[-2.86884346  0.84407197  0.25975372]
[166.   166.     0.75]
[-2.8690634   0.82878603  0.25972245]
[166.   166.     0.75]
[-2.86281446  0.81671685  0.26133582]
[166.   166.     0.75]
[-2.88059367  0.80985721  0.26001646]
[166.   166.     0.75]
[-2.89128203  0.80913308  0.25911699]
[166.   166.     0.75]
[-2.88652075  0.80222189  0.26152124]
[166.   166.     0.75]
[-2.88764844  0.79672421  0.25972994]
[166.   166.     0.75]
[-2.89818273  0.79685943  0.26068654]
[166.   166.     0.75]
[-2.8947125   0.8115321   0.25933642]
[166.   166.     0.75]
[-2.89437653  0.81958813  0.25977778]
[166.   166.     0.75]
[-2.8956343   0.8272607   0.25965059]
[166.   166.     0.75]
[-2.89644472  0.83908056  0.25960294]
[166.   166.     0.75]
[-2.89986266  0.86219038  0.25990142]
[166.   166.     0.75]
[-2.90982139  0.89279825  0.25964808]
[166.   166.     0.75]
[-2.91560761  0.90995574  0.26004   ]
[166.   166.     0.75]
[-2.93025505  0.90919096  0.25934338]
[166.   166.     0.75]
[-2.9469592   0.91524069  0.25960336]
[166.   166.     0.75]
[-2.9618283   0.91424593  0.25964887]
[166.   166.     0.75]
[-2.96943977  0.90395823  0.25969292]
[166.   166.     0.75]
[-2.97769325  0.89923167  0.25961332]
[166.   166.     0.75]
[-2.99091094  0.91380911  0.26228838]
[166.   166.     0.75]
[-2.97792609  0.92962992  0.28023936]
[166.   166.     0.75]
[-2.95849839  0.94871466  0.27857469]
[166.   166.     0.75]
[-2.92683086  0.95804875  0.26244545]
[166.   166.     0.75]
[-2.89443382  0.96622868  0.25781607]
[166.   166.     0.75]
[-2.86842109  0.97831408  0.26281731]
[166.   166.     0.75]
[-2.87328253  0.98481019  0.27664692]
[166.   166.     0.75]
[-2.88086541  0.99665646  0.27327675]
[166.   166.     0.75]
[-2.88722358  1.0053559   0.25548478]
[166.   166.     0.75]
[-2.88988485  0.99922227  0.25863598]
[166.   166.     0.75]
[-2.90242882  0.98131649  0.25965912]
[166.   166.     0.75]
[-2.90460134  0.96131218  0.25950898]
[166.   166.     0.75]
[-2.89913995  0.9413006   0.25964724]
[166.   166.     0.75]
[-2.89422976  0.9239446   0.25958583]
[166.   166.     0.75]
[-2.89453948  0.92286574  0.26383677]
[166.   166.     0.75]
[-2.88710951  0.9332243   0.25821615]
[166.   166.     0.75]
[-2.88598934  0.93689439  0.25931749]
[166.   166.     0.75]
[-2.88483931  0.93878631  0.25974906]
[166.   166.     0.75]
[-2.88026949  0.93465718  0.26044571]
[166.   166.     0.75]
[-2.89191356  0.93893832  0.25917141]
[166.   166.     0.75]
[-2.90437771  0.93784596  0.25915029]
[166.   166.     0.75]
[-2.91423157  0.93683782  0.25941855]
[166.   166.     0.75]
[-2.90823195  0.92664895  0.2596635 ]
[166.   166.     0.75]
[-2.89197945  0.91133836  0.2599033 ]
[166.   166.     0.75]
[-2.88006966  0.90054238  0.26229923]
[166.   166.     0.75]
[-2.88101614  0.89131962  0.27811702]
[166.   166.     0.75]
[-2.88203448  0.87960121  0.27689944]
[166.   166.     0.75]
[-2.88786451  0.87324862  0.25594367]
[166.   166.     0.75]
[-2.89156801  0.8816519   0.25857073]
[166.   166.     0.75]
[-2.88543928  0.88726757  0.25962428]
[166.   166.     0.75]
[-2.87157345  0.88393315  0.25967038]
[166.   166.     0.75]
[-2.8657849   0.88428981  0.25963661]
[166.   166.     0.75]
[-2.87101517  0.88403517  0.25954903]
[166.   166.     0.75]
[-2.88014214  0.87984656  0.25961519]
[166.   166.     0.75]
[-2.90033743  0.88111402  0.25966186]
[166.   166.     0.75]
[-2.92329756  0.88629779  0.25964908]
[166.   166.     0.75]
[-2.94799009  0.87978679  0.25989448]
[166.   166.     0.75]
[-2.96478183  0.86893558  0.25908108]
[166.   166.     0.75]
[-2.968072    0.86480335  0.25992308]
[166.   166.     0.75]
[-2.9609429   0.8608042   0.26037443]
[166.   166.     0.75]
[-2.95084356  0.85963512  0.26490308]
[166.   166.     0.75]
[-2.95421465  0.86504848  0.26038123]
[166.   166.     0.75]
[-2.95456055  0.87592393  0.25862735]
[166.   166.     0.75]
[-2.95316825  0.89191516  0.25965185]
[166.   166.     0.75]
[-2.94880912  0.89974877  0.25971503]
[166.   166.     0.75]
[-2.94434145  0.90265467  0.2595754 ]
[166.   166.     0.75]
[-2.94396445  0.90342438  0.25964913]
[166.   166.     0.75]
[-2.9460639   0.90343776  0.25961569]
[166.   166.     0.75]
[-2.95246288  0.90416193  0.25976239]
[166.   166.     0.75]
[-2.96207644  0.89830083  0.26202945]
[166.   166.     0.75]
[-2.97512051  0.89866395  0.26879471]
[166.   166.     0.75]
[-2.98122116  0.91058605  0.26873722]
[166.   166.     0.75]
[-2.97161684  0.91261692  0.25734746]
[166.   166.     0.75]
[-2.9578108   0.89312298  0.25931504]
[166.   166.     0.75]
[-2.92742525  0.86522752  0.27024807]
[166.   166.     0.75]
[-2.88235079  0.85104797  0.26612841]
[166.   166.     0.75]
[-2.83847847  0.85176355  0.25775482]
[166.   166.     0.75]
[-2.82566261  0.85715243  0.26000675]
[166.   166.     0.75]
[-2.81361351  0.86011831  0.25956547]
[166.   166.     0.75]
[-2.80344473  0.86178113  0.2596337 ]
[166.   166.     0.75]
[-2.78609484  0.85618747  0.25960225]
[166.   166.     0.75]
[-2.77125204  0.8576648   0.27650196]
[166.   166.     0.75]
[-2.75745203  0.85641956  0.28508433]
[166.   166.     0.75]
[-2.75371437  0.84718642  0.27502786]
[166.   166.     0.75]
[-2.75962347  0.86177996  0.25598616]
[166.   166.     0.75]
[-2.76782113  0.87996174  0.25919511]
[166.   166.     0.75]
[-2.76605245  0.88910946  0.25965469]
[166.   166.     0.75]
[-2.76621077  0.89257886  0.25972663]
[166.   166.     0.75]
[-2.77326612  0.91038892  0.25974375]
[166.   166.     0.75]
[-2.78018774  0.93051991  0.25966854]
[166.   166.     0.75]
[-2.77583298  0.93426937  0.25969236]
[166.   166.     0.75]
[-2.76777454  0.9388534   0.25960903]
[166.   166.     0.75]
[-2.77654778  0.95476469  0.26596203]
[166.   166.     0.75]
[-2.79658151  0.96538158  0.27648047]
[166.   166.     0.75]
[-2.80502114  0.96950994  0.26190651]
[166.   166.     0.75]
[-2.80089266  0.97495641  0.25724663]
[166.   166.     0.75]
[-2.79188134  0.99117138  0.25964261]
[166.   166.     0.75]
[-2.80795994  1.00569411  0.25930652]
[166.   166.     0.75]
[-2.836626    1.02217417  0.25958503]
[166.   166.     0.75]
[-2.8659948   1.03263219  0.26045599]
[166.   166.     0.75]
[-2.88186475  1.04509972  0.26077757]
[166.   166.     0.75]
[-2.8732545   1.06587763  0.2696525 ]
[166.   166.     0.75]
[-2.85931069  1.07802542  0.2577114 ]
[166.   166.     0.75]
[-2.859335    1.07186566  0.2597681 ]
[166.   166.     0.75]
[-2.87329148  1.06746343  0.25919427]
[166.   166.     0.75]
[-2.87633258  1.0797757   0.26501751]
[166.   166.     0.75]
[-2.87113017  1.09586795  0.25757478]
[166.   166.     0.75]
[-2.86067995  1.08777231  0.2598385 ]
[166.   166.     0.75]
[-2.84401831  1.06696415  0.26019464]
[166.   166.     0.75]
[-2.83469564  1.05763634  0.25944087]
[166.   166.     0.75]
[-2.84495331  1.04567203  0.25956362]
[166.   166.     0.75]
[-2.86653082  1.0334757   0.26018269]
[166.   166.     0.75]
[-2.87785454  1.02866533  0.25975088]
[166.   166.     0.75]
[-2.87181132  1.02080014  0.25973561]
[166.   166.     0.75]
[-2.85454125  1.01187437  0.25965134]
[166.   166.     0.75]
[-2.83489591  0.99088935  0.25973167]
[166.   166.     0.75]
[-2.812394    0.97566086  0.25957083]
[166.   166.     0.75]
[-2.80823862  0.95990481  0.2599144 ]
[166.   166.     0.75]
[-2.81742036  0.94813329  0.2600253 ]
[166.   166.     0.75]
[-2.84620641  0.936246    0.25968726]
[166.   166.     0.75]
[-2.86753884  0.92874407  0.25986374]
[166.   166.     0.75]
[-2.86929915  0.90848431  0.26918079]
[166.   166.     0.75]
[-2.84938026  0.88895758  0.27681852]
[166.   166.     0.75]
[-2.82972441  0.8633971   0.26185035]
[166.   166.     0.75]
[-2.81360931  0.84284308  0.25802042]
[166.   166.     0.75]
[-2.78410596  0.82019843  0.25947506]
[166.   166.     0.75]
[-2.74142683  0.81912517  0.27595001]
[166.   166.     0.75]
[-2.70393715  0.84021557  0.28403166]
[166.   166.     0.75]
[-2.67327839  0.86652255  0.27260813]
[166.   166.     0.75]
[-2.65819652  0.89815962  0.25552998]
[166.   166.     0.75]
[-2.64836513  0.92703264  0.25899725]
[166.   166.     0.75]
[-2.63033861  0.94926862  0.25962389]
[166.   166.     0.75]
[-2.62155382  0.95201858  0.25961445]
[166.   166.     0.75]
[-2.61147961  0.9621458   0.25958934]
[166.   166.     0.75]
[-2.60324172  0.97182899  0.25966844]
[166.   166.     0.75]
[-2.6069092   0.9743199   0.25964088]
[166.   166.     0.75]
[-2.61484683  0.97923992  0.25982728]
[166.   166.     0.75]
[-2.62223626  0.99376658  0.25966783]
[166.   166.     0.75]
[-2.61317257  1.01540587  0.25968031]
[166.   166.     0.75]
[-2.59949001  1.03096197  0.2595325 ]
[166.   166.     0.75]
[-2.58955971  1.04365967  0.25971183]
[166.   166.     0.75]
[-2.5832455   1.04416304  0.25904618]
[166.   166.     0.75]
[-2.58916522  1.04224965  0.25948128]
[166.   166.     0.75]
[-2.59611618  1.05614084  0.26648149]
[166.   166.     0.75]
[-2.60785717  1.06968081  0.26636229]
[166.   166.     0.75]
[-2.61970554  1.06939525  0.25763402]
[166.   166.     0.75]
[-2.62071841  1.06952406  0.25933825]
[166.   166.     0.75]
[-2.62658652  1.07213365  0.25958973]
[166.   166.     0.75]
[-2.6367788   1.06574849  0.26026587]
[166.   166.     0.75]
[-2.63466324  1.04859761  0.25978368]
[166.   166.     0.75]
[-2.62724803  1.02579365  0.25954074]
[166.   166.     0.75]
[-2.62452155  0.99743144  0.25960109]
[166.   166.     0.75]
[-2.61966653  0.96679517  0.25974703]
[166.   166.     0.75]
[-2.60657461  0.93725656  0.26007129]
[166.   166.     0.75]
[-2.59400993  0.92650736  0.26015051]
[166.   166.     0.75]
[-2.60027024  0.92235052  0.25949933]
[166.   166.     0.75]
[-2.60897089  0.92316213  0.2597772 ]
[166.   166.     0.75]
[-2.61811982  0.92519422  0.2598217 ]
[166.   166.     0.75]
[-2.62132563  0.91689801  0.26074338]
[166.   166.     0.75]
[-2.61781617  0.902048    0.26079663]
[166.   166.     0.75]
[-2.61366997  0.89720329  0.27242222]
[166.   166.     0.75]
[-2.59257518  0.88876092  0.27390904]
[166.   166.     0.75]
[-2.57235486  0.87471201  0.26604028]
[166.   166.     0.75]
[-2.56202261  0.87586389  0.25735626]
[166.   166.     0.75]
[-2.55692691  0.88576777  0.25923664]
[166.   166.     0.75]
[-2.54662411  0.90090065  0.25936465]
[166.   166.     0.75]
[-2.54042336  0.91602588  0.25959098]
[166.   166.     0.75]
[-2.53311708  0.93003187  0.25987081]
[166.   166.     0.75]
[-2.51898886  0.94949707  0.25960046]
[166.   166.     0.75]
[-2.49968222  0.96696727  0.25977743]
[166.   166.     0.75]
[-2.48638063  0.97936694  0.25963121]
[166.   166.     0.75]
[-2.47675002  0.9875588   0.25978213]
[166.   166.     0.75]
[-2.46165195  1.004806    0.26070339]
[166.   166.     0.75]
[-2.42875373  1.0227702   0.26932426]
[166.   166.     0.75]
[-2.39827695  1.0341312   0.25948528]
[166.   166.     0.75]
[-2.38853717  1.03048123  0.26807433]
[166.   166.     0.75]
[-2.38954076  1.01620336  0.27134587]
[166.   166.     0.75]
[-2.3883414   0.99400411  0.25580542]
[166.   166.     0.75]
[-2.38067036  0.9912938   0.258276  ]
[166.   166.     0.75]
[-2.38476474  0.99496319  0.26355885]
[166.   166.     0.75]
[-2.39279778  0.99289735  0.25782859]
[166.   166.     0.75]
[-2.40497996  0.98893513  0.2593239 ]
[166.   166.     0.75]
[-2.4242972   0.98911205  0.25973408]
[166.   166.     0.75]
[-2.43126331  0.9973127   0.25983552]
[166.   166.     0.75]
[-2.43500475  0.9924045   0.25836204]
[166.   166.     0.75]
[-2.43993381  0.98355399  0.25874029]
[166.   166.     0.75]
[-2.44041791  0.98223618  0.25983108]
[166.   166.     0.75]
[-2.44200581  0.9779318   0.25954096]
[166.   166.     0.75]
[-2.44339422  0.96830357  0.25987627]
[166.   166.     0.75]
[-2.44565892  0.95297379  0.25951282]
[166.   166.     0.75]
[-2.44418277  0.94452821  0.2595787 ]
[166.   166.     0.75]
[-2.43536047  0.94028139  0.25959688]
[166.   166.     0.75]
[-2.42914824  0.93000395  0.26010823]
[166.   166.     0.75]
[-2.42993882  0.91632786  0.25975958]
[166.   166.     0.75]
[-2.43719401  0.9079076   0.25973919]
[166.   166.     0.75]
[-2.467705    0.90495542  0.2595949 ]
[166.   166.     0.75]
[-2.50153509  0.90865428  0.26042749]
[166.   166.     0.75]
[-2.4988616   0.90944328  0.26446085]
[166.   166.     0.75]
[-2.4942958   0.92489248  0.25747351]
[166.   166.     0.75]
[-2.49694111  0.93442315  0.259208  ]
[166.   166.     0.75]
[-2.5034419   0.92524514  0.25970309]
[166.   166.     0.75]
[-2.50074712  0.9020635   0.25966041]
[166.   166.     0.75]
[-2.48463122  0.88724522  0.25983991]
[166.   166.     0.75]
[-2.47887699  0.88291117  0.25967195]
[166.   166.     0.75]
[-2.4811875   0.8915159   0.25960013]
[166.   166.     0.75]
[-2.48300041  0.90011734  0.25969347]
[166.   166.     0.75]
[-2.47831657  0.91264088  0.25960385]
[166.   166.     0.75]
[-2.47074763  0.9314371   0.25964074]
[166.   166.     0.75]
[-2.4686662   0.93570242  0.26011807]
[166.   166.     0.75]
[-2.4658483   0.92799079  0.25959999]
[166.   166.     0.75]
[-2.47186805  0.90689448  0.2596335 ]
[166.   166.     0.75]
[-2.47862625  0.89951497  0.26020791]
[166.   166.     0.75]
[-2.4892822   0.92155197  0.25996492]
[166.   166.     0.75]
[-2.49988792  0.94191932  0.25990797]
[166.   166.     0.75]
[-2.50455802  0.95099845  0.2607811 ]
[166.   166.     0.75]
[-2.50114469  0.95161386  0.25998788]
[166.   166.     0.75]
[-2.49359698  0.95403987  0.25951248]
[166.   166.     0.75]
[-2.4877415   0.95705767  0.25960399]
[166.   166.     0.75]
[-2.48636079  0.96214252  0.2595657 ]
[166.   166.     0.75]
[-2.48889191  0.97142451  0.25964261]
[166.   166.     0.75]
[-2.48891035  0.97835929  0.2596261 ]
[166.   166.     0.75]
[-2.49006826  0.98181049  0.25959869]
[166.   166.     0.75]
[-2.48755087  0.99456879  0.25967148]
[166.   166.     0.75]
[-2.48560808  1.00998238  0.26062086]
[166.   166.     0.75]
[-2.47629128  1.01260798  0.25926351]
[166.   166.     0.75]
[-2.46899238  1.01933693  0.25954945]
[166.   166.     0.75]
[-2.46557037  1.03346485  0.25956303]
[166.   166.     0.75]
[-2.46914689  1.05296628  0.25956799]
[166.   166.     0.75]
[-2.4630497   1.05760902  0.26270124]
[166.   166.     0.75]
[-2.42979599  1.03723956  0.27999916]
[166.   166.     0.75]
[-2.37013309  1.01311669  0.29586332]
[166.   166.     0.75]
[-2.31760089  0.99314923  0.30618281]
[166.   166.     0.75]
[-2.30110809  0.95619354  0.30833342]
[166.   166.     0.75]
[-2.29827332  0.91298644  0.27379045]
[166.   166.     0.75]
[-2.28993672  0.89622711  0.25226894]
[166.   166.     0.75]
[-2.27070467  0.89206075  0.25832887]
[166.   166.     0.75]
[-2.25411036  0.8886162   0.25968856]
[166.   166.     0.75]
[-2.23688967  0.88425321  0.25970086]
[166.   166.     0.75]
[-2.21213729  0.8813552   0.25966044]
[166.   166.     0.75]
[-2.18562005  0.88732774  0.25961135]
[166.   166.     0.75]
[-2.15746929  0.87443048  0.26008208]
[166.   166.     0.75]
[-2.12910381  0.85707627  0.26491101]
[166.   166.     0.75]
[-2.12407001  0.86207301  0.2887742 ]
[166.   166.     0.75]
[-2.12641002  0.87341979  0.29506112]
[166.   166.     0.75]
[-2.15002508  0.87237021  0.31592966]
[166.   166.     0.75]
[-2.17498691  0.86638785  0.32349014]
[166.   166.     0.75]
[-2.18726132  0.84886742  0.31029157]
[166.   166.     0.75]
[-2.20765095  0.84349295  0.27916259]
[166.   166.     0.75]
[-2.23042628  0.8467799   0.25097656]
[166.   166.     0.75]
[-2.25025536  0.8479133   0.25801905]
[166.   166.     0.75]
[-2.26502123  0.85300516  0.25985856]
[166.   166.     0.75]
[-2.27279243  0.87074715  0.26011862]
[166.   166.     0.75]
[-2.27727942  0.87702613  0.25987166]
[166.   166.     0.75]
[-2.28270324  0.89259807  0.25959212]
[166.   166.     0.75]
[-2.29814866  0.90239802  0.25961599]
[166.   166.     0.75]
[-2.32219018  0.91088824  0.25964687]
[166.   166.     0.75]
[-2.35056807  0.90979207  0.25966939]
[166.   166.     0.75]
[-2.38191393  0.91410278  0.25958196]
[166.   166.     0.75]
[-2.4179983   0.92971302  0.26724068]
[166.   166.     0.75]
[-2.46568626  0.94010506  0.2635216 ]
[166.   166.     0.75]
[-2.48318339  0.96165002  0.25908321]
[166.   166.     0.75]
[-2.46921319  0.9599574   0.27244147]
[166.   166.     0.75]
[-2.4416742   0.93544946  0.28676753]
[166.   166.     0.75]
[-2.43416438  0.89569367  0.28808891]
[166.   166.     0.75]
[-2.43050949  0.82174598  0.31844193]
[166.   166.     0.75]
[-2.43684613  0.76031665  0.32123456]
[166.   166.     0.75]
[-2.46352725  0.72636306  0.29634016]
[166.   166.     0.75]
[-2.46564509  0.70142514  0.26777394]
[166.   166.     0.75]
[-2.4323873   0.67822078  0.25665629]
[166.   166.     0.75]
[-2.39710757  0.65812656  0.25915967]
[166.   166.     0.75]
[-2.35446447  0.64176043  0.25962113]
[166.   166.     0.75]
[-2.31564605  0.62736213  0.25954599]
[166.   166.     0.75]
[-2.29152803  0.61566295  0.27717992]
[166.   166.     0.75]
[-2.28085677  0.60368066  0.28844477]
[166.   166.     0.75]
[-2.28303538  0.59208254  0.27931281]
[166.   166.     0.75]
[-2.2970302   0.58323617  0.28152258]
[166.   166.     0.75]
[-2.31350295  0.57219767  0.25993298]
[166.   166.     0.75]
[-2.32405309  0.56851368  0.25731467]
[166.   166.     0.75]
[-2.32695469  0.55551661  0.25938672]
[166.   166.     0.75]
[-2.32199928  0.53556246  0.25962361]
[166.   166.     0.75]
[-2.32049876  0.52217014  0.25949655]
[166.   166.     0.75]
[-2.33496731  0.51758304  0.2596562 ]
[166.   166.     0.75]
[-2.34917475  0.51129755  0.25965737]
[166.   166.     0.75]
[-2.37130274  0.50862888  0.2610733 ]
[166.   166.     0.75]
[-2.38790798  0.5128034   0.25881193]
[166.   166.     0.75]
[-2.39070032  0.50913037  0.26113773]
[166.   166.     0.75]
[-2.39294153  0.51088269  0.25902065]
[166.   166.     0.75]
[-2.41012286  0.51278363  0.26112615]
[166.   166.     0.75]
[-2.43290491  0.51821204  0.25848464]
[166.   166.     0.75]
[-2.44512588  0.52634088  0.2594828 ]
[166.   166.     0.75]
[-2.4635679   0.53761708  0.25975372]
[166.   166.     0.75]
[-2.48447385  0.53876155  0.259575  ]
[166.   166.     0.75]
[-2.50001454  0.52905643  0.27676121]
[166.   166.     0.75]
[-2.51043836  0.5229557   0.2898627 ]
[166.   166.     0.75]
[-2.51413067  0.51090588  0.27379122]
[166.   166.     0.75]
[-2.51253523  0.49801085  0.25533861]
[166.   166.     0.75]
[-2.5152732   0.49282946  0.25877233]
[166.   166.     0.75]
[-2.52228503  0.48857788  0.26019161]
[166.   166.     0.75]
[-2.51315515  0.49749785  0.25941118]
[166.   166.     0.75]
[-2.50637696  0.50029839  0.25963401]
[166.   166.     0.75]
[-2.49564328  0.49616404  0.25992449]
[166.   166.     0.75]
[-2.47131308  0.49087003  0.2591299 ]
[166.   166.     0.75]
[-2.46379165  0.48267311  0.25998378]
[166.   166.     0.75]
[-2.45523955  0.48621576  0.2596733 ]
[166.   166.     0.75]
[-2.45514033  0.48447578  0.25993008]
[166.   166.     0.75]
[-2.45743192  0.47972522  0.26006186]
[166.   166.     0.75]
[-2.46516935  0.47779217  0.26057871]
[166.   166.     0.75]
[-2.47530693  0.48612213  0.27233152]
[166.   166.     0.75]
[-2.49014006  0.49558812  0.26749863]
[166.   166.     0.75]
[-2.48493528  0.50126242  0.25649838]
[166.   166.     0.75]
[-2.46331088  0.49951536  0.25909378]
[166.   166.     0.75]
[-2.45111663  0.50002034  0.25980373]
[166.   166.     0.75]
[-2.45066023  0.50282629  0.2597162 ]
[166.   166.     0.75]
[-2.45106745  0.50300025  0.25970639]
[166.   166.     0.75]
[-2.44080813  0.50973865  0.25962523]
[166.   166.     0.75]
[-2.43310897  0.51671288  0.25969066]
[166.   166.     0.75]
[-2.42627709  0.52663742  0.2596869 ]
[166.   166.     0.75]
[-2.41643545  0.53262939  0.25961179]
[166.   166.     0.75]
[-2.40349036  0.53791382  0.25960979]
[166.   166.     0.75]
[-2.38428379  0.54047042  0.26003049]
[166.   166.     0.75]
[-2.37581211  0.53563945  0.25946691]
[166.   166.     0.75]
[-2.37203362  0.53969783  0.2596596 ]
[166.   166.     0.75]
[-2.36701513  0.54482189  0.25972571]
[166.   166.     0.75]
[-2.35925044  0.54710609  0.25959126]
[166.   166.     0.75]
[-2.35038005  0.54421987  0.25958216]
[166.   166.     0.75]
[-2.35249065  0.54001424  0.25968743]
[166.   166.     0.75]
[-2.36139244  0.54650904  0.25968028]
[166.   166.     0.75]
[-2.37526485  0.5599356   0.25965273]
[166.   166.     0.75]
[-2.38770437  0.56609826  0.2596397 ]
[166.   166.     0.75]
[-2.379251    0.56392811  0.25965717]
[166.   166.     0.75]
[-2.36718065  0.56190102  0.25959319]
[166.   166.     0.75]
[-2.36855626  0.55238524  0.26033008]
[166.   166.     0.75]
[-2.38310461  0.54635733  0.25997667]
[166.   166.     0.75]
[-2.39482576  0.54148388  0.25932408]
[166.   166.     0.75]
[-2.40429698  0.53417653  0.25955951]
[166.   166.     0.75]
[-2.41030443  0.52111809  0.25959638]
[166.   166.     0.75]
[-2.40891407  0.51020495  0.25977868]
[166.   166.     0.75]
[-2.39809586  0.50723702  0.26311911]
[166.   166.     0.75]
[-2.38692306  0.51142684  0.25882927]
[166.   166.     0.75]
[-2.35181646  0.51994713  0.26943095]
[166.   166.     0.75]
[-2.34404947  0.53428909  0.26478034]
[166.   166.     0.75]
[-2.36310106  0.54295474  0.25753063]
[166.   166.     0.75]
[-2.38630619  0.54422566  0.25935036]
[166.   166.     0.75]
[-2.41171089  0.53548857  0.26005544]
[166.   166.     0.75]
[-2.42819376  0.52812702  0.25946989]
[166.   166.     0.75]
[-2.4357068   0.52194825  0.25960269]
[166.   166.     0.75]
[-2.43902963  0.51609319  0.26096028]
[166.   166.     0.75]
[-2.45114625  0.51450864  0.25815279]
[166.   166.     0.75]
[-2.45238701  0.5145871   0.25954161]
[166.   166.     0.75]
[-2.45895481  0.52198617  0.25953023]
[166.   166.     0.75]
[-2.47500631  0.53540435  0.26041922]
[166.   166.     0.75]
[-2.48935028  0.55503526  0.25876444]
[166.   166.     0.75]
[-2.50196838  0.57999493  0.25958642]
[166.   166.     0.75]
[-2.51051022  0.60450399  0.25966465]
[166.   166.     0.75]
[-2.51762835  0.61651373  0.25959744]
[166.   166.     0.75]
[-2.52637997  0.62876334  0.25969367]
[166.   166.     0.75]
[-2.54307344  0.64145841  0.25957898]
[166.   166.     0.75]
[-2.55311982  0.63527601  0.26075016]
[166.   166.     0.75]
[-2.54034676  0.64016941  0.26587196]
[166.   166.     0.75]
[-2.52849182  0.65011492  0.27201466]
[166.   166.     0.75]
[-2.51212081  0.65339462  0.26562792]
[166.   166.     0.75]
[-2.48368445  0.65017471  0.25772857]
[166.   166.     0.75]
[-2.45353998  0.65183314  0.25935088]
[166.   166.     0.75]
[-2.43184893  0.65919673  0.25962718]
[166.   166.     0.75]
[-2.42205079  0.67525163  0.25963845]
[166.   166.     0.75]
[-2.41937087  0.6892082   0.25935657]
[166.   166.     0.75]
[-2.40961658  0.69457028  0.25929678]
[166.   166.     0.75]
[-2.40354055  0.69478522  0.25972428]
[166.   166.     0.75]
[-2.38593466  0.6992137   0.25965276]
[166.   166.     0.75]
[-2.36505618  0.71688943  0.260141  ]
[166.   166.     0.75]
[-2.33861994  0.72688857  0.26098789]
[166.   166.     0.75]
[-2.31738683  0.71414304  0.26926705]
[166.   166.     0.75]
[-2.29357458  0.68830343  0.25708526]
[166.   166.     0.75]
[-2.27969205  0.68084745  0.25907286]
[166.   166.     0.75]
[-2.26562188  0.67213757  0.25961172]
[166.   166.     0.75]
[-2.24872226  0.66373313  0.26012277]
[166.   166.     0.75]
[-2.23880676  0.64923925  0.26795982]
[166.   166.     0.75]
[-2.23580608  0.61654731  0.28397344]
[166.   166.     0.75]
[-2.23398347  0.59292861  0.27747888]
[166.   166.     0.75]
[-2.23729611  0.58962006  0.25288573]
[166.   166.     0.75]
[-2.24886504  0.58810302  0.25740448]
[166.   166.     0.75]
[-2.24481064  0.58509825  0.25992964]
[166.   166.     0.75]
[-2.2380137   0.58103282  0.25943117]
[166.   166.     0.75]
[-2.22758375  0.57370139  0.25969918]
[166.   166.     0.75]
[-2.21818349  0.56096964  0.25958936]
[166.   166.     0.75]
[-2.21626679  0.55634253  0.25977765]
[166.   166.     0.75]
[-2.22821633  0.55243996  0.25954733]
[166.   166.     0.75]
[-2.24995679  0.55068959  0.25971269]
[166.   166.     0.75]
[-2.26601903  0.55662771  0.25961227]
[166.   166.     0.75]
[-2.25771734  0.55591594  0.25917508]
[166.   166.     0.75]
[-2.242022    0.55044987  0.25960604]
[166.   166.     0.75]
[-2.21246856  0.54174888  0.25959076]
[166.   166.     0.75]
[-2.19997129  0.53146669  0.28474362]
[166.   166.     0.75]
[-2.23037926  0.51519125  0.30141605]
[166.   166.     0.75]
[-2.26062607  0.51300984  0.31920359]
[166.   166.     0.75]
[-2.2850742   0.51943918  0.32783148]
[166.   166.     0.75]
[-2.30083346  0.52930528  0.31504508]
[166.   166.     0.75]
[-2.31897594  0.5464584   0.28424942]
[166.   166.     0.75]
[-2.36802226  0.55866001  0.25678727]
[166.   166.     0.75]
[-2.38649613  0.58772014  0.25972313]
[166.   166.     0.75]
[-2.39993249  0.62010507  0.25961418]
[166.   166.     0.75]
[-2.40755549  0.64209903  0.25962407]
[166.   166.     0.75]
[-2.40929661  0.65220482  0.25962381]
[166.   166.     0.75]
[-2.41889732  0.66117297  0.25999586]
[166.   166.     0.75]
[-2.42450414  0.66220408  0.25962459]
[166.   166.     0.75]
[-2.43234541  0.6644577   0.2596736 ]
[166.   166.     0.75]
[-2.45262986  0.68800246  0.2597578 ]
[166.   166.     0.75]
[-2.47562134  0.72629735  0.25948865]
[166.   166.     0.75]
[-2.49919561  0.73729432  0.29639579]
[166.   166.     0.75]
[-2.51109741  0.7530759   0.31611013]
[166.   166.     0.75]
[-2.51030907  0.75797738  0.33210118]
[166.   166.     0.75]
[-2.50506302  0.76134746  0.33518951]
[166.   166.     0.75]
[-2.51410787  0.74876101  0.34958443]
[166.   166.     0.75]
[-2.53759865  0.72943355  0.35084229]
[166.   166.     0.75]
[-2.56523511  0.70044633  0.33307451]
[166.   166.     0.75]
[-2.59815421  0.68048607  0.28584745]
[166.   166.     0.75]
[-2.62077114  0.65462286  0.25189618]
[166.   166.     0.75]
[-2.63134996  0.61861955  0.2581259 ]
[166.   166.     0.75]
[-2.63335045  0.57995316  0.25904927]
[166.   166.     0.75]
[-2.62275064  0.54682021  0.25927254]
[166.   166.     0.75]
[-2.60663854  0.51221781  0.25964347]
[166.   166.     0.75]
[-2.59971097  0.45814737  0.26552439]
[166.   166.     0.75]
[-2.61333617  0.41114599  0.2643917 ]
[166.   166.     0.75]
[-2.62910628  0.38863228  0.26471215]
[166.   166.     0.75]
[-2.64894619  0.41283993  0.31305088]
[166.   166.     0.75]
[-2.67037356  0.45579762  0.35431637]
[166.   166.     0.75]
[-2.63973242  0.48605344  0.36953465]
[166.   166.     0.75]
[-2.61749812  0.50432794  0.35868849]
[166.   166.     0.75]
[-2.59227598  0.51958452  0.32818749]
[166.   166.     0.75]
[-2.5748728   0.53896576  0.29578451]
[166.   166.     0.75]
[-2.5767081   0.55794209  0.2529969 ]
[166.   166.     0.75]
[-2.59585428  0.57159811  0.25686738]
[166.   166.     0.75]
[-2.6125709   0.59329863  0.26105294]
[166.   166.     0.75]
[-2.61521149  0.62547575  0.27101005]
[166.   166.     0.75]
[-2.6025949   0.64129981  0.29031086]
[166.   166.     0.75]
[-2.59045841  0.64768567  0.28600035]
[166.   166.     0.75]
[-2.56756733  0.65514979  0.26250295]
[166.   166.     0.75]
[-2.52747112  0.67726744  0.25995894]
[166.   166.     0.75]
[-2.49722415  0.68889734  0.26067796]
[166.   166.     0.75]
[-2.477163    0.69531138  0.25890145]
[166.   166.     0.75]
[-2.45799022  0.69751316  0.27812077]
[166.   166.     0.75]
[-2.43184082  0.68847603  0.30197197]
[166.   166.     0.75]
[-2.4282509   0.67956179  0.29778524]
[166.   166.     0.75]
[-2.42079338  0.67252842  0.27072751]
[166.   166.     0.75]
[-2.41238257  0.64410647  0.25545613]
[166.   166.     0.75]
[-2.4080165   0.62642883  0.25876108]
[166.   166.     0.75]
[-2.41104757  0.60596933  0.25961918]
[166.   166.     0.75]
[-2.41267861  0.57560506  0.25964833]
[166.   166.     0.75]
[-2.40009255  0.54723407  0.26044074]
[166.   166.     0.75]
[-2.39794158  0.53391109  0.25913581]
[166.   166.     0.75]
[-2.40587712  0.52762246  0.2637688 ]
[166.   166.     0.75]
[-2.40885739  0.53311961  0.25795982]
[166.   166.     0.75]
[-2.41494756  0.52740569  0.26116813]
[166.   166.     0.75]
[-2.44364433  0.51277867  0.26408455]
[166.   166.     0.75]
[-2.48133333  0.51402402  0.25798316]
[166.   166.     0.75]
[-2.48224822  0.51957977  0.25994133]
[166.   166.     0.75]
[-2.47059428  0.51432137  0.25975675]
[166.   166.     0.75]
[-2.45410473  0.50335069  0.26553964]
[166.   166.     0.75]
[-2.43921854  0.48320115  0.26357927]
[166.   166.     0.75]
[-2.43686677  0.48467791  0.25812251]
[166.   166.     0.75]
[-2.43111657  0.49178119  0.25948263]
[166.   166.     0.75]
[-2.42861672  0.49839287  0.2596634 ]
[166.   166.     0.75]
[-2.43551668  0.50599243  0.25958639]
[166.   166.     0.75]
[-2.44196799  0.51744     0.25969781]
[166.   166.     0.75]
[-2.44495199  0.52735944  0.25964677]
[166.   166.     0.75]
[-2.44918846  0.52799548  0.259728  ]
[166.   166.     0.75]
[-2.45878401  0.52998945  0.26116259]
[166.   166.     0.75]
[-2.47318283  0.51825601  0.25951375]
[166.   166.     0.75]
[-2.4781205   0.5077744   0.25911947]
[166.   166.     0.75]
[-2.47618559  0.50842334  0.25957691]
[166.   166.     0.75]
[-2.47552014  0.51012241  0.25968048]
[166.   166.     0.75]
[-2.4825323   0.51045913  0.25962562]
[166.   166.     0.75]
[-2.49151008  0.51190002  0.25957664]
[166.   166.     0.75]
[-2.49335451  0.51317389  0.25952767]
[166.   166.     0.75]
[-2.48705663  0.49217071  0.25944868]
[166.   166.     0.75]
[-2.47557401  0.46621271  0.27024017]
[166.   166.     0.75]
[-2.4665674   0.45878425  0.25652763]
[166.   166.     0.75]
[-2.46632583  0.46298166  0.25859984]
[166.   166.     0.75]
[-2.46267097  0.45854616  0.2597558 ]
[166.   166.     0.75]
[-2.45330084  0.44107773  0.25952995]
[166.   166.     0.75]
[-2.44223534  0.41998508  0.2600845 ]
[166.   166.     0.75]
[-2.43346885  0.41833797  0.25947728]
[166.   166.     0.75]
[-0.09034687 -0.04424977  0.77720706]
[444.   444.     0.75]
[-0.08516094 -0.0656522   0.7628979 ]
[444.   444.     0.75]
[-0.07398255 -0.06668336  0.70465966]
[444.   444.     0.75]
[-0.05509878 -0.07637959  0.63138021]
[444.   444.     0.75]
[-0.0342356  -0.09129089  0.59207005]
[444.   444.     0.75]
[-0.00354109 -0.1030071   0.60652271]
[444.   444.     0.75]
[ 0.03302446 -0.12664711  0.60341422]
[444.   444.     0.75]
[ 0.07804406 -0.15860044  0.59045495]
[444.   444.     0.75]
[ 0.08556352 -0.18515711  0.60111013]
[444.   444.     0.75]
[ 0.08708645 -0.21631263  0.59770308]
[444.   444.     0.75]
[ 0.10306553 -0.24209458  0.58422841]
[444.   444.     0.75]
[ 0.12654728 -0.2354529   0.57963804]
[444.   444.     0.75]
[ 0.15965487 -0.17832517  0.58391962]
[444.   444.     0.75]
[ 0.19898292 -0.00752022  0.69390879]
[444.   444.     0.75]
[0.21046767 0.12994012 0.77617401]
[444.   444.     0.75]
[0.20984503 0.260758   0.83303136]
[444.   444.     0.75]
[0.2154447  0.39132164 0.86813768]
[444.   444.     0.75]
[0.23255263 0.50250749 0.87531996]
[444.   444.     0.75]
[0.26351992 0.60085841 0.85421796]
[444.   444.     0.75]
[0.33298073 0.69929513 0.8707561 ]
[444.   444.     0.75]
[0.44711673 0.7743173  0.9577045 ]
[444.   444.     0.75]
[0.55042744 0.85177539 1.02090096]
[444.   444.     0.75]
[-0.07012328  0.01241407  0.82359919]
[7.96e+02 7.96e+02 7.50e-01]
[-0.06368294 -0.01029783  0.82260214]
[7.96e+02 7.96e+02 7.50e-01]
[-0.06592902 -0.01132195  0.76723928]
[7.96e+02 7.96e+02 7.50e-01]
[-0.08259084 -0.01118302  0.69613894]
[7.96e+02 7.96e+02 7.50e-01]
[-0.13425706  0.02082866  0.65023595]
[7.96e+02 7.96e+02 7.50e-01]
[-0.14587259  0.02252542  0.63086869]
[7.96e+02 7.96e+02 7.50e-01]
[-0.14423624  0.00482452  0.61731621]
[7.96e+02 7.96e+02 7.50e-01]
[-0.13484383 -0.01272524  0.58135804]
[7.96e+02 7.96e+02 7.50e-01]
[-0.11539717 -0.04142654  0.54983677]
[7.96e+02 7.96e+02 7.50e-01]
[-0.08328702 -0.09453283  0.60143426]
[7.96e+02 7.96e+02 7.50e-01]
[-0.03773232 -0.13357924  0.62998879]
[7.96e+02 7.96e+02 7.50e-01]
[ 0.01102577 -0.15212843  0.64018609]
[7.96e+02 7.96e+02 7.50e-01]
[ 0.04337343 -0.17486173  0.6291529 ]
[7.96e+02 7.96e+02 7.50e-01]
[ 0.07803707 -0.19927302  0.59128955]
[7.96e+02 7.96e+02 7.50e-01]
[ 0.10722381 -0.2504905   0.56200006]
[7.96e+02 7.96e+02 7.50e-01]
[ 0.11929635 -0.34307021  0.57065562]
[7.96e+02 7.96e+02 7.50e-01]
[ 0.11134343 -0.44878426  0.61643071]
[7.96e+02 7.96e+02 7.50e-01]
[ 0.09382063 -0.53237375  0.64854706]
[7.96e+02 7.96e+02 7.50e-01]
[ 0.06723513 -0.60912085  0.66921661]
[7.96e+02 7.96e+02 7.50e-01]
[ 0.04294296 -0.68689833  0.70319674]
[7.96e+02 7.96e+02 7.50e-01]
[ 0.01019899 -0.72774943  0.78775361]
[7.96e+02 7.96e+02 7.50e-01]
[-0.0311358  -0.74445749  0.92921533]
[7.96e+02 7.96e+02 7.50e-01]
[-0.06010323 -0.75854108  1.0429543 ]
[7.96e+02 7.96e+02 7.50e-01]
[0.06378991 0.04372318 0.71712747]
[212.   212.     0.75]
[0.05583626 0.04387005 0.70866981]
[212.   212.     0.75]
[0.06798962 0.04286105 0.66790639]
[212.   212.     0.75]
[0.11020059 0.046457   0.65938513]
[212.   212.     0.75]
[0.18021864 0.05312627 0.68920391]
[212.   212.     0.75]
[0.25377719 0.05499433 0.68752707]
[212.   212.     0.75]
[0.32172722 0.04694056 0.65377159]
[212.   212.     0.75]
[0.35902813 0.03428145 0.61046065]
[212.   212.     0.75]
[0.36138219 0.0246101  0.64333917]
[212.   212.     0.75]
[0.35911492 0.00667681 0.72371664]
[212.   212.     0.75]
[ 0.35453274 -0.00726591  0.78881553]
[212.   212.     0.75]
[ 0.32432411 -0.01821093  0.84184586]
[212.   212.     0.75]
[ 0.28530008 -0.03167432  0.86718699]
[212.   212.     0.75]
[ 0.24960881 -0.03214955  0.85952823]
[212.   212.     0.75]
[ 0.22525367 -0.03271658  0.82988367]
[212.   212.     0.75]
[ 0.20623019 -0.03995838  0.78343533]
[212.   212.     0.75]
[ 0.18809535 -0.05147561  0.70749586]
[212.   212.     0.75]
[ 0.17967131 -0.05103859  0.62596281]
[212.   212.     0.75]
[ 0.16570617 -0.01756319  0.61219403]
[212.   212.     0.75]
[0.11588961 0.04764879 0.7393226 ]
[212.   212.     0.75]
[0.05636832 0.10515628 0.83796444]
[212.   212.     0.75]
[-0.00771446  0.15541493  0.90957183]
[212.   212.     0.75]
[-0.05424201  0.22083493  0.95556238]
[212.   212.     0.75]
[-0.08900006  0.3063108   0.97422598]
[212.   212.     0.75]
[-0.12154649  0.39286936  0.96632227]
[212.   212.     0.75]
[-0.16665508  0.45817315  0.93014764]
[212.   212.     0.75]
[-0.20809227  0.50138536  0.87000046]
[212.   212.     0.75]
[-0.25581609  0.54149439  0.79450891]
[212.   212.     0.75]
[-0.31044956  0.57209565  0.70427369]
[212.   212.     0.75]
[-0.32355986  0.58515692  0.6256277 ]
[212.   212.     0.75]
[-0.29392743  0.60946447  0.56272152]
[212.   212.     0.75]
[-0.25387682  0.67129586  0.57629677]
[212.   212.     0.75]
[-0.19715045  0.75571736  0.60482406]
[212.   212.     0.75]
[-0.14204545  0.85022816  0.60416377]
[212.   212.     0.75]
[-0.11293379  0.9283807   0.59073685]
[212.   212.     0.75]
[-0.10218611  0.985339    0.58090516]
[212.   212.     0.75]
[-0.09136418  0.9996057   0.56994508]
[212.   212.     0.75]
[-0.08859824  0.97052292  0.59155897]
[212.   212.     0.75]
[-0.06030799  0.95735341  0.60880886]
[212.   212.     0.75]
[-0.02449428  0.94256638  0.5975684 ]
[212.   212.     0.75]
[0.02506196 0.94482036 0.58204821]
[212.   212.     0.75]
[0.09453533 0.97094262 0.68312016]
[212.   212.     0.75]
[0.1388997  0.99363295 0.80127301]
[212.   212.     0.75]
[0.18016407 1.01931672 0.89062505]
[212.   212.     0.75]
[0.2176267  1.03832315 0.95353542]
[212.   212.     0.75]
[0.25176292 1.04846424 0.99504366]
[212.   212.     0.75]
[0.28929736 1.05771819 1.00821127]
[212.   212.     0.75]
----------------------------------
| forward_vel        | 0.972     |
| reward             | -3.21e+05 |
| reward_contact     | -0.000333 |
| reward_ctrl        | -1.38     |
| reward_position    | -3.21e+05 |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 134       |
|    ep_rew_mean     | -1.64e+07 |
| time/              |           |
|    episodes        | 12        |
|    fps             | 64        |
|    time_elapsed    | 24        |
|    total timesteps | 1609      |
----------------------------------
[0.09465811 0.02695066 0.686682  ]
[642.   642.     0.75]
[0.08769646 0.03662046 0.67512329]
[642.   642.     0.75]
[0.07032849 0.04022683 0.64612217]
[642.   642.     0.75]
[0.02789432 0.02331109 0.6155813 ]
[642.   642.     0.75]
[-0.01230193  0.02292101  0.58024667]
[642.   642.     0.75]
[-0.04244455  0.05514313  0.5473212 ]
[642.   642.     0.75]
[-0.07387245  0.0918817   0.49924566]
[642.   642.     0.75]
[-0.10151371  0.09038799  0.59191854]
[642.   642.     0.75]
[-0.14094385  0.06534454  0.71653025]
[642.   642.     0.75]
[-0.17085966  0.04806278  0.81419912]
[642.   642.     0.75]
[-0.19092064  0.04368918  0.90109916]
[642.   642.     0.75]
[-0.21728533  0.03483851  0.99355416]
[642.   642.     0.75]
[-0.2279834   0.05213509  1.24866796]
[642.   642.     0.75]
[0.04453973 0.00627096 0.74206524]
[8.52e+02 8.52e+02 7.50e-01]
[0.0409272  0.02884966 0.73688138]
[8.52e+02 8.52e+02 7.50e-01]
[0.03256296 0.02745599 0.6948767 ]
[8.52e+02 8.52e+02 7.50e-01]
[ 0.01302749 -0.02605429  0.7036777 ]
[8.52e+02 8.52e+02 7.50e-01]
[ 0.00088485 -0.08123463  0.68827417]
[8.52e+02 8.52e+02 7.50e-01]
[-0.01240755 -0.12901212  0.6574855 ]
[8.52e+02 8.52e+02 7.50e-01]
[-0.04250176 -0.13114434  0.65554594]
[8.52e+02 8.52e+02 7.50e-01]
[-0.05663036 -0.13007658  0.6705288 ]
[8.52e+02 8.52e+02 7.50e-01]
[-0.07274141 -0.12417155  0.65849946]
[8.52e+02 8.52e+02 7.50e-01]
[-0.09218131 -0.12039053  0.61097423]
[8.52e+02 8.52e+02 7.50e-01]
[-0.12918801 -0.11311685  0.56609313]
[8.52e+02 8.52e+02 7.50e-01]
[-0.15225131 -0.10046654  0.53757472]
[8.52e+02 8.52e+02 7.50e-01]
[-0.15512907 -0.07236193  0.68282299]
[8.52e+02 8.52e+02 7.50e-01]
[-0.16496944 -0.04838112  0.82344492]
[8.52e+02 8.52e+02 7.50e-01]
[-0.17584648 -0.0130991   0.93340946]
[8.52e+02 8.52e+02 7.50e-01]
[-0.19474041  0.02971955  1.01779408]
[8.52e+02 8.52e+02 7.50e-01]
[ 0.07998218 -0.07979329  0.7917533 ]
[260.   260.     0.75]
[ 0.08056545 -0.06385004  0.78174532]
[260.   260.     0.75]
[ 0.07906173 -0.05497305  0.73474221]
[260.   260.     0.75]
[ 0.09845494 -0.05216454  0.68901562]
[260.   260.     0.75]
[ 0.14465525 -0.0358392   0.66267874]
[260.   260.     0.75]
[ 0.19657968 -0.01786435  0.62950363]
[260.   260.     0.75]
[ 0.2315462  -0.01018284  0.58955496]
[260.   260.     0.75]
[0.25300338 0.00220041 0.55830396]
[260.   260.     0.75]
[0.26488726 0.02073843 0.51780761]
[260.   260.     0.75]
[0.26459621 0.03451954 0.47827199]
[260.   260.     0.75]
[0.24543261 0.01411934 0.52961019]
[260.   260.     0.75]
[ 0.21027268 -0.01864338  0.58365959]
[260.   260.     0.75]
[ 0.17213652 -0.06173728  0.62163933]
[260.   260.     0.75]
[ 0.1614632  -0.09178162  0.68128353]
[260.   260.     0.75]
[ 0.17375447 -0.11319293  0.73659884]
[260.   260.     0.75]
[ 0.190182   -0.12092583  0.76923788]
[260.   260.     0.75]
[ 0.19647962 -0.13438727  0.78280083]
[260.   260.     0.75]
[ 0.18615418 -0.15380215  0.78820974]
[260.   260.     0.75]
[ 0.16378212 -0.15398894  0.79213804]
[260.   260.     0.75]
[ 0.14886714 -0.14423504  0.77864326]
[260.   260.     0.75]
[ 0.14348107 -0.12248706  0.78132438]
[260.   260.     0.75]
[ 0.12159955 -0.10642754  0.78045217]
[260.   260.     0.75]
[ 0.08842938 -0.09856118  0.78214081]
[260.   260.     0.75]
[ 0.06635219 -0.08118255  0.76193631]
[260.   260.     0.75]
[ 0.04265023 -0.06348575  0.72314448]
[260.   260.     0.75]
[ 0.01173825 -0.04015409  0.7027044 ]
[260.   260.     0.75]
[-0.01015838 -0.02882302  0.68137673]
[260.   260.     0.75]
[-0.02899524  0.00573841  0.66378246]
[260.   260.     0.75]
[-0.05204558  0.09149665  0.67858715]
[260.   260.     0.75]
[-0.07343967  0.17751838  0.67019119]
[260.   260.     0.75]
[-0.09183938  0.26655983  0.64610626]
[260.   260.     0.75]
[-0.12363899  0.36963362  0.62062199]
[260.   260.     0.75]
[-0.14929205  0.48769423  0.58337302]
[260.   260.     0.75]
[-0.15653571  0.61867228  0.56393575]
[260.   260.     0.75]
[-0.16221483  0.6693328   0.5813382 ]
[260.   260.     0.75]
[-0.16423449  0.70039775  0.59973134]
[260.   260.     0.75]
[-0.13937692  0.70000286  0.64277192]
[260.   260.     0.75]
[-0.1152892   0.71778375  0.6598523 ]
[260.   260.     0.75]
[-0.09618639  0.73398902  0.66221157]
[260.   260.     0.75]
[-0.08941042  0.74563478  0.63296109]
[260.   260.     0.75]
[-0.08877248  0.75934201  0.5807625 ]
[260.   260.     0.75]
[-0.08261203  0.78407448  0.51337931]
[260.   260.     0.75]
[-0.06302572  0.80743285  0.48573199]
[260.   260.     0.75]
[-0.03561755  0.78634775  0.52784464]
[260.   260.     0.75]
[-0.01738053  0.76309149  0.55228308]
[260.   260.     0.75]
[0.00986815 0.74714117 0.56709903]
[260.   260.     0.75]
[0.03850547 0.73386778 0.56484641]
[260.   260.     0.75]
[0.04717627 0.72951091 0.58766537]
[260.   260.     0.75]
[0.0220593  0.71196717 0.68146785]
[260.   260.     0.75]
[0.00129381 0.68988137 0.74711677]
[260.   260.     0.75]
[-0.01440436  0.67856507  0.79664428]
[260.   260.     0.75]
[-0.03752466  0.68120551  0.84719838]
[260.   260.     0.75]
[-0.06582485  0.67616725  0.87759128]
[260.   260.     0.75]
[-0.09264772  0.65536669  0.88552193]
[260.   260.     0.75]
[-0.11447124  0.63734585  0.87483734]
[260.   260.     0.75]
[-0.11236758  0.65736098  0.89516999]
[260.   260.     0.75]
[-0.08771752  0.69508295  0.95425622]
[260.   260.     0.75]
[-0.05993213  0.72766443  0.99668685]
[260.   260.     0.75]
[-0.03304719  0.75798435  1.01684923]
[260.   260.     0.75]
[ 0.05301699 -0.03752007  0.77643913]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.03633345 -0.00377412  0.76440303]
[9.6e+02 9.6e+02 7.5e-01]
[0.03282304 0.02219589 0.73029553]
[9.6e+02 9.6e+02 7.5e-01]
[0.04892163 0.040178   0.68547264]
[9.6e+02 9.6e+02 7.5e-01]
[0.0947007  0.07800247 0.64845138]
[9.6e+02 9.6e+02 7.5e-01]
[0.10565148 0.0867332  0.62213697]
[9.6e+02 9.6e+02 7.5e-01]
[0.08186699 0.07034006 0.61632088]
[9.6e+02 9.6e+02 7.5e-01]
[0.05766936 0.04586642 0.61224837]
[9.6e+02 9.6e+02 7.5e-01]
[0.03749621 0.02869705 0.59891788]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.02693892 -0.00237668  0.61935677]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.03044397 -0.05522045  0.66430485]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.03346892 -0.11237577  0.68105798]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.04475359 -0.14188404  0.69614121]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.0489367  -0.16236514  0.69189366]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.05198352 -0.16514393  0.6901132 ]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.04713362 -0.16776897  0.68312539]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.03862251 -0.19940225  0.64527664]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.02207603 -0.2221076   0.59491231]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.00747042 -0.2545225   0.5869348 ]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.01468666 -0.31331528  0.64024758]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.05212516 -0.37498619  0.69045417]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.08865185 -0.42919018  0.7153003 ]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.12904119 -0.47232084  0.719488  ]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.17143896 -0.51393662  0.71759409]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.20489729 -0.5577359   0.68857004]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.21224625 -0.59876733  0.67478999]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.19124496 -0.64205088  0.75777553]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.161518   -0.68418318  0.8216332 ]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.13222    -0.73148435  0.85745546]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.10631449 -0.77813908  0.86537657]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.08796686 -0.83084744  0.85137251]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.08213274 -0.87273932  0.83017975]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.12406012 -0.87242303  0.90272157]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.18209214 -0.86618274  0.99503722]
[9.6e+02 9.6e+02 7.5e-01]
[ 0.23660374 -0.86259029  1.06064467]
[9.6e+02 9.6e+02 7.5e-01]
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 108       |
|    ep_rew_mean     | -1.89e+07 |
| time/              |           |
|    episodes        | 16        |
|    fps             | 65        |
|    time_elapsed    | 26        |
|    total timesteps | 1732      |
----------------------------------
[-0.04589726  0.03484538  0.70937669]
[94.   94.    0.75]
[-0.04350849  0.0247612   0.69507702]
[94.   94.    0.75]
[-0.05022263  0.02371299  0.64892045]
[94.   94.    0.75]
[-0.05055824  0.06074653  0.63425882]
[94.   94.    0.75]
[-0.04361528  0.11557596  0.62045213]
[94.   94.    0.75]
[-0.05577458  0.15811917  0.59188946]
[94.   94.    0.75]
[-0.05793197  0.17836997  0.55723144]
[94.   94.    0.75]
[-0.04427582  0.17936163  0.52750462]
[94.   94.    0.75]
[-0.0220299   0.1828889   0.48516506]
[94.   94.    0.75]
[0.02346535 0.20162054 0.57326784]
[94.   94.    0.75]
[0.06236734 0.22825785 0.6543259 ]
[94.   94.    0.75]
[0.10069826 0.23366283 0.71124152]
[94.   94.    0.75]
[0.12580654 0.25829111 0.74157272]
[94.   94.    0.75]
[0.15012254 0.27982289 0.74512296]
[94.   94.    0.75]
[0.17497989 0.27770473 0.72588356]
[94.   94.    0.75]
[0.20791101 0.26040941 0.69958133]
[94.   94.    0.75]
[0.23085207 0.23446993 0.69616111]
[94.   94.    0.75]
[0.23178025 0.20288679 0.67357759]
[94.   94.    0.75]
[0.23579433 0.1731379  0.61997923]
[94.   94.    0.75]
[0.24228752 0.2022261  0.64671286]
[94.   94.    0.75]
[0.24618396 0.25331192 0.66777857]
[94.   94.    0.75]
[0.26297289 0.30143293 0.66836302]
[94.   94.    0.75]
[0.29517172 0.35461358 0.65461398]
[94.   94.    0.75]
[0.33545692 0.4126499  0.66078442]
[94.   94.    0.75]
[0.3714507  0.47174661 0.70477137]
[94.   94.    0.75]
[0.38352469 0.53770381 0.72174152]
[94.   94.    0.75]
[0.38712679 0.60529382 0.72932144]
[94.   94.    0.75]
[0.36655129 0.63489833 0.78155743]
[94.   94.    0.75]
[0.32441908 0.63738854 0.85060388]
[94.   94.    0.75]
[0.28183234 0.63560383 0.90521215]
[94.   94.    0.75]
[0.25281695 0.62455732 0.93501791]
[94.   94.    0.75]
[0.22695137 0.61697293 0.95095949]
[94.   94.    0.75]
[0.21166052 0.61910564 0.93237137]
[94.   94.    0.75]
[0.19986586 0.61341887 0.90685767]
[94.   94.    0.75]
[0.16022515 0.59619368 0.89967299]
[94.   94.    0.75]
[0.10946878 0.57288321 0.87541974]
[94.   94.    0.75]
[0.04934914 0.54979578 0.83711102]
[94.   94.    0.75]
[-0.0347653   0.52561271  0.80997057]
[94.   94.    0.75]
[-0.11483926  0.51044901  0.75278433]
[94.   94.    0.75]
[-0.19686856  0.50440884  0.6798771 ]
[94.   94.    0.75]
[-0.23963935  0.59885178  0.74408221]
[94.   94.    0.75]
[-0.26989529  0.70746129  0.81875449]
[94.   94.    0.75]
[-0.29677391  0.80472218  0.86569055]
[94.   94.    0.75]
[-0.33942689  0.90001555  0.88604023]
[94.   94.    0.75]
[-0.38628313  0.99683146  0.88534516]
[94.   94.    0.75]
[-0.42469599  1.10495786  0.85549739]
[94.   94.    0.75]
[-0.46183452  1.20922009  0.80147019]
[94.   94.    0.75]
[-0.5013684   1.31747475  0.72408087]
[94.   94.    0.75]
[-0.53572156  1.44269085  0.63868001]
[94.   94.    0.75]
[-0.53825825  1.54811613  0.55737379]
[94.   94.    0.75]
[-0.52528248  1.56278162  0.55108276]
[94.   94.    0.75]
[-0.52482944  1.58272019  0.53519952]
[94.   94.    0.75]
[-0.51164367  1.6135108   0.52117328]
[94.   94.    0.75]
[-0.47573054  1.66349626  0.52530674]
[94.   94.    0.75]
[-0.41954229  1.71708239  0.52590951]
[94.   94.    0.75]
[-0.3447893   1.76346372  0.61031401]
[94.   94.    0.75]
[-0.2816904   1.79366512  0.67716967]
[94.   94.    0.75]
[-0.22538415  1.81716352  0.72493887]
[94.   94.    0.75]
[-0.17380745  1.84438224  0.75151225]
[94.   94.    0.75]
[-0.11465684  1.86421718  0.75619281]
[94.   94.    0.75]
[-0.09746827  1.86183943  0.79192063]
[94.   94.    0.75]
[-0.09674311  1.85861738  0.82132783]
[94.   94.    0.75]
[-0.09893188  1.86905261  0.82010734]
[94.   94.    0.75]
[-0.11843199  1.88763564  0.80045072]
[94.   94.    0.75]
[-0.12834494  1.88983643  0.77000192]
[94.   94.    0.75]
[-0.13992546  1.89235879  0.73595983]
[94.   94.    0.75]
[-0.1605904   1.87846439  0.68821502]
[94.   94.    0.75]
[-0.17644013  1.85749408  0.61476898]
[94.   94.    0.75]
[-0.18398352  1.83773211  0.53229343]
[94.   94.    0.75]
[-0.17533488  1.81146342  0.57233316]
[94.   94.    0.75]
[-0.18507218  1.77528436  0.64203894]
[94.   94.    0.75]
[-0.1954223   1.73582074  0.68582502]
[94.   94.    0.75]
[-0.20346227  1.69114238  0.70315703]
[94.   94.    0.75]
[-0.20923791  1.65185505  0.69908289]
[94.   94.    0.75]
[-0.18667262  1.62695633  0.70115071]
[94.   94.    0.75]
[-0.15816251  1.59236048  0.68122269]
[94.   94.    0.75]
[-0.12698395  1.55866659  0.64183327]
[94.   94.    0.75]
[-0.09455422  1.53758573  0.60585277]
[94.   94.    0.75]
[-0.07729201  1.5099038   0.59280664]
[94.   94.    0.75]
[-0.06103825  1.47351734  0.62703697]
[94.   94.    0.75]
[-0.03857438  1.43825912  0.68423505]
[94.   94.    0.75]
[-0.00875534  1.4123486   0.71865161]
[94.   94.    0.75]
[0.01223343 1.39360651 0.72507128]
[94.   94.    0.75]
[0.01789659 1.36170398 0.70360122]
[94.   94.    0.75]
[0.01982803 1.31150596 0.66692483]
[94.   94.    0.75]
[0.01292878 1.22477997 0.66042863]
[94.   94.    0.75]
[-0.01166938  1.1235349   0.66352759]
[94.   94.    0.75]
[-0.03613241  1.04328048  0.65103592]
[94.   94.    0.75]
[-0.03588592  0.9598409   0.64011918]
[94.   94.    0.75]
[-0.0202102   0.88460904  0.62480736]
[94.   94.    0.75]
[-0.01346583  0.82602008  0.58893293]
[94.   94.    0.75]
[-0.03993373  0.83857805  0.62747233]
[94.   94.    0.75]
[-0.0657079   0.88717021  0.69046172]
[94.   94.    0.75]
[-0.07826549  0.92948037  0.74458552]
[94.   94.    0.75]
[-0.08863543  0.97005193  0.7848825 ]
[94.   94.    0.75]
[-0.10740234  1.01538661  0.79788315]
[94.   94.    0.75]
[-0.12862414  1.05010536  0.78099676]
[94.   94.    0.75]
[-0.13366502  1.06602648  0.74236553]
[94.   94.    0.75]
[-0.14539574  1.07227336  0.69070481]
[94.   94.    0.75]
[-0.15631167  1.09473233  0.61990728]
[94.   94.    0.75]
[-0.14589539  1.11526115  0.57890258]
[94.   94.    0.75]
[-0.07819652  1.11525319  0.64339047]
[94.   94.    0.75]
[-0.00897292  1.11924587  0.69133385]
[94.   94.    0.75]
[0.06062174 1.11996168 0.71771407]
[94.   94.    0.75]
[0.11057123 1.11397415 0.71641609]
[94.   94.    0.75]
[0.14529462 1.11151446 0.70265806]
[94.   94.    0.75]
[0.1641773  1.12740116 0.71256464]
[94.   94.    0.75]
[0.18128716 1.15468566 0.73385542]
[94.   94.    0.75]
[0.19542141 1.17441412 0.73047516]
[94.   94.    0.75]
[0.2264973  1.19694245 0.69889911]
[94.   94.    0.75]
[0.2734674  1.21184094 0.64432446]
[94.   94.    0.75]
[0.3108034  1.22454946 0.58828452]
[94.   94.    0.75]
[0.34664833 1.18727452 0.60172573]
[94.   94.    0.75]
[0.39290733 1.15150337 0.59858305]
[94.   94.    0.75]
[0.44038568 1.11804272 0.58204897]
[94.   94.    0.75]
[0.47076971 1.06892695 0.57500381]
[94.   94.    0.75]
[0.50508116 1.0212149  0.55046756]
[94.   94.    0.75]
[0.55021788 0.98538944 0.54634511]
[94.   94.    0.75]
[0.57911073 0.96377503 0.55635408]
[94.   94.    0.75]
[0.60093357 0.94530894 0.53636359]
[94.   94.    0.75]
[0.62507779 0.92001674 0.49696007]
[94.   94.    0.75]
[0.66525115 0.88383555 0.44195271]
[94.   94.    0.75]
[0.70700683 0.83550306 0.51798007]
[94.   94.    0.75]
[0.7463589  0.80219328 0.63262262]
[94.   94.    0.75]
[0.78389501 0.76288823 0.72206566]
[94.   94.    0.75]
[0.81548195 0.728461   0.78670931]
[94.   94.    0.75]
[0.8423535  0.70031087 0.83043564]
[94.   94.    0.75]
[0.86385679 0.65773703 0.85105799]
[94.   94.    0.75]
[0.9024901  0.6034515  0.84677105]
[94.   94.    0.75]
[0.93968659 0.54436464 0.82387377]
[94.   94.    0.75]
[0.9680914  0.47348089 0.77926483]
[94.   94.    0.75]
[0.98854864 0.35818857 0.76432942]
[94.   94.    0.75]
[1.04238914 0.26708408 0.75728951]
[94.   94.    0.75]
[1.10560545 0.18952306 0.73615133]
[94.   94.    0.75]
[1.16120992 0.10267587 0.70056374]
[94.   94.    0.75]
[1.19536057 0.04011739 0.66406827]
[94.   94.    0.75]
[1.228767   0.03886794 0.68362083]
[94.   94.    0.75]
[1.27463268 0.03406609 0.67654279]
[94.   94.    0.75]
[1.32259421 0.02919655 0.64220216]
[94.   94.    0.75]
[ 1.34921275 -0.01016058  0.62559209]
[94.   94.    0.75]
[ 1.37150437 -0.06331159  0.5973425 ]
[94.   94.    0.75]
[ 1.38672913 -0.12378254  0.57470156]
[94.   94.    0.75]
[ 1.38723086 -0.17868344  0.57751453]
[94.   94.    0.75]
[ 1.34512961 -0.18365856  0.63208679]
[94.   94.    0.75]
[ 1.303206   -0.19397407  0.67144729]
[94.   94.    0.75]
[ 1.26724374 -0.20478257  0.69113325]
[94.   94.    0.75]
[ 1.23550183 -0.20431915  0.69516236]
[94.   94.    0.75]
[ 1.22677349 -0.1880756   0.66864309]
[94.   94.    0.75]
[ 1.23741657 -0.16686859  0.63249585]
[94.   94.    0.75]
[ 1.25248924 -0.13397799  0.61022442]
[94.   94.    0.75]
[ 1.23201791 -0.15172392  0.60961708]
[94.   94.    0.75]
[ 1.20455928 -0.18247973  0.59392053]
[94.   94.    0.75]
[ 1.165544   -0.21250013  0.55431855]
[94.   94.    0.75]
[ 1.14397815 -0.22096682  0.52109894]
[94.   94.    0.75]
[ 1.11744787 -0.21530878  0.54012575]
[94.   94.    0.75]
[ 1.07726084 -0.20867321  0.55750993]
[94.   94.    0.75]
[ 1.04802213 -0.22338776  0.58485241]
[94.   94.    0.75]
[ 1.02586188 -0.24019724  0.65653626]
[94.   94.    0.75]
[ 0.99631897 -0.27554467  0.70403363]
[94.   94.    0.75]
[ 0.95470685 -0.30571354  0.72269474]
[94.   94.    0.75]
[ 0.90602514 -0.32424128  0.7313509 ]
[94.   94.    0.75]
[ 0.84963576 -0.33557847  0.72579503]
[94.   94.    0.75]
[ 0.81110238 -0.32659764  0.6995674 ]
[94.   94.    0.75]
[ 0.78325528 -0.33095566  0.64368745]
[94.   94.    0.75]
[ 0.76451001 -0.34948044  0.5693058 ]
[94.   94.    0.75]
[ 0.77715775 -0.36663855  0.56515636]
[94.   94.    0.75]
[ 0.82626865 -0.42735699  0.72783317]
[94.   94.    0.75]
[ 0.85691279 -0.49780662  0.87672888]
[94.   94.    0.75]
[ 0.87958793 -0.57152004  0.99961648]
[94.   94.    0.75]
[ 0.91080492 -0.63564984  1.10355615]
[94.   94.    0.75]
[0.02793334 0.05248868 0.70619317]
[524.   524.     0.75]
[0.02179143 0.05868407 0.69594849]
[524.   524.     0.75]
[0.02622286 0.05977115 0.66640219]
[524.   524.     0.75]
[0.01237903 0.06477948 0.65305989]
[524.   524.     0.75]
[-0.03909377  0.10220258  0.67940394]
[524.   524.     0.75]
[-0.09176601  0.14821463  0.6830214 ]
[524.   524.     0.75]
[-0.10804715  0.18710701  0.66037041]
[524.   524.     0.75]
[-0.12917619  0.24018797  0.62531792]
[524.   524.     0.75]
[-0.16696198  0.29965242  0.5737891 ]
[524.   524.     0.75]
[-0.18065962  0.36470069  0.57823935]
[524.   524.     0.75]
[-0.22782522  0.41669106  0.69671293]
[524.   524.     0.75]
[-0.2614966   0.44121923  0.82122589]
[524.   524.     0.75]
[-0.28736696  0.46826979  0.91451942]
[524.   524.     0.75]
[-0.28995007  0.51355385  0.98478291]
[524.   524.     0.75]
[-0.28493557  0.55979127  1.03414419]
[524.   524.     0.75]
[ 0.03942513 -0.09054098  0.83213646]
[312.   312.     0.75]
[ 0.0464391  -0.09458739  0.83346195]
[312.   312.     0.75]
[ 0.05760024 -0.08201248  0.79015267]
[312.   312.     0.75]
[ 0.06603488 -0.06960099  0.71624378]
[312.   312.     0.75]
[ 0.03314929 -0.09830366  0.66895045]
[312.   312.     0.75]
[-0.03050688 -0.13155329  0.63085887]
[312.   312.     0.75]
[-0.09797865 -0.15296333  0.59289659]
[312.   312.     0.75]
[-0.15918538 -0.15818021  0.56366611]
[312.   312.     0.75]
[-0.20004191 -0.17584962  0.54334174]
[312.   312.     0.75]
[-0.21773744 -0.18077884  0.51727426]
[312.   312.     0.75]
[-0.22701504 -0.19055986  0.47852769]
[312.   312.     0.75]
[-0.20125001 -0.26418646  0.52994143]
[312.   312.     0.75]
[-0.14814442 -0.31214234  0.64194994]
[312.   312.     0.75]
[-0.11718035 -0.34326847  0.73427328]
[312.   312.     0.75]
[-0.08797448 -0.37505906  0.80410245]
[312.   312.     0.75]
[-0.05775416 -0.41250398  0.84543546]
[312.   312.     0.75]
[-0.04053163 -0.45587157  0.85767307]
[312.   312.     0.75]
[-0.03680172 -0.49241553  0.84306683]
[312.   312.     0.75]
[-0.02010467 -0.534314    0.81521521]
[312.   312.     0.75]
[ 0.03219457 -0.57745616  0.80583108]
[312.   312.     0.75]
[ 0.08642304 -0.61446706  0.78776265]
[312.   312.     0.75]
[ 0.1467561  -0.64122828  0.78177923]
[312.   312.     0.75]
[ 0.18588537 -0.66958726  0.781364  ]
[312.   312.     0.75]
[ 0.22564466 -0.69477342  0.75807054]
[312.   312.     0.75]
[ 0.26349359 -0.72201797  0.71702443]
[312.   312.     0.75]
[ 0.30307525 -0.7532369   0.66369504]
[312.   312.     0.75]
[ 0.35656821 -0.80018741  0.69016143]
[312.   312.     0.75]
[ 0.41542986 -0.84767296  0.77178444]
[312.   312.     0.75]
[ 0.48563199 -0.8893836   0.82804101]
[312.   312.     0.75]
[ 0.57038823 -0.93244589  0.8636727 ]
[312.   312.     0.75]
[ 0.64705211 -0.98140028  0.87904386]
[312.   312.     0.75]
[ 0.71676728 -1.03308692  0.83900273]
[312.   312.     0.75]
[ 0.78701792 -1.0784909   0.76331347]
[312.   312.     0.75]
[ 0.8641357  -1.12072444  0.66349445]
[312.   312.     0.75]
[ 0.93640123 -1.17616734  0.58501346]
[312.   312.     0.75]
[ 0.98771791 -1.25229712  0.51174526]
[312.   312.     0.75]
[ 1.00722171 -1.34592456  0.46712558]
[312.   312.     0.75]
[ 1.02494153 -1.4395617   0.43489549]
[312.   312.     0.75]
[ 1.05632785 -1.51811577  0.41022595]
[312.   312.     0.75]
[ 1.09157254 -1.60373522  0.36799393]
[312.   312.     0.75]
[ 1.11659127 -1.6911681   0.29532891]
[312.   312.     0.75]
[ 1.1403395  -1.756226    0.24806732]
[312.   312.     0.75]
[ 1.16039351 -1.80299837  0.28333723]
[312.   312.     0.75]
[ 1.17856151 -1.84457546  0.31423566]
[312.   312.     0.75]
[ 1.18811685 -1.88967984  0.3451298 ]
[312.   312.     0.75]
[ 1.17883421 -1.93341889  0.38978947]
[312.   312.     0.75]
[ 1.16774976 -1.9800372   0.4220738 ]
[312.   312.     0.75]
[ 1.14670212 -2.02374544  0.45190656]
[312.   312.     0.75]
[ 1.0985684  -2.02277176  0.522759  ]
[312.   312.     0.75]
[ 1.06214962 -2.00883629  0.57519893]
[312.   312.     0.75]
[ 1.01397553 -1.98526642  0.61008362]
[312.   312.     0.75]
[ 0.95886057 -1.96799748  0.61459396]
[312.   312.     0.75]
[ 0.90186379 -1.95391229  0.59865798]
[312.   312.     0.75]
[ 0.84598888 -1.93574108  0.57171486]
[312.   312.     0.75]
[ 0.78862076 -1.92020257  0.53096788]
[312.   312.     0.75]
[ 0.74769568 -1.87668882  0.50858787]
[312.   312.     0.75]
[ 0.72054769 -1.80542644  0.46378024]
[312.   312.     0.75]
[ 0.64557837 -1.76115705  0.46499117]
[312.   312.     0.75]
[ 0.56866146 -1.72347977  0.46295024]
[312.   312.     0.75]
[ 0.48721532 -1.68856865  0.43721691]
[312.   312.     0.75]
[ 0.41733469 -1.66827159  0.39350464]
[312.   312.     0.75]
[ 0.35400665 -1.64262167  0.3304765 ]
[312.   312.     0.75]
[ 0.30622504 -1.59981204  0.27151601]
[312.   312.     0.75]
[ 0.31373117 -1.56887135  0.28642784]
[312.   312.     0.75]
[ 0.31214978 -1.54790827  0.28555721]
[312.   312.     0.75]
[ 0.3279476  -1.54872424  0.26974678]
[312.   312.     0.75]
[ 0.34117166 -1.55438811  0.25431793]
[312.   312.     0.75]
[ 0.34575566 -1.56381664  0.2746692 ]
[312.   312.     0.75]
[ 0.34244519 -1.5691616   0.28569048]
[312.   312.     0.75]
[ 0.34770698 -1.58771817  0.27630036]
[312.   312.     0.75]
[ 0.37554516 -1.60823682  0.26692954]
[312.   312.     0.75]
[ 0.39606727 -1.60263064  0.2563378 ]
[312.   312.     0.75]
[ 0.41520087 -1.59001223  0.26034307]
[312.   312.     0.75]
[ 0.43492298 -1.57316455  0.25917896]
[312.   312.     0.75]
[ 0.46023576 -1.55897907  0.25959282]
[312.   312.     0.75]
[ 0.50053666 -1.54558423  0.26820803]
[312.   312.     0.75]
[ 0.5263669  -1.53997157  0.28406225]
[312.   312.     0.75]
[ 0.53582313 -1.55441797  0.28381148]
[312.   312.     0.75]
[ 0.53412794 -1.58628442  0.30428589]
[312.   312.     0.75]
[ 0.51585318 -1.5764196   0.32436085]
[312.   312.     0.75]
[ 0.50268409 -1.56127874  0.32232271]
[312.   312.     0.75]
[ 0.48282613 -1.5645429   0.30930958]
[312.   312.     0.75]
[ 0.45412499 -1.59041687  0.29637308]
[312.   312.     0.75]
Num timesteps: 2000
Best mean reward: -inf - Last mean reward per episode: -17445763.35
Saving new best model to rl/out_dir/models/exp66/best_model.zip
[-0.06291762 -0.00580321  0.77645237]
[348.   348.     0.75]
[-0.08004864  0.0165889   0.77582794]
[348.   348.     0.75]
[-0.08851171  0.02213136  0.72602671]
[348.   348.     0.75]
[-0.10135951  0.02485617  0.6628544 ]
[348.   348.     0.75]
[-0.15240214  0.02963685  0.6355963 ]
[348.   348.     0.75]
[-0.19380486  0.06563077  0.61646403]
[348.   348.     0.75]
[-0.23919272  0.10271363  0.59006829]
[348.   348.     0.75]
[-0.28568699  0.13747666  0.56113351]
[348.   348.     0.75]
[-0.30746441  0.14044344  0.56786364]
[348.   348.     0.75]
[-0.31620904  0.13799155  0.57323376]
[348.   348.     0.75]
[-0.31594383  0.13793489  0.57292081]
[348.   348.     0.75]
[-0.30640109  0.1395081   0.56799565]
[348.   348.     0.75]
[-0.2892792   0.14217524  0.55935633]
[348.   348.     0.75]
[-0.29012506  0.14184424  0.56061121]
[348.   348.     0.75]
[-0.29188859  0.14202588  0.56078277]
[348.   348.     0.75]
[-0.29180886  0.14186006  0.56097934]
[348.   348.     0.75]
[-0.29178519  0.14185043  0.56098238]
[348.   348.     0.75]
[-0.29178576  0.14185144  0.56098107]
[348.   348.     0.75]
[-0.29178607  0.1418516   0.560981  ]
[348.   348.     0.75]
[-0.29178607  0.1418516   0.560981  ]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[-0.29178607  0.14185159  0.56098101]
[348.   348.     0.75]
[6.73596732e-02 6.94055086e-05 7.91510257e-01]
[714.   714.     0.75]
[0.05402637 0.00396482 0.77312994]
[714.   714.     0.75]
[ 5.63782653e-02 -8.08727819e-05  7.14833074e-01]
[714.   714.     0.75]
[0.06692934 0.05071853 0.68816194]
[714.   714.     0.75]
[0.07648426 0.10363727 0.6389616 ]
[714.   714.     0.75]
[0.08751294 0.15984739 0.57264236]
[714.   714.     0.75]
[0.10342761 0.17344981 0.55504803]
[714.   714.     0.75]
[0.10251866 0.17211178 0.56017634]
[714.   714.     0.75]
[0.10185886 0.17201977 0.56101767]
[714.   714.     0.75]
[0.10178867 0.17200189 0.56103309]
[714.   714.     0.75]
[0.10179503 0.17200298 0.56102635]
[714.   714.     0.75]
[0.10179579 0.1720034  0.56102649]
[714.   714.     0.75]
[0.10179571 0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Traceback (most recent call last):
  File "ddpg.py", line 199, in <module>
    env = stable_baselines3.common.env_util.make_vec_env(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 102, in make_vec_env
    return vec_env_cls([make_env(i + start_index) for i in range(n_envs)], **vec_env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 77, in _init
    env = gym.make(env_id, **env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 60, in make
    env = cls(**_kwargs)
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 248, in __init__
    super(AntEnvV2, self).__init__(path)
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 83, in __init__
    mujoco_env.MujocoEnv.__init__(self, path, 5)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/mujoco/mujoco_env.py", line 61, in __init__
    self._set_action_space()
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 112, in _set_action_space
    self.desired_motions = self._create_desired_goal_lst()
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 256, in _create_desired_goal_lst
    self.desired_motions.append(np.array([self.xpos[i], self.ypos[i], self.h], dtype = np.float32))
IndexError: index 24 is out of bounds for axis 0 with size 24

[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]
[714.   714.     0.75]
[0.1017957  0.17200337 0.56102652]/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Traceback (most recent call last):
  File "ddpg.py", line 199, in <module>
    env = stable_baselines3.common.env_util.make_vec_env(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 102, in make_vec_env
    return vec_env_cls([make_env(i + start_index) for i in range(n_envs)], **vec_env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 77, in _init
    env = gym.make(env_id, **env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 60, in make
    env = cls(**_kwargs)
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 248, in __init__
    super(AntEnvV2, self).__init__(path)
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 83, in __init__
    mujoco_env.MujocoEnv.__init__(self, path, 5)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/mujoco/mujoco_env.py", line 61, in __init__
    self._set_action_space()
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 112, in _set_action_space
    self.desired_motions = self._create_desired_goal_lst()
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 256, in _create_desired_goal_lst
    self.desired_motions.append(np.array([self.xpos[i], self.ypos[i], self.h], dtype = np.float32))
IndexError: index 24 is out of bounds for axis 0 with size 24
2021-05-27 10:20:46.311716: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 10:20:46.311780: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
[-0.00530006 -0.0048827   0.7706699 ]
[34.1  34.1   0.75]
MultiInputPolicy
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_11
[-0.07828602 -0.02925626  0.85785384]
[32.8  32.8   0.75]
[-0.08649302 -0.03933086  0.8401997 ]
[32.8  32.8   0.75]
[-0.08118449 -0.04128772  0.78457462]
[32.8  32.8   0.75]
[-0.05357215 -0.04976679  0.70687807]
[32.8  32.8   0.75]
[-0.00425251 -0.10464812  0.66372801]
[32.8  32.8   0.75]
[ 0.05001096 -0.16170506  0.59703857]
[32.8  32.8   0.75]
[ 0.10786835 -0.19896552  0.51530367]
[32.8  32.8   0.75]
[ 0.11592911 -0.19969057  0.53308979]
[32.8  32.8   0.75]
[ 0.07936916 -0.20786704  0.65210517]
[32.8  32.8   0.75]
[ 0.04089419 -0.23160587  0.74456707]
[32.8  32.8   0.75]
[ 0.01667086 -0.24578144  0.80897246]
[32.8  32.8   0.75]
[ 0.0161956  -0.25262333  0.8464794 ]
[32.8  32.8   0.75]
[ 0.0066485  -0.24824493  0.87363662]
[32.8  32.8   0.75]
[-0.0140692  -0.25561391  0.88114923]
[32.8  32.8   0.75]
[-0.04049701 -0.25669241  0.8746169 ]
[32.8  32.8   0.75]
[-0.05725049 -0.23124414  0.88280358]
[32.8  32.8   0.75]
[-0.06238834 -0.20681003  0.88546591]
[32.8  32.8   0.75]
[-0.05293352 -0.1710844   0.90940008]
[32.8  32.8   0.75]
[-0.04823873 -0.13103175  0.91041368]
[32.8  32.8   0.75]
[-0.02005718 -0.08948897  0.89671005]
[32.8  32.8   0.75]
[ 0.028736   -0.03550994  0.90731033]
[32.8  32.8   0.75]
[0.08342189 0.02347291 0.90273334]
[32.8  32.8   0.75]
[0.13327885 0.09093006 0.87525671]
[32.8  32.8   0.75]
[0.18528917 0.15782239 0.81991245]
[32.8  32.8   0.75]
[0.23326431 0.20895515 0.73951076]
[32.8  32.8   0.75]
[0.27678745 0.29527275 0.65775675]
[32.8  32.8   0.75]
[0.33489139 0.42471083 0.58949164]
[32.8  32.8   0.75]
[0.38310758 0.51231105 0.60648019]
[32.8  32.8   0.75]
[0.42241124 0.59072626 0.62277981]
[32.8  32.8   0.75]
[0.46304503 0.66019101 0.6247045 ]
[32.8  32.8   0.75]
[0.50808365 0.72779412 0.61844864]
[32.8  32.8   0.75]
[0.55975596 0.78333583 0.5924746 ]
[32.8  32.8   0.75]
[0.60731852 0.82821441 0.54314202]
[32.8  32.8   0.75]
[0.6305323  0.86978952 0.50112635]
[32.8  32.8   0.75]
[0.59429514 0.8955676  0.5394786 ]
[32.8  32.8   0.75]
[0.56475321 0.91582623 0.60552706]
[32.8  32.8   0.75]
[0.54072868 0.94117205 0.65871085]
[32.8  32.8   0.75]
[0.51571691 0.97412693 0.68940308]
[32.8  32.8   0.75]
[0.4923351  1.01412436 0.69212997]
[32.8  32.8   0.75]
[0.47953411 1.04804892 0.66992319]
[32.8  32.8   0.75]
[0.44825371 1.06898283 0.62448857]
[32.8  32.8   0.75]
[0.42604659 1.06071646 0.58909135]
[32.8  32.8   0.75]
[0.39437285 1.03067721 0.54515435]
[32.8  32.8   0.75]
[0.33349492 0.98631235 0.51211782]
[32.8  32.8   0.75]
[0.27463266 0.99582923 0.51749928]
[32.8  32.8   0.75]
[0.26628262 0.99448434 0.58340826]
[32.8  32.8   0.75]
[0.26412069 0.9809793  0.62717249]
[32.8  32.8   0.75]
[0.2522404  0.96423623 0.64504199]
[32.8  32.8   0.75]
[0.23100056 0.94594623 0.63898184]
[32.8  32.8   0.75]
[0.21628562 0.93291432 0.60786556]
[32.8  32.8   0.75]
[0.20824278 0.92737311 0.60728877]
[32.8  32.8   0.75]
[0.22296205 0.91726764 0.64953266]
[32.8  32.8   0.75]
[0.27010414 0.92300385 0.76823358]
[32.8  32.8   0.75]
[0.29403055 0.94937698 0.85058177]
[32.8  32.8   0.75]
[0.31861446 0.96399997 0.91424911]
[32.8  32.8   0.75]
[0.3527183  0.96325532 0.95134477]
[32.8  32.8   0.75]
[0.39299504 0.95646764 0.95835981]
[32.8  32.8   0.75]
[0.43077034 0.95485674 0.94419497]
[32.8  32.8   0.75]
[0.46990606 0.9593028  0.91381287]
[32.8  32.8   0.75]
[0.51362459 0.96807026 0.86121102]
[32.8  32.8   0.75]
[0.55597724 0.97498556 0.77522646]
[32.8  32.8   0.75]
[0.5719863  0.97939432 0.68692282]
[32.8  32.8   0.75]
[0.524819   0.97494453 0.66673995]
[32.8  32.8   0.75]
[0.47098927 0.97707984 0.63998939]
[32.8  32.8   0.75]
[0.42535618 0.96543492 0.62154171]
[32.8  32.8   0.75]
[0.41351392 0.97600834 0.62836084]
[32.8  32.8   0.75]
[0.39645887 0.98756612 0.60744226]
[32.8  32.8   0.75]
[0.374752   0.98986042 0.56862822]
[32.8  32.8   0.75]
[0.35498921 0.97875807 0.5397724 ]
[32.8  32.8   0.75]
[0.3279752  0.98676397 0.50883447]
[32.8  32.8   0.75]
[0.30552289 1.00683207 0.4900708 ]
[32.8  32.8   0.75]
[0.29252184 1.01195427 0.528028  ]
[32.8  32.8   0.75]
[0.28571016 1.02153013 0.56784514]
[32.8  32.8   0.75]
[0.2774555  1.02434642 0.58639102]
[32.8  32.8   0.75]
[0.25785186 1.03673472 0.63038498]
[32.8  32.8   0.75]
[0.24692408 1.05850832 0.66867781]
[32.8  32.8   0.75]
[0.24606942 1.0810319  0.70755733]
[32.8  32.8   0.75]
[0.25793172 1.09582386 0.77976946]
[32.8  32.8   0.75]
[0.27072939 1.11656212 0.82910706]
[32.8  32.8   0.75]
[0.28290236 1.14518655 0.8499277 ]
[32.8  32.8   0.75]
[0.29929187 1.16797057 0.8570955 ]
[32.8  32.8   0.75]
[0.31550424 1.17710317 0.84129644]
[32.8  32.8   0.75]
[0.33214703 1.19566829 0.83096786]
[32.8  32.8   0.75]
[0.34416061 1.21493076 0.80426609]
[32.8  32.8   0.75]
[0.36277001 1.22692971 0.75986892]
[32.8  32.8   0.75]
[0.39556804 1.23660584 0.69696313]
[32.8  32.8   0.75]
[0.43742824 1.25403466 0.60642842]
[32.8  32.8   0.75]
[0.47606612 1.25620181 0.51608032]
[32.8  32.8   0.75]
[0.49496422 1.20285327 0.48773132]
[32.8  32.8   0.75]
[0.51633165 1.15295722 0.49342705]
[32.8  32.8   0.75]
[0.54111171 1.11781556 0.50374491]
[32.8  32.8   0.75]
[0.55508732 1.08648202 0.52717905]
[32.8  32.8   0.75]
[0.55582675 1.0619464  0.5746314 ]
[32.8  32.8   0.75]
[0.54817371 1.04579078 0.62567415]
[32.8  32.8   0.75]
[0.54597014 1.03716612 0.65018568]
[32.8  32.8   0.75]
[0.54857964 1.02869787 0.65508015]
[32.8  32.8   0.75]
[0.55902448 1.01605926 0.63589976]
[32.8  32.8   0.75]
[0.54611671 0.99692304 0.62472903]
[32.8  32.8   0.75]
[0.53776577 0.97765742 0.59914584]
[32.8  32.8   0.75]
[0.54375617 0.93207573 0.59554284]
[32.8  32.8   0.75]
[0.5431183  0.88295948 0.57193654]
[32.8  32.8   0.75]
[0.55347177 0.85002464 0.5323842 ]
[32.8  32.8   0.75]
[0.57144158 0.83064057 0.50028003]
[32.8  32.8   0.75]
[0.61851365 0.80736037 0.55907225]
[32.8  32.8   0.75]
[0.67730665 0.79225147 0.63891215]
[32.8  32.8   0.75]
[0.72812246 0.77666743 0.69335723]
[32.8  32.8   0.75]
[0.7755508  0.75170266 0.71773606]
[32.8  32.8   0.75]
[0.81724386 0.72374083 0.71419849]
[32.8  32.8   0.75]
[0.86051308 0.69441618 0.68669212]
[32.8  32.8   0.75]
[0.9047973  0.66035714 0.63817236]
[32.8  32.8   0.75]
[0.9462767  0.64853572 0.64162138]
[32.8  32.8   0.75]
[1.00147064 0.65682063 0.67632533]
[32.8  32.8   0.75]
[1.04778989 0.6627905  0.68670183]
[32.8  32.8   0.75]
[1.105753   0.67131185 0.68091773]
[32.8  32.8   0.75]
[1.17246742 0.68985954 0.65922428]
[32.8  32.8   0.75]
[1.23298083 0.74004579 0.64774473]
[32.8  32.8   0.75]
[1.30967173 0.79459705 0.63519578]
[32.8  32.8   0.75]
[1.36506969 0.83508846 0.6033154 ]
[32.8  32.8   0.75]
[1.4160119  0.86694911 0.56122213]
[32.8  32.8   0.75]
[1.43535552 0.88028713 0.52736553]
[32.8  32.8   0.75]
[1.41859091 0.87197211 0.50747021]
[32.8  32.8   0.75]
[1.39817121 0.8667965  0.50757994]
[32.8  32.8   0.75]
[1.37889099 0.84447213 0.53899997]
[32.8  32.8   0.75]
[1.36883487 0.82767722 0.55567227]
[32.8  32.8   0.75]
[1.35545049 0.80569729 0.55580934]
[32.8  32.8   0.75]
[1.33757165 0.78320736 0.52979662]
[32.8  32.8   0.75]
[1.33903414 0.76621618 0.52810815]
[32.8  32.8   0.75]
[1.36702031 0.75352887 0.58025194]
[32.8  32.8   0.75]
[1.40515839 0.75051867 0.61735464]
[32.8  32.8   0.75]
[1.43872131 0.75018052 0.6315245 ]
[32.8  32.8   0.75]
[1.47214448 0.74523259 0.62202453]
[32.8  32.8   0.75]
[1.50981227 0.73068478 0.62244045]
[32.8  32.8   0.75]
[1.53658867 0.72432255 0.61658258]
[32.8  32.8   0.75]
[1.56057191 0.74812579 0.64258179]
[32.8  32.8   0.75]
[1.58307327 0.76766457 0.65559693]
[32.8  32.8   0.75]
[1.60743302 0.78359092 0.64478884]
[32.8  32.8   0.75]
[1.63814408 0.81818597 0.6213392 ]
[32.8  32.8   0.75]
[1.65866012 0.86737009 0.59824466]
[32.8  32.8   0.75]
[1.69490462 0.89127342 0.63076238]
[32.8  32.8   0.75]
[1.73759319 0.90313512 0.64590207]
[32.8  32.8   0.75]
[1.78323022 0.91763139 0.63488018]
[32.8  32.8   0.75]
[1.81505842 0.9304645  0.59775958]
[32.8  32.8   0.75]
[1.84099528 0.94276543 0.57322912]
[32.8  32.8   0.75]
[1.84139257 0.91514655 0.66291552]
[32.8  32.8   0.75]
[1.84224563 0.88215194 0.72688811]
[32.8  32.8   0.75]
[1.84007614 0.86449829 0.77068828]
[32.8  32.8   0.75]
[1.83340243 0.85468171 0.79825883]
[32.8  32.8   0.75]
[1.8277959  0.84603366 0.80031959]
[32.8  32.8   0.75]
[1.82784618 0.83996264 0.77873874]
[32.8  32.8   0.75]
[1.82146525 0.84441811 0.84506405]
[32.8  32.8   0.75]
[1.81437221 0.84067851 0.9104026 ]
[32.8  32.8   0.75]
[1.80603214 0.83773733 0.94486601]
[32.8  32.8   0.75]
[1.79148042 0.83953797 0.96594595]
[32.8  32.8   0.75]
[1.78037206 0.84636581 0.98241311]
[32.8  32.8   0.75]
[1.77890308 0.85787228 0.98026055]
[32.8  32.8   0.75]
[1.78378231 0.87569476 0.99855673]
[32.8  32.8   0.75]
[1.78788815 0.88638204 0.99272346]
[32.8  32.8   0.75]
[1.79482402 0.88796365 0.9552251 ]
[32.8  32.8   0.75]
[1.79002085 0.88674723 0.89139168]
[32.8  32.8   0.75]
[1.79239355 0.8834798  0.87793432]
[32.8  32.8   0.75]
[1.81252445 0.88362231 0.8803015 ]
[32.8  32.8   0.75]
[1.85889619 0.89326654 0.86703452]
[32.8  32.8   0.75]
[1.93037811 0.90104039 0.86120191]
[32.8  32.8   0.75]
[2.00659149 0.90569273 0.82325159]
[32.8  32.8   0.75]
[2.07376728 0.9124913  0.76905864]
[32.8  32.8   0.75]
[2.13616619 0.91726632 0.70307227]
[32.8  32.8   0.75]
[2.19243386 0.9217625  0.60661409]
[32.8  32.8   0.75]
[2.25025501 0.91942596 0.49332937]
[32.8  32.8   0.75]
[2.32712918 0.8965113  0.40401272]
[32.8  32.8   0.75]
[2.41283353 0.85604395 0.33140292]
[32.8  32.8   0.75]
[2.47908263 0.8255091  0.24777557]
[32.8  32.8   0.75]
[2.51710014 0.78574531 0.25523916]
[32.8  32.8   0.75]
[2.54772374 0.75133578 0.25935806]
[32.8  32.8   0.75]
[2.58342947 0.71375068 0.26015453]
[32.8  32.8   0.75]
[2.63128493 0.68296699 0.26770571]
[32.8  32.8   0.75]
[2.6830752  0.6610979  0.26598894]
[32.8  32.8   0.75]
[2.70449894 0.65472079 0.29766035]
[32.8  32.8   0.75]
[2.71214378 0.65532786 0.32846383]
[32.8  32.8   0.75]
[2.70239215 0.65423165 0.3610457 ]
[32.8  32.8   0.75]
[2.67041137 0.67032131 0.41597724]
[32.8  32.8   0.75]
[2.63503846 0.68024257 0.44956082]
[32.8  32.8   0.75]
[2.591739   0.68002715 0.47490797]
[32.8  32.8   0.75]
[2.53881536 0.67570688 0.4774742 ]
[32.8  32.8   0.75]
[2.50941634 0.67921579 0.4460903 ]
[32.8  32.8   0.75]
[2.48664356 0.69880543 0.40335451]
[32.8  32.8   0.75]
[2.45758606 0.69275436 0.33715485]
[32.8  32.8   0.75]
[2.42789381 0.67708701 0.25217788]
[32.8  32.8   0.75]
[2.39366117 0.6929153  0.25262716]
[32.8  32.8   0.75]
[2.36012343 0.72780023 0.27152573]
[32.8  32.8   0.75]
[2.35493218 0.7499894  0.29950385]
[32.8  32.8   0.75]
[2.35100431 0.76184121 0.30567278]
[32.8  32.8   0.75]
[2.34450768 0.74460896 0.31150754]
[32.8  32.8   0.75]
[2.337975   0.71034131 0.31952189]
[32.8  32.8   0.75]
[2.3400547  0.69010166 0.31802367]
[32.8  32.8   0.75]
[2.34920649 0.68824912 0.31256686]
[32.8  32.8   0.75]
[2.35383325 0.68752585 0.28581737]
[32.8  32.8   0.75]
[2.36452052 0.67313244 0.25478159]
[32.8  32.8   0.75]
[2.37620026 0.64883031 0.25815969]
[32.8  32.8   0.75]
[2.38463169 0.62432256 0.25958642]
[32.8  32.8   0.75]
[2.38716358 0.60858094 0.2597677 ]
[32.8  32.8   0.75]
[2.39487087 0.5893738  0.25961873]
[32.8  32.8   0.75]
[2.39227741 0.5631287  0.25970461]
[32.8  32.8   0.75]
[2.38361134 0.54765034 0.2596038 ]
[32.8  32.8   0.75]
[2.36694171 0.52736979 0.25908781]
[32.8  32.8   0.75]
[2.36361961 0.50014172 0.26213986]
[32.8  32.8   0.75]
[2.36635678 0.48883673 0.26336244]
[32.8  32.8   0.75]
[2.37396616 0.47491366 0.26421768]
[32.8  32.8   0.75]
[2.38361056 0.46284206 0.25813527]
[32.8  32.8   0.75]
[2.38834797 0.46360599 0.25938164]
[32.8  32.8   0.75]
[2.39966784 0.46285561 0.25973914]
[32.8  32.8   0.75]
[2.41374236 0.46213553 0.25998694]
[32.8  32.8   0.75]
[2.43497456 0.4624151  0.26087254]
[32.8  32.8   0.75]
[2.45476648 0.47293386 0.26995682]
[32.8  32.8   0.75]
[2.47288006 0.49652313 0.26434305]
[32.8  32.8   0.75]
[2.47093375 0.50835208 0.25782536]
[32.8  32.8   0.75]
[2.45688288 0.51396293 0.2593848 ]
[32.8  32.8   0.75]
[2.44600802 0.5293531  0.25998983]
[32.8  32.8   0.75]
[2.44197088 0.54637354 0.25955157]
[32.8  32.8   0.75]
[2.44792538 0.56063591 0.25961967]
[32.8  32.8   0.75]
[2.45890294 0.57160665 0.25957915]
[32.8  32.8   0.75]
[2.46120084 0.5753105  0.25955858]
[32.8  32.8   0.75]
[2.45660571 0.57625873 0.25961567]
[32.8  32.8   0.75]
[2.45812489 0.58243531 0.25965946]
[32.8  32.8   0.75]
[2.46224313 0.59443199 0.2597204 ]
[32.8  32.8   0.75]
[2.46471637 0.60750554 0.25969788]
[32.8  32.8   0.75]
[2.45675186 0.61627297 0.25960632]
[32.8  32.8   0.75]
[2.44222623 0.62179897 0.2596551 ]
[32.8  32.8   0.75]
[2.42120177 0.62717903 0.25966398]
[32.8  32.8   0.75]
[2.40246363 0.62904802 0.25971174]
[32.8  32.8   0.75]
[2.38655858 0.63922946 0.25957708]
[32.8  32.8   0.75]
[2.37803094 0.64979228 0.26733481]
[32.8  32.8   0.75]
[2.38016267 0.65215198 0.26823315]
[32.8  32.8   0.75]
[2.38047419 0.64258642 0.25956507]
[32.8  32.8   0.75]
[2.38752223 0.62584797 0.25921684]
[32.8  32.8   0.75]
[2.39889356 0.6208697  0.25965811]
[32.8  32.8   0.75]
[2.4091521  0.61360531 0.25959443]
[32.8  32.8   0.75]
[2.42131297 0.59681786 0.25965826]
[32.8  32.8   0.75]
[2.42868741 0.58169497 0.25976826]
[32.8  32.8   0.75]
[2.43168469 0.57732087 0.25963912]
[32.8  32.8   0.75]
[2.43271372 0.57424709 0.25963115]
[32.8  32.8   0.75]
[2.42661255 0.5710114  0.25957929]
[32.8  32.8   0.75]
[2.4153418  0.56616419 0.25987987]
[32.8  32.8   0.75]
[2.40649479 0.55736577 0.25977244]
[32.8  32.8   0.75]
[2.40358761 0.55012722 0.25956331]
[32.8  32.8   0.75]
[2.40560707 0.55177927 0.25958639]
[32.8  32.8   0.75]
[2.39855447 0.55367961 0.25955541]
[32.8  32.8   0.75]
[2.38697421 0.56202885 0.25984077]
[32.8  32.8   0.75]
[2.38278376 0.5614587  0.2596767 ]
[32.8  32.8   0.75]
[2.38298832 0.56139966 0.25971819]
[32.8  32.8   0.75]
[2.377128   0.56248789 0.25958996]
[32.8  32.8   0.75]
[2.37853557 0.57173395 0.26446927]
[32.8  32.8   0.75]
[2.39161467 0.58880319 0.25828823]
[32.8  32.8   0.75]
[2.39182689 0.59518689 0.2594427 ]
[32.8  32.8   0.75]
[2.39238485 0.59141302 0.25969512]
[32.8  32.8   0.75]
[2.38993533 0.59034963 0.25977093]
[32.8  32.8   0.75]
[2.38736599 0.5887844  0.25973415]
[32.8  32.8   0.75]
[2.38080909 0.59170175 0.2594884 ]
[32.8  32.8   0.75]
[2.3744426  0.59213525 0.25982403]
[32.8  32.8   0.75]
[2.37275267 0.60063712 0.25967264]
[32.8  32.8   0.75]
[2.37061649 0.62131201 0.26793025]
[32.8  32.8   0.75]
[2.37051733 0.63151561 0.26556492]
[32.8  32.8   0.75]
[2.37520259 0.63382087 0.25898853]
[32.8  32.8   0.75]
[2.38505009 0.63249503 0.25856654]
[32.8  32.8   0.75]
[2.39998112 0.62661199 0.25953276]
[32.8  32.8   0.75]
[2.41960319 0.61475776 0.25966462]
[32.8  32.8   0.75]
[2.4413037  0.60175908 0.25959808]
[32.8  32.8   0.75]
[2.45046132 0.58937109 0.2598924 ]
[32.8  32.8   0.75]
[2.45516765 0.58993531 0.25975391]
[32.8  32.8   0.75]
[2.45348784 0.59238808 0.25968697]
[32.8  32.8   0.75]
[2.44067994 0.59978033 0.25971219]
[32.8  32.8   0.75]
[2.44100648 0.60360534 0.25951146]
[32.8  32.8   0.75]
[2.45208052 0.60158273 0.25958825]
[32.8  32.8   0.75]
[2.47175617 0.5939383  0.2596185 ]
[32.8  32.8   0.75]
[2.48214446 0.57767536 0.25958672]
[32.8  32.8   0.75]
[2.47779612 0.58042992 0.2595723 ]
[32.8  32.8   0.75]
[2.4699876  0.58783934 0.25987467]
[32.8  32.8   0.75]
[2.45464446 0.60334833 0.2598721 ]
[32.8  32.8   0.75]
[2.4422786  0.61318265 0.26002191]
[32.8  32.8   0.75]
[2.4452962  0.62082099 0.25944188]
[32.8  32.8   0.75]
[2.45808993 0.61756501 0.25962056]
[32.8  32.8   0.75]
[2.46786364 0.60763776 0.25957122]
[32.8  32.8   0.75]
[2.47413237 0.61195589 0.26005948]
[32.8  32.8   0.75]
[2.48224413 0.62276914 0.25949125]
[32.8  32.8   0.75]
[2.49076603 0.63968838 0.25962985]
[32.8  32.8   0.75]
[2.4937134  0.65823524 0.25982271]
[32.8  32.8   0.75]
[2.49866082 0.67638504 0.26187104]
[32.8  32.8   0.75]
[2.49163757 0.67591083 0.2863124 ]
[32.8  32.8   0.75]
[2.48829446 0.67520968 0.29242745]
[32.8  32.8   0.75]
[2.48599619 0.66845516 0.27395419]
[32.8  32.8   0.75]
[2.47937193 0.65778839 0.25513847]
[32.8  32.8   0.75]
[2.47303426 0.64470309 0.25866402]
[32.8  32.8   0.75]
[2.46249924 0.63138619 0.25958617]
[32.8  32.8   0.75]
[2.44209684 0.62674174 0.25987011]
[32.8  32.8   0.75]
[2.42051818 0.62398791 0.25963124]
[32.8  32.8   0.75]
[2.41513453 0.61238386 0.25958166]
[32.8  32.8   0.75]
[2.42303182 0.59028378 0.25973772]
[32.8  32.8   0.75]
[2.42526705 0.57618684 0.26049283]
[32.8  32.8   0.75]
[2.41934631 0.56798561 0.25884887]
[32.8  32.8   0.75]
[2.40550171 0.56550731 0.25949837]
[32.8  32.8   0.75]
[2.39879766 0.55839648 0.25959559]
[32.8  32.8   0.75]
[2.39700296 0.55629864 0.25971901]
[32.8  32.8   0.75]
[2.403993   0.55703832 0.25957562]
[32.8  32.8   0.75]
[2.40968314 0.56303823 0.25967795]
[32.8  32.8   0.75]
[2.40716174 0.56066411 0.25968685]
[32.8  32.8   0.75]
[2.40774921 0.55863757 0.25965941]
[32.8  32.8   0.75]
[2.40590332 0.56134406 0.25964791]
[32.8  32.8   0.75]
[2.40049552 0.55903975 0.25958317]
[32.8  32.8   0.75]
[2.39739533 0.55313029 0.25968983]
[32.8  32.8   0.75]
[2.40668879 0.54299271 0.26242697]
[32.8  32.8   0.75]
[2.40005135 0.54040436 0.25838971]
[32.8  32.8   0.75]
[2.38877193 0.54002325 0.25948895]
[32.8  32.8   0.75]
[2.39493214 0.54864289 0.25908753]
[32.8  32.8   0.75]
[2.40026577 0.5584084  0.25961135]
[32.8  32.8   0.75]
[2.40548555 0.57470487 0.25964599]
[32.8  32.8   0.75]
[2.4152864  0.58701551 0.25971185]
[32.8  32.8   0.75]
[2.42317888 0.5914223  0.25959123]
[32.8  32.8   0.75]
[2.42835608 0.59224017 0.25960307]
[32.8  32.8   0.75]
[2.44153667 0.59157945 0.26012708]
[32.8  32.8   0.75]
[2.46277529 0.59542034 0.25960662]
[32.8  32.8   0.75]
[2.46785408 0.60096053 0.25969567]
[32.8  32.8   0.75]
[2.46004504 0.60848261 0.25967409]
[32.8  32.8   0.75]
[2.45583746 0.62100213 0.25984026]
[32.8  32.8   0.75]
[2.46330625 0.62388999 0.25945534]
[32.8  32.8   0.75]
[2.47134037 0.62848869 0.25958842]
[32.8  32.8   0.75]
[2.48404334 0.63314083 0.25965753]
[32.8  32.8   0.75]
[2.50099592 0.63649001 0.25952683]
[32.8  32.8   0.75]
[2.52331819 0.63898119 0.25965521]
[32.8  32.8   0.75]
[2.54044027 0.63411997 0.26235082]
[32.8  32.8   0.75]
[2.54476593 0.63076484 0.26648981]
[32.8  32.8   0.75]
[2.53360037 0.62902662 0.26011586]
[32.8  32.8   0.75]
[2.50868974 0.62316328 0.25980734]
[32.8  32.8   0.75]
[2.50067616 0.6187036  0.25956666]
[32.8  32.8   0.75]
[2.50411119 0.61771244 0.25975515]
[32.8  32.8   0.75]
[2.51445961 0.61900178 0.25985398]
[32.8  32.8   0.75]
[2.52628229 0.61858642 0.25958875]
[32.8  32.8   0.75]
[2.52799943 0.6295778  0.25926697]
[32.8  32.8   0.75]
[2.52346837 0.64880852 0.25956872]
[32.8  32.8   0.75]
[2.52185707 0.65747017 0.27767993]
[32.8  32.8   0.75]
[2.52054521 0.65026423 0.28829049]
[32.8  32.8   0.75]
[2.51364054 0.64074359 0.28182937]
[32.8  32.8   0.75]
[2.50699959 0.64082597 0.25017704]
[32.8  32.8   0.75]
[2.51369087 0.62915255 0.25643419]
[32.8  32.8   0.75]
[2.52401739 0.61418151 0.25972628]
[32.8  32.8   0.75]
[2.53637445 0.61081179 0.25951992]
[32.8  32.8   0.75]
[2.54907409 0.61470944 0.26057941]
[32.8  32.8   0.75]
[2.54849163 0.62260052 0.2646418 ]
[32.8  32.8   0.75]
[2.53835593 0.63863078 0.25974341]
[32.8  32.8   0.75]
[2.51759391 0.64297526 0.25913242]
[32.8  32.8   0.75]
[2.50262475 0.62623603 0.25957679]
[32.8  32.8   0.75]
[2.50111178 0.60007339 0.25952519]
[32.8  32.8   0.75]
[2.49962337 0.56661721 0.26139233]
[32.8  32.8   0.75]
[2.49585678 0.56640678 0.26534716]
[32.8  32.8   0.75]
[2.49777406 0.57444356 0.25687474]
[32.8  32.8   0.75]
[2.50794842 0.58683696 0.25917949]
[32.8  32.8   0.75]
[2.5149552  0.59570641 0.25966237]
[32.8  32.8   0.75]
[2.51502247 0.59447799 0.25972332]
[32.8  32.8   0.75]
[2.51533359 0.59023766 0.25969992]
[32.8  32.8   0.75]
[2.5144525  0.58722086 0.2596968 ]
[32.8  32.8   0.75]
[2.51750678 0.59892558 0.25965545]
[32.8  32.8   0.75]
[2.52332685 0.6105505  0.2595228 ]
[32.8  32.8   0.75]
[2.53553713 0.62539575 0.25962136]
[32.8  32.8   0.75]
[2.53434012 0.6283945  0.26696598]
[32.8  32.8   0.75]
[2.52489205 0.6296519  0.25952531]
[32.8  32.8   0.75]
[2.5168474  0.62949429 0.25890785]
[32.8  32.8   0.75]
[2.50883394 0.63347014 0.25968833]
[32.8  32.8   0.75]
[2.50055157 0.64357654 0.25956798]
[32.8  32.8   0.75]
[2.49793941 0.65138446 0.25960922]
[32.8  32.8   0.75]
[2.50306535 0.65278743 0.2596005 ]
[32.8  32.8   0.75]
[2.50874339 0.66388699 0.26256787]
[32.8  32.8   0.75]
[2.49055322 0.6636284  0.28238735]
[32.8  32.8   0.75]
[2.46716042 0.65347847 0.28433995]
[32.8  32.8   0.75]
[2.4525413  0.64322554 0.25871277]
[32.8  32.8   0.75]
[2.43496245 0.6430295  0.25693706]
[32.8  32.8   0.75]
[2.41529948 0.63632766 0.25933172]
[32.8  32.8   0.75]
[2.40017682 0.62969384 0.25967521]
[32.8  32.8   0.75]
[2.39121512 0.63638255 0.25968573]
[32.8  32.8   0.75]
[2.38303208 0.64678657 0.25968616]
[32.8  32.8   0.75]
[2.36589299 0.65649802 0.25962109]
[32.8  32.8   0.75]
[2.35103311 0.66474049 0.25953771]
[32.8  32.8   0.75]
[2.33623362 0.66120342 0.25906967]
[32.8  32.8   0.75]
[2.32378482 0.65670128 0.25976781]
[32.8  32.8   0.75]
[2.31310704 0.65266362 0.25964243]
[32.8  32.8   0.75]
[2.3077791  0.64874937 0.25985884]
[32.8  32.8   0.75]
[2.29631062 0.65715188 0.25966186]
[32.8  32.8   0.75]
[2.27837449 0.65428817 0.27203381]
[32.8  32.8   0.75]
[2.26022276 0.64102624 0.27505495]
[32.8  32.8   0.75]
[2.25182533 0.62057851 0.26631601]
[32.8  32.8   0.75]
[2.2739227  0.61760686 0.27763126]
[32.8  32.8   0.75]
[2.30390542 0.61160028 0.26705989]
[32.8  32.8   0.75]
[2.3316783  0.61914727 0.25742483]
[32.8  32.8   0.75]
[2.3487556  0.6361824  0.25935356]
[32.8  32.8   0.75]
[2.36005336 0.65888842 0.25971408]
[32.8  32.8   0.75]
[2.36557843 0.6875484  0.25978339]
[32.8  32.8   0.75]
[2.38635317 0.7124377  0.26161838]
[32.8  32.8   0.75]
[2.41484978 0.71188638 0.27115801]
[32.8  32.8   0.75]
[2.43002579 0.7086232  0.26578037]
[32.8  32.8   0.75]
[2.43692253 0.70436101 0.25785422]
[32.8  32.8   0.75]
[2.43779694 0.70181145 0.25935616]
[32.8  32.8   0.75]
[2.43731302 0.69794142 0.25966878]
[32.8  32.8   0.75]
[2.44371982 0.69221546 0.25966823]
[32.8  32.8   0.75]
[2.44369016 0.68281643 0.25966213]
[32.8  32.8   0.75]
[2.44081115 0.67305082 0.25965751]
[32.8  32.8   0.75]
[2.44321952 0.68117091 0.25964852]
[32.8  32.8   0.75]
[2.4497193  0.6985353  0.25965807]
[32.8  32.8   0.75]
[2.45909731 0.71372683 0.26020993]
[32.8  32.8   0.75]
[2.46266449 0.71263141 0.25909188]
[32.8  32.8   0.75]
[2.46079925 0.70818702 0.25950674]
[32.8  32.8   0.75]
[2.46220985 0.70427245 0.25964623]
[32.8  32.8   0.75]
[2.47461717 0.6968076  0.25959567]
[32.8  32.8   0.75]
[2.47927036 0.6866659  0.25963748]
[32.8  32.8   0.75]
[2.47692426 0.68282904 0.25971514]
[32.8  32.8   0.75]
[2.47466495 0.68043075 0.25964531]
[32.8  32.8   0.75]
[2.46734173 0.68083666 0.25974923]
[32.8  32.8   0.75]
[2.46292725 0.68380606 0.25954935]
[32.8  32.8   0.75]
[2.46066483 0.69308496 0.25949535]
[32.8  32.8   0.75]
[2.46201743 0.71407086 0.26238269]
[32.8  32.8   0.75]
[2.45932209 0.73441525 0.26766068]
[32.8  32.8   0.75]
[2.45681691 0.74638521 0.25687638]
[32.8  32.8   0.75]
[2.44434751 0.74314042 0.25896912]
[32.8  32.8   0.75]
[2.43181866 0.7457431  0.25968   ]
[32.8  32.8   0.75]
[2.41950972 0.74575446 0.26030453]
[32.8  32.8   0.75]
[2.40442694 0.74639592 0.26167649]
[32.8  32.8   0.75]
[2.39241753 0.73865847 0.26849997]
[32.8  32.8   0.75]
[2.3821585  0.72193182 0.26685147]
[32.8  32.8   0.75]
[2.37745102 0.70222641 0.25754994]
[32.8  32.8   0.75]
[2.38177059 0.67516423 0.25938982]
[32.8  32.8   0.75]
[2.38420303 0.64799288 0.2596688 ]
[32.8  32.8   0.75]
[2.38496799 0.62377373 0.25972093]
[32.8  32.8   0.75]
[2.38988864 0.6037675  0.2596335 ]
[32.8  32.8   0.75]
[2.39159992 0.58136517 0.25961445]
[32.8  32.8   0.75]
[2.38471886 0.5692256  0.27001667]
[32.8  32.8   0.75]
[2.37045484 0.57732223 0.28357237]
[32.8  32.8   0.75]
[2.35808026 0.58324029 0.27935982]
[32.8  32.8   0.75]
[2.35477115 0.5864918  0.25966164]
[32.8  32.8   0.75]
[2.36184709 0.59099793 0.25824818]
[32.8  32.8   0.75]
[2.36422955 0.60252464 0.25950373]
[32.8  32.8   0.75]
[2.3555512  0.60891289 0.25988685]
[32.8  32.8   0.75]
[2.35272121 0.62249574 0.25978794]
[32.8  32.8   0.75]
[2.3432816  0.63914166 0.25963963]
[32.8  32.8   0.75]
[2.33410868 0.65227849 0.2595886 ]
[32.8  32.8   0.75]
[2.33042044 0.65526609 0.25964552]
[32.8  32.8   0.75]
[2.33001555 0.66367655 0.25980119]
[32.8  32.8   0.75]
[2.31705385 0.67401325 0.25965699]
[32.8  32.8   0.75]
[2.30591974 0.69004848 0.26640514]
[32.8  32.8   0.75]
[2.30031311 0.7127649  0.25757149]
[32.8  32.8   0.75]
[2.29152359 0.72677507 0.25881896]
[32.8  32.8   0.75]
[2.28411681 0.74118187 0.26030273]
[32.8  32.8   0.75]
[2.28221806 0.74687506 0.26345636]
[32.8  32.8   0.75]
[2.28620228 0.74273346 0.26654645]
[32.8  32.8   0.75]
[2.29927499 0.7299029  0.26203831]
[32.8  32.8   0.75]
[2.30886262 0.7210171  0.25761876]
[32.8  32.8   0.75]
[2.32460404 0.72052024 0.25954017]
[32.8  32.8   0.75]
[2.33388317 0.72313524 0.25964319]
[32.8  32.8   0.75]
[2.33876992 0.72779743 0.25967042]
[32.8  32.8   0.75]
[2.34752603 0.73816014 0.25995738]
[32.8  32.8   0.75]
[2.35204462 0.74855017 0.25891909]
[32.8  32.8   0.75]
[2.34648513 0.74786426 0.26105901]
[32.8  32.8   0.75]
[2.35062578 0.74125376 0.25877814]
[32.8  32.8   0.75]
[2.35777894 0.74088282 0.25955959]
[32.8  32.8   0.75]
[2.3555638  0.74829694 0.2596917 ]
[32.8  32.8   0.75]
[2.36065038 0.75533917 0.26422374]
[32.8  32.8   0.75]
[2.36834832 0.75019367 0.25795541]
[32.8  32.8   0.75]
[2.3677663  0.73155609 0.25937019]
[32.8  32.8   0.75]
[2.36253403 0.71703776 0.25985517]
[32.8  32.8   0.75]
[2.36339776 0.71057377 0.25966802]
[32.8  32.8   0.75]
[2.3684437  0.70768373 0.25972602]
[32.8  32.8   0.75]
[2.3679633  0.70503739 0.2596062 ]
[32.8  32.8   0.75]
[2.35418131 0.70215955 0.259662  ]
[32.8  32.8   0.75]
[2.34101014 0.7021298  0.25956381]
[32.8  32.8   0.75]
[2.32840467 0.69948675 0.25960878]
[32.8  32.8   0.75]
[2.31065079 0.70299618 0.25957958]
[32.8  32.8   0.75]
[2.29301005 0.70302554 0.2597744 ]
[32.8  32.8   0.75]
[2.2870799  0.69731709 0.26147509]
[32.8  32.8   0.75]
[2.29401069 0.69269333 0.25871078]
[32.8  32.8   0.75]
[2.30854608 0.6929839  0.25953886]
[32.8  32.8   0.75]
[2.32434735 0.6934932  0.25993064]
[32.8  32.8   0.75]
[2.32862975 0.69853493 0.25932928]
[32.8  32.8   0.75]
[2.31967294 0.69648368 0.25969245]
[32.8  32.8   0.75]
[2.31228821 0.6964869  0.2597127 ]
[32.8  32.8   0.75]
[2.30674976 0.70191563 0.25963098]
[32.8  32.8   0.75]
[2.29558916 0.71082753 0.25961463]
[32.8  32.8   0.75]
[2.28387513 0.71831463 0.26209555]
[32.8  32.8   0.75]
[2.292681   0.72383592 0.26588432]
[32.8  32.8   0.75]
[2.30154802 0.72566258 0.2574054 ]
[32.8  32.8   0.75]
[2.30930819 0.73316451 0.26036274]
[32.8  32.8   0.75]
[2.32060257 0.73783635 0.25854875]
[32.8  32.8   0.75]
[2.345181   0.729157   0.25945183]
[32.8  32.8   0.75]
[2.36421441 0.71665331 0.25982563]
[32.8  32.8   0.75]
[2.36237583 0.71497553 0.25949101]
[32.8  32.8   0.75]
[2.36076973 0.71675326 0.25967464]
[32.8  32.8   0.75]
[2.36086362 0.72695505 0.25955878]
[32.8  32.8   0.75]
[2.36516793 0.73784109 0.25989684]
[32.8  32.8   0.75]
[2.36754374 0.74227272 0.26023517]
[32.8  32.8   0.75]
[2.37034308 0.74193662 0.2591757 ]
[32.8  32.8   0.75]
[2.37501428 0.7420637  0.25972523]
[32.8  32.8   0.75]
[2.37164445 0.74000066 0.25963284]
[32.8  32.8   0.75]
[2.36782802 0.73428726 0.2597108 ]
[32.8  32.8   0.75]
[2.36621428 0.73179924 0.25961625]
[32.8  32.8   0.75]
[2.3598396  0.73832019 0.25961906]
[32.8  32.8   0.75]
[2.35531448 0.7422221  0.26108375]
[32.8  32.8   0.75]
[2.35459519 0.74231424 0.25935703]
[32.8  32.8   0.75]
[2.34516311 0.74102282 0.25983258]
[32.8  32.8   0.75]
[2.33419599 0.72814701 0.25944308]
[32.8  32.8   0.75]
[2.33063484 0.7176261  0.25963731]
[32.8  32.8   0.75]
[2.32939674 0.71082169 0.25957514]
[32.8  32.8   0.75]
[2.31906447 0.70055741 0.25958962]
[32.8  32.8   0.75]
[2.31103767 0.69315806 0.2596005 ]
[32.8  32.8   0.75]
[2.30182911 0.68647437 0.25974926]
[32.8  32.8   0.75]
[2.28852574 0.68021898 0.25958141]
[32.8  32.8   0.75]
[2.27909801 0.6742114  0.25969301]
[32.8  32.8   0.75]
[2.26933969 0.6664599  0.26197641]
[32.8  32.8   0.75]
[2.26551103 0.65978174 0.25843391]
[32.8  32.8   0.75]
[2.26446398 0.65406964 0.25931334]
[32.8  32.8   0.75]
[2.26484868 0.64701575 0.25965892]
[32.8  32.8   0.75]
[2.26461611 0.64285767 0.25963396]
[32.8  32.8   0.75]
[2.26394086 0.63778215 0.25989576]
[32.8  32.8   0.75]
[2.25987233 0.63193565 0.259839  ]
[32.8  32.8   0.75]
[2.25987346 0.62839812 0.25967364]
[32.8  32.8   0.75]
[2.25998251 0.6166259  0.25983901]
[32.8  32.8   0.75]
[2.26734859 0.60800433 0.26119996]
[32.8  32.8   0.75]
[2.28036687 0.60610645 0.25901609]
[32.8  32.8   0.75]
[2.29284978 0.60390941 0.259737  ]
[32.8  32.8   0.75]
[2.30323538 0.60821216 0.25951203]
[32.8  32.8   0.75]
[2.31123943 0.61560168 0.25963544]
[32.8  32.8   0.75]
[2.31570161 0.62208303 0.25967052]
[32.8  32.8   0.75]
[2.31618549 0.62735295 0.25957481]
[32.8  32.8   0.75]
[2.31068476 0.63269483 0.25955654]
[32.8  32.8   0.75]
[2.30422115 0.63339629 0.26059193]
[32.8  32.8   0.75]
[2.30608778 0.63931911 0.26024132]
[32.8  32.8   0.75]
[2.31281638 0.64657831 0.25945249]
[32.8  32.8   0.75]
[2.31815927 0.65779317 0.25960837]
[32.8  32.8   0.75]
[2.32273722 0.66584194 0.25960188]
[32.8  32.8   0.75]
[2.31717959 0.66994968 0.25988305]
[32.8  32.8   0.75]
[2.3065392  0.67472647 0.25975714]
[32.8  32.8   0.75]
[2.29940602 0.68071643 0.25958665]
[32.8  32.8   0.75]
[2.28436861 0.68870571 0.25960782]
[32.8  32.8   0.75]
[2.26877634 0.6955474  0.26056483]
[32.8  32.8   0.75]
[2.27337474 0.69919678 0.27013155]
[32.8  32.8   0.75]
[2.2806498  0.70350374 0.26533087]
[32.8  32.8   0.75]
[2.29195152 0.70955473 0.2574287 ]
[32.8  32.8   0.75]
[2.30393852 0.71909348 0.25940302]
[32.8  32.8   0.75]
[2.31443618 0.73782507 0.25972402]
[32.8  32.8   0.75]
[2.32149967 0.75086526 0.25955072]
[32.8  32.8   0.75]
[2.32710448 0.76097136 0.26079349]
[32.8  32.8   0.75]
[2.34939467 0.76925131 0.25835948]
[32.8  32.8   0.75]
[2.38326434 0.77819419 0.25921069]
[32.8  32.8   0.75]
[2.40806749 0.77378899 0.26393617]
[32.8  32.8   0.75]
[2.41602183 0.76391324 0.26218666]
[32.8  32.8   0.75]
[2.42820633 0.75713523 0.26114209]
[32.8  32.8   0.75]
[2.44591233 0.74533861 0.25801438]
[32.8  32.8   0.75]
[2.43993117 0.74081556 0.25979377]
[32.8  32.8   0.75]
[2.43474255 0.72990241 0.25972158]
[32.8  32.8   0.75]
[2.43337496 0.71889788 0.25966208]
[32.8  32.8   0.75]
[2.43059434 0.71326535 0.25958246]
[32.8  32.8   0.75]
[2.41280147 0.71190789 0.25963762]
[32.8  32.8   0.75]
[2.39006642 0.71027786 0.25959413]
[32.8  32.8   0.75]
[2.37852032 0.71002327 0.25968456]
[32.8  32.8   0.75]
[2.37290022 0.70660654 0.25968168]
[32.8  32.8   0.75]
[2.36695859 0.70678153 0.25961767]
[32.8  32.8   0.75]
[2.34782585 0.70986739 0.25966337]
[32.8  32.8   0.75]
[2.32583741 0.71318693 0.25957988]
[32.8  32.8   0.75]
[2.29824875 0.71268459 0.26750665]
[32.8  32.8   0.75]
[2.30422931 0.68507624 0.30629969]
[32.8  32.8   0.75]
[2.32277055 0.64864599 0.32827036]
[32.8  32.8   0.75]
[2.35711723 0.61421697 0.3282887 ]
[32.8  32.8   0.75]
[2.38627096 0.5758904  0.30395998]
[32.8  32.8   0.75]
[2.40439338 0.55072216 0.25875274]
[32.8  32.8   0.75]
[2.41058985 0.54609151 0.2566583 ]
[32.8  32.8   0.75]
[2.41422025 0.54476167 0.25934056]
[32.8  32.8   0.75]
[2.41998324 0.5445616  0.25965331]
[32.8  32.8   0.75]
[2.4358301  0.54685813 0.25965842]
[32.8  32.8   0.75]
[2.45255977 0.54858739 0.25962801]
[32.8  32.8   0.75]
[2.47155331 0.5493617  0.25963577]
[32.8  32.8   0.75]
[2.49035206 0.54944049 0.2595817 ]
[32.8  32.8   0.75]
[2.49830665 0.54892452 0.26371969]
[32.8  32.8   0.75]
[2.48858925 0.55121822 0.26295708]
[32.8  32.8   0.75]
[2.47720898 0.55510736 0.25817446]
[32.8  32.8   0.75]
[2.46252368 0.55572552 0.25968609]
[32.8  32.8   0.75]
[2.44733333 0.55368097 0.25963712]
[32.8  32.8   0.75]
[2.43776384 0.55585252 0.25961404]
[32.8  32.8   0.75]
[2.42813872 0.56721909 0.25964408]
[32.8  32.8   0.75]
[2.4262047  0.57963247 0.25966305]
[32.8  32.8   0.75]
[2.41462004 0.59320908 0.26724331]
[32.8  32.8   0.75]
[2.39669759 0.59911917 0.27529693]
[32.8  32.8   0.75]
[2.38266529 0.60514236 0.25790417]
[32.8  32.8   0.75]
[2.37183181 0.59633707 0.2579675 ]
[32.8  32.8   0.75]
[2.35921088 0.58930821 0.2594839 ]
[32.8  32.8   0.75]
[2.34728842 0.58783702 0.25966112]
[32.8  32.8   0.75]
[2.34757137 0.59678786 0.26154189]
[32.8  32.8   0.75]
[2.35949171 0.60495884 0.25928282]
[32.8  32.8   0.75]
[2.37003304 0.59990815 0.25960409]
[32.8  32.8   0.75]
[2.35884092 0.5954512  0.2597102 ]
[32.8  32.8   0.75]
[2.34399986 0.59498736 0.26104803]
[32.8  32.8   0.75]
[2.33455814 0.58313091 0.26282569]
[32.8  32.8   0.75]
[2.33478627 0.57283612 0.25772169]
[32.8  32.8   0.75]
[2.33457024 0.57031054 0.25936147]
[32.8  32.8   0.75]
[2.33671166 0.56927273 0.2597651 ]
[32.8  32.8   0.75]
[2.32952407 0.56720747 0.25963104]
[32.8  32.8   0.75]
[2.31672196 0.566398   0.26210743]
[32.8  32.8   0.75]
[2.313309   0.55449936 0.25882147]
[32.8  32.8   0.75]
[2.32860896 0.5458643  0.25945623]
[32.8  32.8   0.75]
[2.34750755 0.54066496 0.25966592]
[32.8  32.8   0.75]
[2.36762372 0.53512137 0.25956718]
[32.8  32.8   0.75]
[2.38860281 0.53336383 0.25970311]
[32.8  32.8   0.75]
[2.40869194 0.52518735 0.25963293]
[32.8  32.8   0.75]
[2.42063495 0.51381341 0.25958338]
[32.8  32.8   0.75]
[2.42762845 0.51108459 0.25979969]
[32.8  32.8   0.75]
[2.43565048 0.51733498 0.25967735]
[32.8  32.8   0.75]
[2.44725278 0.52478377 0.25971124]
[32.8  32.8   0.75]
[2.45201639 0.52981922 0.25960298]
[32.8  32.8   0.75]
[2.45683349 0.53602486 0.2595903 ]
[32.8  32.8   0.75]
[2.46314879 0.53956524 0.26008452]
[32.8  32.8   0.75]
[2.45588709 0.54340845 0.25885396]
[32.8  32.8   0.75]
[2.46168135 0.54381499 0.25953373]
[32.8  32.8   0.75]
[2.48110006 0.54993899 0.26084525]
[32.8  32.8   0.75]
[2.48834823 0.54601358 0.2670811 ]
[32.8  32.8   0.75]
[2.48716152 0.53414321 0.26595425]
[32.8  32.8   0.75]
[2.47629926 0.53650238 0.2591153 ]
[32.8  32.8   0.75]
[2.4652944  0.53426654 0.25896807]
[32.8  32.8   0.75]
[2.46478438 0.52672472 0.25961016]
[32.8  32.8   0.75]
[2.46048519 0.51918166 0.26009286]
[32.8  32.8   0.75]
[2.44894993 0.50573604 0.25960616]
[32.8  32.8   0.75]
[2.4365815  0.50757548 0.25964762]
[32.8  32.8   0.75]
[2.43529241 0.51888542 0.25962856]
[32.8  32.8   0.75]
[2.43163303 0.53627349 0.25963015]
[32.8  32.8   0.75]
[2.41861735 0.55047463 0.25963889]
[32.8  32.8   0.75]
[2.40429512 0.56116419 0.25973936]
[32.8  32.8   0.75]
[2.38931362 0.5720634  0.25958866]
[32.8  32.8   0.75]
[2.37952004 0.58869963 0.25961866]
[32.8  32.8   0.75]
[2.3816206  0.60285567 0.26393688]
[32.8  32.8   0.75]
[2.38811926 0.61076066 0.25952184]
[32.8  32.8   0.75]
[2.38832158 0.61660936 0.25886842]
[32.8  32.8   0.75]
[2.39362104 0.62103291 0.26002947]
[32.8  32.8   0.75]
[2.38961395 0.62395686 0.2638183 ]
[32.8  32.8   0.75]
[2.3804397  0.61941847 0.26345381]
[32.8  32.8   0.75]
[2.37704378 0.61456793 0.25848839]
[32.8  32.8   0.75]
[2.38119333 0.61283702 0.25940715]
[32.8  32.8   0.75]
[2.39166573 0.60223453 0.26332103]
[32.8  32.8   0.75]
[2.42415053 0.5702853  0.26113115]
[32.8  32.8   0.75]
[2.43584952 0.55140731 0.25915996]
[32.8  32.8   0.75]
[2.44333419 0.53210488 0.25957138]
[32.8  32.8   0.75]
[2.45604254 0.51102201 0.2596883 ]
[32.8  32.8   0.75]
[2.46389948 0.49494221 0.25961556]
[32.8  32.8   0.75]
[2.46306056 0.48832567 0.25964509]
[32.8  32.8   0.75]
[2.4693416  0.47841695 0.25960114]
[32.8  32.8   0.75]
[2.48405416 0.47384065 0.27122924]
[32.8  32.8   0.75]
[2.4974489 0.4724796 0.2608508]
[32.8  32.8   0.75]
[2.50585048 0.47935975 0.25745692]
[32.8  32.8   0.75]
[2.51457026 0.490269   0.25940212]
[32.8  32.8   0.75]
[2.52282474 0.49824653 0.2661544 ]
[32.8  32.8   0.75]
[2.51302169 0.50839483 0.29065152]
[32.8  32.8   0.75]
[2.49512081 0.51308596 0.2889713 ]
[32.8  32.8   0.75]
[2.47438947 0.51038329 0.26064325]
[32.8  32.8   0.75]
[2.46283093 0.51936867 0.25628792]
[32.8  32.8   0.75]
[2.44655341 0.52644163 0.25929334]
[32.8  32.8   0.75]
[2.43349301 0.53058606 0.25965463]
[32.8  32.8   0.75]
[2.43340899 0.54192924 0.25956691]
[32.8  32.8   0.75]
[2.43560327 0.55300478 0.25965539]
[32.8  32.8   0.75]
[2.43501827 0.56790493 0.25964422]
[32.8  32.8   0.75]
[2.43499888 0.59358815 0.25959825]
[32.8  32.8   0.75]
[2.43167284 0.61402619 0.26045862]
[32.8  32.8   0.75]
[2.43045424 0.61106043 0.25948127]
[32.8  32.8   0.75]
[2.42906905 0.61106523 0.25961302]
[32.8  32.8   0.75]
[2.42094338 0.61178557 0.25968947]
[32.8  32.8   0.75]
[2.40467788 0.61029001 0.2596296 ]
[32.8  32.8   0.75]
[2.39511657 0.60796501 0.2595831 ]
[32.8  32.8   0.75]
[2.38718373 0.60869086 0.25964562]
[32.8  32.8   0.75]
[2.38674007 0.60411527 0.25966044]
[32.8  32.8   0.75]
[2.38755829 0.59432059 0.25959938]
[32.8  32.8   0.75]
[2.38141589 0.58198015 0.26000345]
[32.8  32.8   0.75]
[2.38587934 0.58442607 0.25966534]
[32.8  32.8   0.75]
[2.40110057 0.59025996 0.25958193]
[32.8  32.8   0.75]
[2.41234322 0.60826254 0.2595758 ]
[32.8  32.8   0.75]
[2.4182092  0.61425923 0.25970777]
[32.8  32.8   0.75]
[2.41872865 0.61355703 0.25981073]
[32.8  32.8   0.75]
[2.42270056 0.61565332 0.25982378]
[32.8  32.8   0.75]
[2.43259748 0.60599086 0.25973681]
[32.8  32.8   0.75]
[2.43818407 0.59401725 0.25978839]
[32.8  32.8   0.75]
[2.44456609 0.59607973 0.26402696]
[32.8  32.8   0.75]
[2.4432693  0.59390905 0.25910423]
[32.8  32.8   0.75]
[2.44138007 0.58587785 0.25876895]
[32.8  32.8   0.75]
[2.44499318 0.57239089 0.25956203]
[32.8  32.8   0.75]
[2.45663152 0.55736704 0.25964853]
[32.8  32.8   0.75]
[2.44914663 0.54748244 0.2746914 ]
[32.8  32.8   0.75]
[2.43394812 0.54542792 0.27704544]
[32.8  32.8   0.75]
[2.41957818 0.55010951 0.25974818]
[32.8  32.8   0.75]
[2.41258956 0.56281594 0.25835611]
[32.8  32.8   0.75]
[2.40808241 0.58041382 0.25933825]
[32.8  32.8   0.75]
[2.40102179 0.59702376 0.25953786]
[32.8  32.8   0.75]
[2.39494192 0.60122987 0.25948037]
[32.8  32.8   0.75]
[2.38927086 0.60275281 0.25959786]
[32.8  32.8   0.75]
[2.38408513 0.60246358 0.25981571]
[32.8  32.8   0.75]
[2.3863886  0.61065177 0.25966159]
[32.8  32.8   0.75]
[2.37673949 0.62447619 0.25965352]
[32.8  32.8   0.75]
[2.35994703 0.6335476  0.25965698]
[32.8  32.8   0.75]
[2.34565235 0.63725196 0.26122745]
[32.8  32.8   0.75]
[2.35107585 0.6384085  0.25859364]
[32.8  32.8   0.75]
[2.35763796 0.63268163 0.25958913]
[32.8  32.8   0.75]
[2.35888737 0.62052434 0.25961231]
[32.8  32.8   0.75]
[2.35753159 0.61437141 0.25978022]
[32.8  32.8   0.75]
[2.36045431 0.61353965 0.25968301]
[32.8  32.8   0.75]
[2.363121   0.61497159 0.25983243]
[32.8  32.8   0.75]
[2.36626678 0.61670607 0.2595709 ]
[32.8  32.8   0.75]
[2.36764376 0.61250725 0.25979244]
[32.8  32.8   0.75]
[2.36328866 0.60814989 0.25969558]
[32.8  32.8   0.75]
[2.36963377 0.59985517 0.25954518]
[32.8  32.8   0.75]
[2.38890966 0.59102129 0.25953451]
[32.8  32.8   0.75]
[2.39409952 0.58175044 0.27213646]
[32.8  32.8   0.75]
[2.37908903 0.57586122 0.27965739]
[32.8  32.8   0.75]
[2.36076824 0.57172856 0.26408887]
[32.8  32.8   0.75]
[2.34698641 0.5569556  0.25626882]
[32.8  32.8   0.75]
[2.33407954 0.53948195 0.25931284]
[32.8  32.8   0.75]
[2.31847364 0.5288325  0.25955757]
[32.8  32.8   0.75]
[2.30787613 0.517497   0.25958329]
[32.8  32.8   0.75]
[2.29128056 0.50525834 0.26006575]
[32.8  32.8   0.75]
[2.28940958 0.50350626 0.25937931]
[32.8  32.8   0.75]
[2.2861678  0.50027382 0.25989096]
[32.8  32.8   0.75]
[2.28617923 0.48999001 0.2595439 ]
[32.8  32.8   0.75]
[2.28381837 0.48250152 0.26507278]
[32.8  32.8   0.75]
[2.29201341 0.48835199 0.2706735 ]
[32.8  32.8   0.75]
[2.30241066 0.49486908 0.26338309]
[32.8  32.8   0.75]
[2.30112665 0.50347427 0.25788959]
[32.8  32.8   0.75]
[2.30437746 0.51903496 0.2595095 ]
[32.8  32.8   0.75]
[2.31034247 0.53519873 0.25962118]
[32.8  32.8   0.75]
[2.30365997 0.55559795 0.25964024]
[32.8  32.8   0.75]
[2.2924797  0.57979128 0.25959793]
[32.8  32.8   0.75]
[2.28573523 0.59981266 0.25967464]
[32.8  32.8   0.75]
[2.27808016 0.61957546 0.25973536]
[32.8  32.8   0.75]
[2.27480088 0.63376058 0.25983681]
[32.8  32.8   0.75]
[2.27359016 0.64216264 0.25925769]
[32.8  32.8   0.75]
[2.27255801 0.6474105  0.25970789]
[32.8  32.8   0.75]
[2.27364228 0.64247366 0.25975694]
[32.8  32.8   0.75]
[2.27454931 0.63535316 0.26146155]
[32.8  32.8   0.75]
[2.28005916 0.63029204 0.25797885]
[32.8  32.8   0.75]
[2.29259809 0.6390361  0.2591133 ]
[32.8  32.8   0.75]
[2.31114499 0.65239458 0.25962483]
[32.8  32.8   0.75]
[2.34263683 0.65898847 0.26540963]
[32.8  32.8   0.75]
[2.3574541  0.64618718 0.25941408]
[32.8  32.8   0.75]
[2.35243051 0.63354122 0.25908661]
[32.8  32.8   0.75]
[2.37295609 0.62765664 0.25941106]
[32.8  32.8   0.75]
[2.39694794 0.62067948 0.25957541]
[32.8  32.8   0.75]
[2.41696971 0.61499093 0.25963369]
[32.8  32.8   0.75]
[2.43541001 0.61248664 0.25963855]
[32.8  32.8   0.75]
[2.4558458  0.60711947 0.25969108]
[32.8  32.8   0.75]
[2.48001704 0.59659621 0.25962023]
[32.8  32.8   0.75]
[2.5060337  0.58413459 0.26910021]
[32.8  32.8   0.75]
[2.51291877 0.56276449 0.28300536]
[32.8  32.8   0.75]
[2.51595066 0.54056258 0.27234733]
[32.8  32.8   0.75]
[2.51296648 0.51610219 0.25531351]
[32.8  32.8   0.75]
[2.51252223 0.50221851 0.26488913]
[32.8  32.8   0.75]
[2.51718413 0.50153451 0.26841579]
[32.8  32.8   0.75]
[2.5313241  0.50610189 0.25615538]
[32.8  32.8   0.75]
[2.54200522 0.52543317 0.25921174]
[32.8  32.8   0.75]
[2.53616769 0.53047845 0.2592692 ]
[32.8  32.8   0.75]
[2.52748223 0.53255397 0.2596132 ]
[32.8  32.8   0.75]
[2.51238548 0.53013938 0.25964698]
[32.8  32.8   0.75]
[2.49713489 0.52674592 0.25961938]
[32.8  32.8   0.75]
[2.50127095 0.52187189 0.25955393]
[32.8  32.8   0.75]
[2.50090874 0.51393039 0.25961384]
[32.8  32.8   0.75]
[2.49953438 0.50568115 0.25994612]
[32.8  32.8   0.75]
[2.5082287  0.49854776 0.25975106]
[32.8  32.8   0.75]
[2.5123666  0.49828083 0.25963507]
[32.8  32.8   0.75]
[2.50943334 0.50365492 0.25993834]
[32.8  32.8   0.75]
[2.49997489 0.52389355 0.25968358]
[32.8  32.8   0.75]
[2.48568228 0.52532738 0.25949257]
[32.8  32.8   0.75]
[2.47882291 0.51673419 0.25953354]
[32.8  32.8   0.75]
[2.48225906 0.51488112 0.25966797]
[32.8  32.8   0.75]
[2.49069794 0.51537584 0.25956429]
[32.8  32.8   0.75]
[2.5016833  0.51195216 0.25966212]
[32.8  32.8   0.75]
[2.51035682 0.50809141 0.25966663]
[32.8  32.8   0.75]
[2.51373452 0.49714111 0.25965784]
[32.8  32.8   0.75]
[2.51815043 0.48834194 0.25969876]
[32.8  32.8   0.75]
[2.52832479 0.49296862 0.25962915]
[32.8  32.8   0.75]
[2.54083208 0.4989973  0.26222211]
[32.8  32.8   0.75]
[2.54049524 0.50072002 0.26813794]
[32.8  32.8   0.75]
[2.54319085 0.50252799 0.25622808]
[32.8  32.8   0.75]
[2.54068057 0.51863669 0.25879984]
[32.8  32.8   0.75]
[2.52752893 0.54008385 0.26725764]
[32.8  32.8   0.75]
[2.50355368 0.55473504 0.27597313]
[32.8  32.8   0.75]
[2.48629393 0.54399884 0.26300374]
[32.8  32.8   0.75]
[2.47796193 0.52062167 0.2576042 ]
[32.8  32.8   0.75]
[2.48312805 0.51653668 0.25945776]
[32.8  32.8   0.75]
[2.49080986 0.51971593 0.2596081 ]
[32.8  32.8   0.75]
[2.50389826 0.51865069 0.25960343]
[32.8  32.8   0.75]
[2.51008555 0.52355187 0.2597946 ]
[32.8  32.8   0.75]
[2.50540282 0.52780037 0.2596916 ]
[32.8  32.8   0.75]
[2.50402025 0.53050012 0.2595529 ]
[32.8  32.8   0.75]
[2.49705779 0.53110779 0.25963054]
[32.8  32.8   0.75]
[2.48513055 0.52635887 0.25969262]
[32.8  32.8   0.75]
[2.47218723 0.51412159 0.25987769]
[32.8  32.8   0.75]
[2.46637612 0.51201029 0.25995244]
[32.8  32.8   0.75]
[2.47552359 0.53579316 0.25955206]
[32.8  32.8   0.75]
[2.48327512 0.55578074 0.26038468]
[32.8  32.8   0.75]
[2.48895378 0.55025113 0.25951541]
[32.8  32.8   0.75]
[2.50268468 0.53925954 0.25988175]
[32.8  32.8   0.75]
[2.51417322 0.53968234 0.25967169]
[32.8  32.8   0.75]
[2.51614875 0.55518162 0.25957893]
[32.8  32.8   0.75]
[2.51481557 0.57135111 0.26366174]
[32.8  32.8   0.75]
[2.50923963 0.57933055 0.25989074]
[32.8  32.8   0.75]
[2.50278668 0.58349461 0.25945846]
[32.8  32.8   0.75]
[2.51318825 0.58054124 0.26376659]
[32.8  32.8   0.75]
[2.53186323 0.56625151 0.25765482]
[32.8  32.8   0.75]
[2.52208226 0.55832187 0.2592806 ]
[32.8  32.8   0.75]
[2.50823058 0.55818917 0.25975699]
[32.8  32.8   0.75]
[2.49469441 0.55643041 0.26220644]
[32.8  32.8   0.75]
[2.48739412 0.55579441 0.2640649 ]
[32.8  32.8   0.75]
[2.48106086 0.55784265 0.25759755]
[32.8  32.8   0.75]
[2.49596965 0.56364174 0.25944309]
[32.8  32.8   0.75]
[2.51858083 0.56895736 0.25960615]
[32.8  32.8   0.75]
[2.53327324 0.57217625 0.25961932]
[32.8  32.8   0.75]
[2.54382069 0.56846473 0.25969777]
[32.8  32.8   0.75]
[2.55921801 0.56196692 0.25989482]
[32.8  32.8   0.75]
[2.57655863 0.56994366 0.25984874]
[32.8  32.8   0.75]
[2.58752286 0.57744672 0.25956692]
[32.8  32.8   0.75]
[2.59325067 0.58072241 0.25962821]
[32.8  32.8   0.75]
[2.5866354  0.58880007 0.2596358 ]
[32.8  32.8   0.75]
[2.57460971 0.59531031 0.25962423]
[32.8  32.8   0.75]
[2.57094655 0.60175561 0.25963586]
[32.8  32.8   0.75]
[2.58744659 0.61139582 0.2600206 ]
[32.8  32.8   0.75]
[2.60091772 0.59690514 0.27310153]
[32.8  32.8   0.75]
[2.61457457 0.56887467 0.27807708]
[32.8  32.8   0.75]
[2.61979663 0.54310368 0.26041963]
[32.8  32.8   0.75]
[2.62183879 0.53670677 0.25751513]
[32.8  32.8   0.75]
[2.62267834 0.53409291 0.25967905]
[32.8  32.8   0.75]
[2.61571254 0.52630236 0.25974738]
[32.8  32.8   0.75]
[2.61446774 0.51819614 0.25971861]
[32.8  32.8   0.75]
[2.60353636 0.50751387 0.25960585]
[32.8  32.8   0.75]
[2.593083   0.49840689 0.25963141]
[32.8  32.8   0.75]
[2.58583969 0.49195559 0.25969938]
[32.8  32.8   0.75]
[2.57205605 0.46797439 0.25966565]
[32.8  32.8   0.75]
[2.55461097 0.43723853 0.26002948]
[32.8  32.8   0.75]
[2.54311591 0.43087408 0.25937534]
[32.8  32.8   0.75]
[2.52459874 0.43741137 0.25955879]
[32.8  32.8   0.75]
[2.49845007 0.46127512 0.26514446]
[32.8  32.8   0.75]
[2.47086077 0.4961333  0.26250103]
[32.8  32.8   0.75]
[2.46127578 0.51091815 0.25776328]
[32.8  32.8   0.75]
[2.45610024 0.51227053 0.26082483]
[32.8  32.8   0.75]
[2.4472838  0.5100667  0.26385236]
[32.8  32.8   0.75]
[2.44961154 0.51706173 0.25828648]
[32.8  32.8   0.75]
[2.45730792 0.52099282 0.2595174 ]
[32.8  32.8   0.75]
[2.46782113 0.52098454 0.25979674]
[32.8  32.8   0.75]
[2.47032386 0.5128642  0.25956936]
[32.8  32.8   0.75]
[2.46029126 0.50443271 0.25960717]
[32.8  32.8   0.75]
[2.44307818 0.51070255 0.26008747]
[32.8  32.8   0.75]
[2.43275864 0.508377   0.26000089]
[32.8  32.8   0.75]
[2.423      0.5005933  0.26196432]
[32.8  32.8   0.75]
[2.41498551 0.49844868 0.26147744]
[32.8  32.8   0.75]
[2.42011458 0.48639639 0.25839205]
[32.8  32.8   0.75]
[2.42282144 0.48682028 0.25958976]
[32.8  32.8   0.75]
[2.42762229 0.49409564 0.2596982 ]
[32.8  32.8   0.75]
[2.4315036  0.50440156 0.25958453]
[32.8  32.8   0.75]
[2.44100149 0.50407325 0.25985261]
[32.8  32.8   0.75]
[2.45954921 0.49318115 0.25951242]
[32.8  32.8   0.75]
[2.47056932 0.4880639  0.25951212]
[32.8  32.8   0.75]
[2.47163207 0.490952   0.25971043]
[32.8  32.8   0.75]
[2.47290206 0.49756115 0.25970325]
[32.8  32.8   0.75]
[2.46329604 0.50233391 0.25962716]
[32.8  32.8   0.75]
[2.45218691 0.50631367 0.2595866 ]
[32.8  32.8   0.75]
[2.44641105 0.50497887 0.25957325]
[32.8  32.8   0.75]
[2.43179073 0.49924461 0.25970904]
[32.8  32.8   0.75]
[2.42483116 0.49956718 0.25978808]
[32.8  32.8   0.75]
[2.42430485 0.50355446 0.25963432]
[32.8  32.8   0.75]
[2.42878983 0.51224608 0.25962235]
[32.8  32.8   0.75]
[2.43212322 0.52625723 0.25961313]
[32.8  32.8   0.75]
[2.42620674 0.5389702  0.26246106]
[32.8  32.8   0.75]
[2.39595454 0.53861272 0.26459397]
[32.8  32.8   0.75]
[2.37865729 0.54176537 0.25729082]
[32.8  32.8   0.75]
[2.36884604 0.54364986 0.25933494]
[32.8  32.8   0.75]
[2.3696855  0.54686398 0.25964611]
[32.8  32.8   0.75]
[2.38046646 0.55678903 0.25967716]
[32.8  32.8   0.75]
[2.41770609 0.58123312 0.27089711]
[32.8  32.8   0.75]
[2.47395811 0.60934045 0.26935328]
[32.8  32.8   0.75]
[2.49955678 0.62743762 0.25678018]
[32.8  32.8   0.75]
[2.49706658 0.62811156 0.25904555]
[32.8  32.8   0.75]
[2.49148223 0.62637013 0.25954704]
[32.8  32.8   0.75]
[2.48821065 0.62465397 0.25987742]
[32.8  32.8   0.75]
[2.48367142 0.61719678 0.25961231]
[32.8  32.8   0.75]
[2.4734058  0.61028661 0.25986294]
[32.8  32.8   0.75]
[2.46685412 0.60483915 0.25958515]
[32.8  32.8   0.75]
[2.46022271 0.59475187 0.25955447]
[32.8  32.8   0.75]
[2.45198632 0.57942429 0.25991035]
[32.8  32.8   0.75]
[2.44000952 0.57418028 0.2596185 ]
[32.8  32.8   0.75]
[2.43270936 0.56829523 0.26580467]
[32.8  32.8   0.75]
[2.42756008 0.564675   0.25877391]
[32.8  32.8   0.75]
[2.42075203 0.55675399 0.25990489]
[32.8  32.8   0.75]
[2.43271175 0.55118538 0.25944483]
[32.8  32.8   0.75]
[2.44430013 0.54590566 0.25966741]
[32.8  32.8   0.75]
[2.46925599 0.54453727 0.25953213]
[32.8  32.8   0.75]
[2.50087541 0.53222049 0.25953742]
[32.8  32.8   0.75]
[2.53147744 0.52967589 0.25953563]
[32.8  32.8   0.75]
[2.54382551 0.54011353 0.26045546]
[32.8  32.8   0.75]
[2.54558654 0.54109907 0.25927807]
[32.8  32.8   0.75]
[2.54841701 0.53281841 0.25967628]
[32.8  32.8   0.75]
[2.56621963 0.52658007 0.26266886]
[32.8  32.8   0.75]
[2.57234055 0.52375571 0.26775631]
[32.8  32.8   0.75]
[2.57650545 0.50623382 0.25806703]
[32.8  32.8   0.75]
[2.58209362 0.51347761 0.25930183]
[32.8  32.8   0.75]
[2.5763239  0.52796317 0.25939183]
[32.8  32.8   0.75]
[2.55968548 0.54354661 0.25954612]
[32.8  32.8   0.75]
[2.5601024  0.54810609 0.25960903]
[32.8  32.8   0.75]
[2.57042886 0.54415341 0.25960127]
[32.8  32.8   0.75]
[2.58144546 0.54304436 0.25968242]
[32.8  32.8   0.75]
[2.58531378 0.54958203 0.25971751]
[32.8  32.8   0.75]
[2.58168095 0.55825814 0.25966446]
[32.8  32.8   0.75]
[2.57750184 0.56885183 0.25960354]
[32.8  32.8   0.75]
[2.57420258 0.58586138 0.25969448]
[32.8  32.8   0.75]
[2.56214559 0.59983894 0.26862778]
[32.8  32.8   0.75]
[2.54240475 0.6040393  0.28185316]
[32.8  32.8   0.75]
[2.5261414  0.60266944 0.27487951]
[32.8  32.8   0.75]
[2.50721669 0.59193607 0.25514925]
[32.8  32.8   0.75]
[2.50180889 0.57919752 0.25847944]
[32.8  32.8   0.75]
[2.50012177 0.56685889 0.25994697]
[32.8  32.8   0.75]
[2.49625823 0.56013564 0.25901513]
[32.8  32.8   0.75]
[2.49388702 0.55408078 0.25964971]
[32.8  32.8   0.75]
[2.49018942 0.54947855 0.25969502]
[32.8  32.8   0.75]
[2.48813627 0.54018822 0.25964705]
[32.8  32.8   0.75]
[2.49643085 0.5413574  0.25974597]
[32.8  32.8   0.75]
[2.50142462 0.55022083 0.26050921]
[32.8  32.8   0.75]
[2.47987462 0.54477454 0.2591758 ]
[32.8  32.8   0.75]
[2.46404374 0.54020364 0.25953093]
[32.8  32.8   0.75]
[2.45515653 0.5491547  0.25966877]
[32.8  32.8   0.75]
[2.44678546 0.55547032 0.25960836]
[32.8  32.8   0.75]
[2.44195648 0.55210251 0.25959714]
[32.8  32.8   0.75]
[2.43863712 0.5514422  0.25964739]
[32.8  32.8   0.75]
[2.41394023 0.55538283 0.25963489]
[32.8  32.8   0.75]
[2.37986559 0.56288983 0.2597105 ]
[32.8  32.8   0.75]
[2.36618852 0.57096534 0.26746639]
[32.8  32.8   0.75]
[2.35785318 0.57392143 0.2745544 ]
[32.8  32.8   0.75]
[2.35969412 0.57968178 0.25318442]
[32.8  32.8   0.75]
[2.3784074  0.56541735 0.25819397]
[32.8  32.8   0.75]
[2.38838574 0.5545437  0.25918631]
[32.8  32.8   0.75]
[2.39700653 0.55852745 0.25950697]
[32.8  32.8   0.75]
[2.40618585 0.55986143 0.25923849]
[32.8  32.8   0.75]
[2.41188951 0.55654731 0.25970306]
[32.8  32.8   0.75]
[2.42094417 0.5574939  0.25966346]
[32.8  32.8   0.75]
[2.43458606 0.55875218 0.25961216]
[32.8  32.8   0.75]
[2.44807348 0.56240874 0.25970804]
[32.8  32.8   0.75]
[2.44811041 0.56477075 0.25965452]
[32.8  32.8   0.75]
[2.43711029 0.563489   0.25957151]
[32.8  32.8   0.75]
[2.43055082 0.55929862 0.25966185]
[32.8  32.8   0.75]
[2.43074727 0.56174293 0.25966045]
[32.8  32.8   0.75]
[2.4400236  0.57096091 0.25968457]
[32.8  32.8   0.75]
[2.45933113 0.58483862 0.25957527]
[32.8  32.8   0.75]
[2.47871037 0.60473627 0.25886367]
[32.8  32.8   0.75]
[2.48106511 0.62494079 0.25997521]
[32.8  32.8   0.75]
[2.48475799 0.63468234 0.25964494]
[32.8  32.8   0.75]
[2.48884164 0.62626408 0.25881117]
[32.8  32.8   0.75]
[2.49694992 0.62801894 0.25954288]
[32.8  32.8   0.75]
[2.50302211 0.63835138 0.25970673]
[32.8  32.8   0.75]
[2.49827107 0.63963503 0.26773739]
[32.8  32.8   0.75]
[2.48272502 0.6277492  0.27114392]
[32.8  32.8   0.75]
[2.46327487 0.6078953  0.25938915]
[32.8  32.8   0.75]
[2.45832402 0.59701598 0.25830461]
[32.8  32.8   0.75]
[2.45938904 0.58995152 0.2595588 ]
[32.8  32.8   0.75]
[2.4561007  0.58423273 0.25962954]
[32.8  32.8   0.75]
[2.45525012 0.57525133 0.25966029]
[32.8  32.8   0.75]
[2.46330088 0.57064864 0.25959187]
[32.8  32.8   0.75]
[2.4676916  0.56884148 0.25963467]
[32.8  32.8   0.75]
[2.47043984 0.55752857 0.25979545]
[32.8  32.8   0.75]
[2.47418497 0.54370513 0.25959237]
[32.8  32.8   0.75]
[2.4744803  0.53822157 0.2596024 ]
[32.8  32.8   0.75]
[2.46851899 0.53538233 0.25964449]
[32.8  32.8   0.75]
[2.46412753 0.52820415 0.25968162]
[32.8  32.8   0.75]
[2.46290873 0.51552204 0.25955916]
[32.8  32.8   0.75]
[2.47665705 0.50877325 0.26010378]
[32.8  32.8   0.75]
[2.49410292 0.50935414 0.25969883]
[32.8  32.8   0.75]
[2.50922773 0.50787325 0.26063499]
[32.8  32.8   0.75]
[2.51550962 0.49849224 0.26513158]
[32.8  32.8   0.75]
[2.51763741 0.48603043 0.25733334]
[32.8  32.8   0.75]
[2.52603219 0.471924   0.26288208]
[32.8  32.8   0.75]
[2.53307786 0.45811944 0.26311427]
[32.8  32.8   0.75]
[2.53507583 0.44655509 0.257491  ]
[32.8  32.8   0.75]
[2.53393997 0.43822509 0.25948159]
[32.8  32.8   0.75]
[2.52652768 0.43186584 0.25967963]
[32.8  32.8   0.75]
[2.51961403 0.43415268 0.25986414]
[32.8  32.8   0.75]
[2.51179133 0.44467664 0.25961469]
[32.8  32.8   0.75]
[2.50004743 0.44889507 0.259968  ]
[32.8  32.8   0.75]
[2.48707389 0.43123399 0.25966967]
[32.8  32.8   0.75]
[2.47701102 0.41556159 0.26415388]
[32.8  32.8   0.75]
[2.47727603 0.41394401 0.26090242]
[32.8  32.8   0.75]
[2.47353363 0.42313648 0.25864954]
[32.8  32.8   0.75]
[2.47051697 0.43053362 0.25952354]
[32.8  32.8   0.75]
[2.4707753  0.44201222 0.25959945]
[32.8  32.8   0.75]
[2.46675565 0.44356038 0.25976033]
[32.8  32.8   0.75]
[2.45921625 0.44425661 0.25967942]
[32.8  32.8   0.75]
[2.44916615 0.44662922 0.25961805]
[32.8  32.8   0.75]
[2.43213228 0.45171914 0.25959933]
[32.8  32.8   0.75]
[2.42034851 0.45883901 0.25964199]
[32.8  32.8   0.75]
[2.41638403 0.46465317 0.25965576]
[32.8  32.8   0.75]
[2.41017126 0.47477541 0.25963043]
[32.8  32.8   0.75]
[2.39746076 0.49152544 0.26012485]
[32.8  32.8   0.75]
[2.38291786 0.50285052 0.25946893]
[32.8  32.8   0.75]
[2.37804186 0.50009976 0.25960949]
[32.8  32.8   0.75]
[2.37540469 0.49632181 0.25967597]
[32.8  32.8   0.75]
[2.3718135  0.4920779  0.25954881]
[32.8  32.8   0.75]
[2.36944125 0.49484638 0.25960397]
[32.8  32.8   0.75]
[2.37376655 0.49645777 0.25980819]
[32.8  32.8   0.75]
[2.36084318 0.49587486 0.26234079]
[32.8  32.8   0.75]
[2.34709506 0.5138991  0.27178954]
[32.8  32.8   0.75]
[2.33894678 0.5431735  0.27337348]
[32.8  32.8   0.75]
[-0.06585899 -0.08919749  0.80355753]
[4.7  4.7  0.75]
[-0.06775299 -0.10635978  0.80479644]
[4.7  4.7  0.75]
[-0.08144825 -0.11081484  0.75537047]
[4.7  4.7  0.75]
[-0.08385374 -0.08957202  0.6853851 ]
[4.7  4.7  0.75]
[-0.05461064 -0.05722575  0.62791078]
[4.7  4.7  0.75]
[-0.02914817 -0.03202593  0.54616781]
[4.7  4.7  0.75]
[-0.02241627  0.00481958  0.46743796]
[4.7  4.7  0.75]
[-0.01426033  0.05881711  0.59038565]
[4.7  4.7  0.75]
[0.0087798  0.11587999 0.7120885 ]
[4.7  4.7  0.75]
[0.03616041 0.17269062 0.81304459]
[4.7  4.7  0.75]
[0.06003671 0.22268582 0.88554204]
[4.7  4.7  0.75]
[0.09367579 0.27352595 0.92582751]
[4.7  4.7  0.75]
[0.12713049 0.33108103 0.94173198]
[4.7  4.7  0.75]
[0.15154094 0.38681982 0.93083216]
[4.7  4.7  0.75]
[0.16712833 0.44910982 0.89927454]
[4.7  4.7  0.75]
[0.17695233 0.5137941  0.85207813]
[4.7  4.7  0.75]
[0.14296598 0.57262604 0.86652503]
[4.7  4.7  0.75]
[0.1159835  0.62819687 0.86996488]
[4.7  4.7  0.75]
[0.08707683 0.67885611 0.84446304]
[4.7  4.7  0.75]
[0.04712597 0.71919517 0.79257626]
[4.7  4.7  0.75]
[0.00311054 0.76041907 0.71457932]
[4.7  4.7  0.75]
[0.01351487 0.85737138 0.68178638]
[4.7  4.7  0.75]
[0.08136317 0.98146294 0.65832638]
[4.7  4.7  0.75]
[0.13764915 1.09234978 0.61341962]
[4.7  4.7  0.75]
[0.16388289 1.18863693 0.57295854]
[4.7  4.7  0.75]
[0.14980371 1.27608244 0.55718874]
[4.7  4.7  0.75]
[0.12188978 1.34000862 0.58696158]
[4.7  4.7  0.75]
[0.09847674 1.34953037 0.64754469]
[4.7  4.7  0.75]
[0.08568741 1.37979873 0.68404017]
[4.7  4.7  0.75]
[0.08221082 1.41089564 0.68689484]
[4.7  4.7  0.75]
[0.07997146 1.44207575 0.66790074]
[4.7  4.7  0.75]
[0.07895285 1.46091205 0.6473648 ]
[4.7  4.7  0.75]
[0.09368661 1.4718805  0.61611838]
[4.7  4.7  0.75]
[0.12069863 1.47163979 0.58955209]
[4.7  4.7  0.75]
[0.14665855 1.45925163 0.55898458]
[4.7  4.7  0.75]
[0.16166492 1.43958974 0.50739152]
[4.7  4.7  0.75]
[0.18400074 1.41630191 0.45596301]
[4.7  4.7  0.75]
[0.20920112 1.35531896 0.49840478]
[4.7  4.7  0.75]
[0.24556197 1.29158083 0.51898889]
[4.7  4.7  0.75]
[0.28792132 1.22838509 0.52109884]
[4.7  4.7  0.75]
[0.31296057 1.19570001 0.57185625]
[4.7  4.7  0.75]
[0.31426483 1.17168244 0.63176916]
[4.7  4.7  0.75]
[0.29393378 1.14048735 0.65969809]
[4.7  4.7  0.75]
[0.26575123 1.09773925 0.67667719]
[4.7  4.7  0.75]
[0.24144438 1.05418042 0.68869669]
[4.7  4.7  0.75]
[0.23443805 1.00949449 0.67934358]
[4.7  4.7  0.75]
[0.21475062 0.97438464 0.65225233]
[4.7  4.7  0.75]
[0.18121462 0.9395486  0.6240214 ]
[4.7  4.7  0.75]
[0.12729409 0.9321349  0.6981108 ]
[4.7  4.7  0.75]
[0.07597059 0.93173363 0.75005373]
[4.7  4.7  0.75]
[0.030244   0.9278364  0.77346012]
[4.7  4.7  0.75]
[-0.02413607  0.93227492  0.7729284 ]
[4.7  4.7  0.75]
[-0.09279012  0.93288215  0.75312408]
[4.7  4.7  0.75]
[-0.16509816  0.92390331  0.71236632]
[4.7  4.7  0.75]
[-0.22635957  0.91551759  0.64875639]
[4.7  4.7  0.75]
[-0.32372899  0.88031279  0.61967502]
[4.7  4.7  0.75]
[-0.42654899  0.82554682  0.60890804]
[4.7  4.7  0.75]
[-0.44244672  0.78393533  0.65078798]
[4.7  4.7  0.75]
[-0.45580595  0.75005807  0.67595402]
[4.7  4.7  0.75]
[-0.47019739  0.72576152  0.67341531]
[4.7  4.7  0.75]
[-0.48346081  0.70146743  0.65365428]
[4.7  4.7  0.75]
[-0.4941466   0.68390482  0.61824193]
[4.7  4.7  0.75]
[-0.52396233  0.64610076  0.5768018 ]
[4.7  4.7  0.75]
[-0.53906544  0.58597965  0.56704   ]
[4.7  4.7  0.75]
[-0.54015194  0.54096006  0.54572769]
[4.7  4.7  0.75]
[-0.5639291   0.50363133  0.51924722]
[4.7  4.7  0.75]
[-0.60876205  0.48097376  0.49089056]
[4.7  4.7  0.75]
[-0.65090516  0.45242184  0.44767482]
[4.7  4.7  0.75]
[-0.68742197  0.42349318  0.4010174 ]
[4.7  4.7  0.75]
[-0.65597707  0.43450585  0.51868134]
[4.7  4.7  0.75]
[-0.60579989  0.46216006  0.64194507]
[4.7  4.7  0.75]
[-0.56656598  0.47724993  0.73862195]
[4.7  4.7  0.75]
[-0.52813806  0.48880156  0.81275212]
[4.7  4.7  0.75]
[-0.48273097  0.50615339  0.86175129]
[4.7  4.7  0.75]
[-0.43385536  0.52735051  0.88134279]
[4.7  4.7  0.75]
[-0.38825461  0.54034277  0.88306147]
[4.7  4.7  0.75]
[-0.34586581  0.55058168  0.86070803]
[4.7  4.7  0.75]
[-0.30086015  0.54151118  0.81587346]
[4.7  4.7  0.75]
[-0.25537819  0.53759296  0.74652231]
[4.7  4.7  0.75]
[-0.21477348  0.55086684  0.64433695]
[4.7  4.7  0.75]
[-0.18751841  0.55716639  0.57551374]
[4.7  4.7  0.75]
[-0.16705442  0.56968366  0.61925498]
[4.7  4.7  0.75]
[-0.13720029  0.57623419  0.67413942]
[4.7  4.7  0.75]
[-0.10938952  0.58682616  0.70375998]
[4.7  4.7  0.75]
[-0.0748575   0.60134079  0.73331611]
[4.7  4.7  0.75]
[-0.03891951  0.6039838   0.73500276]
[4.7  4.7  0.75]
[-0.00530921  0.60859357  0.71611936]
[4.7  4.7  0.75]
[0.02820713 0.61566557 0.67569283]
[4.7  4.7  0.75]
[0.02537869 0.61493175 0.65314525]
[4.7  4.7  0.75]
[-0.01690401  0.61426726  0.65711959]
[4.7  4.7  0.75]
[-0.04928056  0.65128884  0.65565924]
[4.7  4.7  0.75]
[-0.08644119  0.65046327  0.64152399]
[4.7  4.7  0.75]
[-0.13699736  0.63661022  0.62841413]
[4.7  4.7  0.75]
[-0.18770963  0.64230448  0.67148464]
[4.7  4.7  0.75]
[-0.2223186   0.67356413  0.72319577]
[4.7  4.7  0.75]
[-0.26780615  0.71845287  0.75128648]
[4.7  4.7  0.75]
[-0.32004483  0.76565918  0.75828161]
[4.7  4.7  0.75]
[-0.36098643  0.79652882  0.72909731]
[4.7  4.7  0.75]
[-0.38952706  0.81948637  0.6735257 ]
[4.7  4.7  0.75]
[-0.40961671  0.83109117  0.60745125]
[4.7  4.7  0.75]
[-0.39148386  0.82026792  0.63027111]
[4.7  4.7  0.75]
[-0.36708782  0.82158333  0.64307174]
[4.7  4.7  0.75]
[-0.35059069  0.83058852  0.63871729]
[4.7  4.7  0.75]
[-0.34872368  0.85002119  0.63814007]
[4.7  4.7  0.75]
[-0.36233864  0.85794607  0.63618506]
[4.7  4.7  0.75]
[-0.38439333  0.85202706  0.61510504]
[4.7  4.7  0.75]
[-0.38328214  0.88776745  0.58879543]
[4.7  4.7  0.75]
[-0.36820289  0.95329786  0.56528231]
[4.7  4.7  0.75]
[-0.34676167  1.02549023  0.52738082]
[4.7  4.7  0.75]
[-0.32988027  1.11106592  0.48561043]
[4.7  4.7  0.75]
[-0.33335279  1.19332866  0.477871  ]
[4.7  4.7  0.75]
[-0.34816333  1.25917975  0.48006543]
[4.7  4.7  0.75]
[-0.3752568   1.31416462  0.50241905]
[4.7  4.7  0.75]
[-0.40340968  1.35678587  0.55247953]
[4.7  4.7  0.75]
[-0.42493373  1.40522244  0.57869106]
[4.7  4.7  0.75]
[-0.44706069  1.46698196  0.57418117]
[4.7  4.7  0.75]
[-0.46825563  1.53040771  0.53833877]
[4.7  4.7  0.75]
[-0.48893779  1.59459154  0.48676389]
[4.7  4.7  0.75]
[-0.50391556  1.66718555  0.41972911]
[4.7  4.7  0.75]
[-0.50503331  1.75388379  0.39436766]
[4.7  4.7  0.75]
[-0.53809751  1.81714067  0.46042997]
[4.7  4.7  0.75]
[-0.57160346  1.84733348  0.54478196]
[4.7  4.7  0.75]
[-0.59482099  1.85356002  0.67069332]
[4.7  4.7  0.75]
[-0.61398092  1.86122049  0.777077  ]
[4.7  4.7  0.75]
[-0.62025705  1.8764385   0.84838688]
[4.7  4.7  0.75]
[-0.64617468  1.90037142  0.89060578]
[4.7  4.7  0.75]
[-0.68280552  1.92364631  0.90363706]
[4.7  4.7  0.75]
[-0.72462108  1.93173875  0.89746223]
[4.7  4.7  0.75]
[-0.76850313  1.92625242  0.8779812 ]
[4.7  4.7  0.75]
[-0.81452825  1.94506443  0.84299268]
[4.7  4.7  0.75]
[-0.84738122  1.95974869  0.78927529]
[4.7  4.7  0.75]
[-0.88505614  1.95081209  0.76363626]
[4.7  4.7  0.75]
[-0.92438394  1.95030985  0.74825036]
[4.7  4.7  0.75]
[-0.968557    1.93618092  0.70869053]
[4.7  4.7  0.75]
[-1.02745502  1.92681799  0.66107093]
[4.7  4.7  0.75]
[-1.09700753  1.9548705   0.6284669 ]
[4.7  4.7  0.75]
[-1.1691905   1.97318695  0.57694606]
[4.7  4.7  0.75]
[-1.23166428  1.97723363  0.54158572]
[4.7  4.7  0.75]
[-1.28161949  1.96755653  0.57591067]
[4.7  4.7  0.75]
[-1.31893644  1.94785372  0.60316926]
[4.7  4.7  0.75]
[-1.34702703  1.91585615  0.61265748]
[4.7  4.7  0.75]
[-1.37972672  1.88679204  0.5988037 ]
[4.7  4.7  0.75]
[-1.41478197  1.87286842  0.56124378]
[4.7  4.7  0.75]
[-1.45586596  1.87317828  0.50981564]
[4.7  4.7  0.75]
[-1.50239737  1.91192819  0.52861246]
[4.7  4.7  0.75]
[-1.52840312  1.97006381  0.57619775]
[4.7  4.7  0.75]
[-1.54688197  2.01652475  0.62921033]
[4.7  4.7  0.75]
[-1.57243373  2.04856467  0.66645894]
[4.7  4.7  0.75]
[-1.58049847  2.05949106  0.71153473]
[4.7  4.7  0.75]
[-1.5883379   2.06781699  0.73388822]
[4.7  4.7  0.75]
[-1.59333808  2.07967905  0.73331962]
[4.7  4.7  0.75]
[-1.58916949  2.10149632  0.71705005]
[4.7  4.7  0.75]
[-1.58763931  2.12422982  0.68250839]
[4.7  4.7  0.75]
[-1.59272463  2.11933221  0.64097517]
[4.7  4.7  0.75]
[-1.59369159  2.12590991  0.59367725]
[4.7  4.7  0.75]
[-1.59891813  2.1468194   0.55766396]
[4.7  4.7  0.75]
[-1.55640801  2.15605551  0.58147728]
[4.7  4.7  0.75]
[-1.51883706  2.14722217  0.60753741]
[4.7  4.7  0.75]
[-1.50687051  2.12497368  0.60418665]
[4.7  4.7  0.75]
[-1.51200567  2.10682955  0.5829207 ]
[4.7  4.7  0.75]
[-1.52901921  2.09621961  0.56054825]
[4.7  4.7  0.75]
[-1.53786471  2.07341347  0.53062652]
[4.7  4.7  0.75]
[-1.52428785  2.07156308  0.52550217]
[4.7  4.7  0.75]
[-1.50956975  2.05922653  0.52951933]
[4.7  4.7  0.75]
[-1.49273882  2.04343624  0.51332327]
[4.7  4.7  0.75]
[-1.46308544  2.0316628   0.50675985]
[4.7  4.7  0.75]
[-1.42594222  2.01920299  0.53377283]
[4.7  4.7  0.75]
[-1.37932871  2.0111456   0.53268502]
[4.7  4.7  0.75]
[-1.33479667  2.00713287  0.51641072]
[4.7  4.7  0.75]
[-1.29469043  2.00258897  0.52670121]
[4.7  4.7  0.75]
[-1.24380296  2.01071056  0.53377958]
[4.7  4.7  0.75]
[-1.19589259  2.02712126  0.5333074 ]
[4.7  4.7  0.75]
[-1.19177188  2.02637425  0.55511146]
[4.7  4.7  0.75]
[-1.22934944  2.02497888  0.60055584]
[4.7  4.7  0.75]
[-1.26561151  2.03571995  0.62095308]
[4.7  4.7  0.75]
[-1.29344645  2.02930003  0.61203555]
[4.7  4.7  0.75]
[-1.3069659   2.0187456   0.57926163]
[4.7  4.7  0.75]
[-1.26413197  2.00608845  0.61218534]
[4.7  4.7  0.75]
[-1.21294848  1.98992145  0.69498285]
[4.7  4.7  0.75]
[-1.17481387  1.98244655  0.74843534]
[4.7  4.7  0.75]
[-1.13619309  1.99637941  0.77389727]
[4.7  4.7  0.75]
[-1.10033244  2.01466393  0.7779151 ]
[4.7  4.7  0.75]
[-1.06699959  2.02836772  0.76522074]
[4.7  4.7  0.75]
[-1.03318234  2.03150906  0.72250891]
[4.7  4.7  0.75]
[-1.00611466  2.04923668  0.66526551]
[4.7  4.7  0.75]
[-0.98323666  2.1006859   0.62538956]
[4.7  4.7  0.75]
[-1.01181262  2.15639451  0.60542026]
[4.7  4.7  0.75]
[-1.04843585  2.22070795  0.5685645 ]
[4.7  4.7  0.75]
[-1.05663598  2.27152491  0.53516073]
[4.7  4.7  0.75]
[-1.03225843  2.31815459  0.5079991 ]
[4.7  4.7  0.75]
[-0.96413286  2.33195736  0.64236109]
[4.7  4.7  0.75]
[-0.89327846  2.35860285  0.79922617]
[4.7  4.7  0.75]
[-0.81750608  2.39605455  0.93993976]
[4.7  4.7  0.75]
[-0.75319722  2.42520373  1.05415532]
[4.7  4.7  0.75]
[ 0.10973562 -0.06850938  0.76477284]
[12.2  12.2   0.75]
[ 0.13122061 -0.07315187  0.7490325 ]
[12.2  12.2   0.75]
[ 0.12412424 -0.08141189  0.70636192]
[12.2  12.2   0.75]
[ 0.11173014 -0.07685848  0.65072608]
[12.2  12.2   0.75]
[ 0.08935648 -0.09262671  0.650938  ]
[12.2  12.2   0.75]
[ 0.08857069 -0.08045151  0.68070284]
[12.2  12.2   0.75]
[ 0.06835325 -0.08889552  0.70939609]
[12.2  12.2   0.75]
[ 0.06372321 -0.11086509  0.7403351 ]
[12.2  12.2   0.75]
[ 0.05923609 -0.10861337  0.75621926]
[12.2  12.2   0.75]
[ 0.01527576 -0.10420326  0.76592986]
[12.2  12.2   0.75]
[-0.03577046 -0.09919734  0.75386867]
[12.2  12.2   0.75]
[-0.08472691 -0.07437875  0.71163714]
[12.2  12.2   0.75]
[-0.13667283 -0.02117878  0.68551796]
[12.2  12.2   0.75]
[-0.19502673  0.06462618  0.67151042]
[12.2  12.2   0.75]
[-0.22718739  0.15482753  0.68836572]
[12.2  12.2   0.75]
[-0.27437625  0.25124578  0.69518735]
[12.2  12.2   0.75]
[-0.32771379  0.33976582  0.68021948]
[12.2  12.2   0.75]
[-0.35882678  0.41268377  0.64311517]
[12.2  12.2   0.75]
[-0.3851209   0.44286451  0.65148544]
[12.2  12.2   0.75]
[-0.40189128  0.43573579  0.69171121]
[12.2  12.2   0.75]
[-0.4227034   0.42796884  0.70302627]
[12.2  12.2   0.75]
[-0.4502355   0.42753385  0.69407283]
[12.2  12.2   0.75]
[-0.47813544  0.42392706  0.67606862]
[12.2  12.2   0.75]
[-0.50047327  0.41803458  0.63023701]
[12.2  12.2   0.75]
[-0.52499058  0.40595957  0.5671966 ]
[12.2  12.2   0.75]
[-0.50581024  0.41913466  0.56563442]
[12.2  12.2   0.75]
[-0.44761879  0.45500333  0.61426635]
[12.2  12.2   0.75]
[-0.39042301  0.49379136  0.63654524]
[12.2  12.2   0.75]
[-0.35313476  0.53339871  0.63068165]
[12.2  12.2   0.75]
[-0.32034064  0.56901066  0.59685148]
[12.2  12.2   0.75]
[-0.31572947  0.57815986  0.58478768]
[12.2  12.2   0.75]
[-0.3210698   0.58240015  0.56237182]
[12.2  12.2   0.75]
[-0.34973558  0.62724894  0.5530228 ]
[12.2  12.2   0.75]
[-0.39902975  0.71230365  0.57803481]
[12.2  12.2   0.75]
[-0.42176326  0.78243664  0.59259081]
[12.2  12.2   0.75]
[-0.41806929  0.84781588  0.5993975 ]
[12.2  12.2   0.75]
[-0.42657328  0.9027374   0.58172052]
[12.2  12.2   0.75]
[-0.44980941  0.96227374  0.55909258]
[12.2  12.2   0.75]
[-0.48988781  1.00335401  0.55080852]
[12.2  12.2   0.75]
[-0.52666735  1.01620725  0.57344168]
[12.2  12.2   0.75]
[-0.56263831  1.02992956  0.59699346]
[12.2  12.2   0.75]
[-0.60577263  1.03411576  0.60225618]
[12.2  12.2   0.75]
[-0.63415213  1.04877034  0.60007812]
[12.2  12.2   0.75]
[-0.65236519  1.06314982  0.59677695]
[12.2  12.2   0.75]
[-0.64233601  1.0744035   0.62175143]
[12.2  12.2   0.75]
[-0.633883    1.09000863  0.62238423]
[12.2  12.2   0.75]
[-0.62545071  1.10825482  0.60451767]
[12.2  12.2   0.75]
[-0.62063416  1.13500649  0.5729364 ]
[12.2  12.2   0.75]
[-0.63401192  1.2181575   0.59734065]
[12.2  12.2   0.75]
[-0.6331714   1.33172279  0.65111227]
[12.2  12.2   0.75]
[-0.59522397  1.42171874  0.68747554]
[12.2  12.2   0.75]
[-0.5449542   1.49624027  0.71039922]
[12.2  12.2   0.75]
[-0.51461603  1.5359167   0.72467357]
[12.2  12.2   0.75]
[-0.5573017   1.56079799  0.78805072]
[12.2  12.2   0.75]
[-0.61591525  1.59291966  0.84406037]
[12.2  12.2   0.75]
[-0.65101236  1.61951009  0.87092843]
[12.2  12.2   0.75]
[-0.68155397  1.6282655   0.87447806]
[12.2  12.2   0.75]
[-0.73610751  1.64442648  0.85814051]
[12.2  12.2   0.75]
[-0.80248878  1.67234609  0.84279802]
[12.2  12.2   0.75]
[-0.86572857  1.7022197   0.8108341 ]
[12.2  12.2   0.75]
[-0.9203214   1.73241242  0.74629454]
[12.2  12.2   0.75]
[-0.96756973  1.77585764  0.64871866]
[12.2  12.2   0.75]
[-0.99941693  1.83722789  0.52830803]
[12.2  12.2   0.75]
[-0.98482479  1.92713783  0.47003096]
[12.2  12.2   0.75]
[-1.01550359  1.96260721  0.47213374]
[12.2  12.2   0.75]
[-1.04000244  1.90145452  0.56035645]
[12.2  12.2   0.75]
[-1.05079716  1.82450548  0.74429891]
[12.2  12.2   0.75]
[-1.06985973  1.76229848  0.89357634]
[12.2  12.2   0.75]
[-1.09245775  1.69415946  1.01906932]
[12.2  12.2   0.75]
[ 0.07707557 -0.00429379  0.73380131]
[31.3  31.3   0.75]
[0.06678864 0.00194373 0.72841729]
[31.3  31.3   0.75]
[ 0.05452278 -0.0022141   0.68772974]
[31.3  31.3   0.75]
[ 0.03806078 -0.01017771  0.63704073]
[31.3  31.3   0.75]
[-0.01739182 -0.00595856  0.6370863 ]
[31.3  31.3   0.75]
[-0.08262694 -0.01181347  0.63158389]
[31.3  31.3   0.75]
[-1.20189689e-01  8.87268726e-05  6.28266654e-01]
[31.3  31.3   0.75]
[-0.09959196  0.03348702  0.68579732]
[31.3  31.3   0.75]
[-0.07078747  0.06716852  0.74623338]
[31.3  31.3   0.75]
[-0.06048866  0.08234522  0.77783826]
[31.3  31.3   0.75]
[-0.05702206  0.09482837  0.78375927]
[31.3  31.3   0.75]
[-0.06019099  0.10911532  0.76399616]
[31.3  31.3   0.75]
[-0.05406346  0.12529259  0.71640117]
[31.3  31.3   0.75]
[-0.0450165   0.16733079  0.65322419]
[31.3  31.3   0.75]
[-0.02566346  0.26814319  0.6344432 ]
[31.3  31.3   0.75]
[-0.00672282  0.35320931  0.64051807]
[31.3  31.3   0.75]
[-0.0032979   0.42465462  0.66512706]
[31.3  31.3   0.75]
[-0.01713585  0.50674865  0.66798385]
[31.3  31.3   0.75]
[-0.031569    0.58841787  0.65027089]
[31.3  31.3   0.75]
[-0.05854297  0.64903215  0.63016543]
[31.3  31.3   0.75]
[-0.10366744  0.69423605  0.61729743]
[31.3  31.3   0.75]
[-0.14758135  0.75774891  0.58588574]
[31.3  31.3   0.75]
[-0.18133184  0.80227177  0.55082707]
[31.3  31.3   0.75]
[-0.17802654  0.83497966  0.55892502]
[31.3  31.3   0.75]
[-0.16401446  0.84006887  0.59939544]
[31.3  31.3   0.75]
[-0.17941075  0.83023384  0.62978613]
[31.3  31.3   0.75]
[-0.2125296   0.81466256  0.67363325]
[31.3  31.3   0.75]
[-0.2510404   0.80704694  0.69654358]
[31.3  31.3   0.75]
[-0.27180539  0.81089729  0.68786908]
[31.3  31.3   0.75]
[-0.2970482   0.80540567  0.66965998]
[31.3  31.3   0.75]
[-0.33029727  0.79864675  0.63835366]
[31.3  31.3   0.75]
[-0.34819171  0.79646811  0.59373895]
[31.3  31.3   0.75]
[-0.32255102  0.81187577  0.57365436]
[31.3  31.3   0.75]
[-0.2803553   0.81929752  0.5651192 ]
[31.3  31.3   0.75]
[-0.23896387  0.84453294  0.56663266]
[31.3  31.3   0.75]
[-0.19621555  0.89853558  0.57028303]
[31.3  31.3   0.75]
[-0.17537315  0.95710786  0.57350401]
[31.3  31.3   0.75]
[-0.16441917  0.99162431  0.56348696]
[31.3  31.3   0.75]
[-0.1544248   1.00824141  0.5897881 ]
[31.3  31.3   0.75]
[-0.15259878  1.01363522  0.61176717]
[31.3  31.3   0.75]
[-0.15801848  1.0077194   0.61651179]
[31.3  31.3   0.75]
[-0.17876659  0.97760597  0.6583261 ]
[31.3  31.3   0.75]
[-0.19381359  0.95116773  0.68333374]
[31.3  31.3   0.75]
[-0.20792197  0.92519357  0.69831938]
[31.3  31.3   0.75]
[-0.21664818  0.90578381  0.69430046]
[31.3  31.3   0.75]
[-0.22735757  0.90174828  0.67348837]
[31.3  31.3   0.75]
[-0.25109333  0.89986145  0.63135466]
[31.3  31.3   0.75]
[-0.27041876  0.90978873  0.56692675]
[31.3  31.3   0.75]
[-0.25827816  0.92586893  0.5210088 ]
[31.3  31.3   0.75]
[-0.20852135  0.95572121  0.53525363]
[31.3  31.3   0.75]
[-0.17937266  0.95201001  0.58032388]
[31.3  31.3   0.75]
[-0.15582865  0.94731326  0.61222923]
[31.3  31.3   0.75]
[-0.15569149  0.96552653  0.61637807]
[31.3  31.3   0.75]
[-0.14072022  0.98667253  0.61022963]
[31.3  31.3   0.75]
[-0.11742983  1.01554018  0.5969033 ]
[31.3  31.3   0.75]
[-0.09656879  1.05581917  0.58789081]
[31.3  31.3   0.75]
[-0.07550549  1.0803192   0.6140658 ]
[31.3  31.3   0.75]
[-0.05745072  1.08101889  0.64581445]
[31.3  31.3   0.75]
[-0.05614964  1.0836512   0.64810028]
[31.3  31.3   0.75]
[-0.05666942  1.08655765  0.62484906]
[31.3  31.3   0.75]
[-0.04252494  1.09624074  0.57396484]
[31.3  31.3   0.75]
[-0.01731342  1.08764456  0.51633302]
[31.3  31.3   0.75]
[0.00840958 1.08261639 0.46603625]
[31.3  31.3   0.75]
[0.01255474 1.09755754 0.51888424]
[31.3  31.3   0.75]
[-0.00547387  1.10861239  0.70274157]
[31.3  31.3   0.75]
[-0.02487125  1.11657055  0.85001501]
[31.3  31.3   0.75]
[-0.03974713  1.12887523  0.97170576]
[31.3  31.3   0.75]
[-0.0499004  1.1448791  1.0731974]
[31.3  31.3   0.75]
----------------------------------
| forward_vel        | 1.01      |
| reward             | -1e+03    |
| reward_contact     | 0         |
| reward_ctrl        | -0.953    |
| reward_position    | -1e+03    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 333       |
|    ep_rew_mean     | -5.33e+05 |
| time/              |           |
|    episodes        | 4         |
|    fps             | 60        |
|    time_elapsed    | 22        |
|    total timesteps | 1331      |
----------------------------------
[0.09683137 0.06717819 0.8440633 ]
[37.8  37.8   0.75]
[0.12448901 0.06807073 0.83342763]
[37.8  37.8   0.75]
[0.12386848 0.06714079 0.77145899]
[37.8  37.8   0.75]
[0.12340575 0.06704839 0.67945807]
[37.8  37.8   0.75]
[0.07865099 0.03290646 0.62195374]
[37.8  37.8   0.75]
[0.0309405  0.03398605 0.58871694]
[37.8  37.8   0.75]
[-0.0018048   0.05670424  0.57602768]
[37.8  37.8   0.75]
[-0.0458082   0.07619231  0.61401286]
[37.8  37.8   0.75]
[-0.09350324  0.09457477  0.62272201]
[37.8  37.8   0.75]
[-0.13591221  0.09142543  0.61326119]
[37.8  37.8   0.75]
[-0.1698658   0.08663533  0.58967252]
[37.8  37.8   0.75]
[-0.21595782  0.08159777  0.53929176]
[37.8  37.8   0.75]
[-0.28283143  0.06716988  0.48600125]
[37.8  37.8   0.75]
[-0.41484312  0.08241396  0.49659226]
[37.8  37.8   0.75]
[-0.55344485  0.10908928  0.48745555]
[37.8  37.8   0.75]
[-0.67342929  0.13496847  0.45974845]
[37.8  37.8   0.75]
[-0.74805406  0.11509093  0.54428237]
[37.8  37.8   0.75]
[-0.810485    0.10069281  0.62182355]
[37.8  37.8   0.75]
[-0.88104018  0.09298786  0.66892135]
[37.8  37.8   0.75]
[-0.94043208  0.0737464   0.70028851]
[37.8  37.8   0.75]
[-0.99488678  0.04636731  0.71276272]
[37.8  37.8   0.75]
[-1.06087053  0.01672281  0.69162957]
[37.8  37.8   0.75]
[-1.14091278 -0.01367464  0.65288701]
[37.8  37.8   0.75]
[-1.2076436  -0.05964446  0.61844885]
[37.8  37.8   0.75]
[-1.27378012 -0.11544632  0.56675581]
[37.8  37.8   0.75]
[-1.31114227 -0.16897508  0.52494225]
[37.8  37.8   0.75]
[-1.29792866 -0.18473818  0.54291279]
[37.8  37.8   0.75]
[-1.23993787 -0.18272643  0.58092713]
[37.8  37.8   0.75]
[-1.17154144 -0.19677062  0.6202076 ]
[37.8  37.8   0.75]
[-1.11165265 -0.20746765  0.64581151]
[37.8  37.8   0.75]
[-1.06026151 -0.20890424  0.64132049]
[37.8  37.8   0.75]
[-1.01603934 -0.20243508  0.62018737]
[37.8  37.8   0.75]
[-0.97236597 -0.18557067  0.59017466]
[37.8  37.8   0.75]
[-0.91368862 -0.14148407  0.57483068]
[37.8  37.8   0.75]
[-0.88143835 -0.1066598   0.56390167]
[37.8  37.8   0.75]
[-0.85851447 -0.07782754  0.599237  ]
[37.8  37.8   0.75]
[-0.84264845 -0.04378971  0.66338757]
[37.8  37.8   0.75]
[-0.81700145  0.0022116   0.70226492]
[37.8  37.8   0.75]
[-0.78427753  0.01896988  0.73432798]
[37.8  37.8   0.75]
[-0.74345787  0.02167809  0.74496245]
[37.8  37.8   0.75]
[-0.70118905  0.03345708  0.725464  ]
[37.8  37.8   0.75]
[-0.66963868  0.04547794  0.68128695]
[37.8  37.8   0.75]
[-0.6434503   0.0528708   0.62012363]
[37.8  37.8   0.75]
[-0.63755258  0.0444115   0.5631446 ]
[37.8  37.8   0.75]
[-0.70953149 -0.03129855  0.61594349]
[37.8  37.8   0.75]
[-0.78859413 -0.10678211  0.64550596]
[37.8  37.8   0.75]
[-0.84929422 -0.1601888   0.6627503 ]
[37.8  37.8   0.75]
[-0.8701093  -0.19981064  0.71579046]
[37.8  37.8   0.75]
[-0.85617449 -0.2396091   0.80443462]
[37.8  37.8   0.75]
[-0.85276919 -0.27852559  0.86482322]
[37.8  37.8   0.75]
[-0.85445482 -0.30945885  0.9005494 ]
[37.8  37.8   0.75]
[-0.84757417 -0.33944328  0.91416007]
[37.8  37.8   0.75]
[-0.83148856 -0.37873403  0.90255487]
[37.8  37.8   0.75]
[-0.81753951 -0.42364261  0.86354785]
[37.8  37.8   0.75]
[-0.76423938 -0.51337503  0.85671343]
[37.8  37.8   0.75]
[-0.70150029 -0.61895289  0.83590129]
[37.8  37.8   0.75]
[-0.60658527 -0.69540967  0.84904064]
[37.8  37.8   0.75]
[-0.50969952 -0.76492872  0.87165828]
[37.8  37.8   0.75]
[-0.41058246 -0.8311527   0.87715219]
[37.8  37.8   0.75]
[-0.30410825 -0.89254102  0.86731911]
[37.8  37.8   0.75]
[-0.18919327 -0.9396917   0.86008259]
[37.8  37.8   0.75]
[-0.07337085 -0.99597776  0.82426734]
[37.8  37.8   0.75]
[ 0.02738682 -1.06244859  0.76475428]
[37.8  37.8   0.75]
[ 0.11280877 -1.11413403  0.67970343]
[37.8  37.8   0.75]
[ 0.17419633 -1.10161254  0.64892878]
[37.8  37.8   0.75]
[ 0.18082497 -0.9992371   0.75522733]
[37.8  37.8   0.75]
[ 0.20680741 -0.91181096  0.82464795]
[37.8  37.8   0.75]
[ 0.25118105 -0.82298662  0.87197022]
[37.8  37.8   0.75]
[ 0.29787512 -0.7417224   0.89940575]
[37.8  37.8   0.75]
[ 0.33877633 -0.67111495  0.91078059]
[37.8  37.8   0.75]
[ 0.3744697  -0.61061333  0.89500301]
[37.8  37.8   0.75]
[ 0.39240928 -0.54419937  0.83579351]
[37.8  37.8   0.75]
[ 0.4235233  -0.49839605  0.7889269 ]
[37.8  37.8   0.75]
[ 0.48055925 -0.50391464  0.80101671]
[37.8  37.8   0.75]
[ 0.52484037 -0.50059885  0.79136334]
[37.8  37.8   0.75]
[ 0.57626388 -0.47394015  0.76029561]
[37.8  37.8   0.75]
[ 0.65823657 -0.44729327  0.7022326 ]
[37.8  37.8   0.75]
[ 0.74117155 -0.42979884  0.62513523]
[37.8  37.8   0.75]
[ 0.75713522 -0.46803364  0.6106643 ]
[37.8  37.8   0.75]
[ 0.72183184 -0.53834902  0.61297806]
[37.8  37.8   0.75]
[ 0.66260792 -0.6134293   0.61852504]
[37.8  37.8   0.75]
[ 0.60624233 -0.67863615  0.60280633]
[37.8  37.8   0.75]
[ 0.55911177 -0.73483781  0.58074403]
[37.8  37.8   0.75]
[ 0.52465056 -0.79253918  0.56405956]
[37.8  37.8   0.75]
[ 0.49828342 -0.8329202   0.53143498]
[37.8  37.8   0.75]
[ 0.49406911 -0.85115981  0.51275064]
[37.8  37.8   0.75]
[ 0.48096012 -0.8774862   0.48142566]
[37.8  37.8   0.75]
[ 0.45174029 -0.89339554  0.46743587]
[37.8  37.8   0.75]
[ 0.37096992 -0.89290448  0.59933989]
[37.8  37.8   0.75]
[ 0.28882772 -0.90376705  0.72543303]
[37.8  37.8   0.75]
[ 0.21907903 -0.90438294  0.82587821]
[37.8  37.8   0.75]
[ 0.14233298 -0.90198118  0.90217105]
[37.8  37.8   0.75]
[ 0.06482194 -0.89664782  0.94923821]
[37.8  37.8   0.75]
[ 1.08710719e-04 -8.80556745e-01  9.59615998e-01]
[37.8  37.8   0.75]
[-0.0615976  -0.86970942  0.9519184 ]
[37.8  37.8   0.75]
[-0.13568591 -0.84673273  0.91732001]
[37.8  37.8   0.75]
[-0.20504487 -0.8133877   0.85118556]
[37.8  37.8   0.75]
[-0.27451113 -0.80117918  0.79790991]
[37.8  37.8   0.75]
[-0.30695806 -0.9025155   0.86591112]
[37.8  37.8   0.75]
[-0.3367342  -1.0428748   0.93517661]
[37.8  37.8   0.75]
[-0.3498394  -1.17398987  0.98245816]
[37.8  37.8   0.75]
[-0.36230073 -1.29668012  1.00524645]
[37.8  37.8   0.75]
[0.01142857 0.073279   0.76418373]
[34.6  34.6   0.75]
[0.01147067 0.09940789 0.75238926]
[34.6  34.6   0.75]
[0.0216397  0.1256432  0.69379111]
[34.6  34.6   0.75]
[0.04815609 0.13036414 0.63514703]
[34.6  34.6   0.75]
[0.11398572 0.07685636 0.66497436]
[34.6  34.6   0.75]
[0.17486778 0.03238707 0.67058829]
[34.6  34.6   0.75]
[ 0.22893226 -0.00320791  0.64681424]
[34.6  34.6   0.75]
[ 0.25034121 -0.03372549  0.61137207]
[34.6  34.6   0.75]
[ 0.27035877 -0.07094157  0.57940267]
[34.6  34.6   0.75]
[ 0.30429875 -0.11462912  0.56348318]
[34.6  34.6   0.75]
[ 0.31679318 -0.12795035  0.58804015]
[34.6  34.6   0.75]
[ 0.33210852 -0.13977032  0.58713645]
[34.6  34.6   0.75]
[ 0.34483671 -0.15150421  0.57572281]
[34.6  34.6   0.75]
[ 0.35740775 -0.15030157  0.62626779]
[34.6  34.6   0.75]
[ 0.36557674 -0.15294358  0.70870575]
[34.6  34.6   0.75]
[ 0.38155906 -0.1735815   0.76716796]
[34.6  34.6   0.75]
[ 0.40575868 -0.20035731  0.80193379]
[34.6  34.6   0.75]
[ 0.43505245 -0.22243692  0.8100055 ]
[34.6  34.6   0.75]
[ 0.4530514  -0.24308704  0.79952875]
[34.6  34.6   0.75]
[ 0.44907646 -0.23402257  0.79584426]
[34.6  34.6   0.75]
[ 0.43400354 -0.19880145  0.78948386]
[34.6  34.6   0.75]
[ 0.37656069 -0.14845098  0.81839265]
[34.6  34.6   0.75]
[ 0.29570991 -0.10508751  0.87185863]
[34.6  34.6   0.75]
[ 0.22057676 -0.06818676  0.90193806]
[34.6  34.6   0.75]
[ 0.1572093  -0.03557941  0.90005211]
[34.6  34.6   0.75]
[ 0.09584593 -0.01388524  0.87441317]
[34.6  34.6   0.75]
[ 3.31775101e-02 -4.95022156e-04  8.29968630e-01]
[34.6  34.6   0.75]
[-0.05041057  0.00777391  0.77345138]
[34.6  34.6   0.75]
[-0.13482986  0.02719616  0.71209651]
[34.6  34.6   0.75]
[-0.22348602  0.05162929  0.6403254 ]
[34.6  34.6   0.75]
[-0.31083011  0.08146907  0.60983302]
[34.6  34.6   0.75]
[-0.3656334   0.08196997  0.62946469]
[34.6  34.6   0.75]
[-0.38678218  0.07962781  0.66400628]
[34.6  34.6   0.75]
[-0.39649109  0.07873668  0.67160824]
[34.6  34.6   0.75]
[-0.39276178  0.09660238  0.68458559]
[34.6  34.6   0.75]
[-0.37845597  0.12745497  0.71275569]
[34.6  34.6   0.75]
[-0.36392258  0.17002426  0.73842545]
[34.6  34.6   0.75]
[-0.34331515  0.20875911  0.74773197]
[34.6  34.6   0.75]
[-0.32487685  0.24855856  0.72955949]
[34.6  34.6   0.75]
[-0.31174109  0.28612845  0.68172923]
[34.6  34.6   0.75]
[-0.29300722  0.30860489  0.60422511]
[34.6  34.6   0.75]
[-0.28340174  0.30865776  0.51531357]
[34.6  34.6   0.75]
[-0.32301846  0.26793843  0.53664412]
[34.6  34.6   0.75]
[-0.34994819  0.24971854  0.55307964]
[34.6  34.6   0.75]
[-0.35207325  0.24084984  0.6096802 ]
[34.6  34.6   0.75]
[-0.3535127   0.22928847  0.66151548]
[34.6  34.6   0.75]
[-0.358295    0.21545664  0.68604741]
[34.6  34.6   0.75]
[-0.36890031  0.20476291  0.68286981]
[34.6  34.6   0.75]
[-0.37646314  0.19484704  0.65360202]
[34.6  34.6   0.75]
[-0.39375494  0.19546245  0.61041246]
[34.6  34.6   0.75]
[-0.46135664  0.20610166  0.58918637]
[34.6  34.6   0.75]
[-0.52221878  0.19918493  0.54950183]
[34.6  34.6   0.75]
[-0.56559145  0.19181767  0.51724044]
[34.6  34.6   0.75]
[-0.62518756  0.20270427  0.53143058]
[34.6  34.6   0.75]
[-0.64345754  0.20578941  0.6217977 ]
[34.6  34.6   0.75]
[-0.64719043  0.19672505  0.6995591 ]
[34.6  34.6   0.75]
[-0.64840962  0.18208483  0.75903451]
[34.6  34.6   0.75]
[-0.65250065  0.16761243  0.80183078]
[34.6  34.6   0.75]
[-0.65913589  0.16880243  0.81370927]
[34.6  34.6   0.75]
[-0.66655821  0.1812973   0.8020132 ]
[34.6  34.6   0.75]
[-0.68814215  0.17887986  0.75656764]
[34.6  34.6   0.75]
[-0.72727797  0.16930534  0.6911506 ]
[34.6  34.6   0.75]
[-0.76788901  0.16191032  0.60993524]
[34.6  34.6   0.75]
[-0.79711261  0.19189321  0.56922698]
[34.6  34.6   0.75]
[-0.80136868  0.24074636  0.62421927]
[34.6  34.6   0.75]
[-0.79910583  0.27522369  0.68323251]
[34.6  34.6   0.75]
[-0.79801078  0.27968865  0.80586055]
[34.6  34.6   0.75]
[-0.80100387  0.28747168  0.94672058]
[34.6  34.6   0.75]
[-0.82033556  0.3097506   1.05051329]
[34.6  34.6   0.75]
[ 0.07827681 -0.05409881  0.70031019]
[22.5  22.5   0.75]
[ 0.0668735  -0.04472218  0.69931728]
[22.5  22.5   0.75]
[ 0.06224493 -0.02613548  0.67411588]
[22.5  22.5   0.75]
[ 0.05090999 -0.00753491  0.661162  ]
[22.5  22.5   0.75]
[ 0.01161848 -0.01647011  0.65873601]
[22.5  22.5   0.75]
[-0.02087324 -0.02963279  0.63740518]
[22.5  22.5   0.75]
[-0.0444006  -0.0371867   0.61431025]
[22.5  22.5   0.75]
[-0.0410098  -0.03856455  0.60131425]
[22.5  22.5   0.75]
[-0.02300054 -0.02917431  0.5908416 ]
[22.5  22.5   0.75]
[ 6.16370596e-04 -2.40089077e-02  7.18945152e-01]
[22.5  22.5   0.75]
[ 0.02187309 -0.01165362  0.81762967]
[22.5  22.5   0.75]
[ 0.04974776 -0.00245606  0.88701079]
[22.5  22.5   0.75]
[ 0.07677694 -0.01324603  0.92695908]
[22.5  22.5   0.75]
[ 0.10861098 -0.00843343  0.95499174]
[22.5  22.5   0.75]
[0.1382967  0.01527747 0.9594227 ]
[22.5  22.5   0.75]
[0.15410468 0.04369981 0.93016977]
[22.5  22.5   0.75]
[0.16651226 0.06424782 0.87259155]
[22.5  22.5   0.75]
[0.17882505 0.07261975 0.79463962]
[22.5  22.5   0.75]
[0.19208021 0.11101445 0.73983778]
[22.5  22.5   0.75]
[0.21126053 0.15174951 0.68207806]
[22.5  22.5   0.75]
[0.23902728 0.17723347 0.61190065]
[22.5  22.5   0.75]
[0.25879603 0.19302309 0.62563887]
[22.5  22.5   0.75]
[0.28989671 0.21441783 0.63165302]
[22.5  22.5   0.75]
[0.33421003 0.20906895 0.64694501]
[22.5  22.5   0.75]
[0.38571114 0.18333936 0.65887241]
[22.5  22.5   0.75]
[0.451085   0.18753138 0.71830113]
[22.5  22.5   0.75]
[0.52322258 0.20650657 0.74739693]
[22.5  22.5   0.75]
[0.59870383 0.21636629 0.74401005]
[22.5  22.5   0.75]
[0.67204515 0.21876662 0.71727783]
[22.5  22.5   0.75]
[0.67591559 0.2225135  0.73360604]
[22.5  22.5   0.75]
[0.63385273 0.17966456 0.82488265]
[22.5  22.5   0.75]
[0.59579457 0.14659099 0.89213856]
[22.5  22.5   0.75]
[0.57528489 0.11284611 0.93236038]
[22.5  22.5   0.75]
[0.53920752 0.08071511 0.94562181]
[22.5  22.5   0.75]
[0.49084083 0.04404539 0.93164339]
[22.5  22.5   0.75]
[0.44106957 0.00617592 0.90261835]
[22.5  22.5   0.75]
[ 0.4068695  -0.04359454  0.86064839]
[22.5  22.5   0.75]
[ 0.39466321 -0.10867547  0.8195992 ]
[22.5  22.5   0.75]
[ 0.38913696 -0.16651115  0.7459989 ]
[22.5  22.5   0.75]
[ 0.37259405 -0.19704414  0.66868545]
[22.5  22.5   0.75]
[ 0.33666026 -0.1325331   0.68717035]
[22.5  22.5   0.75]
[ 0.29140071 -0.05007172  0.70616569]
[22.5  22.5   0.75]
[0.24274169 0.01616281 0.70198248]
[22.5  22.5   0.75]
[0.19473347 0.08401014 0.67598571]
[22.5  22.5   0.75]
[0.13915303 0.16335951 0.63326246]
[22.5  22.5   0.75]
[0.07627059 0.23905293 0.57193183]
[22.5  22.5   0.75]
[0.02707418 0.31768315 0.52563282]
[22.5  22.5   0.75]
[0.00730225 0.35329    0.5299665 ]
[22.5  22.5   0.75]
[-0.00609896  0.37041372  0.54210047]
[22.5  22.5   0.75]
[-0.01206222  0.39316862  0.54035709]
[22.5  22.5   0.75]
[-0.01731979  0.41321065  0.5160112 ]
[22.5  22.5   0.75]
[-0.01035115  0.4596944   0.53492114]
[22.5  22.5   0.75]
[-0.00537072  0.49200615  0.55131743]
[22.5  22.5   0.75]
[-0.00541417  0.52087269  0.55516852]
[22.5  22.5   0.75]
[-0.01260597  0.55743949  0.54330821]
[22.5  22.5   0.75]
[-0.00408764  0.56943506  0.55404335]
[22.5  22.5   0.75]
[0.00932686 0.58483914 0.59579661]
[22.5  22.5   0.75]
[0.00093661 0.62408868 0.69343899]
[22.5  22.5   0.75]
[-0.01004204  0.64887138  0.76910993]
[22.5  22.5   0.75]
[-0.01667368  0.66988926  0.82437043]
[22.5  22.5   0.75]
[-0.02138032  0.69138569  0.85482232]
[22.5  22.5   0.75]
[-0.03194034  0.6998398   0.87962246]
[22.5  22.5   0.75]
[-0.04690861  0.70929049  0.89455961]
[22.5  22.5   0.75]
[-0.0334515   0.71442353  0.92048089]
[22.5  22.5   0.75]
[0.00444104 0.71480513 0.95616433]
[22.5  22.5   0.75]
[0.03857435 0.70563549 0.96848222]
[22.5  22.5   0.75]
[0.07433923 0.69129923 0.96220253]
[22.5  22.5   0.75]
[0.11061701 0.67343049 0.92588888]
[22.5  22.5   0.75]
[0.14344415 0.66500364 0.86670139]
[22.5  22.5   0.75]
[0.12868257 0.72323786 0.93939109]
[22.5  22.5   0.75]
[0.11683284 0.79780936 1.0457668 ]
[22.5  22.5   0.75]
[ 0.00657636 -0.07663172  0.72921861]
[25.6  25.6   0.75]
[ 0.00913773 -0.09056195  0.72345602]
[25.6  25.6   0.75]
[ 0.00816881 -0.1143052   0.70290795]
[25.6  25.6   0.75]
[-0.00272788 -0.14781103  0.68638972]
[25.6  25.6   0.75]
[-0.03882317 -0.17137378  0.69201758]
[25.6  25.6   0.75]
[-0.05193522 -0.16955309  0.70647991]
[25.6  25.6   0.75]
[-0.06173323 -0.13140596  0.72790998]
[25.6  25.6   0.75]
[-0.07573494 -0.04075569  0.86519589]
[25.6  25.6   0.75]
[-0.08743474  0.01623051  0.97097166]
[25.6  25.6   0.75]
[-0.09371021  0.06677386  1.04991852]
[25.6  25.6   0.75]
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 198       |
|    ep_rew_mean     | -3.35e+05 |
| time/              |           |
|    episodes        | 8         |
|    fps             | 61        |
|    time_elapsed    | 25        |
|    total timesteps | 1583      |
----------------------------------
[ 0.00329698 -0.01119742  0.79333168]
[3.3  3.3  0.75]
[-0.01122329 -0.01924643  0.78385024]
[3.3  3.3  0.75]
[-0.02384364 -0.02485683  0.73585959]
[3.3  3.3  0.75]
[-0.0217604  -0.02887661  0.66763309]
[3.3  3.3  0.75]
[ 0.02497005 -0.06477383  0.62093998]
[3.3  3.3  0.75]
[ 0.03433915 -0.06910115  0.61229426]
[3.3  3.3  0.75]
[ 0.01896699 -0.05285931  0.6326014 ]
[3.3  3.3  0.75]
[ 0.00786455 -0.02659228  0.63272081]
[3.3  3.3  0.75]
[ 0.01799976 -0.0153043   0.61454624]
[3.3  3.3  0.75]
[ 0.02642067 -0.00461779  0.57663887]
[3.3  3.3  0.75]
[1.46805214e-02 1.02956591e-04 5.20960587e-01]
[3.3  3.3  0.75]
[-0.00447785  0.00233756  0.44266585]
[3.3  3.3  0.75]
[-0.01554806 -0.00534346  0.43397491]
[3.3  3.3  0.75]
[ 0.00810336 -0.02395106  0.49501651]
[3.3  3.3  0.75]
[ 0.04661444 -0.06696326  0.56227259]
[3.3  3.3  0.75]
[ 0.07877244 -0.10134846  0.6050229 ]
[3.3  3.3  0.75]
[ 0.09236504 -0.12158427  0.64316057]
[3.3  3.3  0.75]
[ 0.10169788 -0.15080571  0.65382665]
[3.3  3.3  0.75]
[ 0.10402793 -0.1774251   0.6372672 ]
[3.3  3.3  0.75]
[ 0.11021574 -0.21107963  0.59059934]
[3.3  3.3  0.75]
[ 0.12431253 -0.24380699  0.52127327]
[3.3  3.3  0.75]
[ 0.13569235 -0.2981486   0.53303841]
[3.3  3.3  0.75]
[ 0.1607853  -0.36783515  0.55424695]
[3.3  3.3  0.75]
[ 0.18221217 -0.41942846  0.57625475]
[3.3  3.3  0.75]
[ 0.2210229  -0.44223118  0.63699238]
[3.3  3.3  0.75]
[ 0.27331782 -0.45347916  0.70857775]
[3.3  3.3  0.75]
[ 0.31086485 -0.46830506  0.74377565]
[3.3  3.3  0.75]
[ 0.34502831 -0.49154962  0.74502763]
[3.3  3.3  0.75]
[ 0.37927831 -0.51149068  0.71896557]
[3.3  3.3  0.75]
[ 0.40811281 -0.52201075  0.6712934 ]
[3.3  3.3  0.75]
[ 0.4244479  -0.52325507  0.60692235]
[3.3  3.3  0.75]
[ 0.41930038 -0.53196454  0.54130206]
[3.3  3.3  0.75]
[ 0.36006663 -0.53125512  0.61756468]
[3.3  3.3  0.75]
[ 0.32584322 -0.52828017  0.69440435]
[3.3  3.3  0.75]
[ 0.29742044 -0.52869442  0.74523268]
[3.3  3.3  0.75]
[ 0.27840934 -0.56590889  0.8102046 ]
[3.3  3.3  0.75]
[ 0.25979225 -0.6124732   0.86342155]
[3.3  3.3  0.75]
[ 0.24211185 -0.65542136  0.89234431]
[3.3  3.3  0.75]
[ 0.22144425 -0.70147749  0.90022217]
[3.3  3.3  0.75]
[ 0.19369329 -0.73228292  0.88044215]
[3.3  3.3  0.75]
[ 0.17200139 -0.7715099   0.84424226]
[3.3  3.3  0.75]
[ 0.16075321 -0.81477841  0.79687464]
[3.3  3.3  0.75]
[ 0.14772715 -0.83979187  0.73695209]
[3.3  3.3  0.75]
[ 0.14277976 -0.85743585  0.67041836]
[3.3  3.3  0.75]
[ 0.17834403 -0.87968933  0.6680566 ]
[3.3  3.3  0.75]
[ 0.24037371 -0.91344687  0.67916038]
[3.3  3.3  0.75]
[ 0.24860293 -0.93870726  0.72958436]
[3.3  3.3  0.75]
[ 0.25592071 -0.96860658  0.75232779]
[3.3  3.3  0.75]
[ 0.23895585 -0.99845552  0.77021224]
[3.3  3.3  0.75]
[ 0.22681974 -1.01277321  0.77668316]
[3.3  3.3  0.75]
[ 0.2024357  -1.02217393  0.76527731]
[3.3  3.3  0.75]
[ 0.1707063  -1.03506075  0.72882395]
[3.3  3.3  0.75]
[ 0.15251378 -1.05103534  0.67426031]
[3.3  3.3  0.75]
[ 0.13214899 -1.06211902  0.61062083]
[3.3  3.3  0.75]
[ 0.11750937 -1.03985808  0.57009847]
[3.3  3.3  0.75]
[ 0.14389756 -0.96136183  0.62167886]
[3.3  3.3  0.75]
[ 0.17938359 -0.88169664  0.64429839]
[3.3  3.3  0.75]
[ 0.20603866 -0.7961134   0.65252316]
[3.3  3.3  0.75]
[ 0.22718799 -0.70593385  0.64063974]
[3.3  3.3  0.75]
[ 0.24439309 -0.61592669  0.61201606]
[3.3  3.3  0.75]
[ 0.24696048 -0.57100526  0.61125848]
[3.3  3.3  0.75]
[ 0.2241999  -0.55743164  0.63444403]
[3.3  3.3  0.75]
[ 0.19320407 -0.54284333  0.6448399 ]
[3.3  3.3  0.75]
[ 0.15193143 -0.51622255  0.68751616]
[3.3  3.3  0.75]
[ 0.12183963 -0.49884053  0.70826616]
[3.3  3.3  0.75]
[ 0.09593624 -0.49886602  0.70910225]
[3.3  3.3  0.75]
[ 0.06915409 -0.50242045  0.70987655]
[3.3  3.3  0.75]
[ 0.04443245 -0.51128953  0.68574695]
[3.3  3.3  0.75]
[ 0.02612821 -0.50676616  0.64255635]
[3.3  3.3  0.75]
[ 0.01982117 -0.50546243  0.60781616]
[3.3  3.3  0.75]
[ 0.06180442 -0.49765294  0.6076526 ]
[3.3  3.3  0.75]
[ 0.10726488 -0.49231059  0.57784524]
[3.3  3.3  0.75]
[ 0.1481868  -0.47574721  0.53836362]
[3.3  3.3  0.75]
[ 0.17214433 -0.46011293  0.50162225]
[3.3  3.3  0.75]
[ 0.1974367  -0.44441955  0.49682449]
[3.3  3.3  0.75]
[ 0.20082215 -0.44476117  0.53241922]
[3.3  3.3  0.75]
[ 0.1974726  -0.44487999  0.54329628]
[3.3  3.3  0.75]
[ 0.18561296 -0.45074326  0.52585356]
[3.3  3.3  0.75]
[ 0.153353   -0.44766273  0.50361779]
[3.3  3.3  0.75]
[ 0.09817652 -0.464395    0.55695191]
[3.3  3.3  0.75]
[ 0.04774423 -0.49481914  0.60631047]
[3.3  3.3  0.75]
[ 0.02694241 -0.49657252  0.61997098]
[3.3  3.3  0.75]
[-0.00628976 -0.48774     0.60462581]
[3.3  3.3  0.75]
[-0.04373069 -0.4930945   0.5861214 ]
[3.3  3.3  0.75]
[-0.07129322 -0.5102236   0.55868943]
[3.3  3.3  0.75]
[-0.08614307 -0.5355498   0.53904829]
[3.3  3.3  0.75]
[-0.0992114  -0.55520281  0.50008026]
[3.3  3.3  0.75]
[-0.10240847 -0.54586625  0.46770643]
[3.3  3.3  0.75]
[-0.11813736 -0.52758977  0.50853874]
[3.3  3.3  0.75]
[-0.14937926 -0.49910457  0.58282522]
[3.3  3.3  0.75]
[-0.17681164 -0.4824867   0.62539473]
[3.3  3.3  0.75]
[-0.20291577 -0.47245994  0.64389381]
[3.3  3.3  0.75]
[-0.23676093 -0.46039107  0.63940864]
[3.3  3.3  0.75]
[-0.28314594 -0.45168999  0.60627885]
[3.3  3.3  0.75]
[-0.31962815 -0.42813248  0.55676203]
[3.3  3.3  0.75]
[-0.34194055 -0.37809165  0.53389672]
[3.3  3.3  0.75]
[-0.35726926 -0.27695917  0.57654387]
[3.3  3.3  0.75]
[-0.3706121  -0.15757481  0.61420033]
[3.3  3.3  0.75]
[-0.37921777 -0.02939503  0.64632821]
[3.3  3.3  0.75]
[-0.3933912   0.08517588  0.65129025]
[3.3  3.3  0.75]
[-0.39570751  0.19991518  0.63596097]
[3.3  3.3  0.75]
[-0.37087068  0.29465516  0.63376579]
[3.3  3.3  0.75]
[-0.32186291  0.3599927   0.64617477]
[3.3  3.3  0.75]
[-0.28501398  0.43690165  0.62768141]
[3.3  3.3  0.75]
[-0.24579347  0.50553281  0.58682452]
[3.3  3.3  0.75]
[-0.21500397  0.57276719  0.52555112]
[3.3  3.3  0.75]
[-0.19033758  0.66550766  0.50229263]
[3.3  3.3  0.75]
[-0.16806426  0.76999268  0.54634763]
[3.3  3.3  0.75]
[-0.15981807  0.85506647  0.58535858]
[3.3  3.3  0.75]
[-0.15614682  0.92876673  0.61450218]
[3.3  3.3  0.75]
[-0.15109185  0.99650978  0.62834256]
[3.3  3.3  0.75]
[-0.1409726   1.06996359  0.62715693]
[3.3  3.3  0.75]
[-0.1372355   1.13041634  0.60245881]
[3.3  3.3  0.75]
[-0.13989633  1.17281477  0.58199324]
[3.3  3.3  0.75]
[-0.14179134  1.1515182   0.68022725]
[3.3  3.3  0.75]
[-0.13694322  1.13024177  0.7618598 ]
[3.3  3.3  0.75]
[-0.12630544  1.10900329  0.81692455]
[3.3  3.3  0.75]
[-0.12528908  1.09772694  0.84536869]
[3.3  3.3  0.75]
[-0.12345488  1.10112603  0.84828342]
[3.3  3.3  0.75]
[-0.1241778   1.09409075  0.8274096 ]
[3.3  3.3  0.75]
[-0.12231227  1.06932919  0.78599768]
[3.3  3.3  0.75]
[-0.11047978  1.03658633  0.71796872]
[3.3  3.3  0.75]
[-0.07843586  1.04028557  0.67411981]
[3.3  3.3  0.75]
[-0.03469994  1.05908602  0.64859246]
[3.3  3.3  0.75]
[0.00849124 1.08121649 0.60811226]
[3.3  3.3  0.75]
[0.02497824 1.12155018 0.62367632]
[3.3  3.3  0.75]
[0.03865963 1.14367735 0.65773085]
[3.3  3.3  0.75]
[0.04430643 1.15344394 0.66641901]
[3.3  3.3  0.75]
[0.05711518 1.16230854 0.64840119]
[3.3  3.3  0.75]
[0.06073955 1.17083814 0.62844094]
[3.3  3.3  0.75]
[0.05389527 1.17130693 0.6046989 ]
[3.3  3.3  0.75]
[0.01477771 1.15788084 0.62342609]
[3.3  3.3  0.75]
[-0.04174528  1.14944628  0.65105151]
[3.3  3.3  0.75]
[-0.06408455  1.13645606  0.68857308]
[3.3  3.3  0.75]
[-0.07373275  1.11795853  0.71348338]
[3.3  3.3  0.75]
[-0.08248685  1.10520037  0.71960278]
[3.3  3.3  0.75]
[-0.09542555  1.09142573  0.69636462]
[3.3  3.3  0.75]
[-0.11620079  1.07668789  0.64213224]
[3.3  3.3  0.75]
[-0.14021601  1.05254179  0.57430513]
[3.3  3.3  0.75]
[-0.14218495  1.01766633  0.51598176]
[3.3  3.3  0.75]
[-0.15976746  0.99064884  0.5457979 ]
[3.3  3.3  0.75]
[-0.19108092  0.96282257  0.62438193]
[3.3  3.3  0.75]
[-0.21751293  0.94948483  0.67380007]
[3.3  3.3  0.75]
[-0.25095444  0.93914249  0.69911153]
[3.3  3.3  0.75]
[-0.28639923  0.93218614  0.69808256]
[3.3  3.3  0.75]
[-0.31166274  0.92800109  0.68461558]
[3.3  3.3  0.75]
[-0.3165946   0.91430115  0.68144672]
[3.3  3.3  0.75]
[-0.2841493   0.92651875  0.75308232]
[3.3  3.3  0.75]
[-0.25058387  0.94544939  0.82441916]
[3.3  3.3  0.75]
[-0.2179529   0.96472011  0.87802594]
[3.3  3.3  0.75]
[-0.17775937  0.99612798  0.9201836 ]
[3.3  3.3  0.75]
[-0.14619927  1.03098121  0.92654979]
[3.3  3.3  0.75]
[-0.11554405  1.06113724  0.90801239]
[3.3  3.3  0.75]
[-0.07454651  1.09834914  0.87901616]
[3.3  3.3  0.75]
[-0.03802422  1.12880299  0.83866621]
[3.3  3.3  0.75]
[-0.00889745  1.11587564  0.82693482]
[3.3  3.3  0.75]
[0.02220223 1.09949188 0.79939262]
[3.3  3.3  0.75]
[0.05000406 1.08716491 0.7448437 ]
[3.3  3.3  0.75]
[0.06978819 1.07347543 0.67664076]
[3.3  3.3  0.75]
[0.09179741 1.06687676 0.60009485]
[3.3  3.3  0.75]
[0.07275101 1.12864952 0.62840372]
[3.3  3.3  0.75]
[0.04386319 1.19710299 0.6607475 ]
[3.3  3.3  0.75]
[0.02114894 1.25165215 0.67211668]
[3.3  3.3  0.75]
[-7.44203265e-04  1.28717514e+00  6.78233677e-01]
[3.3  3.3  0.75]
[-0.03522571  1.31649441  0.66709801]
[3.3  3.3  0.75]
[-0.04888618  1.28539113  0.74140998]
[3.3  3.3  0.75]
[-0.04582099  1.24783787  0.8231259 ]
[3.3  3.3  0.75]
[-0.04326462  1.20733559  0.87952134]
[3.3  3.3  0.75]
[-0.03282324  1.17182135  0.91023131]
[3.3  3.3  0.75]
[-0.01266646  1.14925688  0.91472846]
[3.3  3.3  0.75]
[0.00490445 1.13645359 0.88761957]
[3.3  3.3  0.75]
[0.01002971 1.10575668 0.83710041]
[3.3  3.3  0.75]
[-0.00561445  1.06454735  0.81290239]
[3.3  3.3  0.75]
[-0.04265729  1.01489739  0.79971316]
[3.3  3.3  0.75]
[-0.08068442  0.95724604  0.76193842]
[3.3  3.3  0.75]
[-0.1185712   0.8918499   0.70870854]
[3.3  3.3  0.75]
[-0.12101459  0.80051825  0.68721513]
[3.3  3.3  0.75]
[-0.10638875  0.72331408  0.6418536 ]
[3.3  3.3  0.75]
[-0.09640769  0.65100945  0.58317387]
[3.3  3.3  0.75]
[-0.10267564  0.62805799  0.6079208 ]
[3.3  3.3  0.75]
[-0.11813406  0.67583012  0.7132621 ]
[3.3  3.3  0.75]
[-0.1506724   0.71223621  0.78066977]
[3.3  3.3  0.75]
[-0.17477252  0.74648594  0.82076599]
[3.3  3.3  0.75]
[-0.16899752  0.79211646  0.83667589]
[3.3  3.3  0.75]
[-0.16650153  0.83202505  0.83470638]
[3.3  3.3  0.75]
[-0.16389187  0.86661066  0.80850369]
[3.3  3.3  0.75]
[-0.15701968  0.90015329  0.75178874]
[3.3  3.3  0.75]
[-0.16423972  0.93179257  0.68375097]
[3.3  3.3  0.75]
[-0.14406469  0.95749502  0.65415738]
[3.3  3.3  0.75]
[-0.11389706  0.97878434  0.67263461]
[3.3  3.3  0.75]
[-0.08229639  1.00469988  0.68251291]
[3.3  3.3  0.75]
[-0.06166917  1.0260634   0.70465517]
[3.3  3.3  0.75]
[-0.0530381   1.05669612  0.71065627]
[3.3  3.3  0.75]
[-0.05769102  1.10884947  0.76222807]
[3.3  3.3  0.75]
[-0.0518181   1.21382646  0.89786366]
[3.3  3.3  0.75]
[-0.04661917  1.31299495  1.00911023]
[3.3  3.3  0.75]
[-0.07519801 -0.04601294  0.79274873]
[25.3  25.3   0.75]
[-0.07137024 -0.03948788  0.7967758 ]
[25.3  25.3   0.75]
[-0.07355847 -0.03369587  0.75197862]
[25.3  25.3   0.75]
[-0.08283065 -0.01949566  0.67124634]
[25.3  25.3   0.75]
[-0.13725726 -0.02797725  0.60444123]
[25.3  25.3   0.75]
[-0.17642391 -0.01723488  0.60355189]
[25.3  25.3   0.75]
[-0.17385511  0.00135732  0.60327943]
[25.3  25.3   0.75]
[-0.15739106  0.01144744  0.59344549]
[25.3  25.3   0.75]
[-0.12756016  0.0103179   0.57726668]
[25.3  25.3   0.75]
[-8.48805187e-02  3.81023881e-04  5.50646293e-01]
[25.3  25.3   0.75]
[-0.03075736 -0.0229725   0.49564927]
[25.3  25.3   0.75]
[ 0.03864771 -0.08081941  0.48198143]
[25.3  25.3   0.75]
[ 0.09913619 -0.15401301  0.49838897]
[25.3  25.3   0.75]
[ 0.15179635 -0.20954625  0.49416635]
[25.3  25.3   0.75]
[ 0.1951746  -0.26450545  0.46980568]
[25.3  25.3   0.75]
[ 0.21870809 -0.30878682  0.43453429]
[25.3  25.3   0.75]
[ 0.20608166 -0.31512967  0.42102508]
[25.3  25.3   0.75]
[ 0.22882929 -0.3225953   0.43650049]
[25.3  25.3   0.75]
[ 0.26236227 -0.34950543  0.55568599]
[25.3  25.3   0.75]
[ 0.28326995 -0.36827715  0.6712372 ]
[25.3  25.3   0.75]
[ 0.30592301 -0.37771693  0.76242715]
[25.3  25.3   0.75]
[ 0.32997083 -0.39136304  0.82905775]
[25.3  25.3   0.75]
[ 0.35233011 -0.41810899  0.87124423]
[25.3  25.3   0.75]
[ 0.37980236 -0.45367221  0.89320958]
[25.3  25.3   0.75]
[ 0.40653769 -0.48987376  0.89683678]
[25.3  25.3   0.75]
[ 0.42957435 -0.52006427  0.86918813]
[25.3  25.3   0.75]
[ 0.45174614 -0.53548757  0.80759553]
[25.3  25.3   0.75]
[ 0.50126255 -0.56201149  0.78552463]
[25.3  25.3   0.75]
[ 0.6064099  -0.58591254  0.81508957]
[25.3  25.3   0.75]
[ 0.70940982 -0.60155993  0.8184376 ]
[25.3  25.3   0.75]
[ 0.80484365 -0.62020367  0.80351367]
[25.3  25.3   0.75]
[ 0.89277213 -0.64815145  0.76493896]
[25.3  25.3   0.75]
[ 0.97975686 -0.66676472  0.73592457]
[25.3  25.3   0.75]
[ 1.07933353 -0.64184325  0.76466852]
[25.3  25.3   0.75]
[ 1.1817291  -0.631481    0.76074701]
[25.3  25.3   0.75]
[ 1.29150897 -0.61985501  0.73089515]
[25.3  25.3   0.75]
[ 1.39072277 -0.59350978  0.68612672]
[25.3  25.3   0.75]
[ 1.42287563 -0.60509374  0.71445487]
[25.3  25.3   0.75]
[ 1.44868369 -0.62327909  0.7307081 ]
[25.3  25.3   0.75]
[ 1.480779   -0.62834764  0.72138247]
[25.3  25.3   0.75]
[ 1.51941408 -0.64217827  0.69061153]
[25.3  25.3   0.75]
[ 1.53834635 -0.65510569  0.65199308]
[25.3  25.3   0.75]
[ 1.52690581 -0.66222933  0.63270687]
[25.3  25.3   0.75]
[ 1.50389207 -0.6769939   0.61499347]
[25.3  25.3   0.75]
[ 1.48955164 -0.72715385  0.61968803]
[25.3  25.3   0.75]
[ 1.48792867 -0.76964715  0.64583719]
[25.3  25.3   0.75]
[ 1.48871828 -0.79114826  0.6585535 ]
[25.3  25.3   0.75]
[ 1.48485051 -0.80333102  0.65975972]
[25.3  25.3   0.75]
[ 1.48068907 -0.80985903  0.65703305]
[25.3  25.3   0.75]
[ 1.48489182 -0.83634794  0.62912322]
[25.3  25.3   0.75]
[ 1.51484938 -0.85832789  0.59493514]
[25.3  25.3   0.75]
[ 1.53024172 -0.88003188  0.53574404]
[25.3  25.3   0.75]
[ 1.51931474 -0.91109155  0.53935987]
[25.3  25.3   0.75]
[ 1.50223764 -0.95494752  0.55836959]
[25.3  25.3   0.75]
[ 1.46527886 -1.00628515  0.59792407]
[25.3  25.3   0.75]
[ 1.43100833 -1.04479901  0.63131349]
[25.3  25.3   0.75]
[ 1.40017986 -1.0819428   0.6499034 ]
[25.3  25.3   0.75]
[ 1.36891784 -1.11773577  0.63651516]
[25.3  25.3   0.75]
[ 1.33826659 -1.15446536  0.60216564]
[25.3  25.3   0.75]
[ 1.31211682 -1.20022215  0.5504621 ]
[25.3  25.3   0.75]
[ 1.28929731 -1.2386602   0.54285234]
[25.3  25.3   0.75]
[ 1.2484239  -1.25586815  0.66238743]
[25.3  25.3   0.75]
[ 1.21315419 -1.27632439  0.75530055]
[25.3  25.3   0.75]
[ 1.18448513 -1.30615718  0.82716207]
[25.3  25.3   0.75]
[ 1.15421854 -1.329042    0.87345924]
[25.3  25.3   0.75]
[ 1.1306869  -1.34897319  0.89373657]
[25.3  25.3   0.75]
[ 1.10578905 -1.35709587  0.88870539]
[25.3  25.3   0.75]
[ 1.07353113 -1.3610527   0.85748221]
[25.3  25.3   0.75]
[ 1.04274062 -1.37687657  0.79770944]
[25.3  25.3   0.75]
[ 1.02244784 -1.40388108  0.71509021]
[25.3  25.3   0.75]
[ 1.00769416 -1.41880647  0.61428977]
[25.3  25.3   0.75]
[ 1.01000518 -1.43525696  0.49913172]
[25.3  25.3   0.75]
[ 1.04401013 -1.46353637  0.39388951]
[25.3  25.3   0.75]
[ 1.06951622 -1.51987983  0.40589734]
[25.3  25.3   0.75]
[ 1.08978229 -1.58553801  0.49806998]
[25.3  25.3   0.75]
[ 1.10061694 -1.64814069  0.56950689]
[25.3  25.3   0.75]
[ 1.10224483 -1.69679773  0.6242291 ]
[25.3  25.3   0.75]
[ 1.10476652 -1.73782167  0.67904169]
[25.3  25.3   0.75]
[ 1.12230492 -1.77352676  0.76218363]
[25.3  25.3   0.75]
[ 1.15435162 -1.81258085  0.82145187]
[25.3  25.3   0.75]
[ 1.18681997 -1.85167749  0.8527681 ]
[25.3  25.3   0.75]
[ 1.22064203 -1.89510618  0.87428068]
[25.3  25.3   0.75]
[ 1.23520599 -1.94101432  0.87156008]
[25.3  25.3   0.75]
[ 1.25381093 -1.98721034  0.84922475]
[25.3  25.3   0.75]
[ 1.27837275 -2.0178686   0.82843923]
[25.3  25.3   0.75]
[ 1.3095094  -2.04621261  0.79652037]
[25.3  25.3   0.75]
[ 1.33533159 -2.06892769  0.75660203]
[25.3  25.3   0.75]
[ 1.2980029  -2.05429568  0.76789054]
[25.3  25.3   0.75]
[ 1.2562698  -2.03893754  0.76018944]
[25.3  25.3   0.75]
[ 1.21302232 -2.01613229  0.72780908]
[25.3  25.3   0.75]
[ 1.17491925 -1.99002934  0.67140665]
[25.3  25.3   0.75]
[ 1.14643387 -1.97896891  0.60292553]
[25.3  25.3   0.75]
[ 1.11084513 -1.95224158  0.5090963 ]
[25.3  25.3   0.75]
[ 1.07193005 -1.9166285   0.39015208]
[25.3  25.3   0.75]
[ 1.01829105 -1.9079627   0.29723679]
[25.3  25.3   0.75]
[ 0.95327303 -1.94306626  0.24754587]
[25.3  25.3   0.75]
[ 0.89527739 -2.00348864  0.25635653]
[25.3  25.3   0.75]
[ 0.8479886  -2.06673789  0.26706875]
[25.3  25.3   0.75]
[ 0.83075736 -2.1011859   0.33695237]
[25.3  25.3   0.75]
[ 0.81340548 -2.12876222  0.38985209]
[25.3  25.3   0.75]
[ 0.78250736 -2.15477611  0.41507322]
[25.3  25.3   0.75]
[ 0.7415007  -2.18009828  0.43507825]
[25.3  25.3   0.75]
[ 0.68846442 -2.17523926  0.45666123]
[25.3  25.3   0.75]
[ 0.66885249 -2.14315314  0.51212478]
[25.3  25.3   0.75]
[ 0.66768285 -2.11889017  0.55521825]
[25.3  25.3   0.75]
[ 0.67329376 -2.09880618  0.57301026]
[25.3  25.3   0.75]
[ 0.6914309  -2.07955153  0.56809174]
[25.3  25.3   0.75]
[ 0.71688584 -2.07190201  0.53109393]
[25.3  25.3   0.75]
[ 0.73564232 -2.06316021  0.46610247]
[25.3  25.3   0.75]
[ 0.73898396 -2.04505615  0.40907373]
[25.3  25.3   0.75]
[ 0.7430765  -2.00965896  0.4040552 ]
[25.3  25.3   0.75]
[ 0.7645731  -1.96143221  0.39254992]
[25.3  25.3   0.75]
[ 0.79647538 -1.91579106  0.34908739]
[25.3  25.3   0.75]
[ 0.83201989 -1.87752142  0.27946978]
[25.3  25.3   0.75]
[ 0.84820534 -1.8278765   0.25125822]
[25.3  25.3   0.75]
[ 0.86663789 -1.78434017  0.25807327]
[25.3  25.3   0.75]
[ 0.89387707 -1.73814666  0.25956914]
[25.3  25.3   0.75]
[ 0.89214515 -1.68222119  0.28262168]
[25.3  25.3   0.75]
[ 0.88337038 -1.6352501   0.28955138]
[25.3  25.3   0.75]
[ 0.87471222 -1.60668116  0.3087676 ]
[25.3  25.3   0.75]
[ 0.87955722 -1.58854915  0.34225454]
[25.3  25.3   0.75]
[ 0.89060257 -1.57855126  0.35245378]
[25.3  25.3   0.75]
[ 0.89787932 -1.57219059  0.34042278]
[25.3  25.3   0.75]
[ 0.90839696 -1.56864251  0.32573927]
[25.3  25.3   0.75]
[ 0.89892421 -1.57537506  0.33818832]
[25.3  25.3   0.75]
[ 0.88944196 -1.61356953  0.377232  ]
[25.3  25.3   0.75]
[ 0.84467614 -1.62928858  0.42497646]
[25.3  25.3   0.75]
[ 0.7947656  -1.6495338   0.45630282]
[25.3  25.3   0.75]
[ 0.75274733 -1.67814176  0.45605496]
[25.3  25.3   0.75]
[ 0.71109817 -1.71210859  0.43497765]
[25.3  25.3   0.75]
[ 0.67480096 -1.7415309   0.39514083]
[25.3  25.3   0.75]
[ 0.64729205 -1.76955621  0.32953303]
[25.3  25.3   0.75]
[ 0.60303542 -1.80800595  0.30615522]
[25.3  25.3   0.75]
[ 0.53935482 -1.839695    0.27739878]
[25.3  25.3   0.75]
[ 0.48002697 -1.85976106  0.254897  ]
[25.3  25.3   0.75]
[ 0.40808848 -1.85417845  0.28068391]
[25.3  25.3   0.75]
[ 0.33046917 -1.85858403  0.28333484]
[25.3  25.3   0.75]
[ 0.28973745 -1.86746993  0.29012023]
[25.3  25.3   0.75]
[ 0.2686483  -1.88385424  0.33655079]
[25.3  25.3   0.75]
[ 0.25465481 -1.89071118  0.36803665]
[25.3  25.3   0.75]
[ 0.24324749 -1.895253    0.37537339]
[25.3  25.3   0.75]
[ 0.23272494 -1.89936519  0.36312861]
[25.3  25.3   0.75]
[ 0.22591816 -1.89515947  0.3412725 ]
[25.3  25.3   0.75]
[ 0.22795853 -1.88987869  0.31876789]
[25.3  25.3   0.75]
[ 0.21952919 -1.90187835  0.26541139]
[25.3  25.3   0.75]
[ 0.23152091 -1.91633415  0.25873848]
[25.3  25.3   0.75]
[ 0.27366742 -1.93622163  0.26749772]
[25.3  25.3   0.75]
[ 0.30886121 -1.94934797  0.25748867]
[25.3  25.3   0.75]
[ 0.32357519 -1.95665694  0.25959326]
[25.3  25.3   0.75]
[ 0.33228015 -1.9596995   0.25955388]
[25.3  25.3   0.75]
[ 0.33643545 -1.96298277  0.26012824]
[25.3  25.3   0.75]
[ 0.33122105 -1.95264073  0.25942995]
[25.3  25.3   0.75]
[ 0.33216609 -1.92908896  0.26010702]
[25.3  25.3   0.75]
[ 0.36132723 -1.91054005  0.25943828]
[25.3  25.3   0.75]
[ 0.39414126 -1.89937091  0.25958147]
[25.3  25.3   0.75]
[ 0.42540073 -1.8792957   0.25960917]
[25.3  25.3   0.75]
[ 0.44017014 -1.85330545  0.25966932]
[25.3  25.3   0.75]
[ 0.45395752 -1.83934652  0.27121017]
[25.3  25.3   0.75]
[ 0.4665141  -1.82809312  0.27973899]
[25.3  25.3   0.75]
[ 0.48029708 -1.83315224  0.27052156]
[25.3  25.3   0.75]
[ 0.48944943 -1.86218389  0.2609041 ]
[25.3  25.3   0.75]
[ 0.48704066 -1.86667697  0.25977983]
[25.3  25.3   0.75]
[ 0.48775448 -1.87324272  0.2595703 ]
[25.3  25.3   0.75]
[ 0.48745649 -1.8791499   0.25984571]
[25.3  25.3   0.75]
[ 0.48472673 -1.88024228  0.25958259]
[25.3  25.3   0.75]
[ 0.4834758  -1.88391601  0.2597584 ]
[25.3  25.3   0.75]
[ 0.47308565 -1.88204385  0.25955576]
[25.3  25.3   0.75]
[ 0.44721029 -1.8752681   0.25960133]
[25.3  25.3   0.75]
[ 0.42919423 -1.86761458  0.25982725]
[25.3  25.3   0.75]
[ 0.42085744 -1.84998349  0.25965195]
[25.3  25.3   0.75]
[ 0.41916413 -1.83618938  0.25970432]
[25.3  25.3   0.75]
[ 0.42913641 -1.82576593  0.26291379]
[25.3  25.3   0.75]
[ 0.43690695 -1.8188825   0.26812293]
[25.3  25.3   0.75]
[ 0.43762406 -1.81691296  0.25709438]
[25.3  25.3   0.75]
[ 0.43223999 -1.81030826  0.25895878]
[25.3  25.3   0.75]
[ 0.42590098 -1.79334571  0.25962997]
[25.3  25.3   0.75]
[ 0.41853096 -1.77227152  0.26100152]
[25.3  25.3   0.75]
[ 0.41382006 -1.75661123  0.2603476 ]
[25.3  25.3   0.75]
[ 0.40268076 -1.75325485  0.25943285]
[25.3  25.3   0.75]
[ 0.38351196 -1.75444679  0.25961693]
[25.3  25.3   0.75]
[ 0.36961309 -1.75547953  0.25959518]
[25.3  25.3   0.75]
[ 0.35020897 -1.75322194  0.2596058 ]
[25.3  25.3   0.75]
[ 0.32944052 -1.75299969  0.25969049]
[25.3  25.3   0.75]
[ 0.31958346 -1.75002529  0.25981994]
[25.3  25.3   0.75]
[ 0.31255485 -1.74587509  0.25963597]
[25.3  25.3   0.75]
[ 0.29613868 -1.73550996  0.26044918]
[25.3  25.3   0.75]
[ 0.27051856 -1.72659693  0.26083351]
[25.3  25.3   0.75]
[ 0.24324092 -1.72715769  0.26030207]
[25.3  25.3   0.75]
[ 0.22914453 -1.73359893  0.25947248]
[25.3  25.3   0.75]
[ 0.22153123 -1.76627044  0.27993585]
[25.3  25.3   0.75]
[ 0.2020906  -1.80222344  0.27646266]
[25.3  25.3   0.75]
[ 0.19649081 -1.82388498  0.25959194]
[25.3  25.3   0.75]
[ 0.19860313 -1.84005687  0.26022301]
[25.3  25.3   0.75]
[ 0.19481596 -1.85949095  0.2588865 ]
[25.3  25.3   0.75]
[ 0.18544203 -1.8990504   0.26698203]
[25.3  25.3   0.75]
[ 0.19321718 -1.94969098  0.27211167]
[25.3  25.3   0.75]
[ 0.20458331 -1.9744965   0.25846412]
[25.3  25.3   0.75]
[ 0.21400211 -1.97974344  0.25793209]
[25.3  25.3   0.75]
[ 0.22167649 -1.98826766  0.25949331]
[25.3  25.3   0.75]
[ 0.23225899 -2.00175309  0.25964549]
[25.3  25.3   0.75]
[ 0.2365322  -2.01936258  0.25956689]
[25.3  25.3   0.75]
[ 0.23059046 -2.02752146  0.25938725]
[25.3  25.3   0.75]
[ 0.2360301  -2.03267579  0.2593722 ]
[25.3  25.3   0.75]
[ 0.25144111 -2.02656426  0.26711846]
[25.3  25.3   0.75]
[ 0.28171058 -2.01084172  0.26484193]
[25.3  25.3   0.75]
[ 0.27759674 -2.01735311  0.25787895]
[25.3  25.3   0.75]
[ 0.26648184 -2.01867845  0.26048961]
[25.3  25.3   0.75]
[ 0.25566315 -2.00861925  0.25926679]
[25.3  25.3   0.75]
[ 0.24859304 -2.00271551  0.25996189]
[25.3  25.3   0.75]
[ 0.22996697 -1.99093536  0.25932044]
[25.3  25.3   0.75]
[ 0.20313417 -1.9793377   0.25964277]
[25.3  25.3   0.75]
[ 0.17828143 -1.97470933  0.25966355]
[25.3  25.3   0.75]
[ 0.1528608  -1.9735394   0.25964023]
[25.3  25.3   0.75]
[ 0.12845257 -1.97651584  0.2616655 ]
[25.3  25.3   0.75]
[ 0.1251418  -1.99257737  0.27234072]
[25.3  25.3   0.75]
[ 0.10826453 -1.9933935   0.25545383]
[25.3  25.3   0.75]
[ 0.09072297 -1.97778914  0.25883249]
[25.3  25.3   0.75]
[ 0.07894754 -1.9563778   0.27774598]
[25.3  25.3   0.75]
[ 0.07496152 -1.92721744  0.27324348]
[25.3  25.3   0.75]
[ 0.07258583 -1.90352799  0.25495788]
[25.3  25.3   0.75]
[ 0.07530133 -1.90377501  0.25843872]
[25.3  25.3   0.75]
Num timesteps: 2000
Best mean reward: -inf - Last mean reward per episode: -298214.97
Saving new best model to rl/out_dir/models/exp66/best_model.zip
[-0.0478365  -0.00632027  0.78160531]
[43.   43.    0.75]
[-0.03997182 -0.02414067  0.76723507]
[43.   43.    0.75]
[-0.04870328 -0.03378869  0.70892775]
[43.   43.    0.75]
[-0.08122241 -0.05871015  0.66506311]
[43.   43.    0.75]
[-0.12794349 -0.07861375  0.62841808]
[43.   43.    0.75]
[-0.13467681 -0.07814427  0.62311951]
[43.   43.    0.75]
[-0.15026505 -0.08211145  0.60793924]
[43.   43.    0.75]
[-0.15169836 -0.08133405  0.60746882]
[43.   43.    0.75]
[-0.14896967 -0.07954625  0.59928803]
[43.   43.    0.75]
[-0.14441141 -0.07347559  0.58541511]
[43.   43.    0.75]
[-0.14157532 -0.06507437  0.57337002]
[43.   43.    0.75]
[-0.13819119 -0.05595946  0.55988125]
[43.   43.    0.75]
[-0.13555247 -0.05892402  0.5569313 ]
[43.   43.    0.75]
[-0.13533238 -0.07291055  0.55020485]
[43.   43.    0.75]
[-0.13640036 -0.09625851  0.53637332]
[43.   43.    0.75]
[-0.13807505 -0.12781757  0.51553615]2021-05-27 10:23:12.108971: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 10:23:12.132651: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
[-0.00329222 -0.00102186  0.77517455]
[28.9  28.9   0.75]
MultiInputPolicy
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_12
[0.05664043 0.08750389 0.77316515]
[31.3  31.3   0.75]
[0.04542018 0.08973953 0.77104806]
[31.3  31.3   0.75]
[0.03752948 0.09861392 0.72906016]
[31.3  31.3   0.75]
[0.05338128 0.08658347 0.65244148]
[31.3  31.3   0.75]
[0.07915634 0.0674431  0.6086104 ]
[31.3  31.3   0.75]
[0.07892248 0.07406189 0.62022682]
[31.3  31.3   0.75]
[0.08081502 0.08246645 0.63451094]
[31.3  31.3   0.75]
[0.07039336 0.0915048  0.63343188]
[31.3  31.3   0.75]
[0.07176173 0.088747   0.61340221]
[31.3  31.3   0.75]
[0.08404744 0.0730443  0.56043357]
[31.3  31.3   0.75]
[0.09076692 0.0433514  0.48671034]
[31.3  31.3   0.75]
[0.08220376 0.01553734 0.47166461]
[31.3  31.3   0.75]
[ 0.05416584 -0.02461166  0.57706744]
[31.3  31.3   0.75]
[ 0.02082939 -0.03776552  0.65763887]
[31.3  31.3   0.75]
[ 0.00863709 -0.0537159   0.71213388]
[31.3  31.3   0.75]
[ 0.01023239 -0.0738795   0.73781922]
[31.3  31.3   0.75]
[ 0.01879395 -0.10479912  0.74228151]
[31.3  31.3   0.75]
[ 0.01646208 -0.1445495   0.72766363]
[31.3  31.3   0.75]
[-0.01388601 -0.1829355   0.68569888]
[31.3  31.3   0.75]
[-0.06672541 -0.19507653  0.65525345]
[31.3  31.3   0.75]
[-0.10872835 -0.2083172   0.60941838]
[31.3  31.3   0.75]
[-0.15550818 -0.22360666  0.54434049]
[31.3  31.3   0.75]
[-0.19622004 -0.240661    0.4805229 ]
[31.3  31.3   0.75]
[-0.20826851 -0.27560113  0.50371819]
[31.3  31.3   0.75]
[-0.24189762 -0.29883442  0.60171503]
[31.3  31.3   0.75]
[-0.27579531 -0.31439364  0.67207717]
[31.3  31.3   0.75]
[-0.3056442  -0.33346014  0.71688079]
[31.3  31.3   0.75]
[-0.33794341 -0.35784321  0.7361387 ]
[31.3  31.3   0.75]
[-0.37053387 -0.39692643  0.74837744]
[31.3  31.3   0.75]
[-0.4081077  -0.42525471  0.73674233]
[31.3  31.3   0.75]
[-0.4444372  -0.43238106  0.69944465]
[31.3  31.3   0.75]
[-0.47163742 -0.43599384  0.65498587]
[31.3  31.3   0.75]
[-0.48134245 -0.44985218  0.59868528]
[31.3  31.3   0.75]
[-0.4611981  -0.44595795  0.5514877 ]
[31.3  31.3   0.75]
[-0.44654297 -0.43887586  0.48736461]
[31.3  31.3   0.75]
[-0.43177916 -0.44772463  0.48855045]
[31.3  31.3   0.75]
[-0.41741822 -0.49278582  0.55125831]
[31.3  31.3   0.75]
[-0.38900141 -0.54911418  0.60997448]
[31.3  31.3   0.75]
[-0.36803628 -0.60708016  0.64899265]
[31.3  31.3   0.75]
[-0.35094817 -0.63513884  0.68277402]
[31.3  31.3   0.75]
[-0.33500583 -0.64679389  0.68803105]
[31.3  31.3   0.75]
[-0.3183489  -0.65667556  0.66183905]
[31.3  31.3   0.75]
[-0.30730201 -0.6609781   0.63802381]
[31.3  31.3   0.75]
[-0.28593059 -0.66064929  0.60864231]
[31.3  31.3   0.75]
[-0.29149211 -0.65790168  0.58922576]
[31.3  31.3   0.75]
[-0.31740119 -0.62920374  0.57504378]
[31.3  31.3   0.75]
[-0.34373851 -0.58463379  0.59832408]
[31.3  31.3   0.75]
[-0.33604232 -0.5344893   0.66594433]
[31.3  31.3   0.75]
[-0.32360913 -0.47299464  0.70195789]
[31.3  31.3   0.75]
[-0.31919024 -0.42017275  0.72033988]
[31.3  31.3   0.75]
[-0.31268843 -0.3877185   0.73923854]
[31.3  31.3   0.75]
[-0.30174193 -0.35492725  0.74085491]
[31.3  31.3   0.75]
[-0.29573348 -0.33661005  0.72335701]
[31.3  31.3   0.75]
[-0.29236221 -0.32520062  0.68908251]
[31.3  31.3   0.75]
[-0.27973726 -0.30483384  0.64854536]
[31.3  31.3   0.75]
[-0.21276723 -0.26469976  0.66315316]
[31.3  31.3   0.75]
[-0.137493   -0.20842322  0.66645092]
[31.3  31.3   0.75]
[-0.06616692 -0.1579038   0.64896689]
[31.3  31.3   0.75]
[-0.00660092 -0.123602    0.60896829]
[31.3  31.3   0.75]
[ 0.03831557 -0.08837463  0.57717983]
[31.3  31.3   0.75]
[ 0.09157385 -0.07292069  0.5780489 ]
[31.3  31.3   0.75]
[ 0.13592537 -0.07465486  0.64809749]
[31.3  31.3   0.75]
[ 0.17801792 -0.07894267  0.70797678]
[31.3  31.3   0.75]
[ 0.21768822 -0.07538528  0.74285678]
[31.3  31.3   0.75]
[ 0.26483862 -0.07100532  0.75710989]
[31.3  31.3   0.75]
[ 0.32256016 -0.07534715  0.75735632]
[31.3  31.3   0.75]
[ 0.36399111 -0.09649956  0.75319948]
[31.3  31.3   0.75]
[ 0.38608142 -0.13616065  0.78749611]
[31.3  31.3   0.75]
[ 0.43461925 -0.17834434  0.82648188]
[31.3  31.3   0.75]
[ 0.48539205 -0.21431837  0.83493826]
[31.3  31.3   0.75]
[ 0.54004078 -0.24504017  0.81359279]
[31.3  31.3   0.75]
[ 0.60585141 -0.26580434  0.78095249]
[31.3  31.3   0.75]
[ 0.65515258 -0.30297116  0.72894445]
[31.3  31.3   0.75]
[ 0.67670736 -0.35323409  0.67116821]
[31.3  31.3   0.75]
[ 0.62088807 -0.36829953  0.65349193]
[31.3  31.3   0.75]
[ 0.55542532 -0.3652426   0.61137376]
[31.3  31.3   0.75]
[ 0.50538084 -0.37513844  0.58120061]
[31.3  31.3   0.75]
[ 0.46756282 -0.39677082  0.55038496]
[31.3  31.3   0.75]
[ 0.43593833 -0.39996133  0.62367582]
[31.3  31.3   0.75]
[ 0.41448522 -0.41390646  0.71960381]
[31.3  31.3   0.75]
[ 0.39859104 -0.43390989  0.78902646]
[31.3  31.3   0.75]
[ 0.37469123 -0.44297929  0.83612892]
[31.3  31.3   0.75]
[ 0.33821254 -0.45371778  0.86991042]
[31.3  31.3   0.75]
[ 0.29972266 -0.46809815  0.87987428]
[31.3  31.3   0.75]
[ 0.26013774 -0.48040296  0.85940726]
[31.3  31.3   0.75]
[ 0.22944088 -0.51793385  0.87863411]
[31.3  31.3   0.75]
[ 0.20218941 -0.55536447  0.89468178]
[31.3  31.3   0.75]
[ 0.17104611 -0.5930814   0.88079795]
[31.3  31.3   0.75]
[ 0.15040237 -0.62911397  0.84461708]
[31.3  31.3   0.75]
[ 0.124013   -0.66031208  0.78209158]
[31.3  31.3   0.75]
[ 0.09214917 -0.70604424  0.72143076]
[31.3  31.3   0.75]
[ 0.09899497 -0.70840952  0.73615189]
[31.3  31.3   0.75]
[ 0.1233288  -0.70278127  0.75373109]
[31.3  31.3   0.75]
[ 0.14899875 -0.70151974  0.76233436]
[31.3  31.3   0.75]
[ 0.19146254 -0.73291593  0.83932982]
[31.3  31.3   0.75]
[ 0.22318254 -0.76338772  0.89696964]
[31.3  31.3   0.75]
[ 0.2526514  -0.78130064  0.93552668]
[31.3  31.3   0.75]
[ 0.29098594 -0.80202348  0.94850457]
[31.3  31.3   0.75]
[ 0.34892958 -0.83104688  0.95700528]
[31.3  31.3   0.75]
[ 0.41435519 -0.87071024  0.96159395]
[31.3  31.3   0.75]
[ 0.48037719 -0.90366415  0.93414345]
[31.3  31.3   0.75]
[ 0.55126036 -0.918517    0.89524789]
[31.3  31.3   0.75]
[ 0.62415181 -0.92035189  0.86232945]
[31.3  31.3   0.75]
[ 0.68285602 -0.93395978  0.81664672]
[31.3  31.3   0.75]
[ 0.73928583 -0.95726948  0.74260746]
[31.3  31.3   0.75]
[ 0.75906752 -0.98461288  0.68633797]
[31.3  31.3   0.75]
[ 0.72867165 -0.98531466  0.72246442]
[31.3  31.3   0.75]
[ 0.70710397 -0.96832665  0.74955472]
[31.3  31.3   0.75]
[ 0.69085897 -0.94073043  0.75380984]
[31.3  31.3   0.75]
[ 0.66498262 -0.91937385  0.73357636]
[31.3  31.3   0.75]
[ 0.6373524  -0.8960435   0.68741511]
[31.3  31.3   0.75]
[ 0.61607971 -0.86526066  0.63671996]
[31.3  31.3   0.75]
[ 0.58777581 -0.83909161  0.58424251]
[31.3  31.3   0.75]
[ 0.55032303 -0.81029281  0.56155632]
[31.3  31.3   0.75]
[ 0.54242292 -0.81290337  0.57980164]
[31.3  31.3   0.75]
[ 0.53026822 -0.8354547   0.59008441]
[31.3  31.3   0.75]
[ 0.5231753  -0.86984694  0.59865561]
[31.3  31.3   0.75]
[ 0.51216623 -0.88697025  0.57920667]
[31.3  31.3   0.75]
[ 0.51064623 -0.90397174  0.56788573]
[31.3  31.3   0.75]
[ 0.54731505 -0.94799302  0.69578937]
[31.3  31.3   0.75]
[ 0.55136747 -1.0061397   0.79086465]
[31.3  31.3   0.75]
[ 0.55320281 -1.05598681  0.8611395 ]
[31.3  31.3   0.75]
[ 0.56452236 -1.0952301   0.90020866]
[31.3  31.3   0.75]
[ 0.57514745 -1.12736271  0.92152086]
[31.3  31.3   0.75]
[ 0.60003082 -1.16890658  0.93291861]
[31.3  31.3   0.75]
[ 0.62066162 -1.20988164  0.94283227]
[31.3  31.3   0.75]
[ 0.63707775 -1.25951271  0.92557587]
[31.3  31.3   0.75]
[ 0.64500555 -1.310021    0.88608411]
[31.3  31.3   0.75]
[ 0.61137914 -1.35321333  0.87337181]
[31.3  31.3   0.75]
[ 0.57881669 -1.37587226  0.86390692]
[31.3  31.3   0.75]
[ 0.54500335 -1.38997128  0.83319563]
[31.3  31.3   0.75]
[ 0.49515022 -1.3954535   0.80695125]
[31.3  31.3   0.75]
[ 0.44592358 -1.40029456  0.7553333 ]
[31.3  31.3   0.75]
[ 0.38172438 -1.41103286  0.68050492]
[31.3  31.3   0.75]
[ 0.31626213 -1.42437445  0.60222338]
[31.3  31.3   0.75]
[ 0.27906809 -1.42049921  0.72221576]
[31.3  31.3   0.75]
[ 0.26440643 -1.41409409  0.84271209]
[31.3  31.3   0.75]
[ 0.2358907  -1.39534375  0.94347384]
[31.3  31.3   0.75]
[ 0.20314713 -1.37479998  1.02092391]
[31.3  31.3   0.75]
[ 0.04056273 -0.02664464  0.68707379]
[32.6  32.6   0.75]
[ 0.04490109 -0.01761188  0.68239155]
[32.6  32.6   0.75]
[ 0.05818003 -0.00940051  0.65750398]
[32.6  32.6   0.75]
[0.11707453 0.01255963 0.66096115]
[32.6  32.6   0.75]
[0.19711251 0.0174482  0.66719352]
[32.6  32.6   0.75]
[0.24889185 0.00680904 0.67578114]
[32.6  32.6   0.75]
[ 0.26732739 -0.02036491  0.71624748]
[32.6  32.6   0.75]
[ 0.28719214 -0.03052704  0.72828636]
[32.6  32.6   0.75]
[ 0.30662374 -0.02560726  0.70832295]
[32.6  32.6   0.75]
[ 0.33927764 -0.02313441  0.67891996]
[32.6  32.6   0.75]
[ 0.37195758 -0.02242405  0.6436199 ]
[32.6  32.6   0.75]
[ 0.3465478  -0.05566973  0.66856457]
[32.6  32.6   0.75]
[ 0.282235   -0.09239542  0.71169728]
[32.6  32.6   0.75]
[ 0.21135861 -0.12783807  0.73840521]
[32.6  32.6   0.75]
[ 0.15451321 -0.16058905  0.73657024]
[32.6  32.6   0.75]
[ 0.09170808 -0.20060597  0.71606337]
[32.6  32.6   0.75]
[ 0.03594117 -0.24477221  0.66691349]
[32.6  32.6   0.75]
[-0.0213275  -0.28023585  0.59729446]
[32.6  32.6   0.75]
[-0.08217577 -0.28013704  0.52301446]
[32.6  32.6   0.75]
[-0.11181214 -0.26972678  0.48185917]
[32.6  32.6   0.75]
[-0.10120857 -0.29071861  0.53052737]
[32.6  32.6   0.75]
[-0.08985724 -0.32762971  0.58118006]
[32.6  32.6   0.75]
[-0.09085262 -0.36517159  0.61176225]
[32.6  32.6   0.75]
[-0.08500216 -0.39469348  0.61525907]
[32.6  32.6   0.75]
[-0.07301165 -0.41558374  0.60025177]
[32.6  32.6   0.75]
[-0.06816712 -0.43564497  0.57457364]
[32.6  32.6   0.75]
[-0.05386487 -0.44421605  0.55252477]
[32.6  32.6   0.75]
[-0.03402321 -0.41111952  0.57930324]
[32.6  32.6   0.75]
[-0.04418289 -0.39205127  0.59257329]
[32.6  32.6   0.75]
[-0.05385036 -0.38789809  0.58974818]
[32.6  32.6   0.75]
[-0.07113712 -0.38634797  0.57777611]
[32.6  32.6   0.75]
[-0.09332245 -0.39298015  0.56090033]
[32.6  32.6   0.75]
[-0.11719991 -0.40202403  0.52189756]
[32.6  32.6   0.75]
[-0.10498466 -0.42878373  0.56270801]
[32.6  32.6   0.75]
[-0.07459447 -0.44891445  0.66378686]
[32.6  32.6   0.75]
[-0.05440211 -0.47787056  0.73486975]
[32.6  32.6   0.75]
[-0.04916954 -0.51656836  0.77576273]
[32.6  32.6   0.75]
[-0.05109674 -0.54885619  0.7893167 ]
[32.6  32.6   0.75]
[-0.05327107 -0.57244969  0.78556336]
[32.6  32.6   0.75]
[-0.05291266 -0.59165398  0.76721124]
[32.6  32.6   0.75]
[-0.06353598 -0.61478729  0.72293176]
[32.6  32.6   0.75]
[-0.06455124 -0.63176136  0.65012278]
[32.6  32.6   0.75]
[-0.0430926  -0.63353442  0.5530957 ]
[32.6  32.6   0.75]
[-0.01928862 -0.60235586  0.57151869]
[32.6  32.6   0.75]
[ 0.02734625 -0.55727537  0.69619424]
[32.6  32.6   0.75]
[ 0.06116486 -0.52180767  0.79887084]
[32.6  32.6   0.75]
[ 0.09281524 -0.48137032  0.87437476]
[32.6  32.6   0.75]
[ 0.12720967 -0.4333227   0.91474023]
[32.6  32.6   0.75]
[ 0.16011073 -0.38630706  0.93178259]
[32.6  32.6   0.75]
[ 0.20355462 -0.34457352  0.93325657]
[32.6  32.6   0.75]
[ 0.25305807 -0.30835883  0.91007995]
[32.6  32.6   0.75]
[ 0.30455104 -0.30129965  0.89149481]
[32.6  32.6   0.75]
[ 0.37609468 -0.33713816  0.89408138]
[32.6  32.6   0.75]
[ 0.43577837 -0.37788137  0.88425435]
[32.6  32.6   0.75]
[ 0.48354728 -0.41546356  0.87925234]
[32.6  32.6   0.75]
[ 0.52839461 -0.44515348  0.84498012]
[32.6  32.6   0.75]
[ 0.56084136 -0.47878249  0.81410769]
[32.6  32.6   0.75]
[ 0.55502261 -0.50791439  0.88022861]
[32.6  32.6   0.75]
[ 0.5257777  -0.52250427  0.95382545]
[32.6  32.6   0.75]
[ 0.49683617 -0.54872376  1.0035442 ]
[32.6  32.6   0.75]
[ 0.04267315 -0.08227038  0.78602924]
[36.2  36.2   0.75]
[ 0.0560166  -0.09305919  0.77933266]
[36.2  36.2   0.75]
[ 0.06708857 -0.09826397  0.72809138]
[36.2  36.2   0.75]
[ 0.07741314 -0.07623116  0.69648411]
[36.2  36.2   0.75]
[ 0.1140026  -0.01652261  0.69129267]
[36.2  36.2   0.75]
[0.15609699 0.04614416 0.6649189 ]
[36.2  36.2   0.75]
[0.21351076 0.11255074 0.63768074]
[36.2  36.2   0.75]
[0.26620062 0.17973602 0.61254053]
[36.2  36.2   0.75]
[0.31883179 0.25374722 0.60030886]
[36.2  36.2   0.75]
[0.34227746 0.31940088 0.60826852]
[36.2  36.2   0.75]
[0.32366655 0.3817339  0.65575761]
[36.2  36.2   0.75]
[0.31942093 0.44889399 0.66710009]
[36.2  36.2   0.75]
[0.3209217  0.51713693 0.64900151]
[36.2  36.2   0.75]
[0.32282719 0.59198062 0.62073592]
[36.2  36.2   0.75]
[0.32478863 0.67352018 0.57624271]
[36.2  36.2   0.75]
[0.33724238 0.73662089 0.5414785 ]
[36.2  36.2   0.75]
[0.3433961  0.75321191 0.55547033]
[36.2  36.2   0.75]
[0.33480553 0.78842183 0.56503798]
[36.2  36.2   0.75]
[0.34196637 0.82927208 0.56973647]
[36.2  36.2   0.75]
[0.36252677 0.88556868 0.62694922]
[36.2  36.2   0.75]
[0.37078875 0.94031773 0.658833  ]
[36.2  36.2   0.75]
[0.37071646 0.9840378  0.66306977]
[36.2  36.2   0.75]
[0.35444145 1.03335085 0.64653466]
[36.2  36.2   0.75]
[0.35118094 1.07570374 0.61160157]
[36.2  36.2   0.75]
[0.36215315 1.10222714 0.64375755]
[36.2  36.2   0.75]
[0.37197729 1.12846354 0.69779871]
[36.2  36.2   0.75]
[0.38274138 1.17260856 0.72731971]
[36.2  36.2   0.75]
[0.39202646 1.21357739 0.72885274]
[36.2  36.2   0.75]
[0.39608388 1.25145545 0.70722893]
[36.2  36.2   0.75]
[0.38414868 1.27305456 0.69039319]
[36.2  36.2   0.75]
[0.37317464 1.28779031 0.65811748]
[36.2  36.2   0.75]
[0.38644724 1.31424747 0.63409659]
[36.2  36.2   0.75]
[0.43423267 1.35679548 0.63316933]
[36.2  36.2   0.75]
[0.4710063  1.39211081 0.62213924]
[36.2  36.2   0.75]
[0.49026284 1.42495938 0.59852545]
[36.2  36.2   0.75]
[0.50291226 1.46522171 0.56411171]
[36.2  36.2   0.75]
[0.52841497 1.47646435 0.62670104]
[36.2  36.2   0.75]
[0.56163279 1.47495526 0.68209922]
[36.2  36.2   0.75]
[0.59337617 1.47349334 0.7055369 ]
[36.2  36.2   0.75]
[0.62587934 1.48087014 0.71954043]
[36.2  36.2   0.75]
[0.67261067 1.48244351 0.72630348]
[36.2  36.2   0.75]
[0.72162196 1.46475716 0.7091919 ]
[36.2  36.2   0.75]
[0.75083173 1.44768969 0.68555068]
[36.2  36.2   0.75]
[0.75184668 1.44221866 0.67996656]
[36.2  36.2   0.75]
[0.76017015 1.45255094 0.64401765]
[36.2  36.2   0.75]
[0.78180384 1.47950613 0.60747183]
[36.2  36.2   0.75]
[0.83059069 1.56263215 0.61759046]
[36.2  36.2   0.75]
[0.88893252 1.65528412 0.6176021 ]
[36.2  36.2   0.75]
[0.93776325 1.75631549 0.6066552 ]
[36.2  36.2   0.75]
[0.96517214 1.84607905 0.57739188]
[36.2  36.2   0.75]
[0.96487113 1.89791367 0.59094074]
[36.2  36.2   0.75]
[0.95404663 1.91599805 0.62897034]
[36.2  36.2   0.75]
[0.93678947 1.91525108 0.6685691 ]
[36.2  36.2   0.75]
[0.90700643 1.90191395 0.71509929]
[36.2  36.2   0.75]
[0.87530107 1.88756546 0.73492621]
[36.2  36.2   0.75]
[0.83987562 1.86941208 0.74119937]
[36.2  36.2   0.75]
[0.81408122 1.8510648  0.73146178]
[36.2  36.2   0.75]
[0.79039578 1.85412735 0.71378247]
[36.2  36.2   0.75]
[0.73859431 1.88574848 0.71396418]
[36.2  36.2   0.75]
[0.69213145 1.90828355 0.69490408]
[36.2  36.2   0.75]
[0.67730991 1.92583001 0.68557751]
[36.2  36.2   0.75]
[0.68264093 1.96109625 0.68028953]
[36.2  36.2   0.75]
[0.71728071 1.98424661 0.72580014]
[36.2  36.2   0.75]
[0.74847843 1.99109245 0.76904889]
[36.2  36.2   0.75]
[0.77271627 1.9870567  0.79199288]
[36.2  36.2   0.75]
[0.79544123 1.98680035 0.79284895]
[36.2  36.2   0.75]
[0.83064377 2.00136492 0.77108371]
[36.2  36.2   0.75]
[0.85074955 2.02476791 0.71937441]
[36.2  36.2   0.75]
[0.88343448 2.03539597 0.65141289]
[36.2  36.2   0.75]
[0.92104813 1.99808398 0.60820902]
[36.2  36.2   0.75]
[0.95201323 1.94705608 0.55514324]
[36.2  36.2   0.75]
[0.98300328 1.8638112  0.56883934]
[36.2  36.2   0.75]
[1.0221379  1.76926254 0.63056651]
[36.2  36.2   0.75]
[1.04131633 1.68740248 0.66931446]
[36.2  36.2   0.75]
[1.0438505  1.60847165 0.70244564]
[36.2  36.2   0.75]
[1.04657333 1.53935527 0.7298139 ]
[36.2  36.2   0.75]
[1.04292751 1.47452069 0.73104539]
[36.2  36.2   0.75]
[1.03159375 1.41189087 0.72228212]
[36.2  36.2   0.75]
[1.02101117 1.3699819  0.71429763]
[36.2  36.2   0.75]
[1.00901432 1.32277889 0.67848173]
[36.2  36.2   0.75]
[0.97567984 1.26844733 0.63778974]
[36.2  36.2   0.75]
[0.94689637 1.2165951  0.57601416]
[36.2  36.2   0.75]
[0.9669823  1.19892653 0.54007645]
[36.2  36.2   0.75]
[0.96941894 1.15378928 0.51438845]
[36.2  36.2   0.75]
[0.94727071 1.05332637 0.55036728]
[36.2  36.2   0.75]
[0.96199087 0.99326338 0.59927309]
[36.2  36.2   0.75]
[0.99816449 0.94208119 0.65181395]
[36.2  36.2   0.75]
[1.03730998 0.8801648  0.68140103]
[36.2  36.2   0.75]
[1.06350857 0.82102104 0.69849341]
[36.2  36.2   0.75]
[1.08001702 0.75895873 0.712929  ]
[36.2  36.2   0.75]
[1.0926244  0.7006879  0.70979729]
[36.2  36.2   0.75]
[1.07603239 0.67009285 0.72634739]
[36.2  36.2   0.75]
[1.05794303 0.65039898 0.72767516]
[36.2  36.2   0.75]
[1.03619395 0.63137199 0.70700481]
[36.2  36.2   0.75]
[1.01227304 0.62335946 0.68131306]
[36.2  36.2   0.75]
[0.98712496 0.61202451 0.63887997]
[36.2  36.2   0.75]
[0.96312323 0.61531382 0.60213773]
[36.2  36.2   0.75]
[0.92792438 0.6061592  0.61355187]
[36.2  36.2   0.75]
[0.87725717 0.58492734 0.6349313 ]
[36.2  36.2   0.75]
[0.82671698 0.57493922 0.65126301]
[36.2  36.2   0.75]
[0.78828549 0.5661463  0.6487988 ]
[36.2  36.2   0.75]
[0.74432726 0.55019508 0.62163274]
[36.2  36.2   0.75]
[0.70059127 0.51951552 0.6022261 ]
[36.2  36.2   0.75]
[0.67390821 0.52923438 0.60314643]
[36.2  36.2   0.75]
[0.66331124 0.53037296 0.60977634]
[36.2  36.2   0.75]
[0.65456129 0.53567362 0.59676461]
[36.2  36.2   0.75]
[0.64850215 0.54298843 0.57582316]
[36.2  36.2   0.75]
[0.6204936  0.55798282 0.59490672]
[36.2  36.2   0.75]
[0.58272823 0.54767972 0.60528365]
[36.2  36.2   0.75]
[0.54421376 0.54774304 0.59236758]
[36.2  36.2   0.75]
[0.52620262 0.55227567 0.56063907]
[36.2  36.2   0.75]
[0.52604847 0.5695634  0.55635636]
[36.2  36.2   0.75]
[0.53626349 0.58546473 0.58028867]
[36.2  36.2   0.75]
[0.54682918 0.59952681 0.58233308]
[36.2  36.2   0.75]
[0.55420477 0.60612843 0.55975263]
[36.2  36.2   0.75]
[0.5506859  0.60691058 0.52050544]
[36.2  36.2   0.75]
[0.55496493 0.60879893 0.46143793]
[36.2  36.2   0.75]
[0.56807567 0.60692779 0.40196741]
[36.2  36.2   0.75]
[0.59819776 0.60711774 0.50265614]
[36.2  36.2   0.75]
[0.64408188 0.59959255 0.61809176]
[36.2  36.2   0.75]
[0.67774708 0.59598407 0.70488625]
[36.2  36.2   0.75]
[0.70345721 0.59809628 0.76425152]
[36.2  36.2   0.75]
[0.73213427 0.59670563 0.79963925]
[36.2  36.2   0.75]
[0.7516495  0.59278763 0.81129396]
[36.2  36.2   0.75]
[0.76429643 0.59492492 0.79308143]
[36.2  36.2   0.75]
[0.76975643 0.59780754 0.76478134]
[36.2  36.2   0.75]
[0.7488688  0.62859208 0.76647289]
[36.2  36.2   0.75]
[0.74253008 0.65826317 0.74564479]
[36.2  36.2   0.75]
[0.7438333  0.678633   0.69490047]
[36.2  36.2   0.75]
[0.74122569 0.69967177 0.64095178]
[36.2  36.2   0.75]
[0.71970647 0.70682532 0.60085072]
[36.2  36.2   0.75]
[0.68690665 0.69397363 0.57650466]
[36.2  36.2   0.75]
[0.67303485 0.6953555  0.55566808]
[36.2  36.2   0.75]
[0.68333228 0.72602489 0.56981274]
[36.2  36.2   0.75]
[0.69675467 0.75258303 0.60714071]
[36.2  36.2   0.75]
[0.7116132  0.76797405 0.62820857]
[36.2  36.2   0.75]
[0.71428707 0.75541645 0.65007123]
[36.2  36.2   0.75]
[0.69707236 0.73702411 0.66328391]
[36.2  36.2   0.75]
[0.68848894 0.75333007 0.65849535]
[36.2  36.2   0.75]
[0.66470833 0.77887814 0.66006574]
[36.2  36.2   0.75]
[0.64939745 0.80711938 0.64807194]
[36.2  36.2   0.75]
[0.65169808 0.83369259 0.6125076 ]
[36.2  36.2   0.75]
[0.65803117 0.86250555 0.57008991]
[36.2  36.2   0.75]
[0.6454983  0.85250833 0.53204606]
[36.2  36.2   0.75]
[0.64160218 0.84761666 0.5131261 ]
[36.2  36.2   0.75]
[0.6270935  0.86539494 0.49708537]
[36.2  36.2   0.75]
[0.60127773 0.891661   0.49866896]
[36.2  36.2   0.75]
[0.57822756 0.93369502 0.5300374 ]
[36.2  36.2   0.75]
[0.55311451 0.9676554  0.54773349]
[36.2  36.2   0.75]
[0.53050009 1.0013749  0.55416493]
[36.2  36.2   0.75]
[0.50382283 1.03015821 0.55212479]
[36.2  36.2   0.75]
[0.47820631 1.04778787 0.58653287]
[36.2  36.2   0.75]
[0.45932546 1.05450161 0.6086257 ]
[36.2  36.2   0.75]
[0.44697062 1.04642565 0.60784612]
[36.2  36.2   0.75]
[0.43315896 1.05520396 0.58171848]
[36.2  36.2   0.75]
[0.4017388  1.09204361 0.58480222]
[36.2  36.2   0.75]
[0.35964379 1.13315004 0.62448753]
[36.2  36.2   0.75]
[0.32509571 1.1729837  0.6464596 ]
[36.2  36.2   0.75]
[0.28539541 1.21534855 0.64316999]
[36.2  36.2   0.75]
[0.24418488 1.25331189 0.62191884]
[36.2  36.2   0.75]
[0.23938513 1.27110012 0.62601498]
[36.2  36.2   0.75]
[0.24098049 1.2966082  0.6140762 ]
[36.2  36.2   0.75]
[0.25136169 1.28413301 0.59821133]
[36.2  36.2   0.75]
[0.26568662 1.25934696 0.56377385]
[36.2  36.2   0.75]
[0.27390445 1.25066638 0.50867069]
[36.2  36.2   0.75]
[0.26623534 1.22862364 0.49338288]
[36.2  36.2   0.75]
[0.26290872 1.1805352  0.50233822]
[36.2  36.2   0.75]
[0.25833249 1.1242598  0.49231858]
[36.2  36.2   0.75]
[0.2462887  1.07364195 0.4813087 ]
[36.2  36.2   0.75]
[0.215005   1.04414491 0.57483114]
[36.2  36.2   0.75]
[0.17736466 1.02776461 0.67679166]
[36.2  36.2   0.75]
[0.14009121 1.00640832 0.75657856]
[36.2  36.2   0.75]
[0.103075   0.98319941 0.8125914 ]
[36.2  36.2   0.75]
[0.07030395 0.9656167  0.8419453 ]
[36.2  36.2   0.75]
[0.03592339 0.9565509  0.84774453]
[36.2  36.2   0.75]
[-0.01202326  0.94435409  0.8297028 ]
[36.2  36.2   0.75]
[-0.04987061  0.90784415  0.79864888]
[36.2  36.2   0.75]
[-0.09227362  0.8891758   0.74122318]
[36.2  36.2   0.75]
[-0.14188951  0.88285498  0.66157868]
[36.2  36.2   0.75]
[-0.20334021  0.89531245  0.59548404]
[36.2  36.2   0.75]
[-0.23997697  0.94130315  0.58917245]
[36.2  36.2   0.75]
[-0.23166445  0.99585908  0.60119913]
[36.2  36.2   0.75]
[-0.22829193  1.03944873  0.59861814]
[36.2  36.2   0.75]
[-0.21139824  1.05794462  0.60196683]
[36.2  36.2   0.75]
[-0.18641135  1.05826762  0.59888628]
[36.2  36.2   0.75]
[-0.16472026  1.06281763  0.56880618]
[36.2  36.2   0.75]
[-0.17435947  1.07152573  0.54116233]
[36.2  36.2   0.75]
[-0.18824015  1.09977809  0.56739195]
[36.2  36.2   0.75]
[-0.2004372   1.14896005  0.6170274 ]
[36.2  36.2   0.75]
[-0.20121497  1.19200381  0.63717741]
[36.2  36.2   0.75]
[-0.18421711  1.22761823  0.64101588]
[36.2  36.2   0.75]
[-0.09088663  1.2319307   0.71763701]
[36.2  36.2   0.75]
[0.02464448 1.19321521 0.83053523]
[36.2  36.2   0.75]
[0.1357923  1.15675696 0.90947978]
[36.2  36.2   0.75]
[0.25184783 1.15525453 0.96966955]
[36.2  36.2   0.75]
[0.36236859 1.16021625 1.00511632]
[36.2  36.2   0.75]
[ 0.08517657 -0.01521848  0.79434621]
[39.8  39.8   0.75]
[ 0.07732088 -0.0022252   0.77197352]
[39.8  39.8   0.75]
[0.07149928 0.0031709  0.71748045]
[39.8  39.8   0.75]
[ 0.08535815 -0.02452165  0.66523184]
[39.8  39.8   0.75]
[ 0.05959277 -0.02133041  0.63302493]
[39.8  39.8   0.75]
[-0.002851    0.00616826  0.63113229]
[39.8  39.8   0.75]
[-0.06272893  0.04040509  0.61620629]
[39.8  39.8   0.75]
[-0.11693981  0.07659141  0.58281971]
[39.8  39.8   0.75]
[-0.14916486  0.09645593  0.55157275]
[39.8  39.8   0.75]
[-0.19829115  0.11269818  0.51747347]
[39.8  39.8   0.75]
[-0.22045306  0.13226421  0.54355481]
[39.8  39.8   0.75]
[-0.23834539  0.16588627  0.60187703]
[39.8  39.8   0.75]
[-0.26396268  0.19714596  0.63586347]
[39.8  39.8   0.75]
[-0.29278408  0.21601324  0.65702826]
[39.8  39.8   0.75]
[-0.3146781   0.22588969  0.65247093]
[39.8  39.8   0.75]
[-0.3075895   0.20213988  0.67600636]
[39.8  39.8   0.75]
[-0.28917714  0.17327483  0.69413591]
[39.8  39.8   0.75]
[-0.24718922  0.16903124  0.71050064]
[39.8  39.8   0.75]
[-0.19313322  0.18570243  0.72680113]
[39.8  39.8   0.75]
[-0.14646978  0.21032076  0.73828435]
[39.8  39.8   0.75]
[-0.11357242  0.21515923  0.72106502]
[39.8  39.8   0.75]
[-0.08563649  0.21377423  0.67678355]
[39.8  39.8   0.75]
[-0.06313426  0.21751875  0.61658575]
[39.8  39.8   0.75]
[-0.05122395  0.22548339  0.56172659]
[39.8  39.8   0.75]
[-0.05749899  0.23919515  0.53178259]
[39.8  39.8   0.75]
[-0.09011071  0.26113578  0.50682499]
[39.8  39.8   0.75]
[-0.1165112   0.28814664  0.48526641]
[39.8  39.8   0.75]
[-0.0922007   0.34143086  0.51422456]
[39.8  39.8   0.75]
[-0.06887591  0.37888712  0.54309582]
[39.8  39.8   0.75]
[-0.05384871  0.41198076  0.5513482 ]
[39.8  39.8   0.75]
[-0.04026166  0.44823058  0.55717635]
[39.8  39.8   0.75]
[-0.00674597  0.49737668  0.57237154]
[39.8  39.8   0.75]
[0.03565713 0.54724599 0.56276023]
[39.8  39.8   0.75]
[0.05385621 0.6049069  0.54166261]
[39.8  39.8   0.75]
[0.08225312 0.66522129 0.55330582]
[39.8  39.8   0.75]
[0.12161195 0.7292955  0.58686976]
[39.8  39.8   0.75]
[0.14588421 0.7945729  0.59315846]
[39.8  39.8   0.75]
[0.16375532 0.86307647 0.57497751]
[39.8  39.8   0.75]
[0.19692228 0.92573577 0.54532441]
[39.8  39.8   0.75]
[0.25557848 0.95256647 0.57773411]
[39.8  39.8   0.75]
[0.32266673 0.96652828 0.64592172]
[39.8  39.8   0.75]
[0.38250045 0.97955013 0.68515214]
[39.8  39.8   0.75]
[0.45037947 0.98934092 0.69582818]
[39.8  39.8   0.75]
[0.52733791 0.99419599 0.67903652]
[39.8  39.8   0.75]
[0.6119727  1.00838038 0.64360577]
[39.8  39.8   0.75]
[0.63960964 1.01302811 0.63339325]
[39.8  39.8   0.75]
[0.6507227  1.01160326 0.63038462]
[39.8  39.8   0.75]
[0.65210515 1.00018484 0.68405592]
[39.8  39.8   0.75]
[0.6343272  1.00295854 0.73292322]
[39.8  39.8   0.75]
[0.60657669 0.9873744  0.76953516]
[39.8  39.8   0.75]
[0.57217996 0.96832796 0.78687755]
[39.8  39.8   0.75]
[0.5431922  0.95294775 0.77396043]
[39.8  39.8   0.75]
[0.51815112 0.92141889 0.75791987]
[39.8  39.8   0.75]
[0.49938536 0.87745848 0.73217436]
[39.8  39.8   0.75]
[0.49182858 0.8162988  0.6835106 ]
[39.8  39.8   0.75]
[0.47734522 0.76169425 0.61518206]
[39.8  39.8   0.75]
[0.49734914 0.69600568 0.57526857]
[39.8  39.8   0.75]
[0.58852106 0.58132113 0.64411411]
[39.8  39.8   0.75]
[0.65984291 0.46341238 0.68527581]
[39.8  39.8   0.75]
[0.72864046 0.34840748 0.70749829]
[39.8  39.8   0.75]
[0.77834935 0.2449355  0.7278597 ]
[39.8  39.8   0.75]
[0.80881386 0.18445081 0.77755384]
[39.8  39.8   0.75]
[0.82662971 0.14675455 0.82875781]
[39.8  39.8   0.75]
[0.84706918 0.1065387  0.85689805]
[39.8  39.8   0.75]
[0.8755675  0.08291023 0.88778057]
[39.8  39.8   0.75]
[0.90225043 0.06047373 0.89822882]
[39.8  39.8   0.75]
[0.9411988  0.04954002 0.91994107]
[39.8  39.8   0.75]
[0.99004425 0.03677832 0.9475321 ]
[39.8  39.8   0.75]
[1.0313829  0.04065316 0.95154575]
[39.8  39.8   0.75]
[1.08165158 0.04846969 0.93184052]
[39.8  39.8   0.75]
[1.12293571 0.07150577 0.90248044]
[39.8  39.8   0.75]
[1.15436825 0.09978273 0.86071715]
[39.8  39.8   0.75]
[1.18593827 0.125956   0.80071508]
[39.8  39.8   0.75]
[1.20950538 0.14895871 0.71555586]
[39.8  39.8   0.75]
[1.24270187 0.17748263 0.6276301 ]
[39.8  39.8   0.75]
[1.32697049 0.23792779 0.58165221]
[39.8  39.8   0.75]
[1.36736826 0.30359966 0.6118252 ]
[39.8  39.8   0.75]
[1.40090257 0.36419124 0.63190294]
[39.8  39.8   0.75]
[1.4182314  0.41347615 0.62507639]
[39.8  39.8   0.75]
[1.42014246 0.47301306 0.60299475]
[39.8  39.8   0.75]
[1.41605719 0.51893673 0.59544814]
[39.8  39.8   0.75]
[1.41349345 0.54591612 0.64751536]
[39.8  39.8   0.75]
[1.41902835 0.56891846 0.68437396]
[39.8  39.8   0.75]
[1.42444157 0.59619545 0.68995298]
[39.8  39.8   0.75]
[1.4338544  0.61722568 0.6645463 ]
[39.8  39.8   0.75]
[1.44890874 0.64832692 0.62296303]
[39.8  39.8   0.75]
[1.44513977 0.67527569 0.57845655]
[39.8  39.8   0.75]
[1.41017677 0.66241608 0.53775371]
[39.8  39.8   0.75]
[1.35011252 0.6391473  0.5294101 ]
[39.8  39.8   0.75]
[1.2697961  0.61352795 0.55022646]
[39.8  39.8   0.75]
[1.18674697 0.60151268 0.55307153]
[39.8  39.8   0.75]
[1.13476647 0.59064605 0.54912453]
[39.8  39.8   0.75]
[1.09082664 0.57415387 0.53083302]
[39.8  39.8   0.75]
[1.04938455 0.58391795 0.55242805]
[39.8  39.8   0.75]
[0.94275386 0.60202728 0.65746046]
[39.8  39.8   0.75]
[0.83171696 0.61120137 0.74219896]
[39.8  39.8   0.75]
[0.73790712 0.59678743 0.80056707]
[39.8  39.8   0.75]
[0.65116054 0.5982639  0.83095276]
[39.8  39.8   0.75]
[0.56042697 0.60203822 0.83541478]
[39.8  39.8   0.75]
[0.47412178 0.59766831 0.81164769]
[39.8  39.8   0.75]
[0.38368604 0.58210806 0.77901347]
[39.8  39.8   0.75]
[0.31615296 0.56593569 0.76535522]
[39.8  39.8   0.75]
[0.29623416 0.54035983 0.78196851]
[39.8  39.8   0.75]
[0.28227911 0.52231361 0.79728936]
[39.8  39.8   0.75]
[0.26332764 0.50137508 0.8994271 ]
[39.8  39.8   0.75]
[0.23924381 0.47745117 1.01122746]
[39.8  39.8   0.75]
---------------------------------
| forward_vel        | 1.26     |
| reward             | 1.13     |
| reward_contact     | 0        |
| reward_ctrl        | -1.12    |
| reward_position    | 0        |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 125      |
|    ep_rew_mean     | 60.8     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 53       |
|    time_elapsed    | 9        |
|    total timesteps | 501      |
---------------------------------
[ 0.10364994 -0.01876105  0.84505604]
[3.4  3.4  0.75]
[ 0.1214294  -0.00905354  0.84272781]
[3.4  3.4  0.75]
[ 0.1223623  -0.01773617  0.79135264]
[3.4  3.4  0.75]
[ 0.10958456 -0.03204667  0.70393701]
[3.4  3.4  0.75]
[ 0.09204153 -0.04308509  0.5903657 ]
[3.4  3.4  0.75]
[ 0.12489347 -0.08650595  0.57179243]
[3.4  3.4  0.75]
[ 0.17788593 -0.12871761  0.5619952 ]
[3.4  3.4  0.75]
[ 0.22515624 -0.1698475   0.5412801 ]
[3.4  3.4  0.75]
[ 0.26956253 -0.19786471  0.51382567]
[3.4  3.4  0.75]
[ 0.31390613 -0.18981833  0.56175151]
[3.4  3.4  0.75]
[ 0.33398454 -0.18579301  0.63711472]
[3.4  3.4  0.75]
[ 0.36622703 -0.19337242  0.6965126 ]
[3.4  3.4  0.75]
[ 0.40178973 -0.20157323  0.73725316]
[3.4  3.4  0.75]
[ 0.43786071 -0.21510365  0.7531499 ]
[3.4  3.4  0.75]
[ 0.46985463 -0.23854933  0.74500012]
[3.4  3.4  0.75]
[ 0.49600613 -0.24838617  0.70831989]
[3.4  3.4  0.75]
[ 0.52929377 -0.25868868  0.66988843]
[3.4  3.4  0.75]
[ 0.57159879 -0.25987656  0.63845383]
[3.4  3.4  0.75]
[ 0.61116172 -0.24264692  0.58667835]
[3.4  3.4  0.75]
[ 0.66116819 -0.23680493  0.53323394]
[3.4  3.4  0.75]
[ 0.67420515 -0.20396822  0.57873486]
[3.4  3.4  0.75]
[ 0.66194185 -0.17645206  0.66563172]
[3.4  3.4  0.75]
[ 0.63946604 -0.16712148  0.72437888]
[3.4  3.4  0.75]
[ 0.63188619 -0.15608881  0.74694894]
[3.4  3.4  0.75]
[ 0.64686022 -0.13222673  0.75396294]
[3.4  3.4  0.75]
[ 0.65421725 -0.09814116  0.74051397]
[3.4  3.4  0.75]
[ 0.65136898 -0.06336682  0.72383904]
[3.4  3.4  0.75]
[ 0.63785899 -0.03760245  0.69506485]
[3.4  3.4  0.75]
[0.64023939 0.00444109 0.66266398]
[3.4  3.4  0.75]
[0.71392029 0.09701128 0.73977188]
[3.4  3.4  0.75]
[0.78199485 0.18058153 0.80793573]
[3.4  3.4  0.75]
[0.84167875 0.2848609  0.84543212]
[3.4  3.4  0.75]
[0.90897652 0.39472682 0.85905276]
[3.4  3.4  0.75]
[0.97214364 0.51402692 0.84444433]
[3.4  3.4  0.75]
[1.03042154 0.62954198 0.80170179]
[3.4  3.4  0.75]
[1.09909252 0.73649233 0.74509509]
[3.4  3.4  0.75]
[1.16561404 0.810218   0.72316703]
[3.4  3.4  0.75]
[1.26255234 0.84052457 0.75532849]
[3.4  3.4  0.75]
[1.36378899 0.81489602 0.88897724]
[3.4  3.4  0.75]
[1.45535064 0.78756387 1.00874168]
[3.4  3.4  0.75]
[0.07247109 0.04167822 0.72757836]
[19.9  19.9   0.75]
[0.06137845 0.02239947 0.71650721]
[19.9  19.9   0.75]
[0.05963409 0.0012277  0.67130321]
[19.9  19.9   0.75]
[1.00221438e-01 3.02111218e-04 6.58698859e-01]
[19.9  19.9   0.75]
[ 0.15100565 -0.00592633  0.65753954]
[19.9  19.9   0.75]
[ 0.17867844 -0.01325105  0.6582728 ]
[19.9  19.9   0.75]
[ 0.19124984 -0.03015942  0.63174382]
[19.9  19.9   0.75]
[ 0.20369265 -0.03864341  0.58354176]
[19.9  19.9   0.75]
[ 0.20144483 -0.03118025  0.5182609 ]
[19.9  19.9   0.75]
[ 0.18179271 -0.01639166  0.46451745]
[19.9  19.9   0.75]
[0.1734724  0.01182644 0.52637937]
[19.9  19.9   0.75]
[0.17240748 0.05499807 0.57953283]
[19.9  19.9   0.75]
[0.18021666 0.09329323 0.59994392]
[19.9  19.9   0.75]
[0.17732423 0.12483634 0.59594734]
[19.9  19.9   0.75]
[0.17849484 0.14991898 0.58189924]
[19.9  19.9   0.75]
[0.18883763 0.1594602  0.56476774]
[19.9  19.9   0.75]
[0.17758097 0.1470187  0.58476771]
[19.9  19.9   0.75]
[0.18580047 0.14959856 0.64540956]
[19.9  19.9   0.75]
[0.19369005 0.15271011 0.68659186]
[19.9  19.9   0.75]
[0.18822337 0.15717202 0.69648967]
[19.9  19.9   0.75]
[0.17315442 0.18017252 0.69985382]
[19.9  19.9   0.75]
[0.15771156 0.22421991 0.7080665 ]
[19.9  19.9   0.75]
[0.14620398 0.2663304  0.6958677 ]
[19.9  19.9   0.75]
[0.14258084 0.29494425 0.66064375]
[19.9  19.9   0.75]
[0.12362278 0.33021515 0.60612562]
[19.9  19.9   0.75]
[0.06671007 0.35271833 0.60232731]
[19.9  19.9   0.75]
[-0.00368086  0.35926391  0.59586693]
[19.9  19.9   0.75]
[-0.07305617  0.36980554  0.63338259]
[19.9  19.9   0.75]
[-0.12185059  0.38136358  0.68296095]
[19.9  19.9   0.75]
[-0.14662241  0.40656194  0.72400994]
[19.9  19.9   0.75]
[-0.16141818  0.4416122   0.74665636]
[19.9  19.9   0.75]
[-0.18341015  0.46898258  0.7422446 ]
[19.9  19.9   0.75]
[-0.20555376  0.49545292  0.71727796]
[19.9  19.9   0.75]
[-0.23321347  0.51748868  0.6668103 ]
[19.9  19.9   0.75]
[-0.27428319  0.53193199  0.5905792 ]
[19.9  19.9   0.75]
[-0.27461938  0.54450328  0.55695172]
[19.9  19.9   0.75]
[-0.24759985  0.55599301  0.52897181]
[19.9  19.9   0.75]
[-0.20219079  0.57936321  0.5510106 ]
[19.9  19.9   0.75]
[-0.13794603  0.60866776  0.63920678]
[19.9  19.9   0.75]
[-0.08702807  0.62519889  0.71861649]
[19.9  19.9   0.75]
[-0.04187283  0.64900935  0.78072358]
[19.9  19.9   0.75]
[0.00577775 0.67991998 0.81786236]
[19.9  19.9   0.75]
[0.04805259 0.71196666 0.82248026]
[19.9  19.9   0.75]
[0.09325616 0.74156267 0.80167471]
[19.9  19.9   0.75]
[0.14612609 0.77867016 0.75523617]
[19.9  19.9   0.75]
[0.17320888 0.77563945 0.7228557 ]
[19.9  19.9   0.75]
[0.16853406 0.74206907 0.711159  ]
[19.9  19.9   0.75]
[0.15892681 0.71171529 0.67503702]
[19.9  19.9   0.75]
[0.14891722 0.68630571 0.63155975]
[19.9  19.9   0.75]
[0.10737598 0.68573177 0.61322428]
[19.9  19.9   0.75]
[0.04223367 0.67973672 0.5838945 ]
[19.9  19.9   0.75]
[-0.02838728  0.6805507   0.55244176]
[19.9  19.9   0.75]
[-0.08544163  0.67738797  0.54087979]
[19.9  19.9   0.75]
[-0.10763723  0.66464248  0.5639758 ]
[19.9  19.9   0.75]
[-0.1113502   0.66346985  0.57002421]
[19.9  19.9   0.75]
[-0.10964086  0.66918758  0.54725207]
[19.9  19.9   0.75]
[-0.1166476   0.66351393  0.52390327]
[19.9  19.9   0.75]
[-0.11530489  0.66453534  0.53871217]
[19.9  19.9   0.75]
[-0.14195741  0.6931231   0.63524169]
[19.9  19.9   0.75]
[-0.17696717  0.72601401  0.71754783]
[19.9  19.9   0.75]
[-0.21301549  0.7435685   0.77331812]
[19.9  19.9   0.75]
[-0.24547634  0.75126885  0.80565929]
[19.9  19.9   0.75]
[-0.27225319  0.75930376  0.80739036]
[19.9  19.9   0.75]
[-0.29366319  0.76309684  0.78539399]
[19.9  19.9   0.75]
[-0.30779244  0.77461416  0.74515791]
[19.9  19.9   0.75]
[-0.32645106  0.78658154  0.68269167]
[19.9  19.9   0.75]
[-0.34549311  0.80185648  0.61602108]
[19.9  19.9   0.75]
[-0.37881956  0.7923709   0.57616858]
[19.9  19.9   0.75]
[-0.41206922  0.77165842  0.55308368]
[19.9  19.9   0.75]
[-0.44423738  0.74917873  0.50972907]
[19.9  19.9   0.75]
[-0.43864626  0.71293837  0.50252524]
[19.9  19.9   0.75]
[-0.42470353  0.67471882  0.5094209 ]
[19.9  19.9   0.75]
[-0.41886758  0.64211328  0.49601443]
[19.9  19.9   0.75]
[-0.42454866  0.61295403  0.47854024]
[19.9  19.9   0.75]
[-0.45859763  0.59608068  0.55191996]
[19.9  19.9   0.75]
[-0.48797967  0.57642669  0.60194558]
[19.9  19.9   0.75]
[-0.51107141  0.58899986  0.65707391]
[19.9  19.9   0.75]
[-0.53675092  0.60507704  0.71722454]
[19.9  19.9   0.75]
[-0.55648191  0.62325863  0.75551075]
[19.9  19.9   0.75]
[-0.57533302  0.62865902  0.76679395]
[19.9  19.9   0.75]
[-0.59122494  0.637702    0.7584346 ]
[19.9  19.9   0.75]
[-0.59884501  0.65129919  0.73544765]
[19.9  19.9   0.75]
[-0.60759615  0.66759352  0.70142599]
[19.9  19.9   0.75]
[-0.6222228   0.68157154  0.64150875]
[19.9  19.9   0.75]
[-0.63467592  0.70137073  0.55500762]
[19.9  19.9   0.75]
[-0.61932006  0.71018654  0.48466563]
[19.9  19.9   0.75]
[-0.57160475  0.74955094  0.5856324 ]
[19.9  19.9   0.75]
[-0.52471285  0.77583929  0.66591137]
[19.9  19.9   0.75]
[-0.48473159  0.79608216  0.72838492]
[19.9  19.9   0.75]
[-0.45428129  0.82418579  0.77092695]
[19.9  19.9   0.75]
[-0.42155918  0.85602016  0.8058259 ]
[19.9  19.9   0.75]
[-0.38991255  0.87879237  0.82536184]
[19.9  19.9   0.75]
[-0.35910267  0.89635422  0.82238051]
[19.9  19.9   0.75]
[-0.33439288  0.93700473  0.79184325]
[19.9  19.9   0.75]
[-0.31275035  0.96477158  0.76365898]
[19.9  19.9   0.75]
[-0.30040482  0.94935394  0.76874764]
[19.9  19.9   0.75]
[-0.2710738   0.92755308  0.7446203 ]
[19.9  19.9   0.75]
[-0.24757208  0.90389282  0.69403659]
[19.9  19.9   0.75]
[-0.24016851  0.87392703  0.68105437]
[19.9  19.9   0.75]
[-0.22505646  0.84530668  0.66116291]
[19.9  19.9   0.75]
[-0.21655859  0.82624653  0.62152417]
[19.9  19.9   0.75]
[-0.22529173  0.85381056  0.59833177]
[19.9  19.9   0.75]
[-0.228085   0.8638771  0.5805625]
[19.9  19.9   0.75]
[-0.23466454  0.8663268   0.55900646]
[19.9  19.9   0.75]
[-0.20775411  0.82887445  0.5815915 ]
[19.9  19.9   0.75]
[-0.17100733  0.79596855  0.6637595 ]
[19.9  19.9   0.75]
[-0.13248243  0.77162326  0.71945831]
[19.9  19.9   0.75]
[-0.10112224  0.77624943  0.77435107]
[19.9  19.9   0.75]
[-0.08516919  0.81370467  0.85319009]
[19.9  19.9   0.75]
[-0.06017988  0.84078005  0.90107897]
[19.9  19.9   0.75]
[-0.03011021  0.85486637  0.91568493]
[19.9  19.9   0.75]
[-0.01910451  0.87388089  0.91192876]
[19.9  19.9   0.75]
[-0.02243593  0.89644879  0.89652591]
[19.9  19.9   0.75]
[-0.02609241  0.92198078  0.86253711]
[19.9  19.9   0.75]
[-0.03130487  0.93870721  0.81641213]
[19.9  19.9   0.75]
[-0.03708403  0.96276772  0.74396718]
[19.9  19.9   0.75]
[-0.03863384  1.00326931  0.65913815]
[19.9  19.9   0.75]
[-0.01974266  1.05492467  0.5671374 ]
[19.9  19.9   0.75]
[0.0184736  1.0867824  0.54805522]
[19.9  19.9   0.75]
[0.07188043 1.10134512 0.57013512]
[19.9  19.9   0.75]
[0.13675058 1.11868059 0.57839306]
[19.9  19.9   0.75]
[0.1851507  1.14727792 0.57584113]
[19.9  19.9   0.75]
[0.21517606 1.17914225 0.55853536]
[19.9  19.9   0.75]
[0.23846501 1.2043942  0.52012778]
[19.9  19.9   0.75]
[0.21826138 1.2593416  0.53357175]
[19.9  19.9   0.75]
[0.14772587 1.28411313 0.60171205]
[19.9  19.9   0.75]
[0.07643257 1.28992611 0.68695067]
[19.9  19.9   0.75]
[0.01844732 1.29570726 0.74682835]
[19.9  19.9   0.75]
[-0.0418516   1.30125703  0.77830358]
[19.9  19.9   0.75]
[-0.10378603  1.30267709  0.78219902]
[19.9  19.9   0.75]
[-0.14098847  1.29769757  0.76892655]
[19.9  19.9   0.75]
[-0.14323823  1.28781906  0.76116365]
[19.9  19.9   0.75]
[-0.13679894  1.27498815  0.74040084]
[19.9  19.9   0.75]
[-0.17446839  1.26075417  0.68678464]
[19.9  19.9   0.75]
[-0.19963371  1.23778386  0.62629654]
[19.9  19.9   0.75]
[-0.22485146  1.21792203  0.56693055]
[19.9  19.9   0.75]
[-0.26367343  1.20904434  0.55155393]
[19.9  19.9   0.75]
[-0.29855494  1.20786048  0.53237223]
[19.9  19.9   0.75]
[-0.31763321  1.23204904  0.56203152]
[19.9  19.9   0.75]
[-0.34305288  1.24904053  0.58491029]
[19.9  19.9   0.75]
[-0.3656651   1.26660553  0.5885992 ]
[19.9  19.9   0.75]
[-0.39565791  1.28645143  0.58200667]
[19.9  19.9   0.75]
[-0.47276847  1.29055881  0.60913285]
[19.9  19.9   0.75]
[-0.53900863  1.27569599  0.62665347]
[19.9  19.9   0.75]
[-0.59577782  1.26819023  0.6208263 ]
[19.9  19.9   0.75]
[-0.63645718  1.26883691  0.67887764]
[19.9  19.9   0.75]
[-0.6782655   1.27327353  0.72173699]
[19.9  19.9   0.75]
[-0.74367239  1.27253638  0.74127749]
[19.9  19.9   0.75]
[-0.8210336   1.27304243  0.73367394]
[19.9  19.9   0.75]
[-0.89659791  1.28923334  0.69510367]
[19.9  19.9   0.75]
[-0.96867966  1.31469543  0.6269334 ]
[19.9  19.9   0.75]
[-1.03942361  1.30303181  0.5457057 ]
[19.9  19.9   0.75]
[-1.07093438  1.27283247  0.5250295 ]
[19.9  19.9   0.75]
[-1.09970908  1.22715389  0.54966543]
[19.9  19.9   0.75]
[-1.13716145  1.14705153  0.65053182]
[19.9  19.9   0.75]
[-1.15495222  1.10154519  0.75125146]
[19.9  19.9   0.75]
[-1.15665694  1.05884228  0.82551677]
[19.9  19.9   0.75]
[-1.14767481  1.01872567  0.86938132]
[19.9  19.9   0.75]
[-1.15258913  0.97040264  0.88392403]
[19.9  19.9   0.75]
[-1.16964506  0.9191406   0.88130742]
[19.9  19.9   0.75]
[-1.18562139  0.85821312  0.87674098]
[19.9  19.9   0.75]
[-1.20437799  0.79572983  0.84779964]
[19.9  19.9   0.75]
[-1.21417403  0.7529643   0.82667984]
[19.9  19.9   0.75]
[-1.1846471   0.72745013  0.83031339]
[19.9  19.9   0.75]
[-1.15602966  0.70437333  0.81660301]
[19.9  19.9   0.75]
[-1.14783783  0.68847927  0.79729157]
[19.9  19.9   0.75]
[-1.14192682  0.66378296  0.74925715]
[19.9  19.9   0.75]
[-1.15042351  0.6411985   0.69976224]
[19.9  19.9   0.75]
[-1.18433552  0.63540915  0.72729441]
[19.9  19.9   0.75]
[-1.2114003   0.63891825  0.75900663]
[19.9  19.9   0.75]
[-1.23001565  0.65557514  0.81858006]
[19.9  19.9   0.75]
[-1.2470242   0.65142972  0.87842004]
[19.9  19.9   0.75]
[-1.26417301  0.63720117  0.95070366]
[19.9  19.9   0.75]
[-1.27941816  0.62776665  1.007098  ]
[19.9  19.9   0.75]
[0.07616771 0.09158083 0.78121011]
[23.4  23.4   0.75]
[0.04612927 0.09405121 0.78173654]
[23.4  23.4   0.75]
[0.02850085 0.09932548 0.73524315]
[23.4  23.4   0.75]
[0.01186106 0.10712966 0.670758  ]
[23.4  23.4   0.75]
[-0.03592842  0.14885749  0.64028569]
[23.4  23.4   0.75]
[-0.05820965  0.16349138  0.61605195]
[23.4  23.4   0.75]
[-0.07672548  0.18441956  0.58123591]
[23.4  23.4   0.75]
[-0.09411018  0.210944    0.62249266]
[23.4  23.4   0.75]
[-0.10287468  0.22287578  0.68182259]
[23.4  23.4   0.75]
[-0.10167897  0.22168412  0.722554  ]
[23.4  23.4   0.75]
[-0.11236689  0.24939616  0.75554498]
[23.4  23.4   0.75]
[-0.13233602  0.2817374   0.76554854]
[23.4  23.4   0.75]
[-0.14726341  0.31428888  0.75153902]
[23.4  23.4   0.75]
[-0.16189015  0.3514109   0.71181064]
[23.4  23.4   0.75]
[-0.1781897   0.38859878  0.64879424]
[23.4  23.4   0.75]
[-0.19868147  0.43618682  0.55636528]
[23.4  23.4   0.75]
[-0.24689267  0.485941    0.48119145]
[23.4  23.4   0.75]
[-0.34962862  0.50709493  0.55935173]
[23.4  23.4   0.75]
[-0.44311217  0.51227075  0.63239371]
[23.4  23.4   0.75]
[-0.51019786  0.51649805  0.69192516]
[23.4  23.4   0.75]
[-0.5680948   0.53851432  0.72739384]
[23.4  23.4   0.75]
[-0.62989694  0.56740246  0.7340381 ]
[23.4  23.4   0.75]
[-0.67859031  0.57171341  0.75258338]
[23.4  23.4   0.75]
[-0.71410978  0.56729458  0.76906603]
[23.4  23.4   0.75]
[-0.73862708  0.56495042  0.77824789]
[23.4  23.4   0.75]
[-0.74937849  0.53638285  0.78752907]
[23.4  23.4   0.75]
[-0.75728653  0.50496025  0.76929792]
[23.4  23.4   0.75]
[-0.7666428   0.48387173  0.73765669]
[23.4  23.4   0.75]
[-0.79619464  0.4784475   0.72065565]
[23.4  23.4   0.75]
[-0.8249207   0.49568289  0.71590137]
[23.4  23.4   0.75]
[-0.84399844  0.53723491  0.80566339]
[23.4  23.4   0.75]
[-0.86130102  0.59653983  0.93729298]
[23.4  23.4   0.75]
[-0.90153138  0.64914479  1.05033631]
[23.4  23.4   0.75]
[0.08112653 0.01357011 0.8603779 ]
[30.8  30.8   0.75]
[0.06977935 0.02332447 0.84107376]
[30.8  30.8   0.75]
[0.09205608 0.03498181 0.78502089]
[30.8  30.8   0.75]
[0.10443374 0.03909351 0.70138474]
[30.8  30.8   0.75]
[0.11498822 0.06614066 0.61069205]
[30.8  30.8   0.75]
[0.12129232 0.10812762 0.62823775]
[30.8  30.8   0.75]
[0.10854122 0.12449421 0.63347433]
[30.8  30.8   0.75]
[0.1038089  0.14526608 0.62187772]
[30.8  30.8   0.75]
[0.10896094 0.2088361  0.62008646]
[30.8  30.8   0.75]
[0.1141559  0.29664793 0.64017206]
[30.8  30.8   0.75]
[0.12668086 0.37173802 0.64317329]
[30.8  30.8   0.75]
[0.12811855 0.45639724 0.63477568]
[30.8  30.8   0.75]
[0.11331454 0.5361546  0.61438147]
[30.8  30.8   0.75]
[0.103862   0.5995102  0.59112383]
[30.8  30.8   0.75]
[0.10939918 0.65221273 0.57070089]
[30.8  30.8   0.75]
[0.09367143 0.69880077 0.5427367 ]
[30.8  30.8   0.75]
[0.03588041 0.71960707 0.57809129]
[30.8  30.8   0.75]
[-0.02590188  0.73075614  0.59982917]
[30.8  30.8   0.75]
[-0.07764636  0.7245082   0.59694101]
[30.8  30.8   0.75]
[-0.12345987  0.73502301  0.61466491]
[30.8  30.8   0.75]
[-0.17548805  0.73772446  0.62527728]
[30.8  30.8   0.75]
[-0.24923083  0.74234067  0.60676957]
[30.8  30.8   0.75]
[-0.35056664  0.7626441   0.58903206]
[30.8  30.8   0.75]
[-0.43720961  0.77008774  0.56120845]
[30.8  30.8   0.75]
[-0.50767172  0.75417269  0.56401521]
[30.8  30.8   0.75]
[-0.5694038   0.70310677  0.60220919]
[30.8  30.8   0.75]
[-0.64730537  0.65551563  0.62644898]
[30.8  30.8   0.75]
[-0.70085374  0.65154857  0.66076359]
[30.8  30.8   0.75]
[-0.75071011  0.64810763  0.66349729]
[30.8  30.8   0.75]
[-0.7935635   0.64149372  0.65383439]
[30.8  30.8   0.75]
[-0.82766104  0.62318189  0.63252647]
[30.8  30.8   0.75]
[-0.83769596  0.59345071  0.625527  ]
[30.8  30.8   0.75]
[-0.838531    0.57250748  0.6172935 ]
[30.8  30.8   0.75]
[-0.84904406  0.59633909  0.63255054]
[30.8  30.8   0.75]
[-0.87304109  0.63902043  0.63889588]
[30.8  30.8   0.75]
[-0.90166129  0.69588759  0.63009596]
[30.8  30.8   0.75]
[-0.9579429   0.75270772  0.62835796]
[30.8  30.8   0.75]
[-1.02800092  0.81267355  0.61856574]
[30.8  30.8   0.75]
[-1.10051192  0.88804845  0.60835719]
[30.8  30.8   0.75]
[-1.16020354  0.9238453   0.58952038]
[30.8  30.8   0.75]
[-1.18555719  0.91205792  0.62436235]
[30.8  30.8   0.75]
[-1.21268027  0.91079387  0.64497893]
[30.8  30.8   0.75]
[-1.24856766  0.90681715  0.63487654]
[30.8  30.8   0.75]
[-1.28107983  0.89860075  0.60954671]
[30.8  30.8   0.75]
[-1.30034374  0.89183533  0.5865082 ]
[30.8  30.8   0.75]
[-1.31710628  0.87861351  0.61652364]
[30.8  30.8   0.75]
[-1.31572253  0.84314219  0.66955304]
[30.8  30.8   0.75]
[-1.32456266  0.8124627   0.70281398]
[30.8  30.8   0.75]
[-1.33410394  0.78818027  0.71712961]
[30.8  30.8   0.75]
[-1.34616677  0.77008859  0.70896661]
[30.8  30.8   0.75]
[-1.35427572  0.74602682  0.68799404]
[30.8  30.8   0.75]
[-1.37410408  0.70855759  0.68111993]
[30.8  30.8   0.75]
[-1.40289678  0.66261891  0.68711154]
[30.8  30.8   0.75]
[-1.43287277  0.66282214  0.71480887]
[30.8  30.8   0.75]
[-1.4727092   0.72511415  0.75738295]
[30.8  30.8   0.75]
[-1.52039707  0.79078221  0.78853131]
[30.8  30.8   0.75]
[-1.56461359  0.84353797  0.81441821]
[30.8  30.8   0.75]
[-1.58761324  0.89720043  0.81557989]
[30.8  30.8   0.75]
[-1.59798952  0.94638914  0.79265006]
[30.8  30.8   0.75]
[-1.62555508  0.98326897  0.75806136]
[30.8  30.8   0.75]
[-1.64611048  1.01261009  0.70072086]
[30.8  30.8   0.75]
[-1.66875392  1.02407446  0.63472246]
[30.8  30.8   0.75]
[-1.68573522  0.95517277  0.62134205]
[30.8  30.8   0.75]
[-1.69650148  0.8763558   0.60325919]
[30.8  30.8   0.75]
[-1.69959771  0.85776788  0.59961495]
[30.8  30.8   0.75]
[-1.70110466  0.865324    0.59265217]
[30.8  30.8   0.75]
[-1.70833227  0.87623578  0.56741667]
[30.8  30.8   0.75]
[-1.75542336  0.91060108  0.59731154]
[30.8  30.8   0.75]
[-1.81613395  0.93753544  0.65036281]
[30.8  30.8   0.75]
[-1.87018304  0.94600488  0.67568045]
[30.8  30.8   0.75]
[-1.90622356  0.95482283  0.68117336]
[30.8  30.8   0.75]
[-1.92896641  0.98222443  0.65896469]
[30.8  30.8   0.75]
[-1.97105239  1.00626321  0.61779415]
[30.8  30.8   0.75]
[-2.01774131  1.00717679  0.56003177]
[30.8  30.8   0.75]
[-2.04451925  0.98784475  0.62608498]
[30.8  30.8   0.75]
[-2.06675568  0.97851205  0.68876467]
[30.8  30.8   0.75]
[-2.10722207  0.99034157  0.72910936]
[30.8  30.8   0.75]
[-2.15756618  1.00668607  0.75634999]
[30.8  30.8   0.75]
[-2.21329509  1.02118041  0.76862181]
[30.8  30.8   0.75]
[-2.28120495  1.03542033  0.75996017]
[30.8  30.8   0.75]
[-2.36382357  1.04888632  0.7302206 ]
[30.8  30.8   0.75]
[-2.41681397  1.05355252  0.66909947]
[30.8  30.8   0.75]
[-2.46288309  1.05544255  0.58749501]
[30.8  30.8   0.75]
[-2.4880593   1.01354055  0.54684853]
[30.8  30.8   0.75]
[-2.49633683  0.91425243  0.60843799]
[30.8  30.8   0.75]
[-2.53545307  0.82670032  0.6626414 ]
[30.8  30.8   0.75]
[-2.58576244  0.72701482  0.68913803]
[30.8  30.8   0.75]
[-2.65351204  0.64650083  0.68999767]
[30.8  30.8   0.75]
[-2.71611816  0.5855951   0.68208637]
[30.8  30.8   0.75]
[-2.78979625  0.56918803  0.76814535]
[30.8  30.8   0.75]
[-2.87750999  0.56882629  0.91187101]
[30.8  30.8   0.75]
[-2.974951    0.56453798  1.02382278]
[30.8  30.8   0.75]
----------------------------------
| forward_vel        | 1.15      |
| reward             | 0.928     |
| reward_contact     | -0.000363 |
| reward_ctrl        | -1.22     |
| reward_position    | 3.54e-06  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 105       |
|    ep_rew_mean     | 51.8      |
| time/              |           |
|    episodes        | 8         |
|    fps             | 58        |
|    time_elapsed    | 14        |
|    total timesteps | 840       |
----------------------------------
[ 0.07135587 -0.04629164  0.81881912]
[37.8  37.8   0.75]
[ 0.05882383 -0.04777128  0.79664048]
[37.8  37.8   0.75]
[ 0.06883803 -0.0396722   0.72896366]
[37.8  37.8   0.75]
[ 0.09064419 -0.01076043  0.64979636]
[37.8  37.8   0.75]
[0.14576514 0.03201988 0.57815597]
[37.8  37.8   0.75]
[0.20081875 0.06464463 0.50906245]
[37.8  37.8   0.75]
[0.24488245 0.06157814 0.55354752]
[37.8  37.8   0.75]
[0.30243574 0.05428853 0.58997747]
[37.8  37.8   0.75]
[0.35903664 0.06449612 0.60141635]
[37.8  37.8   0.75]
[0.38540613 0.07747948 0.58922243]
[37.8  37.8   0.75]
[0.40389723 0.0959211  0.55596317]
[37.8  37.8   0.75]
[0.4206907  0.09831958 0.55189938]
[37.8  37.8   0.75]
[0.44167303 0.08325147 0.67143181]
[37.8  37.8   0.75]
[0.47193168 0.06433246 0.76641825]
[37.8  37.8   0.75]
[0.51237997 0.04424884 0.83947433]
[37.8  37.8   0.75]
[0.54827838 0.0256025  0.88401179]
[37.8  37.8   0.75]
[ 5.81021853e-01 -1.42774637e-05  9.01114565e-01]
[37.8  37.8   0.75]
[ 0.60528116 -0.01348679  0.88253753]
[37.8  37.8   0.75]
[ 0.62180155 -0.02308593  0.84048118]
[37.8  37.8   0.75]
[ 0.63029983 -0.04640224  0.77968752]
[37.8  37.8   0.75]
[ 0.66223279 -0.06793599  0.70976899]
[37.8  37.8   0.75]
[ 0.72230264 -0.07191166  0.64694975]
[37.8  37.8   0.75]
[ 0.79671382 -0.06500136  0.62334737]
[37.8  37.8   0.75]
[ 0.88748504 -0.0249163   0.66671219]
[37.8  37.8   0.75]
[0.97490344 0.02553199 0.69135861]
[37.8  37.8   0.75]
[1.04961105 0.07138391 0.68908076]
[37.8  37.8   0.75]
[1.13338732 0.10884645 0.6657071 ]
[37.8  37.8   0.75]
[1.21585034 0.13548185 0.66621222]
[37.8  37.8   0.75]
[1.28762969 0.14298307 0.66656014]
[37.8  37.8   0.75]
[1.35265743 0.16787221 0.65826777]
[37.8  37.8   0.75]
[1.41019339 0.19077833 0.62594253]
[37.8  37.8   0.75]
[1.46031048 0.18985311 0.58411778]
[37.8  37.8   0.75]
[1.50791647 0.18588842 0.54481601]
[37.8  37.8   0.75]
[1.52432567 0.20077924 0.5200003 ]
[37.8  37.8   0.75]
[1.52679009 0.19718687 0.51553101]
[37.8  37.8   0.75]
[1.52961305 0.20291375 0.57095271]
[37.8  37.8   0.75]
[1.52021639 0.21540211 0.61071855]
[37.8  37.8   0.75]
[1.5101031  0.23793447 0.62642322]
[37.8  37.8   0.75]
[1.50614509 0.26256118 0.61664408]
[37.8  37.8   0.75]
[1.50374768 0.27660317 0.6000353 ]
[37.8  37.8   0.75]
[1.50003382 0.26966053 0.66226587]
[37.8  37.8   0.75]
[1.50306604 0.26404456 0.7096311 ]
[37.8  37.8   0.75]
[1.52165304 0.25035436 0.73811416]
[37.8  37.8   0.75]
[1.54054872 0.22334026 0.74758129]
[37.8  37.8   0.75]
[1.54370491 0.20941539 0.75450336]
[37.8  37.8   0.75]
[1.54951809 0.20071319 0.74083673]
[37.8  37.8   0.75]
[1.54755092 0.18924597 0.71758806]
[37.8  37.8   0.75]
[1.52970261 0.17207647 0.66462595]
[37.8  37.8   0.75]
[1.52388147 0.13141333 0.61049317]
[37.8  37.8   0.75]
[1.57418752 0.0776487  0.58146564]
[37.8  37.8   0.75]
[1.67758132 0.02797343 0.5605609 ]
[37.8  37.8   0.75]
[ 1.76287871 -0.00711843  0.5264498 ]
[37.8  37.8   0.75]
[ 1.8268932  -0.01110252  0.57847385]
[37.8  37.8   0.75]
[ 1.87899426 -0.00843864  0.65341933]
[37.8  37.8   0.75]
[ 1.92260473 -0.00547537  0.69452021]
[37.8  37.8   0.75]
[ 1.9722823 -0.0064712  0.7069458]
[37.8  37.8   0.75]
[ 2.02091692 -0.01829514  0.69686289]
[37.8  37.8   0.75]
[ 2.06125141 -0.04691061  0.67854469]
[37.8  37.8   0.75]
[ 2.10499564 -0.07892367  0.65738924]
[37.8  37.8   0.75]
[ 2.15129401 -0.09812999  0.6261163 ]
[37.8  37.8   0.75]
[ 2.19596954 -0.12183674  0.63900017]
[37.8  37.8   0.75]
[ 2.24711354 -0.14122418  0.63517727]
[37.8  37.8   0.75]
[ 2.30433086 -0.15043603  0.60439317]
[37.8  37.8   0.75]
[ 2.33412079 -0.16446398  0.5603765 ]
[37.8  37.8   0.75]
[ 2.31768995 -0.16111055  0.54798758]
[37.8  37.8   0.75]
[ 2.29661658 -0.14784531  0.63599719]
[37.8  37.8   0.75]
[ 2.28028059 -0.14203557  0.70273352]
[37.8  37.8   0.75]
[ 2.26756437 -0.13652523  0.74582075]
[37.8  37.8   0.75]
[ 2.24563957 -0.13174424  0.7645402 ]
[37.8  37.8   0.75]
[ 2.21963422 -0.12581534  0.74996307]
[37.8  37.8   0.75]
[ 2.2138679  -0.10145242  0.72420427]
[37.8  37.8   0.75]
[ 2.24998818 -0.05227975  0.76108321]
[37.8  37.8   0.75]
[2.28853932 0.01351423 0.87665083]
[37.8  37.8   0.75]
[2.32994279 0.0763667  0.96169013]
[37.8  37.8   0.75]
[2.36635972 0.12142827 1.01741326]
[37.8  37.8   0.75]
[ 0.02667627 -0.0899498   0.67431021]
[22.5  22.5   0.75]
[ 0.02574284 -0.09342951  0.68108068]
[22.5  22.5   0.75]
[ 0.00723472 -0.09310677  0.68909913]
[22.5  22.5   0.75]
[-0.04157628 -0.11621052  0.72684996]
[22.5  22.5   0.75]
[-0.09533894 -0.15912011  0.74578145]
[22.5  22.5   0.75]
[-0.1569925  -0.20869288  0.73926188]
[22.5  22.5   0.75]
[-0.20708688 -0.25984268  0.71369859]
[22.5  22.5   0.75]
[-0.24053624 -0.31149203  0.65783482]
[22.5  22.5   0.75]
[-0.30299416 -0.34746156  0.57679885]
[22.5  22.5   0.75]
[-0.39414009 -0.36494072  0.49922248]
[22.5  22.5   0.75]
[-0.55951323 -0.37324952  0.49331803]
[22.5  22.5   0.75]
[-0.70073007 -0.39079332  0.52684859]
[22.5  22.5   0.75]
[-0.81871925 -0.39964402  0.76578791]
[22.5  22.5   0.75]
[-0.9333436  -0.40453108  0.97816695]
[22.5  22.5   0.75]
[-1.06008225 -0.41919507  1.16605724]
[22.5  22.5   0.75]
[-0.02995713  0.00747946  0.82059042]
[9.7  9.7  0.75]
[-0.03640133  0.00097709  0.81884325]
[9.7  9.7  0.75]
[-0.02989218 -0.00187838  0.77164371]
[9.7  9.7  0.75]
[-0.01408813 -0.01956542  0.72622726]
[9.7  9.7  0.75]
[ 0.01342512 -0.07411347  0.71932368]
[9.7  9.7  0.75]
[ 0.04914785 -0.13165274  0.70193569]
[9.7  9.7  0.75]
[ 0.08636118 -0.18192689  0.66292577]
[9.7  9.7  0.75]
[ 0.11377245 -0.23242166  0.60518643]
[9.7  9.7  0.75]
[ 0.13201749 -0.31089069  0.52073362]
[9.7  9.7  0.75]
[ 0.13910091 -0.39094496  0.5032393 ]
[9.7  9.7  0.75]
[ 0.13871389 -0.46593959  0.57067806]
[9.7  9.7  0.75]
[ 0.1474972  -0.51481078  0.62934744]
[9.7  9.7  0.75]
[ 0.16528741 -0.54696919  0.65818701]
[9.7  9.7  0.75]
[ 0.16036838 -0.5750227   0.65274267]
[9.7  9.7  0.75]
[ 0.15060664 -0.61429511  0.62987053]
[9.7  9.7  0.75]
[ 0.12717796 -0.67250372  0.57901237]
[9.7  9.7  0.75]
[ 0.08288833 -0.7413376   0.5377465 ]
[9.7  9.7  0.75]
[ 0.04709794 -0.80317326  0.52689736]
[9.7  9.7  0.75]
[ 0.03803145 -0.85927035  0.54039783]
[9.7  9.7  0.75]
[ 0.05006422 -0.90337158  0.55134706]
[9.7  9.7  0.75]
[ 0.10513882 -0.92315931  0.60320112]
[9.7  9.7  0.75]
[ 0.15607514 -0.92893973  0.63814387]
[9.7  9.7  0.75]
[ 0.20473551 -0.93582045  0.64796707]
[9.7  9.7  0.75]
[ 0.25012277 -0.97144406  0.63286839]
[9.7  9.7  0.75]
[ 0.29699379 -1.00625866  0.61186791]
[9.7  9.7  0.75]
[ 0.3156585  -1.03243954  0.60382289]
[9.7  9.7  0.75]
[ 0.3070711  -1.05488447  0.68307064]
[9.7  9.7  0.75]
[ 0.29012565 -1.06024725  0.7384372 ]
[9.7  9.7  0.75]
[ 0.25673866 -1.06299117  0.76996457]
[9.7  9.7  0.75]
[ 0.21882834 -1.06175128  0.77946903]
[9.7  9.7  0.75]
[ 0.19560455 -1.08389128  0.76272701]
[9.7  9.7  0.75]
[ 0.18655647 -1.11301313  0.72143738]
[9.7  9.7  0.75]
[ 0.19884133 -1.12360722  0.68370027]
[9.7  9.7  0.75]
[ 0.21499549 -1.11513925  0.6320232 ]
[9.7  9.7  0.75]
[ 0.22484884 -1.11019882  0.5606363 ]
[9.7  9.7  0.75]
[ 0.20166276 -1.10446917  0.57706334]
[9.7  9.7  0.75]
[ 0.18032554 -1.0918715   0.6044076 ]
[9.7  9.7  0.75]
[ 0.16001907 -1.08143031  0.61555245]
[9.7  9.7  0.75]
[ 0.12824614 -1.09309041  0.64595418]
[9.7  9.7  0.75]
[ 0.07718404 -1.11871862  0.65643883]
[9.7  9.7  0.75]
[ 0.03117047 -1.13824547  0.64467365]
[9.7  9.7  0.75]
[-0.00451728 -1.15003567  0.61807539]
[9.7  9.7  0.75]
[-0.01932852 -1.158899    0.5676664 ]
[9.7  9.7  0.75]
[-0.00736918 -1.15746264  0.50463317]
[9.7  9.7  0.75]
[ 0.05175507 -1.1629433   0.53623361]
[9.7  9.7  0.75]
[ 0.17733902 -1.1995618   0.67983861]
[9.7  9.7  0.75]
[ 0.290817   -1.24492645  0.79031684]
[9.7  9.7  0.75]
[ 0.39612894 -1.2990841   0.87768017]
[9.7  9.7  0.75]
[ 0.50348693 -1.34582927  0.93877413]
[9.7  9.7  0.75]
[ 0.61929928 -1.39203259  0.97806274]
[9.7  9.7  0.75]
[ 0.73301504 -1.44790578  1.0053328 ]
[9.7  9.7  0.75]
[ 0.05998126 -0.08560769  0.74933664]
[29.6  29.6   0.75]
[ 0.07029018 -0.0693634   0.74790271]
[29.6  29.6   0.75]
[ 0.07818602 -0.06592281  0.69967416]
[29.6  29.6   0.75]
[ 0.08524351 -0.07907188  0.63664769]
[29.6  29.6   0.75]
[ 0.05429384 -0.1659738   0.65468342]
[29.6  29.6   0.75]
[ 0.01087012 -0.26026084  0.65727335]
[29.6  29.6   0.75]
[-0.01385101 -0.33921667  0.6572738 ]
[29.6  29.6   0.75]
[-0.01137067 -0.40211224  0.64681734]
[29.6  29.6   0.75]
[ 1.56746514e-05 -4.63966834e-01  6.29423597e-01]
[29.6  29.6   0.75]
[ 0.01515028 -0.52295593  0.59098425]
[29.6  29.6   0.75]
[ 0.04043969 -0.57827104  0.53358525]
[29.6  29.6   0.75]
[ 0.08801434 -0.59290864  0.58125866]
[29.6  29.6   0.75]
[ 0.12743285 -0.5959782   0.64858771]
[29.6  29.6   0.75]
[ 0.1589721  -0.59262831  0.68370241]
[29.6  29.6   0.75]
[ 0.19568992 -0.59637152  0.69666555]
[29.6  29.6   0.75]
[ 0.23000172 -0.60465724  0.68934547]
[29.6  29.6   0.75]
[ 0.26693659 -0.63820286  0.66981201]
[29.6  29.6   0.75]
[ 0.29516157 -0.66906002  0.63458483]
[29.6  29.6   0.75]
[ 0.28103956 -0.7200047   0.62754816]
[29.6  29.6   0.75]
[ 0.26203831 -0.77578708  0.60022149]
[29.6  29.6   0.75]
[ 0.24604195 -0.82493163  0.55612752]
[29.6  29.6   0.75]
[ 0.2604974  -0.84271661  0.54272222]
[29.6  29.6   0.75]
[ 0.28195075 -0.84768975  0.51864609]
[29.6  29.6   0.75]
[ 0.31004185 -0.8514486   0.54444508]
[29.6  29.6   0.75]
[ 0.32472696 -0.87071659  0.5670953 ]
[29.6  29.6   0.75]
[ 0.30345739 -0.87186016  0.61122253]
[29.6  29.6   0.75]
[ 0.27620479 -0.85596012  0.65915771]
[29.6  29.6   0.75]
[ 0.24479559 -0.84206571  0.68927279]
[29.6  29.6   0.75]
[ 0.20822358 -0.83076157  0.69317998]
[29.6  29.6   0.75]
[ 0.18049057 -0.82889203  0.67805912]
[29.6  29.6   0.75]
[ 0.11861987 -0.82479577  0.68989906]
[29.6  29.6   0.75]
[ 0.04765769 -0.83452657  0.7251853 ]
[29.6  29.6   0.75]
[-0.01470481 -0.84127258  0.74698435]
[29.6  29.6   0.75]
[-0.07200889 -0.84921186  0.76278434]
[29.6  29.6   0.75]
[-0.13712029 -0.86447549  0.75275666]
[29.6  29.6   0.75]
[-0.20678842 -0.88161521  0.71972746]
[29.6  29.6   0.75]
[-0.27269484 -0.89928004  0.655208  ]
[29.6  29.6   0.75]
[-0.33534782 -0.92523252  0.57386999]
[29.6  29.6   0.75]
[-0.38373081 -0.94197639  0.60743955]
[29.6  29.6   0.75]
[-0.41882839 -0.95290309  0.65535312]
[29.6  29.6   0.75]
[-0.44735123 -0.96845328  0.68220787]
[29.6  29.6   0.75]
[-0.50028262 -0.97554221  0.68200478]
[29.6  29.6   0.75]
[-0.56616193 -0.97668884  0.65947415]
[29.6  29.6   0.75]
[-0.63815226 -0.96914456  0.62144888]
[29.6  29.6   0.75]
[-0.68382326 -0.98352271  0.603796  ]
[29.6  29.6   0.75]
[-0.71949184 -1.01199832  0.60766515]
[29.6  29.6   0.75]
[-0.76910291 -1.04867783  0.64347129]
[29.6  29.6   0.75]
[-0.81368011 -1.09203873  0.66418044]
[29.6  29.6   0.75]
[-0.83521317 -1.13416127  0.68278249]
[29.6  29.6   0.75]
[-0.8489582  -1.16245764  0.70488499]
[29.6  29.6   0.75]
[-0.85274142 -1.16989639  0.71752601]
[29.6  29.6   0.75]
[-0.84389365 -1.17892752  0.71160182]
[29.6  29.6   0.75]
[-0.81474041 -1.1931677   0.71565947]
[29.6  29.6   0.75]
[-0.81220175 -1.21645     0.7163157 ]
[29.6  29.6   0.75]
[-0.81971206 -1.25280071  0.6998571 ]
[29.6  29.6   0.75]
[-0.80890516 -1.28692084  0.67676468]
[29.6  29.6   0.75]
[-0.81773434 -1.31751304  0.6983209 ]
[29.6  29.6   0.75]
[-0.8380833  -1.36205049  0.71628189]
[29.6  29.6   0.75]
[-0.87921331 -1.4251942   0.72442931]
[29.6  29.6   0.75]
[-0.9139505  -1.4759151   0.70181772]
[29.6  29.6   0.75]
[-0.94474143 -1.5276163   0.66423896]
[29.6  29.6   0.75]
[-0.9791288  -1.56585157  0.62703036]
[29.6  29.6   0.75]
[-1.00367587 -1.62397191  0.64137801]
[29.6  29.6   0.75]
[-1.02302261 -1.70135825  0.64955816]
[29.6  29.6   0.75]
[-1.04527816 -1.78410086  0.64327113]
[29.6  29.6   0.75]
[-1.0597637  -1.85649622  0.64115472]
[29.6  29.6   0.75]
[-1.06726863 -1.91483754  0.62451416]
[29.6  29.6   0.75]
[-1.07571998 -1.95424369  0.60970269]
[29.6  29.6   0.75]
[-1.06961531 -1.99118163  0.5858211 ]
[29.6  29.6   0.75]
[-1.03371191 -2.02230955  0.57106457]
[29.6  29.6   0.75]
[-1.02296983 -2.05858526  0.57073429]
[29.6  29.6   0.75]
[-1.02963897 -2.09925301  0.57098606]
[29.6  29.6   0.75]
[-1.01536149 -2.13895013  0.59082756]
[29.6  29.6   0.75]
[-0.99072437 -2.1634734   0.59558539]
[29.6  29.6   0.75]
[-0.96760146 -2.19261392  0.60473911]
[29.6  29.6   0.75]
[-0.95591244 -2.21595423  0.63824559]
[29.6  29.6   0.75]
[-0.95122085 -2.22484187  0.64398953]
[29.6  29.6   0.75]
[-0.94504413 -2.22235939  0.61864499]
[29.6  29.6   0.75]
[-0.92220353 -2.21042234  0.5712455 ]
[29.6  29.6   0.75]
[-0.89694261 -2.22236176  0.53299669]
[29.6  29.6   0.75]
[-0.88310468 -2.26037732  0.49234139]
[29.6  29.6   0.75]
[-0.86736924 -2.30435273  0.43703913]
[29.6  29.6   0.75]
[-0.86205785 -2.33532002  0.40930092]
[29.6  29.6   0.75]
[-0.87953816 -2.32082228  0.55240327]
[29.6  29.6   0.75]
[-0.89063568 -2.29790922  0.67322844]
[29.6  29.6   0.75]
[-0.91077348 -2.29315316  0.77156769]
[29.6  29.6   0.75]
[-0.92832067 -2.28825363  0.84049208]
[29.6  29.6   0.75]
[-0.93959489 -2.28392772  0.87500769]
[29.6  29.6   0.75]
[-0.94541464 -2.28289158  0.8801586 ]
[29.6  29.6   0.75]
[-0.95984694 -2.28038052  0.87153062]
[29.6  29.6   0.75]
[-0.97420267 -2.28227296  0.84165033]
[29.6  29.6   0.75]
[-0.98884654 -2.29480366  0.8102921 ]
[29.6  29.6   0.75]
[-0.95041397 -2.32847317  0.88126739]
[29.6  29.6   0.75]
[-0.89865088 -2.3572474   1.06762703]
[29.6  29.6   0.75]
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 89.6     |
|    ep_rew_mean     | 46.2     |
| time/              |          |
|    episodes        | 12       |
|    fps             | 60       |
|    time_elapsed    | 17       |
|    total timesteps | 1075     |
---------------------------------
[-0.04526492  0.06158656  0.77640757]
[28.9  28.9   0.75]
[-0.05862078  0.04014522  0.77688667]
[28.9  28.9   0.75]
[-0.06082385  0.04149621  0.73567574]
[28.9  28.9   0.75]
[-0.04049665  0.02446761  0.69101777]
[28.9  28.9   0.75]
[0.02247666 0.02334807 0.67320567]
[28.9  28.9   0.75]
[0.08306922 0.03205736 0.63701524]
[28.9  28.9   0.75]
[0.14552542 0.0372155  0.58962332]
[28.9  28.9   0.75]
[0.18426479 0.03676194 0.53915784]
[28.9  28.9   0.75]
[0.1999929  0.03044368 0.59752566]
[28.9  28.9   0.75]
[0.21071292 0.02268328 0.66596343]
[28.9  28.9   0.75]
[0.21606273 0.01745113 0.71708889]
[28.9  28.9   0.75]
[0.22697066 0.02354697 0.73205947]
[28.9  28.9   0.75]
[0.23739378 0.0149401  0.71958263]
[28.9  28.9   0.75]
[ 0.25471451 -0.01085865  0.69073685]
[28.9  28.9   0.75]
[ 0.27361704 -0.07903645  0.76845458]
[28.9  28.9   0.75]
[ 0.28574342 -0.15393266  0.90215788]
[28.9  28.9   0.75]
[ 0.28686973 -0.21276116  1.00201622]
[28.9  28.9   0.75]
[-0.08289365  0.0764206   0.77053879]
[17.1  17.1   0.75]
[-0.08110648  0.05783008  0.7670569 ]
[17.1  17.1   0.75]
[-0.07951783  0.05394253  0.72356987]
[17.1  17.1   0.75]
[-0.10986502  0.08718222  0.69318581]
[17.1  17.1   0.75]
[-0.16234941  0.13460552  0.64295048]
[17.1  17.1   0.75]
[-0.22244917  0.1766936   0.55846591]
[17.1  17.1   0.75]
[-0.26268712  0.22325185  0.47622241]
[17.1  17.1   0.75]
[-0.29297093  0.22965023  0.43621738]
[17.1  17.1   0.75]
[-0.31756334  0.20744844  0.47863948]
[17.1  17.1   0.75]
[-0.34077426  0.18820912  0.55312073]
[17.1  17.1   0.75]
[-0.36727184  0.17054692  0.63240977]
[17.1  17.1   0.75]
[-0.39999245  0.14909192  0.68387134]
[17.1  17.1   0.75]
[-0.41946349  0.1231345   0.70197501]
[17.1  17.1   0.75]
[-0.42577802  0.10075012  0.70022005]
[17.1  17.1   0.75]
[-0.44814621  0.08493044  0.68066611]
[17.1  17.1   0.75]
[-0.47436327  0.07955169  0.64683581]
[17.1  17.1   0.75]
[-0.50715149  0.08581014  0.60061263]
[17.1  17.1   0.75]
[-0.51589784  0.13932326  0.60468291]
[17.1  17.1   0.75]
[-0.50676128  0.21155881  0.61261263]
[17.1  17.1   0.75]
[-0.48154227  0.28873002  0.59662124]
[17.1  17.1   0.75]
[-0.45765033  0.35958827  0.56024197]
[17.1  17.1   0.75]
[-0.4365608   0.39518711  0.50405336]
[17.1  17.1   0.75]
[-0.34891379  0.37299875  0.55560155]
[17.1  17.1   0.75]
[-0.21022013  0.30941887  0.67711195]
[17.1  17.1   0.75]
[-0.10428129  0.25691546  0.76685169]
[17.1  17.1   0.75]
[-0.00615875  0.21263271  0.84462142]
[17.1  17.1   0.75]
[0.08321329 0.17049394 0.90342634]
[17.1  17.1   0.75]
[0.19167638 0.12661153 0.93397971]
[17.1  17.1   0.75]
[0.31090731 0.08133342 0.93641085]
[17.1  17.1   0.75]
[0.43594633 0.04055473 0.91457485]
[17.1  17.1   0.75]
[ 0.56501229 -0.0045512   0.87459872]
[17.1  17.1   0.75]
[ 0.68963759 -0.04237137  0.81714312]
[17.1  17.1   0.75]
[ 0.80464326 -0.05361099  0.77780451]
[17.1  17.1   0.75]
[ 0.90756625 -0.07059437  0.72437244]
[17.1  17.1   0.75]
[ 1.01135235 -0.08311931  0.6584138 ]
[17.1  17.1   0.75]
[ 1.09648275 -0.08437981  0.61087503]
[17.1  17.1   0.75]
[ 1.09870523 -0.0738578   0.65442013]
[17.1  17.1   0.75]
[ 1.09713799 -0.06820092  0.68598138]
[17.1  17.1   0.75]
[ 1.09384041 -0.04902646  0.688375  ]
[17.1  17.1   0.75]
[ 1.09512469 -0.02386936  0.67323664]
[17.1  17.1   0.75]
[1.10094385e+00 2.89172390e-04 6.35805307e-01]
[17.1  17.1   0.75]
[1.13235862 0.0113003  0.59553648]
[17.1  17.1   0.75]
[ 1.17116619 -0.00721601  0.61244558]
[17.1  17.1   0.75]
[ 1.20082634 -0.01810616  0.63598891]
[17.1  17.1   0.75]
[ 1.20782249 -0.02624862  0.63768608]
[17.1  17.1   0.75]
[ 1.2102821  -0.03234858  0.6130069 ]
[17.1  17.1   0.75]
[ 1.21903241 -0.04473811  0.58744979]
[17.1  17.1   0.75]
[ 1.22463871 -0.04174884  0.56796251]
[17.1  17.1   0.75]
[ 1.22908979 -0.04386653  0.52726208]
[17.1  17.1   0.75]
[ 1.26135954 -0.07544415  0.55914926]
[17.1  17.1   0.75]
[ 1.32106258 -0.12118755  0.65797647]
[17.1  17.1   0.75]
[ 1.4023136  -0.15138621  0.72562568]
[17.1  17.1   0.75]
[ 1.49449095 -0.17706406  0.76881737]
[17.1  17.1   0.75]
[ 1.57240303 -0.19765264  0.78544045]
[17.1  17.1   0.75]
[ 1.62697734 -0.21672636  0.78503975]
[17.1  17.1   0.75]
[ 1.64816865 -0.24405382  0.79098129]
[17.1  17.1   0.75]
[ 1.68227088 -0.28163799  0.76602639]
[17.1  17.1   0.75]
[ 1.72990226 -0.30846446  0.71664093]
[17.1  17.1   0.75]
[ 1.76702758 -0.32242746  0.66238128]
[17.1  17.1   0.75]
[ 1.77864342 -0.33854741  0.62192556]
[17.1  17.1   0.75]
[ 1.77086555 -0.3754661   0.57541675]
[17.1  17.1   0.75]
[ 1.77840134 -0.41266058  0.52210146]
[17.1  17.1   0.75]
[ 1.81160651 -0.40840064  0.55127162]
[17.1  17.1   0.75]
[ 1.86157737 -0.41197142  0.60586712]
[17.1  17.1   0.75]
[ 1.87220313 -0.44225158  0.6814741 ]
[17.1  17.1   0.75]
[ 1.86848236 -0.46668669  0.74551229]
[17.1  17.1   0.75]
[ 1.85600909 -0.48727988  0.78466556]
[17.1  17.1   0.75]
[ 1.84263337 -0.50378273  0.79919438]
[17.1  17.1   0.75]
[ 1.82439981 -0.50083483  0.78269404]
[17.1  17.1   0.75]
[ 1.80984244 -0.50854095  0.75636456]
[17.1  17.1   0.75]
[ 1.83127631 -0.54190032  0.75154201]
[17.1  17.1   0.75]
[ 1.85027581 -0.56497804  0.73096028]
[17.1  17.1   0.75]
[ 1.83643641 -0.56454443  0.75217929]
[17.1  17.1   0.75]
[ 1.82044058 -0.5595842   0.74089702]
[17.1  17.1   0.75]
[ 1.80160037 -0.55482232  0.69734217]
[17.1  17.1   0.75]
[ 1.80578402 -0.56804188  0.66385442]
[17.1  17.1   0.75]
[ 1.82810402 -0.58446298  0.63605421]
[17.1  17.1   0.75]
[ 1.84705264 -0.59276907  0.63881583]
[17.1  17.1   0.75]
[ 1.85347249 -0.58803654  0.64112242]
[17.1  17.1   0.75]
[ 1.86240098 -0.58097164  0.60793772]
[17.1  17.1   0.75]
[ 1.87061587 -0.57283224  0.56184938]
[17.1  17.1   0.75]
[ 1.88738675 -0.55106268  0.58809921]
[17.1  17.1   0.75]
[ 1.89269938 -0.52425547  0.60862275]
[17.1  17.1   0.75]
[ 1.89415309 -0.49764565  0.61343969]
[17.1  17.1   0.75]
[ 1.89010011 -0.47387376  0.59833333]
[17.1  17.1   0.75]
[ 1.88242486 -0.45209581  0.56448534]
[17.1  17.1   0.75]
[ 1.87714903 -0.42284286  0.53317854]
[17.1  17.1   0.75]
[ 1.87227059 -0.388562    0.4929402 ]
[17.1  17.1   0.75]
[ 1.87848105 -0.34634895  0.45712836]
[17.1  17.1   0.75]
[ 1.87243352 -0.29614324  0.4141516 ]
[17.1  17.1   0.75]
[ 1.85379907 -0.25428692  0.34823232]
[17.1  17.1   0.75]
[ 1.85881362 -0.22107861  0.33676829]
[17.1  17.1   0.75]
[ 1.86494001 -0.17470387  0.32829334]
[17.1  17.1   0.75]
[ 1.87715756 -0.1150214   0.29541997]
[17.1  17.1   0.75]
[ 1.89689341 -0.06381068  0.25008365]
[17.1  17.1   0.75]
[ 1.91989767 -0.01984176  0.25725426]
[17.1  17.1   0.75]
[1.93283329 0.0176065  0.26116594]
[17.1  17.1   0.75]
[1.93210645 0.0642338  0.26000854]
[17.1  17.1   0.75]
[1.93030171 0.10951291 0.25937089]
[17.1  17.1   0.75]
[1.90866702 0.15356058 0.28762067]
[17.1  17.1   0.75]
[1.88254059 0.19478688 0.32031996]
[17.1  17.1   0.75]
[1.87657636 0.23648653 0.33372486]
[17.1  17.1   0.75]
[1.890601   0.29177038 0.31961927]
[17.1  17.1   0.75]
[1.89922505 0.33720189 0.28265886]
[17.1  17.1   0.75]
[1.88476892 0.36775466 0.25313737]
[17.1  17.1   0.75]
[1.84433891 0.36819062 0.27536156]
[17.1  17.1   0.75]
[1.79315381 0.34020158 0.29327482]
[17.1  17.1   0.75]
[1.75485893 0.32155105 0.27762746]
[17.1  17.1   0.75]
[1.74056616 0.28920439 0.2795148 ]
[17.1  17.1   0.75]
[1.72228269 0.25276216 0.27134951]
[17.1  17.1   0.75]
[1.70633066 0.23412701 0.25436729]
[17.1  17.1   0.75]
[1.68846058 0.21937162 0.25894897]
[17.1  17.1   0.75]
[1.67470881 0.2067547  0.25960902]
[17.1  17.1   0.75]
[1.66317781 0.18757388 0.25966534]
[17.1  17.1   0.75]
[1.65045621 0.16616412 0.2596348 ]
[17.1  17.1   0.75]
[1.63192356 0.14984284 0.25965086]
[17.1  17.1   0.75]
[1.61426952 0.13556303 0.25975709]
[17.1  17.1   0.75]
[1.61503129 0.12568818 0.25967153]
[17.1  17.1   0.75]
[1.61902671 0.11495178 0.25959435]
[17.1  17.1   0.75]
[1.61195878 0.09937876 0.25958171]
[17.1  17.1   0.75]
[1.59710423 0.07408927 0.2619036 ]
[17.1  17.1   0.75]
[1.58760613 0.06377648 0.28571149]
[17.1  17.1   0.75]
[1.57235662 0.04848098 0.29340646]
[17.1  17.1   0.75]
[1.55761847 0.04917361 0.29529857]
[17.1  17.1   0.75]
[1.55871274 0.08157631 0.30985053]
[17.1  17.1   0.75]
[1.58841386 0.10708022 0.32028711]
[17.1  17.1   0.75]
[1.63975979 0.11329945 0.33299549]
[17.1  17.1   0.75]
[1.68128061 0.10292183 0.32623064]
[17.1  17.1   0.75]
[1.72390402 0.09613073 0.31073241]
[17.1  17.1   0.75]
[1.77211897 0.09312711 0.27727151]
[17.1  17.1   0.75]
[1.80440132 0.1022311  0.25385669]
[17.1  17.1   0.75]
[1.83325177 0.12494498 0.25844509]
[17.1  17.1   0.75]
[1.87110159 0.15259745 0.25979825]
[17.1  17.1   0.75]
[1.91994934 0.17076656 0.25989705]
[17.1  17.1   0.75]
[1.97752844 0.18715016 0.26305966]
[17.1  17.1   0.75]
[2.0232663  0.17815268 0.27685693]
[17.1  17.1   0.75]
[2.04778148 0.1729039  0.27895709]
[17.1  17.1   0.75]
[2.05139815 0.18111615 0.26907928]
[17.1  17.1   0.75]
[2.05056136 0.20139049 0.25840543]
[17.1  17.1   0.75]
[2.05374949 0.19065695 0.26204742]
[17.1  17.1   0.75]
[2.05563576 0.17371181 0.2611587 ]
[17.1  17.1   0.75]
[2.05001733 0.16643223 0.26695321]
[17.1  17.1   0.75]
[2.02755532 0.15656977 0.26512239]
[17.1  17.1   0.75]
[1.98664108 0.15326955 0.25985993]
[17.1  17.1   0.75]
[1.93695732 0.1494745  0.25891146]
[17.1  17.1   0.75]
[1.90009276 0.14600779 0.26169252]
[17.1  17.1   0.75]
[1.88097617 0.14903514 0.27874102]
[17.1  17.1   0.75]
[1.8617224  0.15585798 0.27658772]
[17.1  17.1   0.75]
[1.84904691 0.16490794 0.25830474]
[17.1  17.1   0.75]
[1.84927966 0.18258762 0.25853774]
[17.1  17.1   0.75]
[1.85944277 0.20920265 0.25970962]
[17.1  17.1   0.75]
[1.87550421 0.24533586 0.25970037]
[17.1  17.1   0.75]
[1.88888027 0.2719613  0.25960832]
[17.1  17.1   0.75]
[1.89664235 0.29212666 0.2599684 ]
[17.1  17.1   0.75]
[1.88318481 0.3011053  0.2694545 ]
[17.1  17.1   0.75]
[1.88345182 0.28654159 0.28644045]
[17.1  17.1   0.75]
[1.89192263 0.26772047 0.28251339]
[17.1  17.1   0.75]
[1.90122074 0.23462271 0.25930585]
[17.1  17.1   0.75]
[1.91642668 0.20291449 0.26406637]
[17.1  17.1   0.75]
[1.93345825 0.16248004 0.25869589]
[17.1  17.1   0.75]
[1.93327823 0.11810528 0.25896703]
[17.1  17.1   0.75]
[1.92329619 0.07869345 0.25968571]
[17.1  17.1   0.75]
[1.90982532 0.05823147 0.25947283]
[17.1  17.1   0.75]
[1.89781458 0.05418024 0.25967511]
[17.1  17.1   0.75]
[1.88852183 0.0549455  0.25965516]
[17.1  17.1   0.75]
[1.88736007 0.05093241 0.26142679]
[17.1  17.1   0.75]
[1.89456022 0.03388017 0.26078614]
[17.1  17.1   0.75]
[1.89649132 0.02132728 0.26023367]
[17.1  17.1   0.75]
[1.90195764 0.01467984 0.26201556]
[17.1  17.1   0.75]
[1.90625618 0.01026592 0.2583705 ]
[17.1  17.1   0.75]
[1.91533996 0.01078232 0.26039241]
[17.1  17.1   0.75]
[1.9302579  0.01223339 0.25907525]
[17.1  17.1   0.75]
[1.94304648 0.0252455  0.25934688]
[17.1  17.1   0.75]
[1.956438   0.03383023 0.25958965]
[17.1  17.1   0.75]
[1.96974439 0.0274835  0.25968095]
[17.1  17.1   0.75]
[1.99623016 0.02241927 0.26386401]
[17.1  17.1   0.75]
[2.04560285 0.04377641 0.28109942]
[17.1  17.1   0.75]
[2.07053579 0.06291337 0.27482392]
[17.1  17.1   0.75]
[2.08559411 0.084134   0.25294674]
[17.1  17.1   0.75]
[2.08365813 0.10310756 0.2581074 ]
[17.1  17.1   0.75]
[2.09279694 0.11626187 0.25956064]
[17.1  17.1   0.75]
[2.1166252  0.12244239 0.25965493]
[17.1  17.1   0.75]
[2.14290813 0.1322827  0.26125457]
[17.1  17.1   0.75]
[2.14354805 0.14272607 0.27235581]
[17.1  17.1   0.75]
[2.14268897 0.15563127 0.26270845]
[17.1  17.1   0.75]
[2.14269439 0.16739074 0.25713609]
[17.1  17.1   0.75]
[2.14533631 0.1794956  0.26159055]
[17.1  17.1   0.75]
[2.14199439 0.20898622 0.25812702]
[17.1  17.1   0.75]
[2.15222178 0.22531938 0.27190551]
[17.1  17.1   0.75]
[2.16325327 0.22237792 0.2680721 ]
[17.1  17.1   0.75]
[2.18450378 0.22003002 0.25665656]
[17.1  17.1   0.75]
[2.19157455 0.21518129 0.25922944]
[17.1  17.1   0.75]
[2.18864377 0.21138766 0.25976586]
[17.1  17.1   0.75]
[2.18318371 0.20852866 0.25967262]
[17.1  17.1   0.75]
[2.17572077 0.21227724 0.26033672]
[17.1  17.1   0.75]
[2.16657026 0.21324855 0.26010889]
[17.1  17.1   0.75]
[2.15136169 0.20351131 0.25947716]
[17.1  17.1   0.75]
[2.13057806 0.206637   0.26117251]
[17.1  17.1   0.75]
[2.11856182 0.20550453 0.25849477]
[17.1  17.1   0.75]
[2.12369979 0.18935098 0.25978251]
[17.1  17.1   0.75]
[2.13593101 0.17473948 0.25975077]
[17.1  17.1   0.75]
[2.15176257 0.16009388 0.2597275 ]
[17.1  17.1   0.75]
[2.17207677 0.14374504 0.26025281]
[17.1  17.1   0.75]
[2.18715013 0.14690773 0.25957329]
[17.1  17.1   0.75]
[2.19984331 0.14625217 0.25971702]
[17.1  17.1   0.75]
[2.2104004  0.15881634 0.25958503]
[17.1  17.1   0.75]
[2.21981397 0.16983565 0.25962818]
[17.1  17.1   0.75]
[2.22588878 0.16911764 0.25965929]
[17.1  17.1   0.75]
[2.22699193 0.16697653 0.26102569]
[17.1  17.1   0.75]
[2.22554615 0.16960831 0.26024189]
[17.1  17.1   0.75]
[2.22392523 0.16205158 0.26000343]
[17.1  17.1   0.75]
[2.22398527 0.15135462 0.25952848]
[17.1  17.1   0.75]
[2.23003314 0.14612758 0.2595896 ]
[17.1  17.1   0.75]
[2.23221633 0.12978765 0.25956916]
[17.1  17.1   0.75]
[2.23612753 0.10812923 0.25999447]
[17.1  17.1   0.75]
[2.2329859  0.09065965 0.26010457]
[17.1  17.1   0.75]
[2.23076513 0.0828238  0.25941307]
[17.1  17.1   0.75]
[2.21856574 0.08191281 0.25971484]
[17.1  17.1   0.75]
[2.20093821 0.09220775 0.25970418]
[17.1  17.1   0.75]
[2.18850002 0.09539486 0.25915966]
[17.1  17.1   0.75]
[2.19691443 0.07747261 0.25944612]
[17.1  17.1   0.75]
[2.20324412 0.05851315 0.2596773 ]
[17.1  17.1   0.75]
[2.20457587 0.03984923 0.25960429]
[17.1  17.1   0.75]
[2.20962542 0.02927165 0.2599379 ]
[17.1  17.1   0.75]
[2.22074161 0.03793774 0.25964764]
[17.1  17.1   0.75]
[2.22112715 0.05023642 0.25986943]
[17.1  17.1   0.75]
[2.2085567  0.04592454 0.25937219]
[17.1  17.1   0.75]
[2.19840496 0.03857629 0.25965587]
[17.1  17.1   0.75]
[2.19281613 0.03064729 0.25968276]
[17.1  17.1   0.75]
[2.19458114 0.01902171 0.25953546]
[17.1  17.1   0.75]
[2.19291114 0.01463822 0.25962228]
[17.1  17.1   0.75]
[2.18144595 0.01323597 0.25973279]
[17.1  17.1   0.75]
[2.16387126 0.00454953 0.25955935]
[17.1  17.1   0.75]
[ 2.14890147 -0.008705    0.25962466]
[17.1  17.1   0.75]
[ 2.13069492 -0.01790041  0.2610745 ]
[17.1  17.1   0.75]
[ 2.10423586 -0.01400601  0.25898508]
[17.1  17.1   0.75]
[ 2.08964772 -0.02223125  0.25950687]
[17.1  17.1   0.75]
[ 2.07657201 -0.01997259  0.27095326]
[17.1  17.1   0.75]
[ 2.05856181e+00 -1.23318469e-03  2.82971225e-01]
[17.1  17.1   0.75]
[2.03908457 0.01216594 0.28042725]
[17.1  17.1   0.75]
[2.02494088 0.02883261 0.27529163]
[17.1  17.1   0.75]
[2.01426502 0.04512743 0.25579004]
[17.1  17.1   0.75]
[2.02363818 0.05516681 0.25855048]
[17.1  17.1   0.75]
[2.04846724 0.06222121 0.25950652]
[17.1  17.1   0.75]
[2.06706187 0.05708924 0.26516938]
[17.1  17.1   0.75]
[2.04574977 0.05744881 0.28261544]
[17.1  17.1   0.75]
[2.02149962 0.07460609 0.28248873]
[17.1  17.1   0.75]
[1.99420218 0.10257753 0.25802354]
[17.1  17.1   0.75]
[1.97427128 0.12206654 0.25740984]
[17.1  17.1   0.75]
[1.95645927 0.1372213  0.25942868]
[17.1  17.1   0.75]
[1.94808162 0.1532857  0.25964806]
[17.1  17.1   0.75]
[1.93921463 0.17221456 0.25967685]
[17.1  17.1   0.75]
[1.92748445 0.19639355 0.26204103]
[17.1  17.1   0.75]
[1.90928053 0.20191974 0.28189406]
[17.1  17.1   0.75]
[1.90254961 0.20515972 0.27350738]
[17.1  17.1   0.75]
[1.89675879 0.20343301 0.25671871]
[17.1  17.1   0.75]
[1.8932111  0.18555452 0.25905596]
[17.1  17.1   0.75]
[1.88599105 0.16121111 0.25962163]
[17.1  17.1   0.75]
[1.87587441 0.14345048 0.25964113]
[17.1  17.1   0.75]
[1.86313532 0.13688771 0.25969271]
[17.1  17.1   0.75]
[1.85069169 0.13175119 0.25969379]
[17.1  17.1   0.75]
[1.8409916  0.13658336 0.25988397]
[17.1  17.1   0.75]
[1.82006362 0.14966436 0.25956245]
[17.1  17.1   0.75]
[1.79569901 0.15734614 0.26015667]
[17.1  17.1   0.75]
[1.78535909 0.15888923 0.26827801]
[17.1  17.1   0.75]
[1.78105858 0.15587917 0.27218689]
[17.1  17.1   0.75]
[1.78608268 0.15637207 0.25428016]
[17.1  17.1   0.75]
[1.80153002 0.14476517 0.25788749]
[17.1  17.1   0.75]
[1.81076628 0.12503739 0.25981653]
[17.1  17.1   0.75]
[1.80602131 0.11768132 0.25971642]
[17.1  17.1   0.75]
[1.80853644 0.11968619 0.25971058]
[17.1  17.1   0.75]
[1.81484508 0.11496402 0.2596775 ]
[17.1  17.1   0.75]
[1.81255876 0.11878285 0.25978638]
[17.1  17.1   0.75]
[1.80504368 0.12138905 0.25967691]
[17.1  17.1   0.75]
[1.79582367 0.12289951 0.25960134]
[17.1  17.1   0.75]
[1.79079324 0.11456767 0.2597672 ]
[17.1  17.1   0.75]
[1.78868426 0.10959665 0.25950967]
[17.1  17.1   0.75]
[1.77808526 0.11468661 0.25959896]
[17.1  17.1   0.75]
[1.75835386 0.1322753  0.25954102]
[17.1  17.1   0.75]
[1.74771007 0.14451461 0.2705824 ]
[17.1  17.1   0.75]
[1.73636072 0.15421964 0.26833662]
[17.1  17.1   0.75]
[1.73684894 0.15196914 0.25680009]
[17.1  17.1   0.75]
[1.75255779 0.13968679 0.25915157]
[17.1  17.1   0.75]
[1.75511164 0.13913876 0.25951946]
[17.1  17.1   0.75]
[1.74732646 0.14770547 0.25959287]
[17.1  17.1   0.75]
[1.72710431 0.1441636  0.26283937]
[17.1  17.1   0.75]
[1.71374667 0.13404571 0.25847982]
[17.1  17.1   0.75]
[1.71000068 0.13314727 0.26031717]
[17.1  17.1   0.75]
[1.70439404 0.12399274 0.25909124]
[17.1  17.1   0.75]
[1.70842538 0.12380823 0.25959056]
[17.1  17.1   0.75]
[1.71678679 0.12672655 0.2596784 ]
[17.1  17.1   0.75]
[1.72337556 0.13112811 0.25963133]
[17.1  17.1   0.75]
[1.73083321 0.13690715 0.2595244 ]
[17.1  17.1   0.75]
[1.73432418 0.13794831 0.25999218]
[17.1  17.1   0.75]
[1.7363782  0.13857811 0.25927835]
[17.1  17.1   0.75]
[1.75417437 0.13830046 0.25982442]
[17.1  17.1   0.75]
[1.78718057 0.12976428 0.2592828 ]
[17.1  17.1   0.75]
[1.81386224 0.14332728 0.25914474]
[17.1  17.1   0.75]
[1.82074273 0.16166911 0.25955447]
[17.1  17.1   0.75]
[1.81566304 0.16717855 0.2596358 ]
[17.1  17.1   0.75]
[1.81059195 0.16995155 0.25979288]
[17.1  17.1   0.75]
[1.81413027 0.17574834 0.25963679]
[17.1  17.1   0.75]
[1.81803753 0.18969629 0.25962418]
[17.1  17.1   0.75]
[1.81969268 0.21266814 0.25983525]
[17.1  17.1   0.75]
[1.8145192  0.22770053 0.2592141 ]
[17.1  17.1   0.75]
[1.81254773 0.23616318 0.25990781]
[17.1  17.1   0.75]
[1.82738203 0.22228834 0.27656407]
[17.1  17.1   0.75]
[1.84431054 0.20994641 0.2887648 ]
[17.1  17.1   0.75]
[1.84683517 0.18752977 0.28360174]
[17.1  17.1   0.75]
[1.83054147 0.12985418 0.29103791]
[17.1  17.1   0.75]
[1.81554106 0.07862055 0.27040605]
[17.1  17.1   0.75]
[1.82132121 0.05508779 0.25542724]
[17.1  17.1   0.75]
[1.8254484  0.04340002 0.25896355]
[17.1  17.1   0.75]
[1.8208895  0.02644141 0.25967461]
[17.1  17.1   0.75]
[1.8153462  0.00737322 0.25967733]
[17.1  17.1   0.75]
[ 1.81029629 -0.00978545  0.2596806 ]
[17.1  17.1   0.75]
[ 1.80653944 -0.03145921  0.25959198]
[17.1  17.1   0.75]
[ 1.81223765 -0.04637414  0.25981555]
[17.1  17.1   0.75]
[ 1.83203676 -0.04822213  0.25953912]
[17.1  17.1   0.75]
[ 1.83579121 -0.05398836  0.26043673]
[17.1  17.1   0.75]
[ 1.8327827  -0.05470044  0.25912644]
[17.1  17.1   0.75]
[ 1.83178573 -0.05616635  0.25960128]
[17.1  17.1   0.75]
[ 1.8330312  -0.05380205  0.25960252]
[17.1  17.1   0.75]
[ 1.84371758 -0.05607976  0.25957417]
[17.1  17.1   0.75]
[ 1.84437287 -0.05323375  0.25938582]
[17.1  17.1   0.75]
[ 1.83953228 -0.04802286  0.25936455]
[17.1  17.1   0.75]
[ 1.82815275 -0.05040287  0.25961817]
[17.1  17.1   0.75]
[ 1.81524689 -0.06848117  0.26011634]
[17.1  17.1   0.75]
[ 1.8077575  -0.07373987  0.2591515 ]
[17.1  17.1   0.75]
[ 1.80809978 -0.065511    0.2596881 ]
[17.1  17.1   0.75]
[ 1.80925046 -0.06085117  0.25946243]
[17.1  17.1   0.75]
[ 1.81547617 -0.06084807  0.25975496]
[17.1  17.1   0.75]
[ 1.80834246 -0.06915006  0.25946374]
[17.1  17.1   0.75]
[ 1.79711483 -0.0799242   0.25958834]
[17.1  17.1   0.75]
[ 1.79182374 -0.08817571  0.25961624]
[17.1  17.1   0.75]
[ 1.78579261 -0.10412605  0.25972488]
[17.1  17.1   0.75]
[ 1.75941332 -0.10729249  0.26974754]
[17.1  17.1   0.75]
[ 1.7162866  -0.1029106   0.26971549]
[17.1  17.1   0.75]
[ 1.67658047 -0.0930315   0.26042702]
[17.1  17.1   0.75]
[ 1.65004243 -0.09038478  0.26302838]
[17.1  17.1   0.75]
[ 1.64838403 -0.08011691  0.25796676]
[17.1  17.1   0.75]
[ 1.66118733 -0.05681291  0.25949908]
[17.1  17.1   0.75]
[ 1.66589948 -0.04080724  0.25964306]
[17.1  17.1   0.75]
[ 1.66521229 -0.02865764  0.25962244]
[17.1  17.1   0.75]
[ 1.66746471 -0.01538167  0.25963234]
[17.1  17.1   0.75]
[ 1.66991638 -0.00230168  0.25963603]
[17.1  17.1   0.75]
[1.67208346 0.01090059 0.25960936]
[17.1  17.1   0.75]
[1.67815577 0.02758467 0.25960076]
[17.1  17.1   0.75]
[1.67643005 0.03299349 0.25977817]
[17.1  17.1   0.75]
[1.66931594 0.02898436 0.2596787 ]
[17.1  17.1   0.75]
[1.66536135 0.03016763 0.25960031]
[17.1  17.1   0.75]
[1.66668569 0.04792219 0.25965472]
[17.1  17.1   0.75]
[1.66298053 0.06569242 0.25958794]
[17.1  17.1   0.75]
[1.66834988 0.0752487  0.25963945]
[17.1  17.1   0.75]
[1.67781437 0.08322418 0.25964886]
[17.1  17.1   0.75]
[1.68043262 0.07843134 0.25996535]
[17.1  17.1   0.75]
[1.67663553 0.08555589 0.25950171]
[17.1  17.1   0.75]
[1.67470079 0.09766372 0.25969152]
[17.1  17.1   0.75]
[1.67090708 0.11302309 0.2597142 ]
[17.1  17.1   0.75]
[1.66441857 0.12989056 0.2597032 ]
[17.1  17.1   0.75]
[1.63626386 0.13359561 0.26105895]
[17.1  17.1   0.75]
[1.60208815 0.13858578 0.26083858]
[17.1  17.1   0.75]
[1.57479991 0.13422178 0.25872626]
[17.1  17.1   0.75]
[1.56730189 0.13199461 0.25985138]
[17.1  17.1   0.75]
[1.57207869 0.13746208 0.2597728 ]
[17.1  17.1   0.75]
[1.58656896 0.14531329 0.26134903]
[17.1  17.1   0.75]
[1.60047424 0.14602461 0.2654773 ]
[17.1  17.1   0.75]
[1.61270017 0.14155227 0.25567388]
[17.1  17.1   0.75]
[1.61036896 0.13700601 0.25953598]
[17.1  17.1   0.75]
[1.60209838 0.14058819 0.2592052 ]
[17.1  17.1   0.75]
[1.6004738  0.148221   0.26244361]
[17.1  17.1   0.75]
[1.58390028 0.1715308  0.26166116]
[17.1  17.1   0.75]
[1.55728491 0.19168554 0.26124336]
[17.1  17.1   0.75]
[1.54608635 0.17820775 0.25902581]
[17.1  17.1   0.75]
[1.54833115 0.15756722 0.2596697 ]
[17.1  17.1   0.75]
[1.5509004  0.13953206 0.25971919]
[17.1  17.1   0.75]
[1.55449833 0.13399719 0.25955441]
[17.1  17.1   0.75]
[1.54873309 0.13265524 0.2597805 ]
[17.1  17.1   0.75]
[1.54259636 0.1314068  0.25963132]
[17.1  17.1   0.75]
[1.53590795 0.12274748 0.25959648]
[17.1  17.1   0.75]
[1.52662407 0.10233705 0.25960349]
[17.1  17.1   0.75]
[1.52398557 0.08501448 0.25995744]
[17.1  17.1   0.75]
[1.51913114 0.08730195 0.25960275]
[17.1  17.1   0.75]
[1.51797743 0.09660016 0.25955453]
[17.1  17.1   0.75]
[1.51070204 0.0999322  0.25964949]
[17.1  17.1   0.75]
[1.49515316 0.09651254 0.25964734]
[17.1  17.1   0.75]
[1.48731309 0.09479741 0.25958641]
[17.1  17.1   0.75]
[1.48489978 0.09542135 0.25966946]
[17.1  17.1   0.75]
[1.48893841 0.09267286 0.25986085]
[17.1  17.1   0.75]
[1.49077006 0.07177557 0.25956432]
[17.1  17.1   0.75]
[1.48382687 0.05536073 0.2598395 ]
[17.1  17.1   0.75]
[1.48531137 0.03918606 0.25978714]
[17.1  17.1   0.75]
[1.4992051  0.02864016 0.27092267]
[17.1  17.1   0.75]
[1.5050806  0.03339104 0.27334558]
[17.1  17.1   0.75]
[1.49679187 0.04034563 0.25850417]
[17.1  17.1   0.75]
[1.48662849 0.04860539 0.25962473]
[17.1  17.1   0.75]
[1.47136672 0.05812439 0.25963483]
[17.1  17.1   0.75]
[1.46842433 0.07056617 0.25965281]
[17.1  17.1   0.75]
[1.47776704 0.07841798 0.2595859 ]
[17.1  17.1   0.75]
[1.48468194 0.0839913  0.25964765]
[17.1  17.1   0.75]
[1.48371777 0.09490882 0.25970135]
[17.1  17.1   0.75]
[1.48495022 0.11001455 0.25970484]
[17.1  17.1   0.75]
[1.49590074 0.13207667 0.26013006]
[17.1  17.1   0.75]
[1.48688987 0.1501666  0.25935374]
[17.1  17.1   0.75]
[1.46479922 0.16159437 0.25958236]
[17.1  17.1   0.75]
[1.43774709 0.16569577 0.25983189]
[17.1  17.1   0.75]
[1.42073467 0.16462697 0.25968683]
[17.1  17.1   0.75]
[1.41018312 0.16546505 0.2596554 ]
[17.1  17.1   0.75]
[1.40858076 0.18063345 0.26561065]
[17.1  17.1   0.75]
[1.4185068  0.20939109 0.25903352]
[17.1  17.1   0.75]
[1.42918162 0.22698263 0.25881478]
[17.1  17.1   0.75]
[1.43124522 0.23045768 0.25924154]
[17.1  17.1   0.75]
[1.43860914 0.23863004 0.25953558]
[17.1  17.1   0.75]
[1.44666319 0.24534728 0.26023054]
[17.1  17.1   0.75]
[1.45757179 0.23471386 0.25950462]
[17.1  17.1   0.75]
[1.46926329 0.22672467 0.25956646]
[17.1  17.1   0.75]
[1.47988447 0.22161166 0.25965856]
[17.1  17.1   0.75]
[1.4774853  0.21857773 0.25959945]
[17.1  17.1   0.75]
[1.4695455  0.21937771 0.26017161]
[17.1  17.1   0.75]
[1.46484497 0.21417251 0.25928862]
[17.1  17.1   0.75]
[1.45975273 0.21212002 0.25978745]
[17.1  17.1   0.75]
[1.46080554 0.20973899 0.25903553]
[17.1  17.1   0.75]
[1.47400212 0.20921685 0.25980369]
[17.1  17.1   0.75]
[1.47791167 0.21192824 0.25976172]
[17.1  17.1   0.75]
[1.481796   0.21129071 0.25986184]
[17.1  17.1   0.75]
[1.48581506 0.21689288 0.25955777]
[17.1  17.1   0.75]
[1.49700363 0.22163518 0.25954855]
[17.1  17.1   0.75]
[1.51077298 0.22153093 0.25988819]
[17.1  17.1   0.75]
[1.52033958 0.21178288 0.259408  ]
[17.1  17.1   0.75]
[1.51743289 0.19517422 0.25964046]
[17.1  17.1   0.75]
[1.51173298 0.1785672  0.25966611]
[17.1  17.1   0.75]
[1.51472004 0.16623701 0.25963529]
[17.1  17.1   0.75]
[1.51697174 0.16283283 0.25966095]
[17.1  17.1   0.75]
[1.52360651 0.16284392 0.25962903]
[17.1  17.1   0.75]
[1.54308879 0.15962695 0.25966536]
[17.1  17.1   0.75]
[1.57502274 0.15654945 0.2595319 ]
[17.1  17.1   0.75]
[1.5867115  0.14615195 0.26976404]
[17.1  17.1   0.75]
[1.58424679 0.12524994 0.26388936]
[17.1  17.1   0.75]
[1.57844318 0.10478144 0.25776367]
[17.1  17.1   0.75]
[1.56881869 0.0846579  0.26548697]
[17.1  17.1   0.75]
[1.54762846 0.06892124 0.25777534]
[17.1  17.1   0.75]
[1.5457293  0.07572046 0.26006115]
[17.1  17.1   0.75]
[1.55003543 0.08107447 0.25976372]
[17.1  17.1   0.75]
[1.55449119 0.08222098 0.25972327]
[17.1  17.1   0.75]
[1.55026345 0.09583957 0.25960111]
[17.1  17.1   0.75]
[1.54897881 0.10130632 0.25963668]
[17.1  17.1   0.75]
[1.55142543 0.098477   0.25972932]
[17.1  17.1   0.75]
[1.53534502 0.09506543 0.26113549]
[17.1  17.1   0.75]
[1.5278211  0.10563832 0.25879192]
[17.1  17.1   0.75]
[1.52331853 0.11432128 0.25961777]
[17.1  17.1   0.75]
[1.52241115 0.12638461 0.25960298]
[17.1  17.1   0.75]
[1.53470745 0.13879831 0.25976085]
[17.1  17.1   0.75]
[1.55170165 0.14503264 0.26247936]
[17.1  17.1   0.75]
[1.55646556 0.14447967 0.27081505]
[17.1  17.1   0.75]
[1.55530546 0.13991494 0.26118359]
[17.1  17.1   0.75]
[1.55664083 0.14853438 0.25763607]
[17.1  17.1   0.75]
[1.54948194 0.15440867 0.26002745]
[17.1  17.1   0.75]
[1.52126394 0.15874832 0.2594038 ]
[17.1  17.1   0.75]
[1.49334877 0.158706   0.25965451]
[17.1  17.1   0.75]
[1.47402834 0.16037895 0.25961494]
[17.1  17.1   0.75]
[1.45867267 0.15619962 0.2596951 ]
[17.1  17.1   0.75]
[1.44471407 0.14788092 0.25974659]
[17.1  17.1   0.75]
[1.4217224  0.15104596 0.2594897 ]
[17.1  17.1   0.75]
[1.40319488 0.16486608 0.25964814]
[17.1  17.1   0.75]
[1.41535493 0.18493112 0.26971474]
[17.1  17.1   0.75]
[1.44467409 0.18962806 0.26550151]
[17.1  17.1   0.75]
[1.44736258 0.18573865 0.25771223]
[17.1  17.1   0.75]
[1.44109188 0.18431693 0.2605119 ]
[17.1  17.1   0.75]
[1.44625256 0.18006322 0.25904914]
[17.1  17.1   0.75]
[1.45112633 0.15987674 0.25966859]
[17.1  17.1   0.75]
[1.449671   0.13992257 0.25964391]
[17.1  17.1   0.75]
[1.4355467  0.13111043 0.25954031]
[17.1  17.1   0.75]
[1.41810586 0.11999386 0.25958821]
[17.1  17.1   0.75]
[1.42259262 0.11281456 0.25988861]
[17.1  17.1   0.75]
[1.42746578 0.10368895 0.25971399]
[17.1  17.1   0.75]
[1.42168409 0.09397642 0.25986073]
[17.1  17.1   0.75]
[1.41910379 0.06429809 0.25957734]
[17.1  17.1   0.75]
[1.41399011 0.03372177 0.26360076]
[17.1  17.1   0.75]
[1.43046861 0.01441059 0.27045539]
[17.1  17.1   0.75]
[1.4500881  0.007013   0.26054567]
[17.1  17.1   0.75]
[1.46535701 0.00618634 0.25958444]
[17.1  17.1   0.75]
[1.47849767 0.02454152 0.25964066]
[17.1  17.1   0.75]
[1.4999473  0.03901708 0.25971951]
[17.1  17.1   0.75]
[1.51903178 0.03788113 0.25959756]
[17.1  17.1   0.75]
[1.52465012 0.03276955 0.25971762]
[17.1  17.1   0.75]
[1.52175886 0.02827324 0.25957224]
[17.1  17.1   0.75]
[1.51914808 0.03184031 0.25969549]
[17.1  17.1   0.75]
[1.52460602 0.03380354 0.25968688]
[17.1  17.1   0.75]
[1.53897004 0.03299697 0.25982782]
[17.1  17.1   0.75]
[1.56163449 0.04437034 0.25955236]
[17.1  17.1   0.75]
[1.57925074 0.06071526 0.25972145]
[17.1  17.1   0.75]
[1.58869909 0.07082605 0.25975546]
[17.1  17.1   0.75]
[1.60175223 0.07095147 0.26120954]
[17.1  17.1   0.75]
[1.60766542 0.07525353 0.27195618]
[17.1  17.1   0.75]
[1.611264   0.08747206 0.26265484]
[17.1  17.1   0.75]
[1.59549511 0.08751878 0.26066668]
[17.1  17.1   0.75]
[1.58185473 0.06769381 0.25871411]
[17.1  17.1   0.75]
[1.58024624 0.04376993 0.25945127]
[17.1  17.1   0.75]
[1.58153333 0.03230675 0.25965919]
[17.1  17.1   0.75]
[1.57835626 0.02796516 0.25964726]
[17.1  17.1   0.75]
[1.57898609 0.02396909 0.25957703]
[17.1  17.1   0.75]
[1.58928961 0.0102986  0.25968744]
[17.1  17.1   0.75]
[1.59759683 0.00297319 0.25977521]
[17.1  17.1   0.75]
[1.60770351 0.00371147 0.25956522]
[17.1  17.1   0.75]
[ 1.61471767e+00 -8.90915995e-05  2.59852785e-01]
[17.1  17.1   0.75]
[1.61146483 0.0022508  0.25990358]
[17.1  17.1   0.75]
[1.60464677e+00 7.28567331e-04 2.59645753e-01]
[17.1  17.1   0.75]
[ 1.6091309  -0.00295896  0.25964209]
[17.1  17.1   0.75]
[ 1.6156885  -0.00693116  0.25963512]
[17.1  17.1   0.75]
[ 1.62482347 -0.01663743  0.2616577 ]
[17.1  17.1   0.75]
[ 1.6378902  -0.03519566  0.2584172 ]
[17.1  17.1   0.75]
[ 1.6514154  -0.05748692  0.2598205 ]
[17.1  17.1   0.75]
[ 1.64809857 -0.08234829  0.26724053]
[17.1  17.1   0.75]
[ 1.6405306  -0.07376983  0.28999963]
[17.1  17.1   0.75]
[ 1.64916042 -0.05530076  0.28865681]
[17.1  17.1   0.75]
[ 1.66211168 -0.02778954  0.25766686]
[17.1  17.1   0.75]
[ 1.66990787 -0.00245887  0.25648518]
[17.1  17.1   0.75]
[1.6805644  0.01807513 0.26051174]
[17.1  17.1   0.75]
[1.68747872 0.02689521 0.25894529]
[17.1  17.1   0.75]
[1.69350115 0.03590437 0.25958965]
[17.1  17.1   0.75]
[1.68854505 0.04801799 0.25966562]
[17.1  17.1   0.75]
[1.67365765 0.06437944 0.25959068]
[17.1  17.1   0.75]
[1.65849987 0.0695386  0.25967534]
[17.1  17.1   0.75]
[1.65687572 0.06902937 0.25952326]
[17.1  17.1   0.75]
[1.66335286 0.07388088 0.25966628]
[17.1  17.1   0.75]
[1.66515371 0.08344803 0.25964943]
[17.1  17.1   0.75]
[1.66862743 0.09515865 0.26145675]
[17.1  17.1   0.75]
[1.67708732 0.0984849  0.25964996]
[17.1  17.1   0.75]
[1.69184367 0.09347138 0.26014823]
[17.1  17.1   0.75]
[1.70441784 0.08822614 0.25964928]
[17.1  17.1   0.75]
[1.70705165 0.0773842  0.25931691]
[17.1  17.1   0.75]
[1.69989132 0.064591   0.25920966]
[17.1  17.1   0.75]
[1.68806595 0.0481068  0.25990239]
[17.1  17.1   0.75]
[1.6686216  0.04111537 0.25896589]
[17.1  17.1   0.75]
[1.65507605 0.0533591  0.25958216]
[17.1  17.1   0.75]
[1.64328904 0.07109458 0.25958331]
[17.1  17.1   0.75]
[1.63396033 0.07978944 0.25940742]
[17.1  17.1   0.75]
[1.62249811 0.08366652 0.25955959]
[17.1  17.1   0.75]
[1.61892806 0.08775715 0.25967479]
[17.1  17.1   0.75]
[1.61779942 0.09063018 0.2596252 ]
[17.1  17.1   0.75]
[1.61592137 0.09573424 0.25961943]
[17.1  17.1   0.75]
[1.61078569 0.10268699 0.2595817 ]
[17.1  17.1   0.75]
[1.59147633 0.11975981 0.26388864]
[17.1  17.1   0.75]
[1.56039365 0.12810174 0.26535185]
[17.1  17.1   0.75]
[1.53044748 0.13326474 0.25757243]
[17.1  17.1   0.75]
[1.51150454 0.1294295  0.26469893]
[17.1  17.1   0.75]
[1.50323595 0.11754448 0.28126253]
[17.1  17.1   0.75]
[1.49869629 0.12625427 0.26535342]
[17.1  17.1   0.75]
[1.48975624 0.12826907 0.25567183]
[17.1  17.1   0.75]
[1.47780641 0.10932238 0.26633238]
[17.1  17.1   0.75]
[1.47481152 0.06124125 0.27826989]
[17.1  17.1   0.75]
[1.49063308 0.0444315  0.25884035]
[17.1  17.1   0.75]
[1.51692355 0.04413752 0.25720055]
[17.1  17.1   0.75]
[1.53170763 0.05141394 0.25986542]
[17.1  17.1   0.75]
[1.54022977 0.0496879  0.25952606]
[17.1  17.1   0.75]
[1.54091997 0.04885659 0.25962927]
[17.1  17.1   0.75]
[1.53663311 0.04035745 0.25968941]
[17.1  17.1   0.75]
[1.54037692 0.02896422 0.25911859]
[17.1  17.1   0.75]
[1.55672368 0.03064021 0.2595496 ]
[17.1  17.1   0.75]
[1.57670889 0.04221881 0.25958579]
[17.1  17.1   0.75]
[1.58977443 0.06033364 0.26195362]
[17.1  17.1   0.75]
[1.59312448 0.05463937 0.28237944]
[17.1  17.1   0.75]
[1.60427161 0.05248309 0.28854089]
[17.1  17.1   0.75]
[1.61354634 0.03816597 0.27698309]
[17.1  17.1   0.75]
[1.62531605 0.00970375 0.2544797 ]
[17.1  17.1   0.75]
[ 1.62517035 -0.02458499  0.25877836]
[17.1  17.1   0.75]
[ 1.60651005 -0.03599678  0.25970147]
[17.1  17.1   0.75]
[ 1.57948657 -0.04137045  0.26244477]
[17.1  17.1   0.75]
[ 1.59102611 -0.04932537  0.30192055]
[17.1  17.1   0.75]
[ 1.60733317 -0.06366578  0.32104185]
[17.1  17.1   0.75]
[ 1.64247568 -0.07561416  0.33240345]
[17.1  17.1   0.75]
[ 1.67885058 -0.08036078  0.32516116]
[17.1  17.1   0.75]
[ 1.69960013 -0.07795809  0.29739531]
[17.1  17.1   0.75]
[ 1.70234781 -0.06952002  0.26632796]
[17.1  17.1   0.75]
[ 1.71095454 -0.06165464  0.25800191]
[17.1  17.1   0.75]
[ 1.72652664 -0.06892577  0.25947095]
[17.1  17.1   0.75]
[ 1.75090194 -0.06860554  0.26333179]
[17.1  17.1   0.75]
[ 1.78428222 -0.02140768  0.30741932]
[17.1  17.1   0.75]
[1.81524857 0.03435934 0.33452229]
[17.1  17.1   0.75]
[1.83704564 0.09582235 0.33484222]
[17.1  17.1   0.75]
[1.84985922 0.15636983 0.3121419 ]
[17.1  17.1   0.75]
[1.86122649 0.21463318 0.26810399]
[17.1  17.1   0.75]
[1.85627806 0.2512832  0.25430051]
[17.1  17.1   0.75]
[1.84701102 0.27867508 0.25876786]
[17.1  17.1   0.75]
[1.84125679 0.30451762 0.27096015]
[17.1  17.1   0.75]
[1.81884693 0.32368809 0.28857247]
[17.1  17.1   0.75]
[1.78672474 0.35409067 0.28799515]
[17.1  17.1   0.75]
[1.75369859 0.3710804  0.27695696]
[17.1  17.1   0.75]
[1.73723214 0.37801524 0.25960972]
[17.1  17.1   0.75]
[1.72341303 0.37804019 0.25882041]
[17.1  17.1   0.75]
[1.7053799  0.37850778 0.2595861 ]
[17.1  17.1   0.75]
[1.67426172 0.37071072 0.26156912]
[17.1  17.1   0.75]
[1.65263624 0.35698634 0.27853918]
[17.1  17.1   0.75]
[1.63645524 0.35796601 0.28314648]
[17.1  17.1   0.75]
[1.62793999 0.34257152 0.27852731]
[17.1  17.1   0.75]
[1.63211803 0.32098152 0.25262959]
[17.1  17.1   0.75]
[1.63359505 0.29359931 0.26369162]
[17.1  17.1   0.75]
[1.65389163 0.27314622 0.29452941]
[17.1  17.1   0.75]
[1.69133768 0.22961889 0.30544348]
[17.1  17.1   0.75]
[1.73899299 0.18160329 0.29507886]
[17.1  17.1   0.75]
[1.77395857 0.15093947 0.26222381]
[17.1  17.1   0.75]
[1.80875897 0.14970242 0.257136  ]
[17.1  17.1   0.75]
[1.84322842 0.15429441 0.26058501]
[17.1  17.1   0.75]
[1.86475819 0.15968944 0.259639  ]
[17.1  17.1   0.75]
[1.86972139 0.16419243 0.25960478]
[17.1  17.1   0.75]
[1.89004247 0.17460752 0.26062428]
[17.1  17.1   0.75]
[1.90420173 0.19735194 0.27023675]
[17.1  17.1   0.75]
[1.91337267 0.21616531 0.2766512 ]
[17.1  17.1   0.75]
[1.92332787 0.23936685 0.26904475]
[17.1  17.1   0.75]
[1.92227745 0.25051909 0.2604402 ]
[17.1  17.1   0.75]
[1.90459125 0.26744636 0.26291753]
[17.1  17.1   0.75]
[1.89718125 0.28047399 0.26981594]
[17.1  17.1   0.75]
[1.8816998  0.29032746 0.27289818]
[17.1  17.1   0.75]
[1.85411056 0.29443018 0.27254169]
[17.1  17.1   0.75]
[1.8117607  0.29405143 0.26004666]
[17.1  17.1   0.75]
[1.7703885  0.29365922 0.26074507]
[17.1  17.1   0.75]
[1.74306519 0.29117978 0.25961128]
[17.1  17.1   0.75]
[1.72853628 0.27199038 0.25964166]
[17.1  17.1   0.75]
[1.72035405 0.23558601 0.25946671]
[17.1  17.1   0.75]
[1.71439323 0.19362296 0.25956489]
[17.1  17.1   0.75]
[1.72702087 0.14851817 0.25948574]
[17.1  17.1   0.75]
[1.73625736 0.13094361 0.26638503]
[17.1  17.1   0.75]
[1.7069463  0.12896488 0.27865918]
[17.1  17.1   0.75]
[1.67351754 0.14023828 0.27356591]
[17.1  17.1   0.75]
[1.64235242 0.15182631 0.25899991]
[17.1  17.1   0.75]
[1.62738093 0.15312156 0.26119031]
[17.1  17.1   0.75]
[1.61668556 0.15784455 0.26229556]
[17.1  17.1   0.75]
[1.616123   0.15823154 0.2578023 ]
[17.1  17.1   0.75]
[1.60601755 0.16305351 0.25931525]
[17.1  17.1   0.75]
[1.59464258 0.17225009 0.2596376 ]
[17.1  17.1   0.75]
[1.58683152 0.17014807 0.25956973]
[17.1  17.1   0.75]
[1.57807245 0.16024101 0.26573525]
[17.1  17.1   0.75]
[1.58265226 0.17964777 0.28569946]
[17.1  17.1   0.75]
[1.58554968 0.22492462 0.29260876]
[17.1  17.1   0.75]
[1.58448823 0.26947021 0.28026712]
[17.1  17.1   0.75]
[1.57454229 0.31393668 0.25405686]
[17.1  17.1   0.75]
[1.5684678  0.36236149 0.27273254]
[17.1  17.1   0.75]
[1.56135217 0.41296545 0.2712265 ]
[17.1  17.1   0.75]
[1.56372956 0.46597498 0.25855257]
[17.1  17.1   0.75]
[1.57705771 0.48855744 0.28290351]
[17.1  17.1   0.75]
[1.59987347 0.48647342 0.31895828]
[17.1  17.1   0.75]
[1.62861663 0.48680713 0.32087766]
[17.1  17.1   0.75]
[1.64265397 0.48349419 0.29781672]
[17.1  17.1   0.75]
[1.65466822 0.4703423  0.26023775]
[17.1  17.1   0.75]
[1.6633059  0.45982312 0.25556275]
[17.1  17.1   0.75]
[1.6694025  0.44827097 0.25909866]
[17.1  17.1   0.75]
[1.67523939 0.43698035 0.26337079]
[17.1  17.1   0.75]
[1.66818212 0.40491827 0.2735393 ]
[17.1  17.1   0.75]
[1.66733078 0.38061381 0.25909584]
[17.1  17.1   0.75]
[1.65802486 0.38148142 0.25811673]
[17.1  17.1   0.75]
[1.64587705 0.39224308 0.25943317]
[17.1  17.1   0.75]
[1.64319192 0.40275061 0.25957571]
[17.1  17.1   0.75]
[1.62987838 0.40644933 0.2601325 ]
[17.1  17.1   0.75]
[1.60795971 0.39941375 0.25940882]
[17.1  17.1   0.75]
[1.58669698 0.39565978 0.25957773]
[17.1  17.1   0.75]
[1.57141177 0.39377496 0.25956187]
[17.1  17.1   0.75]
[1.56717849 0.3879883  0.25966705]
[17.1  17.1   0.75]
[1.56066608 0.3894101  0.25975576]
[17.1  17.1   0.75]
[1.53608638 0.39537933 0.25965368]
[17.1  17.1   0.75]
[1.50048906 0.39960867 0.25958642]
[17.1  17.1   0.75]
[1.47229798 0.40000696 0.26025146]
[17.1  17.1   0.75]
[1.44931199 0.39035706 0.25970416]
[17.1  17.1   0.75]
[1.44958186 0.37442188 0.26578112]
[17.1  17.1   0.75]
[1.45468848 0.35020569 0.26917231]
[17.1  17.1   0.75]
[1.46492618 0.32015674 0.26940261]
[17.1  17.1   0.75]
[1.46548349 0.27464008 0.25840589]
[17.1  17.1   0.75]
[1.46964673 0.25896293 0.25855202]
[17.1  17.1   0.75]
[1.48213189 0.25830859 0.25982397]
[17.1  17.1   0.75]
[1.49986536 0.25596122 0.2597399 ]
[17.1  17.1   0.75]
[1.52179607 0.25618719 0.25966073]
[17.1  17.1   0.75]
[1.52856455 0.25307055 0.25959258]
[17.1  17.1   0.75]
[1.5332631  0.23981155 0.25959547]
[17.1  17.1   0.75]
[1.54263748 0.23857747 0.2597412 ]
[17.1  17.1   0.75]
[1.55215209 0.24970295 0.25981728]
[17.1  17.1   0.75]
[1.57571995 0.27119582 0.25963372]
[17.1  17.1   0.75]
[1.61179032 0.29355169 0.2594822 ]
[17.1  17.1   0.75]
[1.64000335 0.30335539 0.26276308]
[17.1  17.1   0.75]
[1.64923948 0.29795458 0.27136118]
[17.1  17.1   0.75]
[1.65105032 0.27996235 0.25579765]
[17.1  17.1   0.75]
[1.64542534 0.25746864 0.25836712]
[17.1  17.1   0.75]
[1.63778108 0.22569488 0.26058507]
[17.1  17.1   0.75]
[1.63401689 0.22904026 0.27089529]
[17.1  17.1   0.75]
[1.62314697 0.23951598 0.27068486]
[17.1  17.1   0.75]
[1.60633045 0.25262231 0.25626102]
[17.1  17.1   0.75]
[1.59403412 0.2711772  0.25887625]
[17.1  17.1   0.75]
[1.58481308 0.29907088 0.25957329]
[17.1  17.1   0.75]
[1.57034631 0.3329933  0.25986639]
[17.1  17.1   0.75]
[1.55825637 0.34098937 0.25966488]
[17.1  17.1   0.75]
[1.55345553 0.33879197 0.25973754]
[17.1  17.1   0.75]
[1.55352977 0.33900662 0.25969821]
[17.1  17.1   0.75]
[1.55710261 0.35555677 0.25957081]
[17.1  17.1   0.75]
[1.5580976  0.3756779  0.25967774]
[17.1  17.1   0.75]
[1.54173362 0.38768094 0.26876203]
[17.1  17.1   0.75]
[1.53277438 0.38956838 0.28599982]
[17.1  17.1   0.75]
[1.51534873 0.38985687 0.28326596]
[17.1  17.1   0.75]
[1.49623447 0.37819758 0.25744554]
[17.1  17.1   0.75]
[1.49763469 0.3772624  0.25698898]
[17.1  17.1   0.75]
[1.50101276 0.37877381 0.2593371 ]
[17.1  17.1   0.75]
[1.51068519 0.37535838 0.25993463]
[17.1  17.1   0.75]
[1.51840017 0.37112151 0.25976839]
[17.1  17.1   0.75]
[1.52056705 0.37112281 0.26019431]
[17.1  17.1   0.75]
[1.53675554 0.36824719 0.25893937]
[17.1  17.1   0.75]
[1.55642047 0.37491584 0.25955274]
[17.1  17.1   0.75]
[1.55869918 0.36689528 0.27478969]
[17.1  17.1   0.75]
[1.55107373 0.34928981 0.2742434 ]
[17.1  17.1   0.75]
[1.5412242  0.32586151 0.2594882 ]
[17.1  17.1   0.75]
[1.53533122 0.31657243 0.25860288]
[17.1  17.1   0.75]
[1.53685219 0.30035025 0.25961758]
[17.1  17.1   0.75]
[1.53686721 0.28231045 0.25973682]
[17.1  17.1   0.75]
[1.53841947 0.26834455 0.25967973]
[17.1  17.1   0.75]
[1.54458526 0.26186757 0.25957123]
[17.1  17.1   0.75]
[1.54870828 0.24930188 0.25966819]
[17.1  17.1   0.75]
[1.54644808 0.23707538 0.25960154]
[17.1  17.1   0.75]
[1.53616816 0.22973137 0.25963235]
[17.1  17.1   0.75]
[1.52516118 0.21687859 0.25970222]
[17.1  17.1   0.75]
[1.51561306 0.20520614 0.25962719]
[17.1  17.1   0.75]
[1.50693247 0.19376786 0.25964344]
[17.1  17.1   0.75]
[1.50244013 0.18864001 0.26178142]
[17.1  17.1   0.75]
[1.49842736 0.19597086 0.25842825]
[17.1  17.1   0.75]
[1.49748708 0.1919326  0.26406618]
[17.1  17.1   0.75]
[1.51675201 0.18116669 0.26662642]
[17.1  17.1   0.75]
[1.52102718 0.18698051 0.25747567]
[17.1  17.1   0.75]
[1.51658808 0.19340787 0.25919226]
[17.1  17.1   0.75]
[1.50646489 0.19891249 0.25970702]
[17.1  17.1   0.75]
[1.49671754 0.20198122 0.2596647 ]
[17.1  17.1   0.75]
[1.47849191 0.21370479 0.26641395]
[17.1  17.1   0.75]
[1.45626303 0.2217225  0.27145991]
[17.1  17.1   0.75]
[1.45192091 0.24733497 0.26186064]
[17.1  17.1   0.75]
[1.45578869 0.2778607  0.25810914]
[17.1  17.1   0.75]
[1.45993404 0.30119244 0.25943131]
[17.1  17.1   0.75]
[1.45986251 0.30688146 0.26978565]
[17.1  17.1   0.75]
[1.45235494 0.31465805 0.27077427]
[17.1  17.1   0.75]
[1.44268321 0.33134633 0.25532454]
[17.1  17.1   0.75]
[1.46518793 0.33555981 0.25821638]
[17.1  17.1   0.75]
[1.48515078 0.33704941 0.2609704 ]
[17.1  17.1   0.75]
[1.50105666 0.32970155 0.26269763]
[17.1  17.1   0.75]
[1.51324584 0.32496162 0.25956239]
[17.1  17.1   0.75]
[1.52280662 0.32725589 0.26134805]
[17.1  17.1   0.75]
[1.52834164 0.32168226 0.25949143]
[17.1  17.1   0.75]
[1.53608786 0.31276338 0.25951487]
[17.1  17.1   0.75]
[1.53726612 0.30403385 0.25963234]
[17.1  17.1   0.75]
[1.52309963 0.28468423 0.25982967]
[17.1  17.1   0.75]
[1.50569309 0.28125806 0.25983956]
[17.1  17.1   0.75]
[1.50575978 0.28293295 0.25951931]
[17.1  17.1   0.75]
[1.51147978 0.28839542 0.25960527]
[17.1  17.1   0.75]
[1.51610606 0.28408124 0.26036557]
[17.1  17.1   0.75]
[1.50729994 0.27338525 0.2590953 ]
[17.1  17.1   0.75]
[1.49516525 0.26863472 0.25964072]
[17.1  17.1   0.75]
[1.48146615 0.26084449 0.25966567]
[17.1  17.1   0.75]
[1.46202931 0.23909083 0.2595987 ]
[17.1  17.1   0.75]
[1.44847864 0.21070389 0.26035611]
[17.1  17.1   0.75]
[1.43901909 0.2085684  0.25911493]
[17.1  17.1   0.75]
[1.42251183 0.20574102 0.25957918]
[17.1  17.1   0.75]
[1.39862817 0.20327214 0.26085934]
[17.1  17.1   0.75]
[1.39248566 0.19046402 0.26587113]
[17.1  17.1   0.75]
[1.39400147 0.17685827 0.25774804]
[17.1  17.1   0.75]
[1.39514459 0.16467661 0.27229258]
[17.1  17.1   0.75]
[1.42110772 0.15146046 0.29936185]
[17.1  17.1   0.75]
[1.42883848 0.16195966 0.31356683]
[17.1  17.1   0.75]
[1.43233693 0.18932462 0.31380706]
[17.1  17.1   0.75]
[1.44282637 0.2219139  0.29402373]
[17.1  17.1   0.75]
[1.45172691 0.27186249 0.26456503]
[17.1  17.1   0.75]
[1.4588355  0.31066675 0.25785698]
[17.1  17.1   0.75]
[1.48810585 0.32175831 0.2592234 ]
[17.1  17.1   0.75]
[1.5100082  0.31892434 0.25952544]
[17.1  17.1   0.75]
[1.53329038 0.30263141 0.2595605 ]
[17.1  17.1   0.75]
[1.55498198 0.29389117 0.26204812]
[17.1  17.1   0.75]
[1.54634299 0.31951816 0.27606893]
[17.1  17.1   0.75]
[1.52470097 0.3445159  0.27668384]
[17.1  17.1   0.75]
[1.53235203 0.3775611  0.26182601]
[17.1  17.1   0.75]
[1.52964601 0.3965184  0.27025759]
[17.1  17.1   0.75]
[1.52479333 0.40418522 0.25864379]
[17.1  17.1   0.75]
[1.50066523 0.41379001 0.25861455]
[17.1  17.1   0.75]
[1.4627511  0.43996164 0.25968035]
[17.1  17.1   0.75]
[1.42933879 0.44243046 0.25965064]
[17.1  17.1   0.75]
[1.40632635 0.43705617 0.25953834]
[17.1  17.1   0.75]
[1.38706223 0.42498963 0.25970395]
[17.1  17.1   0.75]
[1.36773147 0.41511705 0.25985672]
[17.1  17.1   0.75]
[1.33894448 0.39580888 0.27406521]
[17.1  17.1   0.75]
[1.32227392 0.37072798 0.28573218]
[17.1  17.1   0.75]
[1.31573464 0.34690711 0.27384026]
[17.1  17.1   0.75]
[1.3074195  0.32381542 0.2560414 ]
[17.1  17.1   0.75]
[1.30208169 0.30810022 0.25899832]
[17.1  17.1   0.75]
[1.29519429 0.29903451 0.25975482]
[17.1  17.1   0.75]
[1.28255327 0.2986753  0.259491  ]
[17.1  17.1   0.75]
[1.28297644 0.31323648 0.26503485]
[17.1  17.1   0.75]
[1.30109523 0.30576469 0.26686412]
[17.1  17.1   0.75]
[1.3211456  0.29893662 0.25750919]
[17.1  17.1   0.75]
[1.34015641 0.30470888 0.25915759]
[17.1  17.1   0.75]
[1.3459674  0.31484864 0.25964429]
[17.1  17.1   0.75]
[1.34470382 0.31968397 0.25964373]
[17.1  17.1   0.75]
[1.34851833 0.32029384 0.25967869]
[17.1  17.1   0.75]
[1.35163028 0.31958855 0.25961103]
[17.1  17.1   0.75]
[1.34181599 0.31953772 0.25987896]
[17.1  17.1   0.75]
[1.33284533 0.31904083 0.25948135]
[17.1  17.1   0.75]
[1.33002448 0.31755457 0.25983458]
[17.1  17.1   0.75]
[1.33056592 0.32386286 0.25967247]
[17.1  17.1   0.75]
[1.32179418 0.33583183 0.2640623 ]
[17.1  17.1   0.75]
[1.3055163  0.34280607 0.26757514]
[17.1  17.1   0.75]
[1.30192015 0.32348914 0.26013191]
[17.1  17.1   0.75]
[1.31320304 0.31830774 0.25901473]
[17.1  17.1   0.75]
[1.32494193 0.30997175 0.25959198]
[17.1  17.1   0.75]
[1.34299306 0.30640989 0.25972815]
[17.1  17.1   0.75]
[1.35894788 0.3064428  0.25961532]
[17.1  17.1   0.75]
[1.36119787 0.30268448 0.25972101]
[17.1  17.1   0.75]
[1.35303277 0.29510699 0.25972257]
[17.1  17.1   0.75]
[1.35056241 0.28426373 0.25961999]
[17.1  17.1   0.75]
[1.35421371 0.27062186 0.25970076]
[17.1  17.1   0.75]
[1.35608901 0.25896375 0.25951403]
[17.1  17.1   0.75]
[1.36222324 0.24560987 0.25898753]
[17.1  17.1   0.75]
[1.3830378  0.23756222 0.26028162]
[17.1  17.1   0.75]
[1.40306949 0.241207   0.25920229]
[17.1  17.1   0.75]
[1.41128053 0.24899222 0.26116084]
[17.1  17.1   0.75]
[1.39691568 0.26496855 0.25836895]
[17.1  17.1   0.75]
[1.39088737 0.25824237 0.25944556]
[17.1  17.1   0.75]
[1.38187855 0.24963906 0.25962809]
[17.1  17.1   0.75]
[1.38371178 0.2457604  0.2595914 ]
[17.1  17.1   0.75]
[1.39454882 0.24994074 0.2596895 ]
[17.1  17.1   0.75]
[1.40104379 0.24660184 0.25918292]
[17.1  17.1   0.75]
[1.40753892 0.24300922 0.25989532]
[17.1  17.1   0.75]
[1.39594086 0.23631641 0.25969551]
[17.1  17.1   0.75]
[1.37747859 0.22995156 0.25964987]
[17.1  17.1   0.75]
[1.36544381 0.21524381 0.25964046]
[17.1  17.1   0.75]
[1.35257936 0.21172528 0.26942919]
[17.1  17.1   0.75]
[1.34291303 0.23797898 0.28450034]
[17.1  17.1   0.75]
[1.34637393 0.26226752 0.27668596]
[17.1  17.1   0.75]
[1.35449277 0.27437672 0.25851922]
[17.1  17.1   0.75]
[1.35328352 0.28897093 0.25983802]
[17.1  17.1   0.75]
[1.35986162 0.31905277 0.25956999]
[17.1  17.1   0.75]
[1.36746884 0.3532837  0.25957861]
[17.1  17.1   0.75]
[1.36265302 0.3756346  0.25976664]
[17.1  17.1   0.75]
[1.34135998 0.39743841 0.25969326]
[17.1  17.1   0.75]
[1.31913046 0.43062464 0.25967901]
[17.1  17.1   0.75]
[1.29103515 0.45974623 0.27802621]
[17.1  17.1   0.75]
[1.25315346 0.47483098 0.28126479]
[17.1  17.1   0.75]
[1.21867096 0.49062414 0.26067207]
[17.1  17.1   0.75]
[1.20149828 0.49092374 0.25693478]
[17.1  17.1   0.75]
[1.18970575 0.4914013  0.25938104]
[17.1  17.1   0.75]
[1.17938958 0.49634145 0.25962525]
[17.1  17.1   0.75]
[1.17949123 0.50052575 0.27080129]
[17.1  17.1   0.75]
[1.19598706 0.50206383 0.27374127]
[17.1  17.1   0.75]
[1.23550926 0.50339093 0.26977513]
[17.1  17.1   0.75]
[1.25544541 0.49135526 0.25779313]
[17.1  17.1   0.75]
[1.25929625 0.47712344 0.25833674]
[17.1  17.1   0.75]
[1.25431471 0.46134132 0.25988235]
[17.1  17.1   0.75]
[1.24931841 0.43176977 0.25986251]
[17.1  17.1   0.75]
[1.24353484 0.41039462 0.25957365]
[17.1  17.1   0.75]
[1.24152859 0.39096983 0.25956811]
[17.1  17.1   0.75]
[1.25326192 0.38867252 0.2598192 ]
[17.1  17.1   0.75]
[1.25876104 0.38384379 0.25944464]
[17.1  17.1   0.75]
[1.26783459 0.37745905 0.26256547]
[17.1  17.1   0.75]
[1.2936233  0.36528846 0.26206106]
[17.1  17.1   0.75]
[1.35765478 0.3442202  0.27148559]
[17.1  17.1   0.75]
[1.42724869 0.32575866 0.26100092]
[17.1  17.1   0.75]
[1.44827527 0.33481544 0.26049951]
[17.1  17.1   0.75]
[1.45792693 0.36341716 0.25922017]
[17.1  17.1   0.75]
[1.47033787 0.39107783 0.25970373]
[17.1  17.1   0.75]
[1.47683511 0.41324896 0.25963281]
[17.1  17.1   0.75]
[1.48303933 0.42687783 0.25968724]
[17.1  17.1   0.75]
[1.50138137 0.44524902 0.26850229]
[17.1  17.1   0.75]
[1.5312078  0.46150449 0.27749184]
[17.1  17.1   0.75]
[1.55375789 0.47735141 0.26583092]
[17.1  17.1   0.75]
[1.57312913 0.47935824 0.25732899]
[17.1  17.1   0.75]
[1.58078483 0.47508635 0.25925695]
[17.1  17.1   0.75]
[1.5814707  0.47402335 0.25959651]
[17.1  17.1   0.75]
[1.58150861 0.47313517 0.25969771]
[17.1  17.1   0.75]
[1.58076106 0.46011714 0.25970055]
[17.1  17.1   0.75]
[1.58341664 0.43802359 0.25965563]
[17.1  17.1   0.75]
[1.58518617 0.42567656 0.25967495]
[17.1  17.1   0.75]
[1.58010615 0.41699202 0.25961573]
[17.1  17.1   0.75]
[1.57512648 0.40943948 0.25957957]
[17.1  17.1   0.75]
[1.57629072 0.399384   0.26006025]
[17.1  17.1   0.75]
[1.5837046  0.39512202 0.25950549]
[17.1  17.1   0.75]
[1.5943399  0.39677801 0.25953852]
[17.1  17.1   0.75]
[1.5990916  0.38833268 0.25968483]
[17.1  17.1   0.75]
[1.60271984 0.38226653 0.26063671]
[17.1  17.1   0.75]
[1.60994795 0.38804725 0.25895437]
[17.1  17.1   0.75]
[1.61628563 0.38765057 0.25960264]
[17.1  17.1   0.75]
[1.62159287 0.39522372 0.2596555 ]
[17.1  17.1   0.75]
[1.62998096 0.41856613 0.25960089]
[17.1  17.1   0.75]
[1.62859752 0.43527529 0.25958437]
[17.1  17.1   0.75]
[1.6304627  0.43667019 0.25974027]
[17.1  17.1   0.75]
[1.63190518 0.4406937  0.25960934]
[17.1  17.1   0.75]
[1.62181388 0.43849119 0.26016053]
[17.1  17.1   0.75]
[1.60895585 0.42921547 0.25963005]
[17.1  17.1   0.75]
[1.60864082 0.41750932 0.25960591]
[17.1  17.1   0.75]
[1.61507586 0.42406231 0.25953804]
[17.1  17.1   0.75]
[1.6212672  0.4537721  0.25992455]
[17.1  17.1   0.75]
[1.62294076 0.47659142 0.25965878]
[17.1  17.1   0.75]
[1.6247238  0.49694754 0.25961031]
[17.1  17.1   0.75]
[1.62822594 0.51380217 0.26044899]
[17.1  17.1   0.75]
[1.61205285 0.51680993 0.26052285]
[17.1  17.1   0.75]
[1.58638238 0.49604406 0.27882609]
[17.1  17.1   0.75]
[1.5580135  0.46651701 0.28655145]
[17.1  17.1   0.75]
[1.54630981 0.4496858  0.27685274]
[17.1  17.1   0.75]
[1.5530689  0.4297143  0.25599318]
[17.1  17.1   0.75]
[1.57377873 0.41143881 0.25816742]
[17.1  17.1   0.75]
[1.59502242 0.40180821 0.25980702]
[17.1  17.1   0.75]
[1.60067706 0.39932155 0.25953614]
[17.1  17.1   0.75]
[1.61292215 0.39309115 0.25960063]
[17.1  17.1   0.75]
[1.62340625 0.38515049 0.25969786]
[17.1  17.1   0.75]
[1.62746945 0.38937304 0.25982163]
[17.1  17.1   0.75]
[1.63571898 0.39530759 0.25960561]
[17.1  17.1   0.75]
[1.64428864 0.40241213 0.25961615]
[17.1  17.1   0.75]
[1.66057934 0.40440765 0.25961192]
[17.1  17.1   0.75]
[1.67752108 0.3993754  0.26346808]
[17.1  17.1   0.75]
[1.68287885 0.38867697 0.25777241]
[17.1  17.1   0.75]
[1.6777095  0.37275695 0.25903555]
[17.1  17.1   0.75]
Num timesteps: 2000
Best mean reward: -inf - Last mean reward per episode: 43.11
Saving new best model to rl/out_dir/models/exp66/best_model.zip
[ 0.09135194 -0.06546721  0.70307078]
[19.4  19.4   0.75]
[ 0.09462653 -0.08410869  0.69813901]
[19.4  19.4   0.75]
[ 0.09334864 -0.07880362  0.64786299]
[19.4  19.4   0.75]
[ 0.10349732 -0.07605099  0.58825053]
[19.4  19.4   0.75]
[ 0.11141276 -0.07770948  0.6066612 ]
[19.4  19.4   0.75]
[ 0.11332027 -0.07901957  0.60586636]
[19.4  19.4   0.75]
[ 0.11267112 -0.07436571  0.59682551]
[19.4  19.4   0.75]
[ 0.11327024 -0.06048801  0.59518555]
[19.4  19.4   0.75]
[ 0.11654318 -0.05394639  0.59812316]
[19.4  19.4   0.75]
[ 0.11758278 -0.05197691  0.59891475]
[19.4  19.4   0.75]
[ 0.11653    -0.05473438  0.59807364]
[19.4  19.4   0.75]
[ 0.11357464 -0.06246804  0.59578361]
[19.4  19.4   0.75]
[ 0.11314282 -0.06625576  0.59602086]
[19.4  19.4   0.75]
[ 0.11318259 -0.06298714  0.59540948]
[19.4  19.4   0.75]
[ 0.11317029 -0.06364419  0.5955207 ]
[19.4  19.4   0.75]
[ 0.11321195 -0.0637158   0.59558514]
[19.4  19.4   0.75]
[ 0.11322367 -0.06366395  0.59558852]
[19.4  19.4   0.75]
[ 0.11322473 -0.06365979  0.59558897]
[19.4  19.4   0.75]
[ 0.11322463 -0.06366078  0.59558906]
[19.4  19.4   0.75]
[ 0.1132246  -0.0636609   0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366089  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]
[ 0.1132246  -0.06366088  0.59558904]
[19.4  19.4   0.75]/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Traceback (most recent call last):
  File "ddpg.py", line 199, in <module>
    env = stable_baselines3.common.env_util.make_vec_env(
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 102, in make_vec_env
    return vec_env_cls([make_env(i + start_index) for i in range(n_envs)], **vec_env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/.local/lib/python3.8/site-packages/stable_baselines3/common/env_util.py", line 77, in _init
    env = gym.make(env_id, **env_kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/registration.py", line 60, in make
    env = cls(**_kwargs)
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 248, in __init__
    super(AntEnvV2, self).__init__(path)
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 83, in __init__
    mujoco_env.MujocoEnv.__init__(self, path, 5)
  File "/home/shandilya/.local/lib/python3.8/site-packages/gym/envs/mujoco/mujoco_env.py", line 61, in __init__
    self._set_action_space()
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 112, in _set_action_space
    self.desired_motions = self._create_desired_goal_lst()
  File "/home/shandilya/Desktop/CNS/AntController/src/simulations/gym/ant.py", line 256, in _create_desired_goal_lst
    self.desired_motions.append(np.array([self.xpos[i], self.ypos[i], self.h], dtype = np.float32))
IndexError: index 50 is out of bounds for axis 0 with size 50
2021-05-27 10:25:48.348555: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/home/shandilya/.mujoco/mjpro150/bin
2021-05-27 10:25:48.348626: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Creating window glfw
MultiInputPolicy
Using cpu device
[Actor] Version 4
[Actor] Version 4
[400, 300]
[400, 300]
Logging to rl/out_dir/models/exp66/TD3_13
---------------------------------
| forward_vel        | 0.569    |
| reward             | 0.0491   |
| reward_contact     | 0        |
| reward_ctrl        | -1.52    |
| reward_position    | 1.6e-07  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 340      |
|    ep_rew_mean     | 31.5     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 63       |
|    time_elapsed    | 21       |
|    total timesteps | 1358     |
---------------------------------
---------------------------------
| forward_vel        | 0.863    |
| reward             | 0.402    |
| reward_contact     | 0        |
| reward_ctrl        | -1.47    |
| reward_position    | 0.00557  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 234      |
|    ep_rew_mean     | 46       |
| time/              |          |
|    episodes        | 8        |
|    fps             | 65       |
|    time_elapsed    | 28       |
|    total timesteps | 1876     |
---------------------------------
Num timesteps: 2000
Best mean reward: -inf - Last mean reward per episode: 41.34
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(-996.85418, 24.428637623519162)
---------------------------------
| forward_vel        | 0.443    |
| reward             | -0.266   |
| reward_contact     | -0.00229 |
| reward_ctrl        | -1.71    |
| reward_position    | 0.00212  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 41.8     |
| time/              |          |
|    episodes        | 12       |
|    fps             | 6        |
|    time_elapsed    | 327      |
|    total timesteps | 2141     |
---------------------------------
---------------------------------
| forward_vel        | 0.621    |
| reward             | -0.00696 |
| reward_contact     | -0.00195 |
| reward_ctrl        | -1.63    |
| reward_position    | 0.00375  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 211      |
|    ep_rew_mean     | 43.3     |
| time/              |          |
|    episodes        | 16       |
|    fps             | 9        |
|    time_elapsed    | 343      |
|    total timesteps | 3386     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 40.2     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 10       |
|    time_elapsed    | 346      |
|    total timesteps | 3579     |
---------------------------------
---------------------------------
| forward_vel        | 0.616    |
| reward             | 0.0227   |
| reward_contact     | -0.00166 |
| reward_ctrl        | -1.6     |
| reward_position    | 0.00312  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 158      |
|    ep_rew_mean     | 39.3     |
| time/              |          |
|    episodes        | 24       |
|    fps             | 10       |
|    time_elapsed    | 348      |
|    total timesteps | 3796     |
---------------------------------
Num timesteps: 4000
Best mean reward: 41.34 - Last mean reward per episode: -257.64
---------------------------------
| forward_vel        | 0.767    |
| reward             | 0.202    |
| reward_contact     | -0.00143 |
| reward_ctrl        | -1.57    |
| reward_position    | 0.00268  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 36.2     |
| time/              |          |
|    episodes        | 28       |
|    fps             | 13       |
|    time_elapsed    | 362      |
|    total timesteps | 4854     |
---------------------------------
Num timesteps: 6000
Best mean reward: 41.34 - Last mean reward per episode: -233.63
---------------------------------
| forward_vel        | 0.871    |
| reward             | 0.31     |
| reward_contact     | -0.00125 |
| reward_ctrl        | -1.57    |
| reward_position    | 0.00812  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 187      |
|    ep_rew_mean     | 12       |
| time/              |          |
|    episodes        | 32       |
|    fps             | 14       |
|    time_elapsed    | 422      |
|    total timesteps | 6004     |
| train/             |          |
|    actor_loss      | -0.727   |
|    critic_loss     | 0.553    |
|    learning_rate   | 0.001    |
|    n_updates       | 1000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 170      |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    episodes        | 36       |
|    fps             | 14       |
|    time_elapsed    | 431      |
|    total timesteps | 6147     |
| train/             |          |
|    actor_loss      | -1.01    |
|    critic_loss     | 0.585    |
|    learning_rate   | 0.001    |
|    n_updates       | 1145     |
---------------------------------
Num timesteps: 8000
Best mean reward: 41.34 - Last mean reward per episode: -178.51
---------------------------------
| forward_vel        | 0.934    |
| reward             | 0.347    |
| reward_contact     | -0.0012  |
| reward_ctrl        | -1.59    |
| reward_position    | 0.00679  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 205      |
|    ep_rew_mean     | 53.1     |
| time/              |          |
|    episodes        | 40       |
|    fps             | 14       |
|    time_elapsed    | 550      |
|    total timesteps | 8201     |
| train/             |          |
|    actor_loss      | -7.01    |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.001    |
|    n_updates       | 3200     |
---------------------------------
Num timesteps: 10000
Best mean reward: 41.34 - Last mean reward per episode: -135.31
---------------------------------
| forward_vel        | 0.916    |
| reward             | 0.371    |
| reward_contact     | -0.00122 |
| reward_ctrl        | -1.55    |
| reward_position    | 0.00628  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | 107      |
| time/              |          |
|    episodes        | 44       |
|    fps             | 15       |
|    time_elapsed    | 716      |
|    total timesteps | 11014    |
| train/             |          |
|    actor_loss      | -16.1    |
|    critic_loss     | 1.52     |
|    learning_rate   | 0.001    |
|    n_updates       | 6010     |
---------------------------------
Num timesteps: 12000
Best mean reward: 41.34 - Last mean reward per episode: -77.78
---------------------------------
| forward_vel        | 0.929    |
| reward             | 0.41     |
| reward_contact     | -0.00113 |
| reward_ctrl        | -1.52    |
| reward_position    | 0.00584  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 262      |
|    ep_rew_mean     | 130      |
| time/              |          |
|    episodes        | 48       |
|    fps             | 15       |
|    time_elapsed    | 810      |
|    total timesteps | 12596    |
| train/             |          |
|    actor_loss      | -21.9    |
|    critic_loss     | 2.12     |
|    learning_rate   | 0.001    |
|    n_updates       | 7595     |
---------------------------------
---------------------------------
| forward_vel        | 0.935    |
| reward             | 0.432    |
| reward_contact     | -0.00109 |
| reward_ctrl        | -1.51    |
| reward_position    | 0.00546  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | 131      |
| time/              |          |
|    episodes        | 52       |
|    fps             | 15       |
|    time_elapsed    | 834      |
|    total timesteps | 13019    |
| train/             |          |
|    actor_loss      | -23      |
|    critic_loss     | 2.55     |
|    learning_rate   | 0.001    |
|    n_updates       | 8015     |
---------------------------------
Num timesteps: 14000
Best mean reward: 41.34 - Last mean reward per episode: -51.22
Num timesteps: 16000
Best mean reward: 41.34 - Last mean reward per episode: -21.98
---------------------------------
| forward_vel        | 0.92     |
| reward             | 0.395    |
| reward_contact     | -0.00113 |
| reward_ctrl        | -1.53    |
| reward_position    | 0.00512  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 286      |
|    ep_rew_mean     | 158      |
| time/              |          |
|    episodes        | 56       |
|    fps             | 15       |
|    time_elapsed    | 1010     |
|    total timesteps | 16040    |
| train/             |          |
|    actor_loss      | -31.1    |
|    critic_loss     | 3.58     |
|    learning_rate   | 0.001    |
|    n_updates       | 11035    |
---------------------------------
---------------------------------
| forward_vel        | 0.902    |
| reward             | 0.38     |
| reward_contact     | -0.0011  |
| reward_ctrl        | -1.53    |
| reward_position    | 0.00497  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 298      |
|    ep_rew_mean     | 173      |
| time/              |          |
|    episodes        | 60       |
|    fps             | 15       |
|    time_elapsed    | 1119     |
|    total timesteps | 17879    |
| train/             |          |
|    actor_loss      | -35.9    |
|    critic_loss     | 3        |
|    learning_rate   | 0.001    |
|    n_updates       | 12875    |
---------------------------------
Num timesteps: 18000
Best mean reward: 41.34 - Last mean reward per episode: 7.54
---------------------------------
| forward_vel        | 0.92     |
| reward             | 0.426    |
| reward_contact     | -0.00103 |
| reward_ctrl        | -1.5     |
| reward_position    | 0.00462  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 283      |
|    ep_rew_mean     | 167      |
| time/              |          |
|    episodes        | 64       |
|    fps             | 15       |
|    time_elapsed    | 1133     |
|    total timesteps | 18119    |
| train/             |          |
|    actor_loss      | -36.1    |
|    critic_loss     | 2.63     |
|    learning_rate   | 0.001    |
|    n_updates       | 13115    |
---------------------------------
Num timesteps: 20000
Best mean reward: 41.34 - Last mean reward per episode: 19.11
---------------------------------
| forward_vel        | 0.922    |
| reward             | 0.404    |
| reward_contact     | -0.00096 |
| reward_ctrl        | -1.52    |
| reward_position    | 0.00433  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 298      |
|    ep_rew_mean     | 175      |
| time/              |          |
|    episodes        | 68       |
|    fps             | 16       |
|    time_elapsed    | 1258     |
|    total timesteps | 20246    |
| train/             |          |
|    actor_loss      | -40.3    |
|    critic_loss     | 2.69     |
|    learning_rate   | 0.001    |
|    n_updates       | 15245    |
---------------------------------
Num timesteps: 22000
Best mean reward: 41.34 - Last mean reward per episode: 36.49
----------------------------------
| forward_vel        | 0.922     |
| reward             | 0.413     |
| reward_contact     | -0.000957 |
| reward_ctrl        | -1.51     |
| reward_position    | 0.00417   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 312       |
|    ep_rew_mean     | 190       |
| time/              |           |
|    episodes        | 72        |
|    fps             | 15        |
|    time_elapsed    | 1421      |
|    total timesteps | 22454     |
| train/             |           |
|    actor_loss      | -45.1     |
|    critic_loss     | 2.53      |
|    learning_rate   | 0.001     |
|    n_updates       | 17450     |
----------------------------------
Num timesteps: 24000
Best mean reward: 41.34 - Last mean reward per episode: 54.48
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(97.3767144, 54.682486412207304)
----------------------------------
| forward_vel        | 1.02      |
| reward             | 0.437     |
| reward_contact     | -0.000892 |
| reward_ctrl        | -1.58     |
| reward_position    | 0.00654   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 318       |
|    ep_rew_mean     | 200       |
| time/              |           |
|    episodes        | 76        |
|    fps             | 15        |
|    time_elapsed    | 1566      |
|    total timesteps | 24528     |
| train/             |           |
|    actor_loss      | -47.8     |
|    critic_loss     | 3.46      |
|    learning_rate   | 0.001     |
|    n_updates       | 19525     |
----------------------------------
Num timesteps: 26000
Best mean reward: 54.48 - Last mean reward per episode: 76.92
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(587.2426389999999, 427.77526158236765)
----------------------------------
| forward_vel        | 1.01      |
| reward             | 0.471     |
| reward_contact     | -0.000916 |
| reward_ctrl        | -1.55     |
| reward_position    | 0.0138    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 332       |
|    ep_rew_mean     | 218       |
| time/              |           |
|    episodes        | 80        |
|    fps             | 14        |
|    time_elapsed    | 1877      |
|    total timesteps | 26884     |
| train/             |           |
|    actor_loss      | -51.2     |
|    critic_loss     | 2.98      |
|    learning_rate   | 0.001     |
|    n_updates       | 21880     |
----------------------------------
Num timesteps: 28000
Best mean reward: 76.92 - Last mean reward per episode: 161.58
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(356.87378879999994, 295.27178655653904)
---------------------------------
| forward_vel        | 1.17     |
| reward             | 0.667    |
| reward_contact     | -0.00054 |
| reward_ctrl        | -1.52    |
| reward_position    | 0.0144   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 331      |
|    ep_rew_mean     | 218      |
| time/              |          |
|    episodes        | 84       |
|    fps             | 13       |
|    time_elapsed    | 2090     |
|    total timesteps | 29022    |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 3.15     |
|    learning_rate   | 0.001    |
|    n_updates       | 24020    |
---------------------------------
Num timesteps: 30000
Best mean reward: 161.58 - Last mean reward per episode: 280.88
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(281.010544, 247.92777064593787)
Num timesteps: 32000
Best mean reward: 280.88 - Last mean reward per episode: 316.28
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(357.9387028, 300.66529930899975)
----------------------------------
| forward_vel        | 1.14      |
| reward             | 0.717     |
| reward_contact     | -0.000614 |
| reward_ctrl        | -1.44     |
| reward_position    | 0.0125    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 333       |
|    ep_rew_mean     | 225       |
| time/              |           |
|    episodes        | 88        |
|    fps             | 13        |
|    time_elapsed    | 2459      |
|    total timesteps | 32413     |
| train/             |           |
|    actor_loss      | -60.2     |
|    critic_loss     | 4.16      |
|    learning_rate   | 0.001     |
|    n_updates       | 27410     |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 322      |
|    ep_rew_mean     | 219      |
| time/              |          |
|    episodes        | 92       |
|    fps             | 13       |
|    time_elapsed    | 2476     |
|    total timesteps | 32703    |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 3.14     |
|    learning_rate   | 0.001    |
|    n_updates       | 27700    |
---------------------------------
Num timesteps: 34000
Best mean reward: 316.28 - Last mean reward per episode: 334.17
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(564.3101896, 386.77708386367226)
----------------------------------
| forward_vel        | 1.19      |
| reward             | 0.769     |
| reward_contact     | -0.000557 |
| reward_ctrl        | -1.43     |
| reward_position    | 0.0132    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 329       |
|    ep_rew_mean     | 230       |
| time/              |           |
|    episodes        | 96        |
|    fps             | 12        |
|    time_elapsed    | 2780      |
|    total timesteps | 35000     |
| train/             |           |
|    actor_loss      | -64.5     |
|    critic_loss     | 4.23      |
|    learning_rate   | 0.001     |
|    n_updates       | 29995     |
----------------------------------
Num timesteps: 36000
Best mean reward: 334.17 - Last mean reward per episode: 359.83
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(730.8935662, 293.67268252730025)
Num timesteps: 38000
Best mean reward: 359.83 - Last mean reward per episode: 412.52
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(442.8559888000001, 362.5935961396851)
----------------------------------
| forward_vel        | 1.19      |
| reward             | 0.866     |
| reward_contact     | -0.000655 |
| reward_ctrl        | -1.33     |
| reward_position    | 0.0114    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 347       |
|    ep_rew_mean     | 241       |
| time/              |           |
|    episodes        | 100       |
|    fps             | 11        |
|    time_elapsed    | 3378      |
|    total timesteps | 39000     |
| train/             |           |
|    actor_loss      | -69.1     |
|    critic_loss     | 4.27      |
|    learning_rate   | 0.001     |
|    n_updates       | 33995     |
----------------------------------
Num timesteps: 40000
Best mean reward: 412.52 - Last mean reward per episode: 435.92
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(270.66002850000007, 259.36400308350636)
----------------------------------
| forward_vel        | 1.18      |
| reward             | 0.906     |
| reward_contact     | -0.000645 |
| reward_ctrl        | -1.28     |
| reward_position    | 0.00528   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 355       |
|    ep_rew_mean     | 255       |
| time/              |           |
|    episodes        | 104       |
|    fps             | 11        |
|    time_elapsed    | 3599      |
|    total timesteps | 41214     |
| train/             |           |
|    actor_loss      | -70.9     |
|    critic_loss     | 4.76      |
|    learning_rate   | 0.001     |
|    n_updates       | 36210     |
----------------------------------
Num timesteps: 42000
Best mean reward: 435.92 - Last mean reward per episode: 408.02
----------------------------------
| forward_vel        | 1.19      |
| reward             | 0.917     |
| reward_contact     | -0.000648 |
| reward_ctrl        | -1.28     |
| reward_position    | 0.00528   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 373       |
|    ep_rew_mean     | 269       |
| time/              |           |
|    episodes        | 108       |
|    fps             | 11        |
|    time_elapsed    | 3735      |
|    total timesteps | 43570     |
| train/             |           |
|    actor_loss      | -72.1     |
|    critic_loss     | 5.09      |
|    learning_rate   | 0.001     |
|    n_updates       | 38565     |
----------------------------------
----------------------------------
| forward_vel        | 1.18      |
| reward             | 0.914     |
| reward_contact     | -0.000665 |
| reward_ctrl        | -1.27     |
| reward_position    | 0.00528   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 375       |
|    ep_rew_mean     | 273       |
| time/              |           |
|    episodes        | 112       |
|    fps             | 11        |
|    time_elapsed    | 3757      |
|    total timesteps | 43941     |
| train/             |           |
|    actor_loss      | -72.8     |
|    critic_loss     | 6.6       |
|    learning_rate   | 0.001     |
|    n_updates       | 38940     |
----------------------------------
Num timesteps: 44000
Best mean reward: 435.92 - Last mean reward per episode: 400.90
----------------------------------
| forward_vel        | 1.23      |
| reward             | 0.976     |
| reward_contact     | -0.000635 |
| reward_ctrl        | -1.25     |
| reward_position    | 0.00489   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 370       |
|    ep_rew_mean     | 282       |
| time/              |           |
|    episodes        | 116       |
|    fps             | 11        |
|    time_elapsed    | 3806      |
|    total timesteps | 44766     |
| train/             |           |
|    actor_loss      | -70.5     |
|    critic_loss     | 9.83      |
|    learning_rate   | 0.001     |
|    n_updates       | 39765     |
----------------------------------
Num timesteps: 46000
Best mean reward: 435.92 - Last mean reward per episode: 403.11
Num timesteps: 48000
Best mean reward: 435.92 - Last mean reward per episode: 419.42
---------------------------------
| forward_vel        | 1.17     |
| reward             | 0.874    |
| reward_contact     | -0.00068 |
| reward_ctrl        | -1.31    |
| reward_position    | 0.0134   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 408      |
|    ep_rew_mean     | 316      |
| time/              |          |
|    episodes        | 120      |
|    fps             | 12       |
|    time_elapsed    | 4051     |
|    total timesteps | 48766    |
| train/             |          |
|    actor_loss      | -76.7    |
|    critic_loss     | 3.62     |
|    learning_rate   | 0.001    |
|    n_updates       | 43765    |
---------------------------------
----------------------------------
| forward_vel        | 1.16      |
| reward             | 0.859     |
| reward_contact     | -0.000692 |
| reward_ctrl        | -1.31     |
| reward_position    | 0.0134    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 418       |
|    ep_rew_mean     | 327       |
| time/              |           |
|    episodes        | 124       |
|    fps             | 12        |
|    time_elapsed    | 4119      |
|    total timesteps | 49935     |
| train/             |           |
|    actor_loss      | -77       |
|    critic_loss     | 4.79      |
|    learning_rate   | 0.001     |
|    n_updates       | 44930     |
----------------------------------
Num timesteps: 50000
Best mean reward: 435.92 - Last mean reward per episode: 418.56
----------------------------------
| forward_vel        | 1.16      |
| reward             | 0.893     |
| reward_contact     | -0.000614 |
| reward_ctrl        | -1.28     |
| reward_position    | 0.0154    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 424       |
|    ep_rew_mean     | 345       |
| time/              |           |
|    episodes        | 128       |
|    fps             | 12        |
|    time_elapsed    | 4218      |
|    total timesteps | 51623     |
| train/             |           |
|    actor_loss      | -77.4     |
|    critic_loss     | 3.69      |
|    learning_rate   | 0.001     |
|    n_updates       | 46620     |
----------------------------------
Num timesteps: 52000
Best mean reward: 435.92 - Last mean reward per episode: 431.02
----------------------------------
| forward_vel        | 1.15      |
| reward             | 0.874     |
| reward_contact     | -0.000633 |
| reward_ctrl        | -1.29     |
| reward_position    | 0.0154    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 435       |
|    ep_rew_mean     | 377       |
| time/              |           |
|    episodes        | 132       |
|    fps             | 12        |
|    time_elapsed    | 4349      |
|    total timesteps | 53883     |
| train/             |           |
|    actor_loss      | -76.3     |
|    critic_loss     | 4.45      |
|    learning_rate   | 0.001     |
|    n_updates       | 48880     |
----------------------------------
Num timesteps: 54000
Best mean reward: 435.92 - Last mean reward per episode: 449.42
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(448.4085593, 235.34220859526815)
Num timesteps: 56000
Best mean reward: 449.42 - Last mean reward per episode: 458.72
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(829.1559890000001, 475.7036412471594)
----------------------------------
| forward_vel        | 1.1       |
| reward             | 0.793     |
| reward_contact     | -0.000715 |
| reward_ctrl        | -1.32     |
| reward_position    | 0.0145    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 458       |
|    ep_rew_mean     | 394       |
| time/              |           |
|    episodes        | 136       |
|    fps             | 11        |
|    time_elapsed    | 4824      |
|    total timesteps | 57025     |
| train/             |           |
|    actor_loss      | -79.1     |
|    critic_loss     | 25.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 52020     |
----------------------------------
Num timesteps: 58000
Best mean reward: 458.72 - Last mean reward per episode: 502.24
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(402.8358442, 400.99212786934345)
Num timesteps: 60000
Best mean reward: 502.24 - Last mean reward per episode: 487.29
Num timesteps: 62000
Best mean reward: 502.24 - Last mean reward per episode: 478.83
----------------------------------
| forward_vel        | 1.14      |
| reward             | 0.733     |
| reward_contact     | -0.000792 |
| reward_ctrl        | -1.43     |
| reward_position    | 0.0273    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 478       |
|    ep_rew_mean     | 395       |
| time/              |           |
|    episodes        | 140       |
|    fps             | 11        |
|    time_elapsed    | 5204      |
|    total timesteps | 62000     |
| train/             |           |
|    actor_loss      | -83.9     |
|    critic_loss     | 4.24      |
|    learning_rate   | 0.001     |
|    n_updates       | 56995     |
----------------------------------
Num timesteps: 64000
Best mean reward: 502.24 - Last mean reward per episode: 476.92
Num timesteps: 66000
Best mean reward: 502.24 - Last mean reward per episode: 475.84
----------------------------------
| forward_vel        | 1.12      |
| reward             | 0.705     |
| reward_contact     | -0.000772 |
| reward_ctrl        | -1.44     |
| reward_position    | 0.0273    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 489       |
|    ep_rew_mean     | 394       |
| time/              |           |
|    episodes        | 144       |
|    fps             | 12        |
|    time_elapsed    | 5484      |
|    total timesteps | 66000     |
| train/             |           |
|    actor_loss      | -86.6     |
|    critic_loss     | 6.57      |
|    learning_rate   | 0.001     |
|    n_updates       | 60995     |
----------------------------------
----------------------------------
| forward_vel        | 1.07      |
| reward             | 0.634     |
| reward_contact     | -0.000756 |
| reward_ctrl        | -1.46     |
| reward_position    | 0.0276    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 486       |
|    ep_rew_mean     | 387       |
| time/              |           |
|    episodes        | 148       |
|    fps             | 12        |
|    time_elapsed    | 5558      |
|    total timesteps | 67232     |
| train/             |           |
|    actor_loss      | -83       |
|    critic_loss     | 5.17      |
|    learning_rate   | 0.001     |
|    n_updates       | 62230     |
----------------------------------
Num timesteps: 68000
Best mean reward: 502.24 - Last mean reward per episode: 458.06
Num timesteps: 70000
Best mean reward: 502.24 - Last mean reward per episode: 454.44
----------------------------------
| forward_vel        | 1.06      |
| reward             | 0.603     |
| reward_contact     | -0.000751 |
| reward_ctrl        | -1.48     |
| reward_position    | 0.0276    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 513       |
|    ep_rew_mean     | 398       |
| time/              |           |
|    episodes        | 152       |
|    fps             | 12        |
|    time_elapsed    | 5744      |
|    total timesteps | 70316     |
| train/             |           |
|    actor_loss      | -86.7     |
|    critic_loss     | 4.8       |
|    learning_rate   | 0.001     |
|    n_updates       | 65315     |
----------------------------------
Num timesteps: 72000
Best mean reward: 502.24 - Last mean reward per episode: 464.83
----------------------------------
| forward_vel        | 1.05      |
| reward             | 0.586     |
| reward_contact     | -0.000735 |
| reward_ctrl        | -1.49     |
| reward_position    | 0.0276    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 506       |
|    ep_rew_mean     | 398       |
| time/              |           |
|    episodes        | 156       |
|    fps             | 12        |
|    time_elapsed    | 5884      |
|    total timesteps | 72638     |
| train/             |           |
|    actor_loss      | -82.2     |
|    critic_loss     | 5         |
|    learning_rate   | 0.001     |
|    n_updates       | 67635     |
----------------------------------
Num timesteps: 74000
Best mean reward: 502.24 - Last mean reward per episode: 469.85
----------------------------------
| forward_vel        | 1.02      |
| reward             | 0.576     |
| reward_contact     | -0.000769 |
| reward_ctrl        | -1.47     |
| reward_position    | 0.0286    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 519       |
|    ep_rew_mean     | 417       |
| time/              |           |
|    episodes        | 160       |
|    fps             | 12        |
|    time_elapsed    | 6075      |
|    total timesteps | 75852     |
| train/             |           |
|    actor_loss      | -84       |
|    critic_loss     | 5.11      |
|    learning_rate   | 0.001     |
|    n_updates       | 70850     |
----------------------------------
Num timesteps: 76000
Best mean reward: 502.24 - Last mean reward per episode: 474.62
Num timesteps: 78000
Best mean reward: 502.24 - Last mean reward per episode: 484.84
----------------------------------
| forward_vel        | 1.01      |
| reward             | 0.586     |
| reward_contact     | -0.000796 |
| reward_ctrl        | -1.45     |
| reward_position    | 0.0308    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 548       |
|    ep_rew_mean     | 447       |
| time/              |           |
|    episodes        | 164       |
|    fps             | 12        |
|    time_elapsed    | 6257      |
|    total timesteps | 78913     |
| train/             |           |
|    actor_loss      | -89.3     |
|    critic_loss     | 4.56      |
|    learning_rate   | 0.001     |
|    n_updates       | 73910     |
----------------------------------
Num timesteps: 80000
Best mean reward: 502.24 - Last mean reward per episode: 490.76
----------------------------------
| forward_vel        | 1.03      |
| reward             | 0.618     |
| reward_contact     | -0.000766 |
| reward_ctrl        | -1.44     |
| reward_position    | 0.0308    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 550       |
|    ep_rew_mean     | 458       |
| time/              |           |
|    episodes        | 168       |
|    fps             | 12        |
|    time_elapsed    | 6401      |
|    total timesteps | 81314     |
| train/             |           |
|    actor_loss      | -90.3     |
|    critic_loss     | 11.2      |
|    learning_rate   | 0.001     |
|    n_updates       | 76310     |
----------------------------------
Num timesteps: 82000
Best mean reward: 502.24 - Last mean reward per episode: 505.16
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(729.2090216999999, 328.7762981342257)
Num timesteps: 84000
Best mean reward: 505.16 - Last mean reward per episode: 557.42
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(422.887449, 301.90006636136343)
----------------------------------
| forward_vel        | 0.945     |
| reward             | 0.492     |
| reward_contact     | -0.000802 |
| reward_ctrl        | -1.47     |
| reward_position    | 0.0211    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 557       |
|    ep_rew_mean     | 471       |
| time/              |           |
|    episodes        | 172       |
|    fps             | 12        |
|    time_elapsed    | 6950      |
|    total timesteps | 85136     |
| train/             |           |
|    actor_loss      | -89.9     |
|    critic_loss     | 5.18      |
|    learning_rate   | 0.001     |
|    n_updates       | 80135     |
----------------------------------
Num timesteps: 86000
Best mean reward: 557.42 - Last mean reward per episode: 556.88
----------------------------------
| forward_vel        | 0.904     |
| reward             | 0.474     |
| reward_contact     | -0.000864 |
| reward_ctrl        | -1.46     |
| reward_position    | 0.0261    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 562       |
|    ep_rew_mean     | 476       |
| time/              |           |
|    episodes        | 176       |
|    fps             | 12        |
|    time_elapsed    | 7086      |
|    total timesteps | 87409     |
| train/             |           |
|    actor_loss      | -91.7     |
|    critic_loss     | 7.8       |
|    learning_rate   | 0.001     |
|    n_updates       | 82405     |
----------------------------------
Num timesteps: 88000
Best mean reward: 557.42 - Last mean reward per episode: 565.30
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(919.9431477, 322.51854394593545)
Num timesteps: 90000
Best mean reward: 565.30 - Last mean reward per episode: 614.13
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1251.0044801999998, 295.62021619823673)
----------------------------------
| forward_vel        | 0.828     |
| reward             | 0.467     |
| reward_contact     | -0.000853 |
| reward_ctrl        | -1.39     |
| reward_position    | 0.0256    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 568       |
|    ep_rew_mean     | 483       |
| time/              |           |
|    episodes        | 180       |
|    fps             | 11        |
|    time_elapsed    | 7798      |
|    total timesteps | 91083     |
| train/             |           |
|    actor_loss      | -95       |
|    critic_loss     | 6.85      |
|    learning_rate   | 0.001     |
|    n_updates       | 86080     |
----------------------------------
Num timesteps: 92000
Best mean reward: 614.13 - Last mean reward per episode: 660.07
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(686.4244253999999, 314.8308857168966)
Num timesteps: 94000
Best mean reward: 660.07 - Last mean reward per episode: 688.84
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1176.2924027000001, 449.61095360134294)
----------------------------------
| forward_vel        | 0.75      |
| reward             | 0.433     |
| reward_contact     | -0.000748 |
| reward_ctrl        | -1.33     |
| reward_position    | 0.015     |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 588       |
|    ep_rew_mean     | 506       |
| time/              |           |
|    episodes        | 184       |
|    fps             | 11        |
|    time_elapsed    | 8506      |
|    total timesteps | 95350     |
| train/             |           |
|    actor_loss      | -91       |
|    critic_loss     | 6.25      |
|    learning_rate   | 0.001     |
|    n_updates       | 90345     |
----------------------------------
Num timesteps: 96000
Best mean reward: 688.84 - Last mean reward per episode: 768.14
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(766.9832725, 381.2683245732964)
Num timesteps: 98000
Best mean reward: 768.14 - Last mean reward per episode: 806.84
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(757.7749087, 482.31428012463863)
----------------------------------
| forward_vel        | 0.757     |
| reward             | 0.501     |
| reward_contact     | -0.000785 |
| reward_ctrl        | -1.27     |
| reward_position    | 0.0161    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 600       |
|    ep_rew_mean     | 512       |
| time/              |           |
|    episodes        | 188       |
|    fps             | 10        |
|    time_elapsed    | 9033      |
|    total timesteps | 98111     |
| train/             |           |
|    actor_loss      | -94.7     |
|    critic_loss     | 6.35      |
|    learning_rate   | 0.001     |
|    n_updates       | 93110     |
----------------------------------
Num timesteps: 100000
Best mean reward: 806.84 - Last mean reward per episode: 800.84
Num timesteps: 102000
Best mean reward: 806.84 - Last mean reward per episode: 797.76
----------------------------------
| forward_vel        | 0.768     |
| reward             | 0.519     |
| reward_contact     | -0.000788 |
| reward_ctrl        | -1.26     |
| reward_position    | 0.0161    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 637       |
|    ep_rew_mean     | 543       |
| time/              |           |
|    episodes        | 192       |
|    fps             | 11        |
|    time_elapsed    | 9272      |
|    total timesteps | 102111    |
| train/             |           |
|    actor_loss      | -95.9     |
|    critic_loss     | 5.75      |
|    learning_rate   | 0.001     |
|    n_updates       | 97110     |
----------------------------------
Num timesteps: 104000
Best mean reward: 806.84 - Last mean reward per episode: 803.69
----------------------------------
| forward_vel        | 0.778     |
| reward             | 0.545     |
| reward_contact     | -0.000752 |
| reward_ctrl        | -1.25     |
| reward_position    | 0.0144    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 641       |
|    ep_rew_mean     | 552       |
| time/              |           |
|    episodes        | 196       |
|    fps             | 11        |
|    time_elapsed    | 9431      |
|    total timesteps | 104554    |
| train/             |           |
|    actor_loss      | -96.3     |
|    critic_loss     | 5.59      |
|    learning_rate   | 0.001     |
|    n_updates       | 99550     |
----------------------------------
Num timesteps: 106000
Best mean reward: 806.84 - Last mean reward per episode: 809.45
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(870.6975359999999, 562.7329842211306)
Num timesteps: 108000
Best mean reward: 809.45 - Last mean reward per episode: 856.59
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(580.8247947, 375.39306548844905)
----------------------------------
| forward_vel        | 0.774     |
| reward             | 0.585     |
| reward_contact     | -0.000834 |
| reward_ctrl        | -1.2      |
| reward_position    | 0.0145    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 642       |
|    ep_rew_mean     | 566       |
| time/              |           |
|    episodes        | 200       |
|    fps             | 10        |
|    time_elapsed    | 9975      |
|    total timesteps | 108000    |
| train/             |           |
|    actor_loss      | -99.9     |
|    critic_loss     | 7.49      |
|    learning_rate   | 0.001     |
|    n_updates       | 102995    |
----------------------------------
Num timesteps: 110000
Best mean reward: 856.59 - Last mean reward per episode: 841.04
----------------------------------
| forward_vel        | 0.764     |
| reward             | 0.609     |
| reward_contact     | -0.000887 |
| reward_ctrl        | -1.16     |
| reward_position    | 0.00797   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 651       |
|    ep_rew_mean     | 586       |
| time/              |           |
|    episodes        | 204       |
|    fps             | 10        |
|    time_elapsed    | 10160     |
|    total timesteps | 111094    |
| train/             |           |
|    actor_loss      | -99.7     |
|    critic_loss     | 4.49      |
|    learning_rate   | 0.001     |
|    n_updates       | 106090    |
----------------------------------
Num timesteps: 112000
Best mean reward: 856.59 - Last mean reward per episode: 841.44
----------------------------------
| forward_vel        | 0.787     |
| reward             | 0.638     |
| reward_contact     | -0.000879 |
| reward_ctrl        | -1.16     |
| reward_position    | 0.00818   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 645       |
|    ep_rew_mean     | 594       |
| time/              |           |
|    episodes        | 208       |
|    fps             | 10        |
|    time_elapsed    | 10264     |
|    total timesteps | 112843    |
| train/             |           |
|    actor_loss      | -95.7     |
|    critic_loss     | 5.41      |
|    learning_rate   | 0.001     |
|    n_updates       | 107840    |
----------------------------------
Num timesteps: 114000
Best mean reward: 856.59 - Last mean reward per episode: 826.26
----------------------------------
| forward_vel        | 0.8       |
| reward             | 0.662     |
| reward_contact     | -0.000893 |
| reward_ctrl        | -1.14     |
| reward_position    | 0.00818   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 666       |
|    ep_rew_mean     | 622       |
| time/              |           |
|    episodes        | 212       |
|    fps             | 11        |
|    time_elapsed    | 10419     |
|    total timesteps | 115277    |
| train/             |           |
|    actor_loss      | -99.5     |
|    critic_loss     | 5.03      |
|    learning_rate   | 0.001     |
|    n_updates       | 110275    |
----------------------------------
Num timesteps: 116000
Best mean reward: 856.59 - Last mean reward per episode: 803.19
Num timesteps: 118000
Best mean reward: 856.59 - Last mean reward per episode: 803.38
----------------------------------
| forward_vel        | 0.833     |
| reward             | 0.685     |
| reward_contact     | -0.000909 |
| reward_ctrl        | -1.16     |
| reward_position    | 0.00818   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 695       |
|    ep_rew_mean     | 655       |
| time/              |           |
|    episodes        | 216       |
|    fps             | 11        |
|    time_elapsed    | 10643     |
|    total timesteps | 119039    |
| train/             |           |
|    actor_loss      | -98.2     |
|    critic_loss     | 4.74      |
|    learning_rate   | 0.001     |
|    n_updates       | 114035    |
----------------------------------
Num timesteps: 120000
Best mean reward: 856.59 - Last mean reward per episode: 808.58
----------------------------------
| forward_vel        | 0.839     |
| reward             | 0.689     |
| reward_contact     | -0.000896 |
| reward_ctrl        | -1.16     |
| reward_position    | 0.00827   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 683       |
|    ep_rew_mean     | 656       |
| time/              |           |
|    episodes        | 220       |
|    fps             | 11        |
|    time_elapsed    | 10805     |
|    total timesteps | 121836    |
| train/             |           |
|    actor_loss      | -101      |
|    critic_loss     | 5.44      |
|    learning_rate   | 0.001     |
|    n_updates       | 116835    |
----------------------------------
Num timesteps: 122000
Best mean reward: 856.59 - Last mean reward per episode: 806.76
Num timesteps: 124000
Best mean reward: 856.59 - Last mean reward per episode: 813.50
----------------------------------
| forward_vel        | 0.794     |
| reward             | 0.676     |
| reward_contact     | -0.000952 |
| reward_ctrl        | -1.13     |
| reward_position    | 0.00827   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 695       |
|    ep_rew_mean     | 663       |
| time/              |           |
|    episodes        | 224       |
|    fps             | 11        |
|    time_elapsed    | 10943     |
|    total timesteps | 124163    |
| train/             |           |
|    actor_loss      | -101      |
|    critic_loss     | 5.38      |
|    learning_rate   | 0.001     |
|    n_updates       | 119160    |
----------------------------------
Num timesteps: 126000
Best mean reward: 856.59 - Last mean reward per episode: 798.38
----------------------------------
| forward_vel        | 0.826     |
| reward             | 0.685     |
| reward_contact     | -0.000941 |
| reward_ctrl        | -1.15     |
| reward_position    | 0.00542   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 698       |
|    ep_rew_mean     | 672       |
| time/              |           |
|    episodes        | 228       |
|    fps             | 11        |
|    time_elapsed    | 11062     |
|    total timesteps | 126210    |
| train/             |           |
|    actor_loss      | -103      |
|    critic_loss     | 5.62      |
|    learning_rate   | 0.001     |
|    n_updates       | 121205    |
----------------------------------
Num timesteps: 128000
Best mean reward: 856.59 - Last mean reward per episode: 804.19
Num timesteps: 130000
Best mean reward: 856.59 - Last mean reward per episode: 811.87
----------------------------------
| forward_vel        | 0.822     |
| reward             | 0.701     |
| reward_contact     | -0.000973 |
| reward_ctrl        | -1.13     |
| reward_position    | 0.00542   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 715       |
|    ep_rew_mean     | 694       |
| time/              |           |
|    episodes        | 232       |
|    fps             | 11        |
|    time_elapsed    | 11290     |
|    total timesteps | 130163    |
| train/             |           |
|    actor_loss      | -101      |
|    critic_loss     | 6.49      |
|    learning_rate   | 0.001     |
|    n_updates       | 125160    |
----------------------------------
Num timesteps: 132000
Best mean reward: 856.59 - Last mean reward per episode: 809.42
----------------------------------
| forward_vel        | 0.851     |
| reward             | 0.701     |
| reward_contact     | -0.000892 |
| reward_ctrl        | -1.16     |
| reward_position    | 0.0083    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 723       |
|    ep_rew_mean     | 710       |
| time/              |           |
|    episodes        | 236       |
|    fps             | 11        |
|    time_elapsed    | 11478     |
|    total timesteps | 133361    |
| train/             |           |
|    actor_loss      | -104      |
|    critic_loss     | 5.85      |
|    learning_rate   | 0.001     |
|    n_updates       | 128360    |
----------------------------------
Num timesteps: 134000
Best mean reward: 856.59 - Last mean reward per episode: 784.17
Num timesteps: 136000
Best mean reward: 856.59 - Last mean reward per episode: 794.34
----------------------------------
| forward_vel        | 0.856     |
| reward             | 0.696     |
| reward_contact     | -0.000874 |
| reward_ctrl        | -1.17     |
| reward_position    | 0.0104    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 722       |
|    ep_rew_mean     | 740       |
| time/              |           |
|    episodes        | 240       |
|    fps             | 11        |
|    time_elapsed    | 11704     |
|    total timesteps | 137252    |
| train/             |           |
|    actor_loss      | -103      |
|    critic_loss     | 6.3       |
|    learning_rate   | 0.001     |
|    n_updates       | 132250    |
----------------------------------
Num timesteps: 138000
Best mean reward: 856.59 - Last mean reward per episode: 782.07
----------------------------------
| forward_vel        | 0.864     |
| reward             | 0.739     |
| reward_contact     | -0.000878 |
| reward_ctrl        | -1.14     |
| reward_position    | 0.0126    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 705       |
|    ep_rew_mean     | 748       |
| time/              |           |
|    episodes        | 244       |
|    fps             | 11        |
|    time_elapsed    | 11842     |
|    total timesteps | 139600    |
| train/             |           |
|    actor_loss      | -107      |
|    critic_loss     | 4.89      |
|    learning_rate   | 0.001     |
|    n_updates       | 134595    |
----------------------------------
Num timesteps: 140000
Best mean reward: 856.59 - Last mean reward per episode: 797.88
Num timesteps: 142000
Best mean reward: 856.59 - Last mean reward per episode: 803.98
----------------------------------
| forward_vel        | 0.835     |
| reward             | 0.722     |
| reward_contact     | -0.000919 |
| reward_ctrl        | -1.13     |
| reward_position    | 0.0141    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 728       |
|    ep_rew_mean     | 776       |
| time/              |           |
|    episodes        | 248       |
|    fps             | 11        |
|    time_elapsed    | 12044     |
|    total timesteps | 143089    |
| train/             |           |
|    actor_loss      | -104      |
|    critic_loss     | 12.3      |
|    learning_rate   | 0.001     |
|    n_updates       | 138085    |
----------------------------------
Num timesteps: 144000
Best mean reward: 856.59 - Last mean reward per episode: 808.09
----------------------------------
| forward_vel        | 0.841     |
| reward             | 0.703     |
| reward_contact     | -0.000935 |
| reward_ctrl        | -1.15     |
| reward_position    | 0.0141    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 720       |
|    ep_rew_mean     | 784       |
| time/              |           |
|    episodes        | 252       |
|    fps             | 11        |
|    time_elapsed    | 12174     |
|    total timesteps | 145327    |
| train/             |           |
|    actor_loss      | -107      |
|    critic_loss     | 5.23      |
|    learning_rate   | 0.001     |
|    n_updates       | 140325    |
----------------------------------
Num timesteps: 146000
Best mean reward: 856.59 - Last mean reward per episode: 790.63
---------------------------------
| forward_vel        | 0.87     |
| reward             | 0.73     |
| reward_contact     | -0.00092 |
| reward_ctrl        | -1.15    |
| reward_position    | 0.0141   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 721      |
|    ep_rew_mean     | 799      |
| time/              |          |
|    episodes        | 256      |
|    fps             | 11       |
|    time_elapsed    | 12318    |
|    total timesteps | 147787   |
| train/             |          |
|    actor_loss      | -104     |
|    critic_loss     | 5.52     |
|    learning_rate   | 0.001    |
|    n_updates       | 142785   |
---------------------------------
Num timesteps: 148000
Best mean reward: 856.59 - Last mean reward per episode: 803.22
Num timesteps: 150000
Best mean reward: 856.59 - Last mean reward per episode: 821.70
----------------------------------
| forward_vel        | 0.868     |
| reward             | 0.736     |
| reward_contact     | -0.000915 |
| reward_ctrl        | -1.15     |
| reward_position    | 0.0141    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 723       |
|    ep_rew_mean     | 810       |
| time/              |           |
|    episodes        | 260       |
|    fps             | 12        |
|    time_elapsed    | 12517     |
|    total timesteps | 151195    |
| train/             |           |
|    actor_loss      | -105      |
|    critic_loss     | 10.3      |
|    learning_rate   | 0.001     |
|    n_updates       | 146190    |
----------------------------------
Num timesteps: 152000
Best mean reward: 856.59 - Last mean reward per episode: 827.79
---------------------------------
| forward_vel        | 0.879    |
| reward             | 0.761    |
| reward_contact     | -0.00091 |
| reward_ctrl        | -1.13    |
| reward_position    | 0.00936  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 718      |
|    ep_rew_mean     | 808      |
| time/              |          |
|    episodes        | 264      |
|    fps             | 12       |
|    time_elapsed    | 12664    |
|    total timesteps | 153736   |
| train/             |          |
|    actor_loss      | -107     |
|    critic_loss     | 6.08     |
|    learning_rate   | 0.001    |
|    n_updates       | 148735   |
---------------------------------
Num timesteps: 154000
Best mean reward: 856.59 - Last mean reward per episode: 821.38
----------------------------------
| forward_vel        | 0.893     |
| reward             | 0.767     |
| reward_contact     | -0.000913 |
| reward_ctrl        | -1.13     |
| reward_position    | 0.00936   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 709       |
|    ep_rew_mean     | 800       |
| time/              |           |
|    episodes        | 268       |
|    fps             | 12        |
|    time_elapsed    | 12751     |
|    total timesteps | 155228    |
| train/             |           |
|    actor_loss      | -106      |
|    critic_loss     | 6.05      |
|    learning_rate   | 0.001     |
|    n_updates       | 150225    |
----------------------------------
Num timesteps: 156000
Best mean reward: 856.59 - Last mean reward per episode: 806.66
Num timesteps: 158000
Best mean reward: 856.59 - Last mean reward per episode: 810.38
----------------------------------
| forward_vel        | 0.902     |
| reward             | 0.791     |
| reward_contact     | -0.000933 |
| reward_ctrl        | -1.12     |
| reward_position    | 0.00936   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 710       |
|    ep_rew_mean     | 797       |
| time/              |           |
|    episodes        | 272       |
|    fps             | 12        |
|    time_elapsed    | 12923     |
|    total timesteps | 158237    |
| train/             |           |
|    actor_loss      | -110      |
|    critic_loss     | 7.38      |
|    learning_rate   | 0.001     |
|    n_updates       | 153235    |
----------------------------------
Num timesteps: 160000
Best mean reward: 856.59 - Last mean reward per episode: 818.28
----------------------------------
| forward_vel        | 0.899     |
| reward             | 0.802     |
| reward_contact     | -0.000924 |
| reward_ctrl        | -1.11     |
| reward_position    | 0.00924   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 722       |
|    ep_rew_mean     | 826       |
| time/              |           |
|    episodes        | 276       |
|    fps             | 12        |
|    time_elapsed    | 13124     |
|    total timesteps | 161747    |
| train/             |           |
|    actor_loss      | -110      |
|    critic_loss     | 4.93      |
|    learning_rate   | 0.001     |
|    n_updates       | 156745    |
----------------------------------
Num timesteps: 162000
Best mean reward: 856.59 - Last mean reward per episode: 815.46
----------------------------------
| forward_vel        | 0.896     |
| reward             | 0.824     |
| reward_contact     | -0.000903 |
| reward_ctrl        | -1.08     |
| reward_position    | 0.0101    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 710       |
|    ep_rew_mean     | 815       |
| time/              |           |
|    episodes        | 280       |
|    fps             | 12        |
|    time_elapsed    | 13231     |
|    total timesteps | 163434    |
| train/             |           |
|    actor_loss      | -108      |
|    critic_loss     | 6.87      |
|    learning_rate   | 0.001     |
|    n_updates       | 158430    |
----------------------------------
Num timesteps: 164000
Best mean reward: 856.59 - Last mean reward per episode: 814.87
----------------------------------
| forward_vel        | 0.896     |
| reward             | 0.796     |
| reward_contact     | -0.000925 |
| reward_ctrl        | -1.11     |
| reward_position    | 0.0141    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 693       |
|    ep_rew_mean     | 798       |
| time/              |           |
|    episodes        | 284       |
|    fps             | 12        |
|    time_elapsed    | 13321     |
|    total timesteps | 165018    |
| train/             |           |
|    actor_loss      | -111      |
|    critic_loss     | 5.85      |
|    learning_rate   | 0.001     |
|    n_updates       | 160015    |
----------------------------------
Num timesteps: 166000
Best mean reward: 856.59 - Last mean reward per episode: 796.62
Num timesteps: 168000
Best mean reward: 856.59 - Last mean reward per episode: 801.28
----------------------------------
| forward_vel        | 0.883     |
| reward             | 0.779     |
| reward_contact     | -0.000863 |
| reward_ctrl        | -1.12     |
| reward_position    | 0.014     |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 701       |
|    ep_rew_mean     | 819       |
| time/              |           |
|    episodes        | 288       |
|    fps             | 12        |
|    time_elapsed    | 13524     |
|    total timesteps | 168472    |
| train/             |           |
|    actor_loss      | -110      |
|    critic_loss     | 5.72      |
|    learning_rate   | 0.001     |
|    n_updates       | 163470    |
----------------------------------
Num timesteps: 170000
Best mean reward: 856.59 - Last mean reward per episode: 797.75
----------------------------------
| forward_vel        | 0.911     |
| reward             | 0.798     |
| reward_contact     | -0.000843 |
| reward_ctrl        | -1.13     |
| reward_position    | 0.014     |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 693       |
|    ep_rew_mean     | 823       |
| time/              |           |
|    episodes        | 292       |
|    fps             | 12        |
|    time_elapsed    | 13704     |
|    total timesteps | 171623    |
| train/             |           |
|    actor_loss      | -112      |
|    critic_loss     | 6.3       |
|    learning_rate   | 0.001     |
|    n_updates       | 166620    |
----------------------------------
Num timesteps: 172000
Best mean reward: 856.59 - Last mean reward per episode: 796.08
Num timesteps: 174000
Best mean reward: 856.59 - Last mean reward per episode: 817.56
----------------------------------
| forward_vel        | 0.919     |
| reward             | 0.808     |
| reward_contact     | -0.000855 |
| reward_ctrl        | -1.12     |
| reward_position    | 0.014     |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 699       |
|    ep_rew_mean     | 833       |
| time/              |           |
|    episodes        | 296       |
|    fps             | 12        |
|    time_elapsed    | 13885     |
|    total timesteps | 174742    |
| train/             |           |
|    actor_loss      | -109      |
|    critic_loss     | 25.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 169740    |
----------------------------------
Num timesteps: 176000
Best mean reward: 856.59 - Last mean reward per episode: 822.67
Num timesteps: 178000
Best mean reward: 856.59 - Last mean reward per episode: 837.11
----------------------------------
| forward_vel        | 0.872     |
| reward             | 0.773     |
| reward_contact     | -0.000876 |
| reward_ctrl        | -1.11     |
| reward_position    | 0.0146    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 707       |
|    ep_rew_mean     | 835       |
| time/              |           |
|    episodes        | 300       |
|    fps             | 12        |
|    time_elapsed    | 14119     |
|    total timesteps | 178742    |
| train/             |           |
|    actor_loss      | -108      |
|    critic_loss     | 16.7      |
|    learning_rate   | 0.001     |
|    n_updates       | 173740    |
----------------------------------
Num timesteps: 180000
Best mean reward: 856.59 - Last mean reward per episode: 824.89
----------------------------------
| forward_vel        | 0.892     |
| reward             | 0.77      |
| reward_contact     | -0.000788 |
| reward_ctrl        | -1.14     |
| reward_position    | 0.0146    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 699       |
|    ep_rew_mean     | 829       |
| time/              |           |
|    episodes        | 304       |
|    fps             | 12        |
|    time_elapsed    | 14244     |
|    total timesteps | 180974    |
| train/             |           |
|    actor_loss      | -110      |
|    critic_loss     | 8.94      |
|    learning_rate   | 0.001     |
|    n_updates       | 175970    |
----------------------------------
Num timesteps: 182000
Best mean reward: 856.59 - Last mean reward per episode: 829.78
Num timesteps: 184000
Best mean reward: 856.59 - Last mean reward per episode: 841.01
----------------------------------
| forward_vel        | 0.875     |
| reward             | 0.742     |
| reward_contact     | -0.000814 |
| reward_ctrl        | -1.15     |
| reward_position    | 0.0144    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 721       |
|    ep_rew_mean     | 848       |
| time/              |           |
|    episodes        | 308       |
|    fps             | 12        |
|    time_elapsed    | 14472     |
|    total timesteps | 184974    |
| train/             |           |
|    actor_loss      | -112      |
|    critic_loss     | 4.64      |
|    learning_rate   | 0.001     |
|    n_updates       | 179970    |
----------------------------------
Num timesteps: 186000
Best mean reward: 856.59 - Last mean reward per episode: 840.49
----------------------------------
| forward_vel        | 0.861     |
| reward             | 0.709     |
| reward_contact     | -0.000861 |
| reward_ctrl        | -1.16     |
| reward_position    | 0.0144    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 722       |
|    ep_rew_mean     | 838       |
| time/              |           |
|    episodes        | 312       |
|    fps             | 12        |
|    time_elapsed    | 14614     |
|    total timesteps | 187434    |
| train/             |           |
|    actor_loss      | -114      |
|    critic_loss     | 8.84      |
|    learning_rate   | 0.001     |
|    n_updates       | 182430    |
----------------------------------
Num timesteps: 188000
Best mean reward: 856.59 - Last mean reward per episode: 838.47
Num timesteps: 190000
Best mean reward: 856.59 - Last mean reward per episode: 836.59
----------------------------------
| forward_vel        | 0.844     |
| reward             | 0.687     |
| reward_contact     | -0.000903 |
| reward_ctrl        | -1.17     |
| reward_position    | 0.0153    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 718       |
|    ep_rew_mean     | 830       |
| time/              |           |
|    episodes        | 316       |
|    fps             | 12        |
|    time_elapsed    | 14805     |
|    total timesteps | 190793    |
| train/             |           |
|    actor_loss      | -111      |
|    critic_loss     | 10.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 185790    |
----------------------------------
Num timesteps: 192000
Best mean reward: 856.59 - Last mean reward per episode: 824.73
----------------------------------
| forward_vel        | 0.852     |
| reward             | 0.681     |
| reward_contact     | -0.000905 |
| reward_ctrl        | -1.19     |
| reward_position    | 0.0153    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 711       |
|    ep_rew_mean     | 824       |
| time/              |           |
|    episodes        | 320       |
|    fps             | 12        |
|    time_elapsed    | 14929     |
|    total timesteps | 192985    |
| train/             |           |
|    actor_loss      | -114      |
|    critic_loss     | 6.87      |
|    learning_rate   | 0.001     |
|    n_updates       | 187980    |
----------------------------------
Num timesteps: 194000
Best mean reward: 856.59 - Last mean reward per episode: 827.90
Num timesteps: 196000
Best mean reward: 856.59 - Last mean reward per episode: 837.99
----------------------------------
| forward_vel        | 0.882     |
| reward             | 0.699     |
| reward_contact     | -0.000841 |
| reward_ctrl        | -1.2      |
| reward_position    | 0.016     |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 728       |
|    ep_rew_mean     | 844       |
| time/              |           |
|    episodes        | 324       |
|    fps             | 12        |
|    time_elapsed    | 15156     |
|    total timesteps | 196985    |
| train/             |           |
|    actor_loss      | -115      |
|    critic_loss     | 10.3      |
|    learning_rate   | 0.001     |
|    n_updates       | 191980    |
----------------------------------
Num timesteps: 198000
Best mean reward: 856.59 - Last mean reward per episode: 857.57
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1673.7013985999997, 484.4760404411742)
Num timesteps: 200000
Best mean reward: 857.57 - Last mean reward per episode: 926.42
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1588.7191025, 499.17811312673746)
----------------------------------
| forward_vel        | 0.87      |
| reward             | 0.824     |
| reward_contact     | -0.000826 |
| reward_ctrl        | -1.05     |
| reward_position    | 0.00727   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 748       |
|    ep_rew_mean     | 867       |
| time/              |           |
|    episodes        | 328       |
|    fps             | 12        |
|    time_elapsed    | 15881     |
|    total timesteps | 201000    |
| train/             |           |
|    actor_loss      | -115      |
|    critic_loss     | 9.56      |
|    learning_rate   | 0.001     |
|    n_updates       | 195995    |
----------------------------------
Num timesteps: 202000
Best mean reward: 926.42 - Last mean reward per episode: 990.53
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1715.2981065, 272.4604929578722)
Num timesteps: 204000
Best mean reward: 990.53 - Last mean reward per episode: 1082.57
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1383.0372776, 465.2918380615005)
----------------------------------
| forward_vel        | 0.86      |
| reward             | 0.903     |
| reward_contact     | -0.000849 |
| reward_ctrl        | -0.97     |
| reward_position    | 0.0129    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 732       |
|    ep_rew_mean     | 852       |
| time/              |           |
|    episodes        | 332       |
|    fps             | 12        |
|    time_elapsed    | 16577     |
|    total timesteps | 204000    |
| train/             |           |
|    actor_loss      | -110      |
|    critic_loss     | 6.32      |
|    learning_rate   | 0.001     |
|    n_updates       | 198995    |
----------------------------------
Num timesteps: 206000
Best mean reward: 1082.57 - Last mean reward per episode: 1153.37
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1176.2387909000001, 610.198281452756)
Num timesteps: 208000
Best mean reward: 1153.37 - Last mean reward per episode: 1215.27
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1187.2986448, 566.2855220625265)
----------------------------------
| forward_vel        | 0.867     |
| reward             | 1.03      |
| reward_contact     | -0.000848 |
| reward_ctrl        | -0.863    |
| reward_position    | 0.0258    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 732       |
|    ep_rew_mean     | 859       |
| time/              |           |
|    episodes        | 336       |
|    fps             | 12        |
|    time_elapsed    | 17216     |
|    total timesteps | 208000    |
| train/             |           |
|    actor_loss      | -113      |
|    critic_loss     | 5.04      |
|    learning_rate   | 0.001     |
|    n_updates       | 202995    |
----------------------------------
Num timesteps: 210000
Best mean reward: 1215.27 - Last mean reward per episode: 1227.81
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1093.1381213, 522.7549163461387)
---------------------------------
| forward_vel        | 0.874    |
| reward             | 1.06     |
| reward_contact     | -0.00113 |
| reward_ctrl        | -0.84    |
| reward_position    | 0.0255   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 719      |
|    ep_rew_mean     | 846      |
| time/              |          |
|    episodes        | 340      |
|    fps             | 12       |
|    time_elapsed    | 17570    |
|    total timesteps | 211000   |
| train/             |          |
|    actor_loss      | -112     |
|    critic_loss     | 6.11     |
|    learning_rate   | 0.001    |
|    n_updates       | 205995   |
---------------------------------
Num timesteps: 212000
Best mean reward: 1227.81 - Last mean reward per episode: 1262.64
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1243.0545295999998, 493.6400551278712)
Num timesteps: 214000
Best mean reward: 1262.64 - Last mean reward per episode: 1315.92
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1220.0373845, 459.26855073894916)
---------------------------------
| forward_vel        | 0.796    |
| reward             | 1.1      |
| reward_contact     | -0.00115 |
| reward_ctrl        | -0.733   |
| reward_position    | 0.0417   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 736      |
|    ep_rew_mean     | 869      |
| time/              |          |
|    episodes        | 344      |
|    fps             | 11       |
|    time_elapsed    | 18225    |
|    total timesteps | 215000   |
| train/             |          |
|    actor_loss      | -117     |
|    critic_loss     | 7.09     |
|    learning_rate   | 0.001    |
|    n_updates       | 209995   |
---------------------------------
Num timesteps: 216000
Best mean reward: 1315.92 - Last mean reward per episode: 1273.72
---------------------------------
| forward_vel        | 0.806    |
| reward             | 1.11     |
| reward_contact     | -0.00108 |
| reward_ctrl        | -0.74    |
| reward_position    | 0.0417   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 727      |
|    ep_rew_mean     | 871      |
| time/              |          |
|    episodes        | 348      |
|    fps             | 11       |
|    time_elapsed    | 18334    |
|    total timesteps | 217585   |
| train/             |          |
|    actor_loss      | -116     |
|    critic_loss     | 6.21     |
|    learning_rate   | 0.001    |
|    n_updates       | 212580   |
---------------------------------
Num timesteps: 218000
Best mean reward: 1315.92 - Last mean reward per episode: 1260.00
Num timesteps: 220000
Best mean reward: 1315.92 - Last mean reward per episode: 1231.22
---------------------------------
| forward_vel        | 0.811    |
| reward             | 1.07     |
| reward_contact     | -0.00115 |
| reward_ctrl        | -0.779   |
| reward_position    | 0.0418   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 737      |
|    ep_rew_mean     | 881      |
| time/              |          |
|    episodes        | 352      |
|    fps             | 11       |
|    time_elapsed    | 18479    |
|    total timesteps | 220854   |
| train/             |          |
|    actor_loss      | -117     |
|    critic_loss     | 5.77     |
|    learning_rate   | 0.001    |
|    n_updates       | 215850   |
---------------------------------
Num timesteps: 222000
Best mean reward: 1315.92 - Last mean reward per episode: 1227.41
---------------------------------
| forward_vel        | 0.8      |
| reward             | 1.05     |
| reward_contact     | -0.0012  |
| reward_ctrl        | -0.793   |
| reward_position    | 0.0418   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 737      |
|    ep_rew_mean     | 881      |
| time/              |          |
|    episodes        | 356      |
|    fps             | 12       |
|    time_elapsed    | 18589    |
|    total timesteps | 223323   |
| train/             |          |
|    actor_loss      | -113     |
|    critic_loss     | 5.39     |
|    learning_rate   | 0.001    |
|    n_updates       | 218320   |
---------------------------------
Num timesteps: 224000
Best mean reward: 1315.92 - Last mean reward per episode: 1205.16
Num timesteps: 226000
Best mean reward: 1315.92 - Last mean reward per episode: 1208.56
---------------------------------
| forward_vel        | 0.824    |
| reward             | 1.06     |
| reward_contact     | -0.00119 |
| reward_ctrl        | -0.8     |
| reward_position    | 0.0373   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 738      |
|    ep_rew_mean     | 888      |
| time/              |          |
|    episodes        | 360      |
|    fps             | 12       |
|    time_elapsed    | 18742    |
|    total timesteps | 226799   |
| train/             |          |
|    actor_loss      | -115     |
|    critic_loss     | 7.51     |
|    learning_rate   | 0.001    |
|    n_updates       | 221795   |
---------------------------------
Num timesteps: 228000
Best mean reward: 1315.92 - Last mean reward per episode: 1213.57
Num timesteps: 230000
Best mean reward: 1315.92 - Last mean reward per episode: 1208.19
---------------------------------
| forward_vel        | 0.824    |
| reward             | 1.06     |
| reward_contact     | -0.00125 |
| reward_ctrl        | -0.805   |
| reward_position    | 0.0373   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 747      |
|    ep_rew_mean     | 904      |
| time/              |          |
|    episodes        | 364      |
|    fps             | 12       |
|    time_elapsed    | 18898    |
|    total timesteps | 230284   |
| train/             |          |
|    actor_loss      | -116     |
|    critic_loss     | 5.28     |
|    learning_rate   | 0.001    |
|    n_updates       | 225280   |
---------------------------------
Num timesteps: 232000
Best mean reward: 1315.92 - Last mean reward per episode: 1193.77
---------------------------------
| forward_vel        | 0.831    |
| reward             | 1.02     |
| reward_contact     | -0.00127 |
| reward_ctrl        | -0.843   |
| reward_position    | 0.0373   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 767      |
|    ep_rew_mean     | 943      |
| time/              |          |
|    episodes        | 368      |
|    fps             | 12       |
|    time_elapsed    | 19081    |
|    total timesteps | 233807   |
| train/             |          |
|    actor_loss      | -115     |
|    critic_loss     | 5.3      |
|    learning_rate   | 0.001    |
|    n_updates       | 228805   |
---------------------------------
Num timesteps: 234000
Best mean reward: 1315.92 - Last mean reward per episode: 1187.56
Num timesteps: 236000
Best mean reward: 1315.92 - Last mean reward per episode: 1169.00
---------------------------------
| forward_vel        | 0.826    |
| reward             | 1.02     |
| reward_contact     | -0.00121 |
| reward_ctrl        | -0.845   |
| reward_position    | 0.0373   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 769      |
|    ep_rew_mean     | 945      |
| time/              |          |
|    episodes        | 372      |
|    fps             | 12       |
|    time_elapsed    | 19341    |
|    total timesteps | 236967   |
| train/             |          |
|    actor_loss      | -115     |
|    critic_loss     | 7.18     |
|    learning_rate   | 0.001    |
|    n_updates       | 231965   |
---------------------------------
Num timesteps: 238000
Best mean reward: 1315.92 - Last mean reward per episode: 1140.37
---------------------------------
| forward_vel        | 0.822    |
| reward             | 0.977    |
| reward_contact     | -0.00122 |
| reward_ctrl        | -0.882   |
| reward_position    | 0.0376   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 759      |
|    ep_rew_mean     | 927      |
| time/              |          |
|    episodes        | 376      |
|    fps             | 12       |
|    time_elapsed    | 19538    |
|    total timesteps | 239450   |
| train/             |          |
|    actor_loss      | -113     |
|    critic_loss     | 5.59     |
|    learning_rate   | 0.001    |
|    n_updates       | 234445   |
---------------------------------
Num timesteps: 240000
Best mean reward: 1315.92 - Last mean reward per episode: 1112.56
Num timesteps: 242000
Best mean reward: 1315.92 - Last mean reward per episode: 1121.49
---------------------------------
| forward_vel        | 0.843    |
| reward             | 0.961    |
| reward_contact     | -0.00123 |
| reward_ctrl        | -0.918   |
| reward_position    | 0.0376   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 779      |
|    ep_rew_mean     | 953      |
| time/              |          |
|    episodes        | 380      |
|    fps             | 12       |
|    time_elapsed    | 19784    |
|    total timesteps | 243139   |
| train/             |          |
|    actor_loss      | -119     |
|    critic_loss     | 5.27     |
|    learning_rate   | 0.001    |
|    n_updates       | 238135   |
---------------------------------
Num timesteps: 244000
Best mean reward: 1315.92 - Last mean reward per episode: 1113.76
Num timesteps: 246000
Best mean reward: 1315.92 - Last mean reward per episode: 1101.38
---------------------------------
| forward_vel        | 0.829    |
| reward             | 0.946    |
| reward_contact     | -0.00125 |
| reward_ctrl        | -0.921   |
| reward_position    | 0.0393   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 795      |
|    ep_rew_mean     | 980      |
| time/              |          |
|    episodes        | 384      |
|    fps             | 12       |
|    time_elapsed    | 20033    |
|    total timesteps | 246340   |
| train/             |          |
|    actor_loss      | -117     |
|    critic_loss     | 6.62     |
|    learning_rate   | 0.001    |
|    n_updates       | 241335   |
---------------------------------
Num timesteps: 248000
Best mean reward: 1315.92 - Last mean reward per episode: 1120.57
---------------------------------
| forward_vel        | 0.838    |
| reward             | 0.973    |
| reward_contact     | -0.0013  |
| reward_ctrl        | -0.902   |
| reward_position    | 0.0385   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 793      |
|    ep_rew_mean     | 985      |
| time/              |          |
|    episodes        | 388      |
|    fps             | 12       |
|    time_elapsed    | 20282    |
|    total timesteps | 249631   |
| train/             |          |
|    actor_loss      | -122     |
|    critic_loss     | 7.08     |
|    learning_rate   | 0.001    |
|    n_updates       | 244630   |
---------------------------------
Num timesteps: 250000
Best mean reward: 1315.92 - Last mean reward per episode: 1118.30
Num timesteps: 252000
Best mean reward: 1315.92 - Last mean reward per episode: 1135.82
---------------------------------
| forward_vel        | 0.806    |
| reward             | 0.991    |
| reward_contact     | -0.00133 |
| reward_ctrl        | -0.842   |
| reward_position    | 0.0286   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 802      |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    episodes        | 392      |
|    fps             | 12       |
|    time_elapsed    | 20573    |
|    total timesteps | 253631   |
| train/             |          |
|    actor_loss      | -121     |
|    critic_loss     | 6.08     |
|    learning_rate   | 0.001    |
|    n_updates       | 248630   |
---------------------------------
Num timesteps: 254000
Best mean reward: 1315.92 - Last mean reward per episode: 1132.37
Num timesteps: 256000
Best mean reward: 1315.92 - Last mean reward per episode: 1124.91
---------------------------------
| forward_vel        | 0.823    |
| reward             | 0.999    |
| reward_contact     | -0.00137 |
| reward_ctrl        | -0.851   |
| reward_position    | 0.0286   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 811      |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 396      |
|    fps             | 12       |
|    time_elapsed    | 20851    |
|    total timesteps | 257631   |
| train/             |          |
|    actor_loss      | -121     |
|    critic_loss     | 4.63     |
|    learning_rate   | 0.001    |
|    n_updates       | 252630   |
---------------------------------
Num timesteps: 258000
Best mean reward: 1315.92 - Last mean reward per episode: 1132.03
Num timesteps: 260000
Best mean reward: 1315.92 - Last mean reward per episode: 1130.09
---------------------------------
| forward_vel        | 0.808    |
| reward             | 0.977    |
| reward_contact     | -0.00128 |
| reward_ctrl        | -0.859   |
| reward_position    | 0.0284   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 802      |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    episodes        | 400      |
|    fps             | 12       |
|    time_elapsed    | 21095    |
|    total timesteps | 260768   |
| train/             |          |
|    actor_loss      | -121     |
|    critic_loss     | 6.01     |
|    learning_rate   | 0.001    |
|    n_updates       | 255765   |
---------------------------------
Num timesteps: 262000
Best mean reward: 1315.92 - Last mean reward per episode: 1142.36
Num timesteps: 264000
Best mean reward: 1315.92 - Last mean reward per episode: 1132.61
---------------------------------
| forward_vel        | 0.822    |
| reward             | 1        |
| reward_contact     | -0.00122 |
| reward_ctrl        | -0.848   |
| reward_position    | 0.0284   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 818      |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    episodes        | 404      |
|    fps             | 12       |
|    time_elapsed    | 21358    |
|    total timesteps | 264564   |
| train/             |          |
|    actor_loss      | -118     |
|    critic_loss     | 5.22     |
|    learning_rate   | 0.001    |
|    n_updates       | 259560   |
---------------------------------
Num timesteps: 266000
Best mean reward: 1315.92 - Last mean reward per episode: 1126.94
Num timesteps: 268000
Best mean reward: 1315.92 - Last mean reward per episode: 1132.21
---------------------------------
| forward_vel        | 0.821    |
| reward             | 1.01     |
| reward_contact     | -0.00128 |
| reward_ctrl        | -0.839   |
| reward_position    | 0.0284   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 818      |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    episodes        | 408      |
|    fps             | 12       |
|    time_elapsed    | 21644    |
|    total timesteps | 268564   |
| train/             |          |
|    actor_loss      | -120     |
|    critic_loss     | 10.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 263560   |
---------------------------------
Num timesteps: 270000
Best mean reward: 1315.92 - Last mean reward per episode: 1140.42
---------------------------------
| forward_vel        | 0.847    |
| reward             | 1.02     |
| reward_contact     | -0.00121 |
| reward_ctrl        | -0.852   |
| reward_position    | 0.0284   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 825      |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    episodes        | 412      |
|    fps             | 12       |
|    time_elapsed    | 21880    |
|    total timesteps | 271772   |
| train/             |          |
|    actor_loss      | -117     |
|    critic_loss     | 5.35     |
|    learning_rate   | 0.001    |
|    n_updates       | 266770   |
---------------------------------
Num timesteps: 272000
Best mean reward: 1315.92 - Last mean reward per episode: 1133.89
Num timesteps: 274000
Best mean reward: 1315.92 - Last mean reward per episode: 1124.49
---------------------------------
| forward_vel        | 0.81     |
| reward             | 1.02     |
| reward_contact     | -0.00126 |
| reward_ctrl        | -0.82    |
| reward_position    | 0.0283   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 825      |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    episodes        | 416      |
|    fps             | 12       |
|    time_elapsed    | 22112    |
|    total timesteps | 275163   |
| train/             |          |
|    actor_loss      | -121     |
|    critic_loss     | 18.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 270160   |
---------------------------------
Num timesteps: 276000
Best mean reward: 1315.92 - Last mean reward per episode: 1133.92
Num timesteps: 278000
Best mean reward: 1315.92 - Last mean reward per episode: 1137.13
---------------------------------
| forward_vel        | 0.791    |
| reward             | 1.02     |
| reward_contact     | -0.00123 |
| reward_ctrl        | -0.802   |
| reward_position    | 0.0293   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 839      |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    episodes        | 420      |
|    fps             | 12       |
|    time_elapsed    | 22401    |
|    total timesteps | 278698   |
| train/             |          |
|    actor_loss      | -119     |
|    critic_loss     | 5.94     |
|    learning_rate   | 0.001    |
|    n_updates       | 273695   |
---------------------------------
Num timesteps: 280000
Best mean reward: 1315.92 - Last mean reward per episode: 1132.20
Num timesteps: 282000
Best mean reward: 1315.92 - Last mean reward per episode: 1125.75
---------------------------------
| forward_vel        | 0.806    |
| reward             | 1.01     |
| reward_contact     | -0.00116 |
| reward_ctrl        | -0.825   |
| reward_position    | 0.0293   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 838      |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    episodes        | 424      |
|    fps             | 12       |
|    time_elapsed    | 22704    |
|    total timesteps | 282635   |
| train/             |          |
|    actor_loss      | -121     |
|    critic_loss     | 7.87     |
|    learning_rate   | 0.001    |
|    n_updates       | 277630   |
---------------------------------
Num timesteps: 284000
Best mean reward: 1315.92 - Last mean reward per episode: 1126.46
---------------------------------
| forward_vel        | 0.814    |
| reward             | 1.02     |
| reward_contact     | -0.00115 |
| reward_ctrl        | -0.822   |
| reward_position    | 0.0298   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 820      |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    episodes        | 428      |
|    fps             | 12       |
|    time_elapsed    | 22863    |
|    total timesteps | 284794   |
| train/             |          |
|    actor_loss      | -119     |
|    critic_loss     | 10       |
|    learning_rate   | 0.001    |
|    n_updates       | 279790   |
---------------------------------
Num timesteps: 286000
Best mean reward: 1315.92 - Last mean reward per episode: 1107.24
Num timesteps: 288000
Best mean reward: 1315.92 - Last mean reward per episode: 1104.04
---------------------------------
| forward_vel        | 0.822    |
| reward             | 1        |
| reward_contact     | -0.0011  |
| reward_ctrl        | -0.844   |
| reward_position    | 0.0266   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 836      |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    episodes        | 432      |
|    fps             | 12       |
|    time_elapsed    | 23162    |
|    total timesteps | 288794   |
| train/             |          |
|    actor_loss      | -119     |
|    critic_loss     | 8.35     |
|    learning_rate   | 0.001    |
|    n_updates       | 283790   |
---------------------------------
Num timesteps: 290000
Best mean reward: 1315.92 - Last mean reward per episode: 1106.91
Num timesteps: 292000
Best mean reward: 1315.92 - Last mean reward per episode: 1111.24
---------------------------------
| forward_vel        | 0.83     |
| reward             | 0.99     |
| reward_contact     | -0.00108 |
| reward_ctrl        | -0.85    |
| reward_position    | 0.0119   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 844      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    episodes        | 436      |
|    fps             | 12       |
|    time_elapsed    | 23435    |
|    total timesteps | 292794   |
| train/             |          |
|    actor_loss      | -119     |
|    critic_loss     | 5.5      |
|    learning_rate   | 0.001    |
|    n_updates       | 287790   |
---------------------------------
Num timesteps: 294000
Best mean reward: 1315.92 - Last mean reward per episode: 1107.60
---------------------------------
| forward_vel        | 0.843    |
| reward             | 0.959    |
| reward_contact     | -0.00107 |
| reward_ctrl        | -0.895   |
| reward_position    | 0.0122   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 845      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    episodes        | 440      |
|    fps             | 12       |
|    time_elapsed    | 23639    |
|    total timesteps | 295456   |
| train/             |          |
|    actor_loss      | -117     |
|    critic_loss     | 8.36     |
|    learning_rate   | 0.001    |
|    n_updates       | 290455   |
---------------------------------
Num timesteps: 296000
Best mean reward: 1315.92 - Last mean reward per episode: 1101.68
Num timesteps: 298000
Best mean reward: 1315.92 - Last mean reward per episode: 1099.39
---------------------------------
| forward_vel        | 0.886    |
| reward             | 0.992    |
| reward_contact     | -0.00105 |
| reward_ctrl        | -0.905   |
| reward_position    | 0.0122   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 841      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    episodes        | 444      |
|    fps             | 12       |
|    time_elapsed    | 23894    |
|    total timesteps | 299087   |
| train/             |          |
|    actor_loss      | -116     |
|    critic_loss     | 10.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 294085   |
---------------------------------
Num timesteps: 300000
Best mean reward: 1315.92 - Last mean reward per episode: 1106.02
Num timesteps: 302000
Best mean reward: 1315.92 - Last mean reward per episode: 1091.30
---------------------------------
| forward_vel        | 0.875    |
| reward             | 0.992    |
| reward_contact     | -0.00107 |
| reward_ctrl        | -0.894   |
| reward_position    | 0.0122   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 855      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    episodes        | 448      |
|    fps             | 12       |
|    time_elapsed    | 24196    |
|    total timesteps | 303087   |
| train/             |          |
|    actor_loss      | -122     |
|    critic_loss     | 7.12     |
|    learning_rate   | 0.001    |
|    n_updates       | 298085   |
---------------------------------
Num timesteps: 304000
Best mean reward: 1315.92 - Last mean reward per episode: 1112.03
Num timesteps: 306000
Best mean reward: 1315.92 - Last mean reward per episode: 1123.72
---------------------------------
| forward_vel        | 0.879    |
| reward             | 1.01     |
| reward_contact     | -0.00117 |
| reward_ctrl        | -0.876   |
| reward_position    | 0.0121   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 862      |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    episodes        | 452      |
|    fps             | 12       |
|    time_elapsed    | 24480    |
|    total timesteps | 307087   |
| train/             |          |
|    actor_loss      | -120     |
|    critic_loss     | 5.99     |
|    learning_rate   | 0.001    |
|    n_updates       | 302085   |
---------------------------------
Num timesteps: 308000
Best mean reward: 1315.92 - Last mean reward per episode: 1132.67
Num timesteps: 310000
Best mean reward: 1315.92 - Last mean reward per episode: 1129.10
---------------------------------
| forward_vel        | 0.887    |
| reward             | 1.01     |
| reward_contact     | -0.00129 |
| reward_ctrl        | -0.891   |
| reward_position    | 0.0121   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 872      |
|    ep_rew_mean     | 1.14e+03 |
| time/              |          |
|    episodes        | 456      |
|    fps             | 12       |
|    time_elapsed    | 24731    |
|    total timesteps | 310513   |
| train/             |          |
|    actor_loss      | -119     |
|    critic_loss     | 17.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 305510   |
---------------------------------
Num timesteps: 312000
Best mean reward: 1315.92 - Last mean reward per episode: 1136.51
---------------------------------
| forward_vel        | 0.849    |
| reward             | 0.968    |
| reward_contact     | -0.00136 |
| reward_ctrl        | -0.89    |
| reward_position    | 0.0109   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 867      |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    episodes        | 460      |
|    fps             | 12       |
|    time_elapsed    | 24954    |
|    total timesteps | 313512   |
| train/             |          |
|    actor_loss      | -119     |
|    critic_loss     | 11.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 308510   |
---------------------------------
Num timesteps: 314000
Best mean reward: 1315.92 - Last mean reward per episode: 1125.33
Num timesteps: 316000
Best mean reward: 1315.92 - Last mean reward per episode: 1127.66
---------------------------------
| forward_vel        | 0.863    |
| reward             | 0.978    |
| reward_contact     | -0.00133 |
| reward_ctrl        | -0.895   |
| reward_position    | 0.0109   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 872      |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    episodes        | 464      |
|    fps             | 12       |
|    time_elapsed    | 25252    |
|    total timesteps | 317512   |
| train/             |          |
|    actor_loss      | -119     |
|    critic_loss     | 10.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 312510   |
---------------------------------
Num timesteps: 318000
Best mean reward: 1315.92 - Last mean reward per episode: 1133.38
Num timesteps: 320000
Best mean reward: 1315.92 - Last mean reward per episode: 1131.35
---------------------------------
| forward_vel        | 0.86     |
| reward             | 0.998    |
| reward_contact     | -0.00135 |
| reward_ctrl        | -0.871   |
| reward_position    | 0.0109   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 875      |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    episodes        | 468      |
|    fps             | 12       |
|    time_elapsed    | 25543    |
|    total timesteps | 321318   |
| train/             |          |
|    actor_loss      | -119     |
|    critic_loss     | 12.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 316315   |
---------------------------------
Num timesteps: 322000
Best mean reward: 1315.92 - Last mean reward per episode: 1129.72
Num timesteps: 324000
Best mean reward: 1315.92 - Last mean reward per episode: 1136.64
---------------------------------
| forward_vel        | 0.868    |
| reward             | 0.984    |
| reward_contact     | -0.00138 |
| reward_ctrl        | -0.893   |
| reward_position    | 0.0109   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 884      |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    episodes        | 472      |
|    fps             | 12       |
|    time_elapsed    | 25822    |
|    total timesteps | 325318   |
| train/             |          |
|    actor_loss      | -122     |
|    critic_loss     | 6.83     |
|    learning_rate   | 0.001    |
|    n_updates       | 320315   |
---------------------------------
Num timesteps: 326000
Best mean reward: 1315.92 - Last mean reward per episode: 1153.10
Num timesteps: 328000
Best mean reward: 1315.92 - Last mean reward per episode: 1154.10
---------------------------------
| forward_vel        | 0.845    |
| reward             | 0.972    |
| reward_contact     | -0.00144 |
| reward_ctrl        | -0.882   |
| reward_position    | 0.0106   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 891      |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    episodes        | 476      |
|    fps             | 12       |
|    time_elapsed    | 26058    |
|    total timesteps | 328537   |
| train/             |          |
|    actor_loss      | -123     |
|    critic_loss     | 8.76     |
|    learning_rate   | 0.001    |
|    n_updates       | 323535   |
---------------------------------
Num timesteps: 330000
Best mean reward: 1315.92 - Last mean reward per episode: 1163.72
Num timesteps: 332000
Best mean reward: 1315.92 - Last mean reward per episode: 1168.08
---------------------------------
| forward_vel        | 0.841    |
| reward             | 0.985    |
| reward_contact     | -0.00138 |
| reward_ctrl        | -0.865   |
| reward_position    | 0.0106   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 892      |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 480      |
|    fps             | 12       |
|    time_elapsed    | 26334    |
|    total timesteps | 332326   |
| train/             |          |
|    actor_loss      | -120     |
|    critic_loss     | 7.03     |
|    learning_rate   | 0.001    |
|    n_updates       | 327325   |
---------------------------------
Num timesteps: 334000
Best mean reward: 1315.92 - Last mean reward per episode: 1180.17
Num timesteps: 336000
Best mean reward: 1315.92 - Last mean reward per episode: 1181.47
---------------------------------
| forward_vel        | 0.83     |
| reward             | 0.959    |
| reward_contact     | -0.0014  |
| reward_ctrl        | -0.871   |
| reward_position    | 0.00175  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 900      |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 484      |
|    fps             | 12       |
|    time_elapsed    | 26615    |
|    total timesteps | 336326   |
| train/             |          |
|    actor_loss      | -120     |
|    critic_loss     | 6.83     |
|    learning_rate   | 0.001    |
|    n_updates       | 331325   |
---------------------------------
Num timesteps: 338000
Best mean reward: 1315.92 - Last mean reward per episode: 1181.32
Num timesteps: 340000
Best mean reward: 1315.92 - Last mean reward per episode: 1191.53
---------------------------------
| forward_vel        | 0.828    |
| reward             | 0.946    |
| reward_contact     | -0.00142 |
| reward_ctrl        | -0.882   |
| reward_position    | 0.00175  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 905      |
|    ep_rew_mean     | 1.19e+03 |
| time/              |          |
|    episodes        | 488      |
|    fps             | 12       |
|    time_elapsed    | 26909    |
|    total timesteps | 340178   |
| train/             |          |
|    actor_loss      | -125     |
|    critic_loss     | 11.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 335175   |
---------------------------------
Num timesteps: 342000
Best mean reward: 1315.92 - Last mean reward per episode: 1191.48
Num timesteps: 344000
Best mean reward: 1315.92 - Last mean reward per episode: 1194.76
---------------------------------
| forward_vel        | 0.84     |
| reward             | 0.964    |
| reward_contact     | -0.00157 |
| reward_ctrl        | -0.877   |
| reward_position    | 0.00175  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 905      |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    episodes        | 492      |
|    fps             | 12       |
|    time_elapsed    | 27193    |
|    total timesteps | 344178   |
| train/             |          |
|    actor_loss      | -119     |
|    critic_loss     | 5.19     |
|    learning_rate   | 0.001    |
|    n_updates       | 339175   |
---------------------------------
Num timesteps: 346000
Best mean reward: 1315.92 - Last mean reward per episode: 1189.39
---------------------------------
| forward_vel        | 0.825    |
| reward             | 0.929    |
| reward_contact     | -0.00156 |
| reward_ctrl        | -0.896   |
| reward_position    | 0.00175  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 888      |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 496      |
|    fps             | 12       |
|    time_elapsed    | 27361    |
|    total timesteps | 346381   |
| train/             |          |
|    actor_loss      | -126     |
|    critic_loss     | 7.04     |
|    learning_rate   | 0.001    |
|    n_updates       | 341380   |
---------------------------------
Num timesteps: 348000
Best mean reward: 1315.92 - Last mean reward per episode: 1173.88
Num timesteps: 350000
Best mean reward: 1315.92 - Last mean reward per episode: 1188.80
---------------------------------
| forward_vel        | 0.871    |
| reward             | 0.976    |
| reward_contact     | -0.00161 |
| reward_ctrl        | -0.895   |
| reward_position    | 0.00175  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 896      |
|    ep_rew_mean     | 1.19e+03 |
| time/              |          |
|    episodes        | 500      |
|    fps             | 12       |
|    time_elapsed    | 27643    |
|    total timesteps | 350381   |
| train/             |          |
|    actor_loss      | -121     |
|    critic_loss     | 10.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 345380   |
---------------------------------
Num timesteps: 352000
Best mean reward: 1315.92 - Last mean reward per episode: 1193.39
Num timesteps: 354000
Best mean reward: 1315.92 - Last mean reward per episode: 1199.44
---------------------------------
| forward_vel        | 0.868    |
| reward             | 0.968    |
| reward_contact     | -0.00164 |
| reward_ctrl        | -0.901   |
| reward_position    | 0.00175  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 898      |
|    ep_rew_mean     | 1.19e+03 |
| time/              |          |
|    episodes        | 504      |
|    fps             | 12       |
|    time_elapsed    | 27924    |
|    total timesteps | 354381   |
| train/             |          |
|    actor_loss      | -123     |
|    critic_loss     | 6.61     |
|    learning_rate   | 0.001    |
|    n_updates       | 349380   |
---------------------------------
Num timesteps: 356000
Best mean reward: 1315.92 - Last mean reward per episode: 1185.75
---------------------------------
| forward_vel        | 0.866    |
| reward             | 0.952    |
| reward_contact     | -0.00157 |
| reward_ctrl        | -0.915   |
| reward_position    | 0.00175  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 890      |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 508      |
|    fps             | 12       |
|    time_elapsed    | 28164    |
|    total timesteps | 357522   |
| train/             |          |
|    actor_loss      | -121     |
|    critic_loss     | 8.61     |
|    learning_rate   | 0.001    |
|    n_updates       | 352520   |
---------------------------------
Num timesteps: 358000
Best mean reward: 1315.92 - Last mean reward per episode: 1181.74
Num timesteps: 360000
Best mean reward: 1315.92 - Last mean reward per episode: 1179.62
---------------------------------
| forward_vel        | 0.853    |
| reward             | 0.956    |
| reward_contact     | -0.00158 |
| reward_ctrl        | -0.897   |
| reward_position    | 0.00175  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 898      |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 512      |
|    fps             | 12       |
|    time_elapsed    | 28435    |
|    total timesteps | 361522   |
| train/             |          |
|    actor_loss      | -122     |
|    critic_loss     | 7.07     |
|    learning_rate   | 0.001    |
|    n_updates       | 356520   |
---------------------------------
Num timesteps: 362000
Best mean reward: 1315.92 - Last mean reward per episode: 1182.94
Num timesteps: 364000
Best mean reward: 1315.92 - Last mean reward per episode: 1182.38
---------------------------------
| forward_vel        | 0.843    |
| reward             | 0.945    |
| reward_contact     | -0.00157 |
| reward_ctrl        | -0.899   |
| reward_position    | 0.00224  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 516      |
|    fps             | 12       |
|    time_elapsed    | 28635    |
|    total timesteps | 364641   |
| train/             |          |
|    actor_loss      | -121     |
|    critic_loss     | 7.66     |
|    learning_rate   | 0.001    |
|    n_updates       | 359640   |
---------------------------------
Num timesteps: 366000
Best mean reward: 1315.92 - Last mean reward per episode: 1186.47
---------------------------------
| forward_vel        | 0.85     |
| reward             | 0.956    |
| reward_contact     | -0.00158 |
| reward_ctrl        | -0.895   |
| reward_position    | 0.00224  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 890      |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 520      |
|    fps             | 12       |
|    time_elapsed    | 28831    |
|    total timesteps | 367740   |
| train/             |          |
|    actor_loss      | -124     |
|    critic_loss     | 9.57     |
|    learning_rate   | 0.001    |
|    n_updates       | 362735   |
---------------------------------
Num timesteps: 368000
Best mean reward: 1315.92 - Last mean reward per episode: 1180.34
Num timesteps: 370000
Best mean reward: 1315.92 - Last mean reward per episode: 1186.81
---------------------------------
| forward_vel        | 0.856    |
| reward             | 0.992    |
| reward_contact     | -0.00156 |
| reward_ctrl        | -0.87    |
| reward_position    | 0.0077   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 886      |
|    ep_rew_mean     | 1.19e+03 |
| time/              |          |
|    episodes        | 524      |
|    fps             | 12       |
|    time_elapsed    | 29056    |
|    total timesteps | 371261   |
| train/             |          |
|    actor_loss      | -125     |
|    critic_loss     | 9.84     |
|    learning_rate   | 0.001    |
|    n_updates       | 366260   |
---------------------------------
Num timesteps: 372000
Best mean reward: 1315.92 - Last mean reward per episode: 1190.87
Num timesteps: 374000
Best mean reward: 1315.92 - Last mean reward per episode: 1200.35
---------------------------------
| forward_vel        | 0.858    |
| reward             | 1.01     |
| reward_contact     | -0.00161 |
| reward_ctrl        | -0.859   |
| reward_position    | 0.00725  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 905      |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 528      |
|    fps             | 12       |
|    time_elapsed    | 29311    |
|    total timesteps | 375261   |
| train/             |          |
|    actor_loss      | -123     |
|    critic_loss     | 8.36     |
|    learning_rate   | 0.001    |
|    n_updates       | 370260   |
---------------------------------
Num timesteps: 376000
Best mean reward: 1315.92 - Last mean reward per episode: 1219.16
Num timesteps: 378000
Best mean reward: 1315.92 - Last mean reward per episode: 1219.74
---------------------------------
| forward_vel        | 0.855    |
| reward             | 0.986    |
| reward_contact     | -0.00161 |
| reward_ctrl        | -0.875   |
| reward_position    | 0.00724  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 896      |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    episodes        | 532      |
|    fps             | 12       |
|    time_elapsed    | 29511    |
|    total timesteps | 378402   |
| train/             |          |
|    actor_loss      | -123     |
|    critic_loss     | 6.59     |
|    learning_rate   | 0.001    |
|    n_updates       | 373400   |
---------------------------------
Num timesteps: 380000
Best mean reward: 1315.92 - Last mean reward per episode: 1196.51
---------------------------------
| forward_vel        | 0.852    |
| reward             | 0.965    |
| reward_contact     | -0.00159 |
| reward_ctrl        | -0.893   |
| reward_position    | 0.00724  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 882      |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 536      |
|    fps             | 12       |
|    time_elapsed    | 29678    |
|    total timesteps | 380991   |
| train/             |          |
|    actor_loss      | -129     |
|    critic_loss     | 11.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 375990   |
---------------------------------
Num timesteps: 382000
Best mean reward: 1315.92 - Last mean reward per episode: 1183.14
Num timesteps: 384000
Best mean reward: 1315.92 - Last mean reward per episode: 1205.33
---------------------------------
| forward_vel        | 0.85     |
| reward             | 0.998    |
| reward_contact     | -0.00166 |
| reward_ctrl        | -0.857   |
| reward_position    | 0.00696  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    episodes        | 540      |
|    fps             | 12       |
|    time_elapsed    | 29933    |
|    total timesteps | 384991   |
| train/             |          |
|    actor_loss      | -127     |
|    critic_loss     | 8.53     |
|    learning_rate   | 0.001    |
|    n_updates       | 379990   |
---------------------------------
Num timesteps: 386000
Best mean reward: 1315.92 - Last mean reward per episode: 1211.70
Num timesteps: 388000
Best mean reward: 1315.92 - Last mean reward per episode: 1217.51
---------------------------------
| forward_vel        | 0.844    |
| reward             | 0.986    |
| reward_contact     | -0.00178 |
| reward_ctrl        | -0.863   |
| reward_position    | 0.00693  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 899      |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 544      |
|    fps             | 12       |
|    time_elapsed    | 30188    |
|    total timesteps | 388991   |
| train/             |          |
|    actor_loss      | -125     |
|    critic_loss     | 24.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 383990   |
---------------------------------
Num timesteps: 390000
Best mean reward: 1315.92 - Last mean reward per episode: 1226.13
Num timesteps: 392000
Best mean reward: 1315.92 - Last mean reward per episode: 1233.19
---------------------------------
| forward_vel        | 0.854    |
| reward             | 0.996    |
| reward_contact     | -0.00177 |
| reward_ctrl        | -0.863   |
| reward_position    | 0.00693  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 899      |
|    ep_rew_mean     | 1.23e+03 |
| time/              |          |
|    episodes        | 548      |
|    fps             | 12       |
|    time_elapsed    | 30443    |
|    total timesteps | 392991   |
| train/             |          |
|    actor_loss      | -127     |
|    critic_loss     | 8        |
|    learning_rate   | 0.001    |
|    n_updates       | 387990   |
---------------------------------
Num timesteps: 394000
Best mean reward: 1315.92 - Last mean reward per episode: 1221.67
Num timesteps: 396000
Best mean reward: 1315.92 - Last mean reward per episode: 1221.15
---------------------------------
| forward_vel        | 0.848    |
| reward             | 0.982    |
| reward_contact     | -0.00161 |
| reward_ctrl        | -0.871   |
| reward_position    | 0.00693  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 892      |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 552      |
|    fps             | 12       |
|    time_elapsed    | 30656    |
|    total timesteps | 396303   |
| train/             |          |
|    actor_loss      | -128     |
|    critic_loss     | 9.01     |
|    learning_rate   | 0.001    |
|    n_updates       | 391300   |
---------------------------------
Num timesteps: 398000
Best mean reward: 1315.92 - Last mean reward per episode: 1217.61
Num timesteps: 400000
Best mean reward: 1315.92 - Last mean reward per episode: 1217.52
---------------------------------
| forward_vel        | 0.816    |
| reward             | 0.947    |
| reward_contact     | -0.00155 |
| reward_ctrl        | -0.874   |
| reward_position    | 0.00693  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 898      |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 556      |
|    fps             | 12       |
|    time_elapsed    | 30911    |
|    total timesteps | 400303   |
| train/             |          |
|    actor_loss      | -127     |
|    critic_loss     | 6.95     |
|    learning_rate   | 0.001    |
|    n_updates       | 395300   |
---------------------------------
Num timesteps: 402000
Best mean reward: 1315.92 - Last mean reward per episode: 1215.05
---------------------------------
| forward_vel        | 0.831    |
| reward             | 0.944    |
| reward_contact     | -0.00161 |
| reward_ctrl        | -0.892   |
| reward_position    | 0.00693  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 898      |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 560      |
|    fps             | 12       |
|    time_elapsed    | 31106    |
|    total timesteps | 403330   |
| train/             |          |
|    actor_loss      | -126     |
|    critic_loss     | 5.76     |
|    learning_rate   | 0.001    |
|    n_updates       | 398325   |
---------------------------------
Num timesteps: 404000
Best mean reward: 1315.92 - Last mean reward per episode: 1214.16
Num timesteps: 406000
Best mean reward: 1315.92 - Last mean reward per episode: 1211.94
---------------------------------
| forward_vel        | 0.827    |
| reward             | 0.927    |
| reward_contact     | -0.0016  |
| reward_ctrl        | -0.905   |
| reward_position    | 0.00693  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 894      |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    episodes        | 564      |
|    fps             | 12       |
|    time_elapsed    | 31336    |
|    total timesteps | 406928   |
| train/             |          |
|    actor_loss      | -128     |
|    critic_loss     | 8.52     |
|    learning_rate   | 0.001    |
|    n_updates       | 401925   |
---------------------------------
Num timesteps: 408000
Best mean reward: 1315.92 - Last mean reward per episode: 1208.89
Num timesteps: 410000
Best mean reward: 1315.92 - Last mean reward per episode: 1217.18
---------------------------------
| forward_vel        | 0.842    |
| reward             | 0.915    |
| reward_contact     | -0.00162 |
| reward_ctrl        | -0.932   |
| reward_position    | 0.00692  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 894      |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 568      |
|    fps             | 13       |
|    time_elapsed    | 31578    |
|    total timesteps | 410703   |
| train/             |          |
|    actor_loss      | -121     |
|    critic_loss     | 6.58     |
|    learning_rate   | 0.001    |
|    n_updates       | 405700   |
---------------------------------
Num timesteps: 412000
Best mean reward: 1315.92 - Last mean reward per episode: 1213.98
Num timesteps: 414000
Best mean reward: 1315.92 - Last mean reward per episode: 1212.51
---------------------------------
| forward_vel        | 0.842    |
| reward             | 0.928    |
| reward_contact     | -0.00159 |
| reward_ctrl        | -0.919   |
| reward_position    | 0.00692  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 887      |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 572      |
|    fps             | 13       |
|    time_elapsed    | 31792    |
|    total timesteps | 414057   |
| train/             |          |
|    actor_loss      | -127     |
|    critic_loss     | 5.98     |
|    learning_rate   | 0.001    |
|    n_updates       | 409055   |
---------------------------------
Num timesteps: 416000
Best mean reward: 1315.92 - Last mean reward per episode: 1224.99
Num timesteps: 418000
Best mean reward: 1315.92 - Last mean reward per episode: 1239.28
---------------------------------
| forward_vel        | 0.85     |
| reward             | 0.949    |
| reward_contact     | -0.00154 |
| reward_ctrl        | -0.906   |
| reward_position    | 0.00691  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 1.24e+03 |
| time/              |          |
|    episodes        | 576      |
|    fps             | 13       |
|    time_elapsed    | 32049    |
|    total timesteps | 418057   |
| train/             |          |
|    actor_loss      | -121     |
|    critic_loss     | 18.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 413055   |
---------------------------------
Num timesteps: 420000
Best mean reward: 1315.92 - Last mean reward per episode: 1243.62
Num timesteps: 422000
Best mean reward: 1315.92 - Last mean reward per episode: 1252.59
---------------------------------
| forward_vel        | 0.855    |
| reward             | 0.964    |
| reward_contact     | -0.00156 |
| reward_ctrl        | -0.897   |
| reward_position    | 0.00691  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 897      |
|    ep_rew_mean     | 1.26e+03 |
| time/              |          |
|    episodes        | 580      |
|    fps             | 13       |
|    time_elapsed    | 32304    |
|    total timesteps | 422057   |
| train/             |          |
|    actor_loss      | -125     |
|    critic_loss     | 6.6      |
|    learning_rate   | 0.001    |
|    n_updates       | 417055   |
---------------------------------
Num timesteps: 424000
Best mean reward: 1315.92 - Last mean reward per episode: 1256.58
---------------------------------
| forward_vel        | 0.857    |
| reward             | 0.983    |
| reward_contact     | -0.00163 |
| reward_ctrl        | -0.886   |
| reward_position    | 0.0136   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 893      |
|    ep_rew_mean     | 1.26e+03 |
| time/              |          |
|    episodes        | 584      |
|    fps             | 13       |
|    time_elapsed    | 32534    |
|    total timesteps | 425663   |
| train/             |          |
|    actor_loss      | -131     |
|    critic_loss     | 9.14     |
|    learning_rate   | 0.001    |
|    n_updates       | 420660   |
---------------------------------
Num timesteps: 426000
Best mean reward: 1315.92 - Last mean reward per episode: 1259.93
Num timesteps: 428000
Best mean reward: 1315.92 - Last mean reward per episode: 1257.63
---------------------------------
| forward_vel        | 0.847    |
| reward             | 0.97     |
| reward_contact     | -0.00157 |
| reward_ctrl        | -0.889   |
| reward_position    | 0.0136   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 1.26e+03 |
| time/              |          |
|    episodes        | 588      |
|    fps             | 13       |
|    time_elapsed    | 32788    |
|    total timesteps | 429663   |
| train/             |          |
|    actor_loss      | -127     |
|    critic_loss     | 6.5      |
|    learning_rate   | 0.001    |
|    n_updates       | 424660   |
---------------------------------
Num timesteps: 430000
Best mean reward: 1315.92 - Last mean reward per episode: 1257.44
Num timesteps: 432000
Best mean reward: 1315.92 - Last mean reward per episode: 1257.24
---------------------------------
| forward_vel        | 0.859    |
| reward             | 0.954    |
| reward_contact     | -0.00149 |
| reward_ctrl        | -0.917   |
| reward_position    | 0.0136   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 1.26e+03 |
| time/              |          |
|    episodes        | 592      |
|    fps             | 13       |
|    time_elapsed    | 33043    |
|    total timesteps | 433663   |
| train/             |          |
|    actor_loss      | -129     |
|    critic_loss     | 12.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 428660   |
---------------------------------
Num timesteps: 434000
Best mean reward: 1315.92 - Last mean reward per episode: 1259.12
Num timesteps: 436000
Best mean reward: 1315.92 - Last mean reward per episode: 1264.23
---------------------------------
| forward_vel        | 0.849    |
| reward             | 0.956    |
| reward_contact     | -0.00145 |
| reward_ctrl        | -0.905   |
| reward_position    | 0.0136   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 902      |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    episodes        | 596      |
|    fps             | 13       |
|    time_elapsed    | 33230    |
|    total timesteps | 436576   |
| train/             |          |
|    actor_loss      | -127     |
|    critic_loss     | 12.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 431575   |
---------------------------------
Num timesteps: 438000
Best mean reward: 1315.92 - Last mean reward per episode: 1262.70
---------------------------------
| forward_vel        | 0.81     |
| reward             | 0.892    |
| reward_contact     | -0.00142 |
| reward_ctrl        | -0.93    |
| reward_position    | 0.0136   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 1.26e+03 |
| time/              |          |
|    episodes        | 600      |
|    fps             | 13       |
|    time_elapsed    | 33439    |
|    total timesteps | 439854   |
| train/             |          |
|    actor_loss      | -126     |
|    critic_loss     | 7.82     |
|    learning_rate   | 0.001    |
|    n_updates       | 434850   |
---------------------------------
Num timesteps: 440000
Best mean reward: 1315.92 - Last mean reward per episode: 1264.52
Num timesteps: 442000
Best mean reward: 1315.92 - Last mean reward per episode: 1268.22
---------------------------------
| forward_vel        | 0.8      |
| reward             | 0.889    |
| reward_contact     | -0.00138 |
| reward_ctrl        | -0.923   |
| reward_position    | 0.0136   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    episodes        | 604      |
|    fps             | 13       |
|    time_elapsed    | 33694    |
|    total timesteps | 443854   |
| train/             |          |
|    actor_loss      | -130     |
|    critic_loss     | 6.88     |
|    learning_rate   | 0.001    |
|    n_updates       | 438850   |
---------------------------------
Num timesteps: 444000
Best mean reward: 1315.92 - Last mean reward per episode: 1270.21
Num timesteps: 446000
Best mean reward: 1315.92 - Last mean reward per episode: 1270.43
---------------------------------
| forward_vel        | 0.838    |
| reward             | 0.931    |
| reward_contact     | -0.00148 |
| reward_ctrl        | -0.919   |
| reward_position    | 0.0136   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 898      |
|    ep_rew_mean     | 1.29e+03 |
| time/              |          |
|    episodes        | 608      |
|    fps             | 13       |
|    time_elapsed    | 33912    |
|    total timesteps | 447274   |
| train/             |          |
|    actor_loss      | -125     |
|    critic_loss     | 12.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 442270   |
---------------------------------
Num timesteps: 448000
Best mean reward: 1315.92 - Last mean reward per episode: 1286.23
Num timesteps: 450000
Best mean reward: 1315.92 - Last mean reward per episode: 1298.65
---------------------------------
| forward_vel        | 0.835    |
| reward             | 0.927    |
| reward_contact     | -0.0015  |
| reward_ctrl        | -0.92    |
| reward_position    | 0.0136   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 898      |
|    ep_rew_mean     | 1.31e+03 |
| time/              |          |
|    episodes        | 612      |
|    fps             | 13       |
|    time_elapsed    | 34168    |
|    total timesteps | 451274   |
| train/             |          |
|    actor_loss      | -129     |
|    critic_loss     | 15.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 446270   |
---------------------------------
Num timesteps: 452000
Best mean reward: 1315.92 - Last mean reward per episode: 1306.64
Num timesteps: 454000
Best mean reward: 1315.92 - Last mean reward per episode: 1311.96
---------------------------------
| forward_vel        | 0.84     |
| reward             | 0.944    |
| reward_contact     | -0.00154 |
| reward_ctrl        | -0.907   |
| reward_position    | 0.0131   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 906      |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    episodes        | 616      |
|    fps             | 13       |
|    time_elapsed    | 34425    |
|    total timesteps | 455274   |
| train/             |          |
|    actor_loss      | -122     |
|    critic_loss     | 11.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 450270   |
---------------------------------
Num timesteps: 456000
Best mean reward: 1315.92 - Last mean reward per episode: 1327.15
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2131.2586251999996, 563.6808283801739)
Num timesteps: 458000
Best mean reward: 1327.15 - Last mean reward per episode: 1400.18
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2170.8534785, 316.96110241659636)
---------------------------------
| forward_vel        | 1.01     |
| reward             | 1.18     |
| reward_contact     | -0.00145 |
| reward_ctrl        | -0.837   |
| reward_position    | 0.00671  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 908      |
|    ep_rew_mean     | 1.32e+03 |
| time/              |          |
|    episodes        | 620      |
|    fps             | 13       |
|    time_elapsed    | 35217    |
|    total timesteps | 459297   |
| train/             |          |
|    actor_loss      | -133     |
|    critic_loss     | 8.08     |
|    learning_rate   | 0.001    |
|    n_updates       | 454295   |
---------------------------------
Num timesteps: 460000
Best mean reward: 1400.18 - Last mean reward per episode: 1496.64
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1896.7788725999999, 706.8102106234527)
Num timesteps: 462000
Best mean reward: 1496.64 - Last mean reward per episode: 1535.31
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2029.3325912999996, 548.9287496690388)
Num timesteps: 464000
Best mean reward: 1535.31 - Last mean reward per episode: 1634.94
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1929.8355047, 506.85827856948157)
---------------------------------
| forward_vel        | 1.22     |
| reward             | 1.47     |
| reward_contact     | -0.00112 |
| reward_ctrl        | -0.757   |
| reward_position    | 0.00747  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 904      |
|    ep_rew_mean     | 1.3e+03  |
| time/              |          |
|    episodes        | 624      |
|    fps             | 12       |
|    time_elapsed    | 36264    |
|    total timesteps | 464000   |
| train/             |          |
|    actor_loss      | -124     |
|    critic_loss     | 8.11     |
|    learning_rate   | 0.001    |
|    n_updates       | 458995   |
---------------------------------
Num timesteps: 466000
Best mean reward: 1634.94 - Last mean reward per episode: 1687.79
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1504.3907370000002, 935.3317133563538)
Num timesteps: 468000
Best mean reward: 1687.79 - Last mean reward per episode: 1687.43
----------------------------------
| forward_vel        | 1.36      |
| reward             | 1.66      |
| reward_contact     | -0.000986 |
| reward_ctrl        | -0.699    |
| reward_position    | 0.00103   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 904       |
|    ep_rew_mean     | 1.31e+03  |
| time/              |           |
|    episodes        | 628       |
|    fps             | 12        |
|    time_elapsed    | 36704     |
|    total timesteps | 468000    |
| train/             |           |
|    actor_loss      | -126      |
|    critic_loss     | 8.71      |
|    learning_rate   | 0.001     |
|    n_updates       | 462995    |
----------------------------------
Num timesteps: 470000
Best mean reward: 1687.79 - Last mean reward per episode: 1681.11
Num timesteps: 472000
Best mean reward: 1687.79 - Last mean reward per episode: 1677.74
----------------------------------
| forward_vel        | 1.33      |
| reward             | 1.64      |
| reward_contact     | -0.000922 |
| reward_ctrl        | -0.686    |
| reward_position    | 0.00103   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 912       |
|    ep_rew_mean     | 1.31e+03  |
| time/              |           |
|    episodes        | 632       |
|    fps             | 12        |
|    time_elapsed    | 36960     |
|    total timesteps | 472000    |
| train/             |           |
|    actor_loss      | -125      |
|    critic_loss     | 12.5      |
|    learning_rate   | 0.001     |
|    n_updates       | 466995    |
----------------------------------
Num timesteps: 474000
Best mean reward: 1687.79 - Last mean reward per episode: 1680.40
----------------------------------
| forward_vel        | 1.34      |
| reward             | 1.66      |
| reward_contact     | -0.000931 |
| reward_ctrl        | -0.682    |
| reward_position    | 0.00103   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 917       |
|    ep_rew_mean     | 1.32e+03  |
| time/              |           |
|    episodes        | 636       |
|    fps             | 12        |
|    time_elapsed    | 37155     |
|    total timesteps | 475057    |
| train/             |           |
|    actor_loss      | -131      |
|    critic_loss     | 9.2       |
|    learning_rate   | 0.001     |
|    n_updates       | 470055    |
----------------------------------
Num timesteps: 476000
Best mean reward: 1687.79 - Last mean reward per episode: 1674.89
Num timesteps: 478000
Best mean reward: 1687.79 - Last mean reward per episode: 1673.29
----------------------------------
| forward_vel        | 1.36      |
| reward             | 1.69      |
| reward_contact     | -0.000937 |
| reward_ctrl        | -0.672    |
| reward_position    | 0.00103   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 917       |
|    ep_rew_mean     | 1.31e+03  |
| time/              |           |
|    episodes        | 640       |
|    fps             | 12        |
|    time_elapsed    | 37410     |
|    total timesteps | 479057    |
| train/             |           |
|    actor_loss      | -132      |
|    critic_loss     | 5.08      |
|    learning_rate   | 0.001     |
|    n_updates       | 474055    |
----------------------------------
Num timesteps: 480000
Best mean reward: 1687.79 - Last mean reward per episode: 1669.27
Num timesteps: 482000
Best mean reward: 1687.79 - Last mean reward per episode: 1665.38
----------------------------------
| forward_vel        | 1.37      |
| reward             | 1.69      |
| reward_contact     | -0.000911 |
| reward_ctrl        | -0.674    |
| reward_position    | 0.00103   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 917       |
|    ep_rew_mean     | 1.31e+03  |
| time/              |           |
|    episodes        | 644       |
|    fps             | 12        |
|    time_elapsed    | 37666     |
|    total timesteps | 483057    |
| train/             |           |
|    actor_loss      | -128      |
|    critic_loss     | 15.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 478055    |
----------------------------------
Num timesteps: 484000
Best mean reward: 1687.79 - Last mean reward per episode: 1674.33
Num timesteps: 486000
Best mean reward: 1687.79 - Last mean reward per episode: 1689.97
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2302.7443727, 29.44760216664386)
Num timesteps: 488000
Best mean reward: 1689.97 - Last mean reward per episode: 1745.38
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(1760.0320100999998, 815.1175880299975)
----------------------------------
| forward_vel        | 1.46      |
| reward             | 1.81      |
| reward_contact     | -0.000679 |
| reward_ctrl        | -0.65     |
| reward_position    | 0.00103   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 917       |
|    ep_rew_mean     | 1.31e+03  |
| time/              |           |
|    episodes        | 648       |
|    fps             | 12        |
|    time_elapsed    | 38485     |
|    total timesteps | 488000    |
| train/             |           |
|    actor_loss      | -130      |
|    critic_loss     | 7.77      |
|    learning_rate   | 0.001     |
|    n_updates       | 482995    |
----------------------------------
Num timesteps: 490000
Best mean reward: 1745.38 - Last mean reward per episode: 1737.08
----------------------------------
| forward_vel        | 1.46      |
| reward             | 1.77      |
| reward_contact     | -0.000899 |
| reward_ctrl        | -0.689    |
| reward_position    | 0.00103   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 924       |
|    ep_rew_mean     | 1.32e+03  |
| time/              |           |
|    episodes        | 652       |
|    fps             | 12        |
|    time_elapsed    | 38738     |
|    total timesteps | 491972    |
| train/             |           |
|    actor_loss      | -131      |
|    critic_loss     | 7.21      |
|    learning_rate   | 0.001     |
|    n_updates       | 486970    |
----------------------------------
Num timesteps: 492000
Best mean reward: 1745.38 - Last mean reward per episode: 1723.31
Num timesteps: 494000
Best mean reward: 1745.38 - Last mean reward per episode: 1698.19
---------------------------------
| forward_vel        | 1.43     |
| reward             | 1.73     |
| reward_contact     | -0.00094 |
| reward_ctrl        | -0.697   |
| reward_position    | 0.00103  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 924      |
|    ep_rew_mean     | 1.34e+03 |
| time/              |          |
|    episodes        | 656      |
|    fps             | 12       |
|    time_elapsed    | 38996    |
|    total timesteps | 495972   |
| train/             |          |
|    actor_loss      | -129     |
|    critic_loss     | 19.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 490970   |
---------------------------------
Num timesteps: 496000
Best mean reward: 1745.38 - Last mean reward per episode: 1687.31
Num timesteps: 498000
Best mean reward: 1745.38 - Last mean reward per episode: 1670.66
---------------------------------
| forward_vel        | 1.37     |
| reward             | 1.67     |
| reward_contact     | -0.00108 |
| reward_ctrl        | -0.705   |
| reward_position    | 0.00103  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 933      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 660      |
|    fps             | 12       |
|    time_elapsed    | 39250    |
|    total timesteps | 499972   |
| train/             |          |
|    actor_loss      | -131     |
|    critic_loss     | 7.2      |
|    learning_rate   | 0.001    |
|    n_updates       | 494970   |
---------------------------------
Num timesteps: 500000
Best mean reward: 1745.38 - Last mean reward per episode: 1680.68
Num timesteps: 502000
Best mean reward: 1745.38 - Last mean reward per episode: 1667.56
---------------------------------
| forward_vel        | 1.34     |
| reward             | 1.6      |
| reward_contact     | -0.00111 |
| reward_ctrl        | -0.733   |
| reward_position    | 0.00103  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 937      |
|    ep_rew_mean     | 1.38e+03 |
| time/              |          |
|    episodes        | 664      |
|    fps             | 12       |
|    time_elapsed    | 39506    |
|    total timesteps | 503972   |
| train/             |          |
|    actor_loss      | -130     |
|    critic_loss     | 6.89     |
|    learning_rate   | 0.001    |
|    n_updates       | 498970   |
---------------------------------
Num timesteps: 504000
Best mean reward: 1745.38 - Last mean reward per episode: 1655.80
Num timesteps: 506000
Best mean reward: 1745.38 - Last mean reward per episode: 1641.91
---------------------------------
| forward_vel        | 1.33     |
| reward             | 1.6      |
| reward_contact     | -0.00117 |
| reward_ctrl        | -0.735   |
| reward_position    | 0.00103  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 938      |
|    ep_rew_mean     | 1.38e+03 |
| time/              |          |
|    episodes        | 668      |
|    fps             | 12       |
|    time_elapsed    | 39756    |
|    total timesteps | 507848   |
| train/             |          |
|    actor_loss      | -132     |
|    critic_loss     | 7.91     |
|    learning_rate   | 0.001    |
|    n_updates       | 502845   |
---------------------------------
Num timesteps: 508000
Best mean reward: 1745.38 - Last mean reward per episode: 1640.72
Num timesteps: 510000
Best mean reward: 1745.38 - Last mean reward per episode: 1642.65
---------------------------------
| forward_vel        | 1.29     |
| reward             | 1.54     |
| reward_contact     | -0.00123 |
| reward_ctrl        | -0.748   |
| reward_position    | 0.00103  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 945      |
|    ep_rew_mean     | 1.39e+03 |
| time/              |          |
|    episodes        | 672      |
|    fps             | 12       |
|    time_elapsed    | 40013    |
|    total timesteps | 511848   |
| train/             |          |
|    actor_loss      | -133     |
|    critic_loss     | 5.51     |
|    learning_rate   | 0.001    |
|    n_updates       | 506845   |
---------------------------------
Num timesteps: 512000
Best mean reward: 1745.38 - Last mean reward per episode: 1661.11
Num timesteps: 514000
Best mean reward: 1745.38 - Last mean reward per episode: 1637.26
---------------------------------
| forward_vel        | 1.26     |
| reward             | 1.52     |
| reward_contact     | -0.00123 |
| reward_ctrl        | -0.744   |
| reward_position    | 0.000262 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 940      |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 676      |
|    fps             | 12       |
|    time_elapsed    | 40236    |
|    total timesteps | 515303   |
| train/             |          |
|    actor_loss      | -133     |
|    critic_loss     | 8.11     |
|    learning_rate   | 0.001    |
|    n_updates       | 510300   |
---------------------------------
Num timesteps: 516000
Best mean reward: 1745.38 - Last mean reward per episode: 1613.70
Num timesteps: 518000
Best mean reward: 1745.38 - Last mean reward per episode: 1598.29
---------------------------------
| forward_vel        | 1.23     |
| reward             | 1.48     |
| reward_contact     | -0.00128 |
| reward_ctrl        | -0.746   |
| reward_position    | 0.000262 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 934      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 680      |
|    fps             | 12       |
|    time_elapsed    | 40456    |
|    total timesteps | 518717   |
| train/             |          |
|    actor_loss      | -136     |
|    critic_loss     | 10.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 513715   |
---------------------------------
Num timesteps: 520000
Best mean reward: 1745.38 - Last mean reward per episode: 1603.28
Num timesteps: 522000
Best mean reward: 1745.38 - Last mean reward per episode: 1610.61
---------------------------------
| forward_vel        | 1.23     |
| reward             | 1.47     |
| reward_contact     | -0.00131 |
| reward_ctrl        | -0.752   |
| reward_position    | 0.000262 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 938      |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 684      |
|    fps             | 12       |
|    time_elapsed    | 40717    |
|    total timesteps | 522717   |
| train/             |          |
|    actor_loss      | -130     |
|    critic_loss     | 8.73     |
|    learning_rate   | 0.001    |
|    n_updates       | 517715   |
---------------------------------
Num timesteps: 524000
Best mean reward: 1745.38 - Last mean reward per episode: 1596.98
---------------------------------
| forward_vel        | 1.21     |
| reward             | 1.44     |
| reward_contact     | -0.00135 |
| reward_ctrl        | -0.766   |
| reward_position    | 0.000262 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 928      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 688      |
|    fps             | 12       |
|    time_elapsed    | 40914    |
|    total timesteps | 525729   |
| train/             |          |
|    actor_loss      | -133     |
|    critic_loss     | 10.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 520725   |
---------------------------------
Num timesteps: 526000
Best mean reward: 1745.38 - Last mean reward per episode: 1567.72
Num timesteps: 528000
Best mean reward: 1745.38 - Last mean reward per episode: 1553.14
---------------------------------
| forward_vel        | 1.23     |
| reward             | 1.45     |
| reward_contact     | -0.00141 |
| reward_ctrl        | -0.775   |
| reward_position    | 0.000262 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 928      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 692      |
|    fps             | 12       |
|    time_elapsed    | 41175    |
|    total timesteps | 529729   |
| train/             |          |
|    actor_loss      | -134     |
|    critic_loss     | 8.95     |
|    learning_rate   | 0.001    |
|    n_updates       | 524725   |
---------------------------------
Num timesteps: 530000
Best mean reward: 1745.38 - Last mean reward per episode: 1552.59
Num timesteps: 532000
Best mean reward: 1745.38 - Last mean reward per episode: 1538.81
---------------------------------
| forward_vel        | 1.2      |
| reward             | 1.44     |
| reward_contact     | -0.00137 |
| reward_ctrl        | -0.76    |
| reward_position    | 0.000277 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 939      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 696      |
|    fps             | 12       |
|    time_elapsed    | 41435    |
|    total timesteps | 533729   |
| train/             |          |
|    actor_loss      | -135     |
|    critic_loss     | 12.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 528725   |
---------------------------------
Num timesteps: 534000
Best mean reward: 1745.38 - Last mean reward per episode: 1530.27
Num timesteps: 536000
Best mean reward: 1745.38 - Last mean reward per episode: 1524.62
---------------------------------
| forward_vel        | 1.18     |
| reward             | 1.42     |
| reward_contact     | -0.00134 |
| reward_ctrl        | -0.763   |
| reward_position    | 1.65e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 941      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 700      |
|    fps             | 12       |
|    time_elapsed    | 41662    |
|    total timesteps | 537204   |
| train/             |          |
|    actor_loss      | -135     |
|    critic_loss     | 49.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 532200   |
---------------------------------
Num timesteps: 538000
Best mean reward: 1745.38 - Last mean reward per episode: 1525.48
Num timesteps: 540000
Best mean reward: 1745.38 - Last mean reward per episode: 1537.63
---------------------------------
| forward_vel        | 1.15     |
| reward             | 1.37     |
| reward_contact     | -0.00131 |
| reward_ctrl        | -0.778   |
| reward_position    | 1.65e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 941      |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 704      |
|    fps             | 12       |
|    time_elapsed    | 41925    |
|    total timesteps | 541204   |
| train/             |          |
|    actor_loss      | -131     |
|    critic_loss     | 9.67     |
|    learning_rate   | 0.001    |
|    n_updates       | 536200   |
---------------------------------
Num timesteps: 542000
Best mean reward: 1745.38 - Last mean reward per episode: 1521.87
Num timesteps: 544000
Best mean reward: 1745.38 - Last mean reward per episode: 1524.02
---------------------------------
| forward_vel        | 1.13     |
| reward             | 1.35     |
| reward_contact     | -0.0014  |
| reward_ctrl        | -0.778   |
| reward_position    | 1.65e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 944      |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 708      |
|    fps             | 12       |
|    time_elapsed    | 42172    |
|    total timesteps | 544959   |
| train/             |          |
|    actor_loss      | -135     |
|    critic_loss     | 7.04     |
|    learning_rate   | 0.001    |
|    n_updates       | 539955   |
---------------------------------
Num timesteps: 546000
Best mean reward: 1745.38 - Last mean reward per episode: 1535.82
Num timesteps: 548000
Best mean reward: 1745.38 - Last mean reward per episode: 1532.01
---------------------------------
| forward_vel        | 1.18     |
| reward             | 1.4      |
| reward_contact     | -0.00138 |
| reward_ctrl        | -0.782   |
| reward_position    | 1.65e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 941      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 712      |
|    fps             | 12       |
|    time_elapsed    | 42418    |
|    total timesteps | 548710   |
| train/             |          |
|    actor_loss      | -138     |
|    critic_loss     | 29.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 543705   |
---------------------------------
Num timesteps: 550000
Best mean reward: 1745.38 - Last mean reward per episode: 1531.05
Num timesteps: 552000
Best mean reward: 1745.38 - Last mean reward per episode: 1539.83
---------------------------------
| forward_vel        | 1.17     |
| reward             | 1.4      |
| reward_contact     | -0.00136 |
| reward_ctrl        | -0.778   |
| reward_position    | 2.58e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 938      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 716      |
|    fps             | 12       |
|    time_elapsed    | 42660    |
|    total timesteps | 552367   |
| train/             |          |
|    actor_loss      | -136     |
|    critic_loss     | 11.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 547365   |
---------------------------------
Num timesteps: 554000
Best mean reward: 1745.38 - Last mean reward per episode: 1538.25
Num timesteps: 556000
Best mean reward: 1745.38 - Last mean reward per episode: 1540.98
---------------------------------
| forward_vel        | 1.16     |
| reward             | 1.37     |
| reward_contact     | -0.00136 |
| reward_ctrl        | -0.782   |
| reward_position    | 2.42e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 945      |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 720      |
|    fps             | 12       |
|    time_elapsed    | 42924    |
|    total timesteps | 556367   |
| train/             |          |
|    actor_loss      | -137     |
|    critic_loss     | 7.18     |
|    learning_rate   | 0.001    |
|    n_updates       | 551365   |
---------------------------------
Num timesteps: 558000
Best mean reward: 1745.38 - Last mean reward per episode: 1528.98
Num timesteps: 560000
Best mean reward: 1745.38 - Last mean reward per episode: 1527.27
---------------------------------
| forward_vel        | 1.15     |
| reward             | 1.38     |
| reward_contact     | -0.00141 |
| reward_ctrl        | -0.775   |
| reward_position    | 2.47e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 954      |
|    ep_rew_mean     | 1.39e+03 |
| time/              |          |
|    episodes        | 724      |
|    fps             | 12       |
|    time_elapsed    | 43185    |
|    total timesteps | 560367   |
| train/             |          |
|    actor_loss      | -137     |
|    critic_loss     | 9.62     |
|    learning_rate   | 0.001    |
|    n_updates       | 555365   |
---------------------------------
Num timesteps: 562000
Best mean reward: 1745.38 - Last mean reward per episode: 1520.80
Num timesteps: 564000
Best mean reward: 1745.38 - Last mean reward per episode: 1509.59
---------------------------------
| forward_vel        | 1.12     |
| reward             | 1.34     |
| reward_contact     | -0.00147 |
| reward_ctrl        | -0.782   |
| reward_position    | 2.47e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 954      |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 728      |
|    fps             | 12       |
|    time_elapsed    | 43445    |
|    total timesteps | 564367   |
| train/             |          |
|    actor_loss      | -136     |
|    critic_loss     | 10.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 559365   |
---------------------------------
Num timesteps: 566000
Best mean reward: 1745.38 - Last mean reward per episode: 1489.52
Num timesteps: 568000
Best mean reward: 1745.38 - Last mean reward per episode: 1467.97
---------------------------------
| forward_vel        | 1.1      |
| reward             | 1.3      |
| reward_contact     | -0.00152 |
| reward_ctrl        | -0.8     |
| reward_position    | 2.47e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 954      |
|    ep_rew_mean     | 1.38e+03 |
| time/              |          |
|    episodes        | 732      |
|    fps             | 13       |
|    time_elapsed    | 43705    |
|    total timesteps | 568367   |
| train/             |          |
|    actor_loss      | -133     |
|    critic_loss     | 5.79     |
|    learning_rate   | 0.001    |
|    n_updates       | 563365   |
---------------------------------
Num timesteps: 570000
Best mean reward: 1745.38 - Last mean reward per episode: 1453.02
Num timesteps: 572000
Best mean reward: 1745.38 - Last mean reward per episode: 1438.28
---------------------------------
| forward_vel        | 1.08     |
| reward             | 1.25     |
| reward_contact     | -0.00152 |
| reward_ctrl        | -0.824   |
| reward_position    | 2.47e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 964      |
|    ep_rew_mean     | 1.4e+03  |
| time/              |          |
|    episodes        | 736      |
|    fps             | 13       |
|    time_elapsed    | 43961    |
|    total timesteps | 572367   |
| train/             |          |
|    actor_loss      | -137     |
|    critic_loss     | 4.96     |
|    learning_rate   | 0.001    |
|    n_updates       | 567365   |
---------------------------------
Num timesteps: 574000
Best mean reward: 1745.38 - Last mean reward per episode: 1443.55
Num timesteps: 576000
Best mean reward: 1745.38 - Last mean reward per episode: 1429.97
---------------------------------
| forward_vel        | 1.07     |
| reward             | 1.25     |
| reward_contact     | -0.0014  |
| reward_ctrl        | -0.816   |
| reward_position    | 2.47e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 964      |
|    ep_rew_mean     | 1.41e+03 |
| time/              |          |
|    episodes        | 740      |
|    fps             | 13       |
|    time_elapsed    | 44220    |
|    total timesteps | 576367   |
| train/             |          |
|    actor_loss      | -132     |
|    critic_loss     | 8.89     |
|    learning_rate   | 0.001    |
|    n_updates       | 571365   |
---------------------------------
Num timesteps: 578000
Best mean reward: 1745.38 - Last mean reward per episode: 1437.76
Num timesteps: 580000
Best mean reward: 1745.38 - Last mean reward per episode: 1428.53
---------------------------------
| forward_vel        | 1.1      |
| reward             | 1.31     |
| reward_contact     | -0.00157 |
| reward_ctrl        | -0.785   |
| reward_position    | 2.47e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 964      |
|    ep_rew_mean     | 1.41e+03 |
| time/              |          |
|    episodes        | 744      |
|    fps             | 13       |
|    time_elapsed    | 44475    |
|    total timesteps | 580367   |
| train/             |          |
|    actor_loss      | -131     |
|    critic_loss     | 10.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 575365   |
---------------------------------
Num timesteps: 582000
Best mean reward: 1745.38 - Last mean reward per episode: 1410.35
Num timesteps: 584000
Best mean reward: 1745.38 - Last mean reward per episode: 1416.70
---------------------------------
| forward_vel        | 1.04     |
| reward             | 1.25     |
| reward_contact     | -0.00165 |
| reward_ctrl        | -0.789   |
| reward_position    | 2.46e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 964      |
|    ep_rew_mean     | 1.41e+03 |
| time/              |          |
|    episodes        | 748      |
|    fps             | 13       |
|    time_elapsed    | 44730    |
|    total timesteps | 584367   |
| train/             |          |
|    actor_loss      | -141     |
|    critic_loss     | 13.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 579365   |
---------------------------------
Num timesteps: 586000
Best mean reward: 1745.38 - Last mean reward per episode: 1415.45
Num timesteps: 588000
Best mean reward: 1745.38 - Last mean reward per episode: 1418.80
---------------------------------
| forward_vel        | 1.06     |
| reward             | 1.28     |
| reward_contact     | -0.00155 |
| reward_ctrl        | -0.781   |
| reward_position    | 2.46e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 964      |
|    ep_rew_mean     | 1.42e+03 |
| time/              |          |
|    episodes        | 752      |
|    fps             | 13       |
|    time_elapsed    | 44985    |
|    total timesteps | 588367   |
| train/             |          |
|    actor_loss      | -138     |
|    critic_loss     | 5.81     |
|    learning_rate   | 0.001    |
|    n_updates       | 583365   |
---------------------------------
Num timesteps: 590000
Best mean reward: 1745.38 - Last mean reward per episode: 1422.87
Num timesteps: 592000
Best mean reward: 1745.38 - Last mean reward per episode: 1419.06
---------------------------------
| forward_vel        | 1.05     |
| reward             | 1.25     |
| reward_contact     | -0.00157 |
| reward_ctrl        | -0.798   |
| reward_position    | 2.48e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 964      |
|    ep_rew_mean     | 1.42e+03 |
| time/              |          |
|    episodes        | 756      |
|    fps             | 13       |
|    time_elapsed    | 45241    |
|    total timesteps | 592367   |
| train/             |          |
|    actor_loss      | -137     |
|    critic_loss     | 6.36     |
|    learning_rate   | 0.001    |
|    n_updates       | 587365   |
---------------------------------
---------------------------------
| forward_vel        | 1.05     |
| reward             | 1.24     |
| reward_contact     | -0.00151 |
| reward_ctrl        | -0.815   |
| reward_position    | 2.48e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 938      |
|    ep_rew_mean     | 1.38e+03 |
| time/              |          |
|    episodes        | 760      |
|    fps             | 13       |
|    time_elapsed    | 45332    |
|    total timesteps | 593786   |
| train/             |          |
|    actor_loss      | -134     |
|    critic_loss     | 4.95     |
|    learning_rate   | 0.001    |
|    n_updates       | 588785   |
---------------------------------
Num timesteps: 594000
Best mean reward: 1745.38 - Last mean reward per episode: 1382.69
Num timesteps: 596000
Best mean reward: 1745.38 - Last mean reward per episode: 1373.96
---------------------------------
| forward_vel        | 1.05     |
| reward             | 1.25     |
| reward_contact     | -0.00151 |
| reward_ctrl        | -0.816   |
| reward_position    | 0.00886  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 932      |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 764      |
|    fps             | 13       |
|    time_elapsed    | 45548    |
|    total timesteps | 597180   |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 8.83     |
|    learning_rate   | 0.001    |
|    n_updates       | 592175   |
---------------------------------
Num timesteps: 598000
Best mean reward: 1745.38 - Last mean reward per episode: 1367.25
Num timesteps: 600000
Best mean reward: 1745.38 - Last mean reward per episode: 1369.12
---------------------------------
| forward_vel        | 1.05     |
| reward             | 1.22     |
| reward_contact     | -0.00147 |
| reward_ctrl        | -0.841   |
| reward_position    | 0.00886  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 924      |
|    ep_rew_mean     | 1.35e+03 |
| time/              |          |
|    episodes        | 768      |
|    fps             | 13       |
|    time_elapsed    | 45742    |
|    total timesteps | 600224   |
| train/             |          |
|    actor_loss      | -135     |
|    critic_loss     | 7.43     |
|    learning_rate   | 0.001    |
|    n_updates       | 595220   |
---------------------------------
Num timesteps: 602000
Best mean reward: 1745.38 - Last mean reward per episode: 1356.07
Num timesteps: 604000
Best mean reward: 1745.38 - Last mean reward per episode: 1363.99
---------------------------------
| forward_vel        | 1.1      |
| reward             | 1.29     |
| reward_contact     | -0.00136 |
| reward_ctrl        | -0.823   |
| reward_position    | 0.00886  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 924      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 772      |
|    fps             | 13       |
|    time_elapsed    | 45995    |
|    total timesteps | 604224   |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 7.06     |
|    learning_rate   | 0.001    |
|    n_updates       | 599220   |
---------------------------------
Num timesteps: 606000
Best mean reward: 1745.38 - Last mean reward per episode: 1361.82
---------------------------------
| forward_vel        | 1.1      |
| reward             | 1.29     |
| reward_contact     | -0.00134 |
| reward_ctrl        | -0.815   |
| reward_position    | 0.00886  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 917      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 776      |
|    fps             | 13       |
|    time_elapsed    | 46171    |
|    total timesteps | 606992   |
| train/             |          |
|    actor_loss      | -138     |
|    critic_loss     | 9.24     |
|    learning_rate   | 0.001    |
|    n_updates       | 601990   |
---------------------------------
Num timesteps: 608000
Best mean reward: 1745.38 - Last mean reward per episode: 1372.11
Num timesteps: 610000
Best mean reward: 1745.38 - Last mean reward per episode: 1360.79
---------------------------------
| forward_vel        | 1.13     |
| reward             | 1.32     |
| reward_contact     | -0.00121 |
| reward_ctrl        | -0.821   |
| reward_position    | 0.00886  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 923      |
|    ep_rew_mean     | 1.35e+03 |
| time/              |          |
|    episodes        | 780      |
|    fps             | 13       |
|    time_elapsed    | 46426    |
|    total timesteps | 610992   |
| train/             |          |
|    actor_loss      | -139     |
|    critic_loss     | 8.35     |
|    learning_rate   | 0.001    |
|    n_updates       | 605990   |
---------------------------------
Num timesteps: 612000
Best mean reward: 1745.38 - Last mean reward per episode: 1350.41
Num timesteps: 614000
Best mean reward: 1745.38 - Last mean reward per episode: 1344.35
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.33     |
| reward_contact     | -0.00122 |
| reward_ctrl        | -0.824   |
| reward_position    | 0.00886  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 917      |
|    ep_rew_mean     | 1.34e+03 |
| time/              |          |
|    episodes        | 784      |
|    fps             | 13       |
|    time_elapsed    | 46647    |
|    total timesteps | 614453   |
| train/             |          |
|    actor_loss      | -137     |
|    critic_loss     | 14.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 609450   |
---------------------------------
Num timesteps: 616000
Best mean reward: 1745.38 - Last mean reward per episode: 1342.24
---------------------------------
| forward_vel        | 1.13     |
| reward             | 1.29     |
| reward_contact     | -0.00123 |
| reward_ctrl        | -0.847   |
| reward_position    | 0.00886  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 1.35e+03 |
| time/              |          |
|    episodes        | 788      |
|    fps             | 13       |
|    time_elapsed    | 46870    |
|    total timesteps | 617955   |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 11.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 612950   |
---------------------------------
Num timesteps: 618000
Best mean reward: 1745.38 - Last mean reward per episode: 1350.14
Num timesteps: 620000
Best mean reward: 1745.38 - Last mean reward per episode: 1348.92
---------------------------------
| forward_vel        | 1.1      |
| reward             | 1.26     |
| reward_contact     | -0.00125 |
| reward_ctrl        | -0.844   |
| reward_position    | 0.00886  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 1.35e+03 |
| time/              |          |
|    episodes        | 792      |
|    fps             | 13       |
|    time_elapsed    | 47128    |
|    total timesteps | 621955   |
| train/             |          |
|    actor_loss      | -143     |
|    critic_loss     | 7.27     |
|    learning_rate   | 0.001    |
|    n_updates       | 616950   |
---------------------------------
Num timesteps: 622000
Best mean reward: 1745.38 - Last mean reward per episode: 1352.72
Num timesteps: 624000
Best mean reward: 1745.38 - Last mean reward per episode: 1342.30
---------------------------------
| forward_vel        | 1.12     |
| reward             | 1.28     |
| reward_contact     | -0.00127 |
| reward_ctrl        | -0.849   |
| reward_position    | 0.00885  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 904      |
|    ep_rew_mean     | 1.34e+03 |
| time/              |          |
|    episodes        | 796      |
|    fps             | 13       |
|    time_elapsed    | 47271    |
|    total timesteps | 624178   |
| train/             |          |
|    actor_loss      | -138     |
|    critic_loss     | 7.99     |
|    learning_rate   | 0.001    |
|    n_updates       | 619175   |
---------------------------------
Num timesteps: 626000
Best mean reward: 1745.38 - Last mean reward per episode: 1329.03
---------------------------------
| forward_vel        | 1.1      |
| reward             | 1.26     |
| reward_contact     | -0.00135 |
| reward_ctrl        | -0.848   |
| reward_position    | 0.00885  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 903      |
|    ep_rew_mean     | 1.32e+03 |
| time/              |          |
|    episodes        | 800      |
|    fps             | 13       |
|    time_elapsed    | 47485    |
|    total timesteps | 627473   |
| train/             |          |
|    actor_loss      | -136     |
|    critic_loss     | 12.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 622470   |
---------------------------------
Num timesteps: 628000
Best mean reward: 1745.38 - Last mean reward per episode: 1323.43
Num timesteps: 630000
Best mean reward: 1745.38 - Last mean reward per episode: 1322.30
---------------------------------
| forward_vel        | 1.12     |
| reward             | 1.27     |
| reward_contact     | -0.00135 |
| reward_ctrl        | -0.865   |
| reward_position    | 0.00885  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 897      |
|    ep_rew_mean     | 1.31e+03 |
| time/              |          |
|    episodes        | 804      |
|    fps             | 13       |
|    time_elapsed    | 47706    |
|    total timesteps | 630896   |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 8.94     |
|    learning_rate   | 0.001    |
|    n_updates       | 625895   |
---------------------------------
Num timesteps: 632000
Best mean reward: 1745.38 - Last mean reward per episode: 1313.31
Num timesteps: 634000
Best mean reward: 1745.38 - Last mean reward per episode: 1306.49
---------------------------------
| forward_vel        | 1.12     |
| reward             | 1.24     |
| reward_contact     | -0.00129 |
| reward_ctrl        | -0.884   |
| reward_position    | 0.00885  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 898      |
|    ep_rew_mean     | 1.31e+03 |
| time/              |          |
|    episodes        | 808      |
|    fps             | 13       |
|    time_elapsed    | 47956    |
|    total timesteps | 634741   |
| train/             |          |
|    actor_loss      | -139     |
|    critic_loss     | 9.55     |
|    learning_rate   | 0.001    |
|    n_updates       | 629740   |
---------------------------------
Num timesteps: 636000
Best mean reward: 1745.38 - Last mean reward per episode: 1312.53
Num timesteps: 638000
Best mean reward: 1745.38 - Last mean reward per episode: 1320.16
---------------------------------
| forward_vel        | 1.1      |
| reward             | 1.23     |
| reward_contact     | -0.00134 |
| reward_ctrl        | -0.879   |
| reward_position    | 0.00885  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 900      |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    episodes        | 812      |
|    fps             | 13       |
|    time_elapsed    | 48216    |
|    total timesteps | 638741   |
| train/             |          |
|    actor_loss      | -138     |
|    critic_loss     | 11.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 633740   |
---------------------------------
Num timesteps: 640000
Best mean reward: 1745.38 - Last mean reward per episode: 1332.47
Num timesteps: 642000
Best mean reward: 1745.38 - Last mean reward per episode: 1337.07
---------------------------------
| forward_vel        | 1.09     |
| reward             | 1.2      |
| reward_contact     | -0.00136 |
| reward_ctrl        | -0.894   |
| reward_position    | 0.00884  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 904      |
|    ep_rew_mean     | 1.34e+03 |
| time/              |          |
|    episodes        | 816      |
|    fps             | 13       |
|    time_elapsed    | 48478    |
|    total timesteps | 642741   |
| train/             |          |
|    actor_loss      | -139     |
|    critic_loss     | 8.49     |
|    learning_rate   | 0.001    |
|    n_updates       | 637740   |
---------------------------------
Num timesteps: 644000
Best mean reward: 1745.38 - Last mean reward per episode: 1325.82
---------------------------------
| forward_vel        | 1.11     |
| reward             | 1.22     |
| reward_contact     | -0.00139 |
| reward_ctrl        | -0.902   |
| reward_position    | 0.00884  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 1.34e+03 |
| time/              |          |
|    episodes        | 820      |
|    fps             | 13       |
|    time_elapsed    | 48684    |
|    total timesteps | 645851   |
| train/             |          |
|    actor_loss      | -138     |
|    critic_loss     | 13       |
|    learning_rate   | 0.001    |
|    n_updates       | 640850   |
---------------------------------
Num timesteps: 646000
Best mean reward: 1745.38 - Last mean reward per episode: 1343.98
Num timesteps: 648000
Best mean reward: 1745.38 - Last mean reward per episode: 1347.43
---------------------------------
| forward_vel        | 1.12     |
| reward             | 1.21     |
| reward_contact     | -0.00136 |
| reward_ctrl        | -0.918   |
| reward_position    | 0.00884  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 891      |
|    ep_rew_mean     | 1.34e+03 |
| time/              |          |
|    episodes        | 824      |
|    fps             | 13       |
|    time_elapsed    | 48927    |
|    total timesteps | 649474   |
| train/             |          |
|    actor_loss      | -138     |
|    critic_loss     | 14.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 644470   |
---------------------------------
Num timesteps: 650000
Best mean reward: 1745.38 - Last mean reward per episode: 1341.03
Num timesteps: 652000
Best mean reward: 1745.38 - Last mean reward per episode: 1348.77
---------------------------------
| forward_vel        | 1.13     |
| reward             | 1.22     |
| reward_contact     | -0.00134 |
| reward_ctrl        | -0.917   |
| reward_position    | 0.00884  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 891      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 828      |
|    fps             | 13       |
|    time_elapsed    | 49196    |
|    total timesteps | 653474   |
| train/             |          |
|    actor_loss      | -139     |
|    critic_loss     | 9.03     |
|    learning_rate   | 0.001    |
|    n_updates       | 648470   |
---------------------------------
Num timesteps: 654000
Best mean reward: 1745.38 - Last mean reward per episode: 1345.83
Num timesteps: 656000
Best mean reward: 1745.38 - Last mean reward per episode: 1348.92
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.22     |
| reward_contact     | -0.00125 |
| reward_ctrl        | -0.932   |
| reward_position    | 0.00884  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 885      |
|    ep_rew_mean     | 1.35e+03 |
| time/              |          |
|    episodes        | 832      |
|    fps             | 13       |
|    time_elapsed    | 49423    |
|    total timesteps | 656839   |
| train/             |          |
|    actor_loss      | -137     |
|    critic_loss     | 21.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 651835   |
---------------------------------
Num timesteps: 658000
Best mean reward: 1745.38 - Last mean reward per episode: 1331.23
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.19     |
| reward_contact     | -0.00127 |
| reward_ctrl        | -0.954   |
| reward_position    | 0.00884  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 876      |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    episodes        | 836      |
|    fps             | 13       |
|    time_elapsed    | 49634    |
|    total timesteps | 659960   |
| train/             |          |
|    actor_loss      | -137     |
|    critic_loss     | 13.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 654955   |
---------------------------------
Num timesteps: 660000
Best mean reward: 1745.38 - Last mean reward per episode: 1331.83
Num timesteps: 662000
Best mean reward: 1745.38 - Last mean reward per episode: 1328.28
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.18     |
| reward_contact     | -0.00128 |
| reward_ctrl        | -0.964   |
| reward_position    | 0.00884  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 876      |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    episodes        | 840      |
|    fps             | 13       |
|    time_elapsed    | 49906    |
|    total timesteps | 663960   |
| train/             |          |
|    actor_loss      | -138     |
|    critic_loss     | 8.42     |
|    learning_rate   | 0.001    |
|    n_updates       | 658955   |
---------------------------------
Num timesteps: 664000
Best mean reward: 1745.38 - Last mean reward per episode: 1332.40
Num timesteps: 666000
Best mean reward: 1745.38 - Last mean reward per episode: 1333.02
---------------------------------
| forward_vel        | 1.11     |
| reward             | 1.15     |
| reward_contact     | -0.00112 |
| reward_ctrl        | -0.97    |
| reward_position    | 0.00884  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 876      |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    episodes        | 844      |
|    fps             | 13       |
|    time_elapsed    | 50178    |
|    total timesteps | 667960   |
| train/             |          |
|    actor_loss      | -137     |
|    critic_loss     | 9.36     |
|    learning_rate   | 0.001    |
|    n_updates       | 662955   |
---------------------------------
Num timesteps: 668000
Best mean reward: 1745.38 - Last mean reward per episode: 1334.51
Num timesteps: 670000
Best mean reward: 1745.38 - Last mean reward per episode: 1333.34
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.19     |
| reward_contact     | -0.0011  |
| reward_ctrl        | -0.963   |
| reward_position    | 0.00884  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 876      |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    episodes        | 848      |
|    fps             | 13       |
|    time_elapsed    | 50451    |
|    total timesteps | 671960   |
| train/             |          |
|    actor_loss      | -140     |
|    critic_loss     | 11.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 666955   |
---------------------------------
Num timesteps: 672000
Best mean reward: 1745.38 - Last mean reward per episode: 1333.07
Num timesteps: 674000
Best mean reward: 1745.38 - Last mean reward per episode: 1318.90
---------------------------------
| forward_vel        | 1.13     |
| reward             | 1.17     |
| reward_contact     | -0.00119 |
| reward_ctrl        | -0.972   |
| reward_position    | 0.00884  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 867      |
|    ep_rew_mean     | 1.32e+03 |
| time/              |          |
|    episodes        | 852      |
|    fps             | 13       |
|    time_elapsed    | 50664    |
|    total timesteps | 675083   |
| train/             |          |
|    actor_loss      | -135     |
|    critic_loss     | 17.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 670080   |
---------------------------------
Num timesteps: 676000
Best mean reward: 1745.38 - Last mean reward per episode: 1320.79
Num timesteps: 678000
Best mean reward: 1745.38 - Last mean reward per episode: 1319.31
---------------------------------
| forward_vel        | 1.16     |
| reward             | 1.19     |
| reward_contact     | -0.00119 |
| reward_ctrl        | -0.973   |
| reward_position    | 0.00884  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 867      |
|    ep_rew_mean     | 1.32e+03 |
| time/              |          |
|    episodes        | 856      |
|    fps             | 13       |
|    time_elapsed    | 50936    |
|    total timesteps | 679083   |
| train/             |          |
|    actor_loss      | -139     |
|    critic_loss     | 10.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 674080   |
---------------------------------
Num timesteps: 680000
Best mean reward: 1745.38 - Last mean reward per episode: 1324.13
Num timesteps: 682000
Best mean reward: 1745.38 - Last mean reward per episode: 1338.08
---------------------------------
| forward_vel        | 1.16     |
| reward             | 1.23     |
| reward_contact     | -0.00123 |
| reward_ctrl        | -0.941   |
| reward_position    | 0.00884  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 893      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 860      |
|    fps             | 13       |
|    time_elapsed    | 51224    |
|    total timesteps | 683083   |
| train/             |          |
|    actor_loss      | -141     |
|    critic_loss     | 8.29     |
|    learning_rate   | 0.001    |
|    n_updates       | 678080   |
---------------------------------
Num timesteps: 684000
Best mean reward: 1745.38 - Last mean reward per episode: 1364.33
Num timesteps: 686000
Best mean reward: 1745.38 - Last mean reward per episode: 1358.32
---------------------------------
| forward_vel        | 1.19     |
| reward             | 1.25     |
| reward_contact     | -0.00116 |
| reward_ctrl        | -0.935   |
| reward_position    | 1.51e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 891      |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 864      |
|    fps             | 13       |
|    time_elapsed    | 51395    |
|    total timesteps | 686239   |
| train/             |          |
|    actor_loss      | -134     |
|    critic_loss     | 13.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 681235   |
---------------------------------
Num timesteps: 688000
Best mean reward: 1745.38 - Last mean reward per episode: 1358.26
Num timesteps: 690000
Best mean reward: 1745.38 - Last mean reward per episode: 1358.03
---------------------------------
| forward_vel        | 1.16     |
| reward             | 1.25     |
| reward_contact     | -0.00115 |
| reward_ctrl        | -0.914   |
| reward_position    | 1.51e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 900      |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 868      |
|    fps             | 13       |
|    time_elapsed    | 51652    |
|    total timesteps | 690239   |
| train/             |          |
|    actor_loss      | -135     |
|    critic_loss     | 9.63     |
|    learning_rate   | 0.001    |
|    n_updates       | 685235   |
---------------------------------
Num timesteps: 692000
Best mean reward: 1745.38 - Last mean reward per episode: 1371.91
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.22     |
| reward_contact     | -0.00112 |
| reward_ctrl        | -0.921   |
| reward_position    | 1.37e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 890      |
|    ep_rew_mean     | 1.35e+03 |
| time/              |          |
|    episodes        | 872      |
|    fps             | 13       |
|    time_elapsed    | 51896    |
|    total timesteps | 693271   |
| train/             |          |
|    actor_loss      | -137     |
|    critic_loss     | 12.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 688270   |
---------------------------------
Num timesteps: 694000
Best mean reward: 1745.38 - Last mean reward per episode: 1353.15
Num timesteps: 696000
Best mean reward: 1745.38 - Last mean reward per episode: 1370.72
---------------------------------
| forward_vel        | 1.15     |
| reward             | 1.23     |
| reward_contact     | -0.00114 |
| reward_ctrl        | -0.914   |
| reward_position    | 1.37e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 903      |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 876      |
|    fps             | 13       |
|    time_elapsed    | 52197    |
|    total timesteps | 697271   |
| train/             |          |
|    actor_loss      | -139     |
|    critic_loss     | 10       |
|    learning_rate   | 0.001    |
|    n_updates       | 692270   |
---------------------------------
Num timesteps: 698000
Best mean reward: 1745.38 - Last mean reward per episode: 1371.02
Num timesteps: 700000
Best mean reward: 1745.38 - Last mean reward per episode: 1369.24
---------------------------------
| forward_vel        | 1.13     |
| reward             | 1.22     |
| reward_contact     | -0.00123 |
| reward_ctrl        | -0.914   |
| reward_position    | 1.37e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 903      |
|    ep_rew_mean     | 1.38e+03 |
| time/              |          |
|    episodes        | 880      |
|    fps             | 13       |
|    time_elapsed    | 52470    |
|    total timesteps | 701271   |
| train/             |          |
|    actor_loss      | -143     |
|    critic_loss     | 11.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 696270   |
---------------------------------
Num timesteps: 702000
Best mean reward: 1745.38 - Last mean reward per episode: 1380.40
Num timesteps: 704000
Best mean reward: 1745.38 - Last mean reward per episode: 1388.99
---------------------------------
| forward_vel        | 1.13     |
| reward             | 1.2      |
| reward_contact     | -0.00127 |
| reward_ctrl        | -0.925   |
| reward_position    | 1.37e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 908      |
|    ep_rew_mean     | 1.39e+03 |
| time/              |          |
|    episodes        | 884      |
|    fps             | 13       |
|    time_elapsed    | 52744    |
|    total timesteps | 705271   |
| train/             |          |
|    actor_loss      | -136     |
|    critic_loss     | 13.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 700270   |
---------------------------------
Num timesteps: 706000
Best mean reward: 1745.38 - Last mean reward per episode: 1388.58
Num timesteps: 708000
Best mean reward: 1745.38 - Last mean reward per episode: 1390.04
---------------------------------
| forward_vel        | 1.16     |
| reward             | 1.24     |
| reward_contact     | -0.0013  |
| reward_ctrl        | -0.916   |
| reward_position    | 1.24e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 911      |
|    ep_rew_mean     | 1.4e+03  |
| time/              |          |
|    episodes        | 888      |
|    fps             | 13       |
|    time_elapsed    | 52999    |
|    total timesteps | 709006   |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 9.83     |
|    learning_rate   | 0.001    |
|    n_updates       | 704005   |
---------------------------------
Num timesteps: 710000
Best mean reward: 1745.38 - Last mean reward per episode: 1398.72
Num timesteps: 712000
Best mean reward: 1745.38 - Last mean reward per episode: 1400.35
---------------------------------
| forward_vel        | 1.13     |
| reward             | 1.21     |
| reward_contact     | -0.00128 |
| reward_ctrl        | -0.92    |
| reward_position    | 2.08e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 911      |
|    ep_rew_mean     | 1.38e+03 |
| time/              |          |
|    episodes        | 892      |
|    fps             | 13       |
|    time_elapsed    | 53278    |
|    total timesteps | 713006   |
| train/             |          |
|    actor_loss      | -137     |
|    critic_loss     | 17.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 708005   |
---------------------------------
Num timesteps: 714000
Best mean reward: 1745.38 - Last mean reward per episode: 1382.13
Num timesteps: 716000
Best mean reward: 1745.38 - Last mean reward per episode: 1397.81
---------------------------------
| forward_vel        | 1.13     |
| reward             | 1.21     |
| reward_contact     | -0.00129 |
| reward_ctrl        | -0.922   |
| reward_position    | 2.08e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 925      |
|    ep_rew_mean     | 1.41e+03 |
| time/              |          |
|    episodes        | 896      |
|    fps             | 13       |
|    time_elapsed    | 53555    |
|    total timesteps | 716708   |
| train/             |          |
|    actor_loss      | -138     |
|    critic_loss     | 14.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 711705   |
---------------------------------
Num timesteps: 718000
Best mean reward: 1745.38 - Last mean reward per episode: 1420.85
Num timesteps: 720000
Best mean reward: 1745.38 - Last mean reward per episode: 1423.76
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.21     |
| reward_contact     | -0.00122 |
| reward_ctrl        | -0.923   |
| reward_position    | 2.08e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 932      |
|    ep_rew_mean     | 1.44e+03 |
| time/              |          |
|    episodes        | 900      |
|    fps             | 13       |
|    time_elapsed    | 53792    |
|    total timesteps | 720708   |
| train/             |          |
|    actor_loss      | -140     |
|    critic_loss     | 10.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 715705   |
---------------------------------
Num timesteps: 722000
Best mean reward: 1745.38 - Last mean reward per episode: 1434.29
Num timesteps: 724000
Best mean reward: 1745.38 - Last mean reward per episode: 1442.87
---------------------------------
| forward_vel        | 1.12     |
| reward             | 1.22     |
| reward_contact     | -0.00125 |
| reward_ctrl        | -0.897   |
| reward_position    | 2.08e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 938      |
|    ep_rew_mean     | 1.45e+03 |
| time/              |          |
|    episodes        | 904      |
|    fps             | 13       |
|    time_elapsed    | 54119    |
|    total timesteps | 724708   |
| train/             |          |
|    actor_loss      | -139     |
|    critic_loss     | 18.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 719705   |
---------------------------------
Num timesteps: 726000
Best mean reward: 1745.38 - Last mean reward per episode: 1455.34
Num timesteps: 728000
Best mean reward: 1745.38 - Last mean reward per episode: 1464.38
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.23     |
| reward_contact     | -0.00126 |
| reward_ctrl        | -0.901   |
| reward_position    | 2.08e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 939      |
|    ep_rew_mean     | 1.47e+03 |
| time/              |          |
|    episodes        | 908      |
|    fps             | 13       |
|    time_elapsed    | 54393    |
|    total timesteps | 728658   |
| train/             |          |
|    actor_loss      | -136     |
|    critic_loss     | 9.74     |
|    learning_rate   | 0.001    |
|    n_updates       | 723655   |
---------------------------------
Num timesteps: 730000
Best mean reward: 1745.38 - Last mean reward per episode: 1463.83
Num timesteps: 732000
Best mean reward: 1745.38 - Last mean reward per episode: 1452.90
---------------------------------
| forward_vel        | 1.11     |
| reward             | 1.21     |
| reward_contact     | -0.00118 |
| reward_ctrl        | -0.903   |
| reward_position    | 2.08e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 939      |
|    ep_rew_mean     | 1.45e+03 |
| time/              |          |
|    episodes        | 912      |
|    fps             | 13       |
|    time_elapsed    | 54658    |
|    total timesteps | 732599   |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 11.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 727595   |
---------------------------------
Num timesteps: 734000
Best mean reward: 1745.38 - Last mean reward per episode: 1445.79
Num timesteps: 736000
Best mean reward: 1745.38 - Last mean reward per episode: 1448.70
---------------------------------
| forward_vel        | 1.12     |
| reward             | 1.21     |
| reward_contact     | -0.00116 |
| reward_ctrl        | -0.91    |
| reward_position    | 2.08e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 937      |
|    ep_rew_mean     | 1.44e+03 |
| time/              |          |
|    episodes        | 916      |
|    fps             | 13       |
|    time_elapsed    | 54914    |
|    total timesteps | 736461   |
| train/             |          |
|    actor_loss      | -143     |
|    critic_loss     | 10.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 731460   |
---------------------------------
Num timesteps: 738000
Best mean reward: 1745.38 - Last mean reward per episode: 1440.28
Num timesteps: 740000
Best mean reward: 1745.38 - Last mean reward per episode: 1460.44
---------------------------------
| forward_vel        | 1.15     |
| reward             | 1.23     |
| reward_contact     | -0.00109 |
| reward_ctrl        | -0.911   |
| reward_position    | 2.03e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 943      |
|    ep_rew_mean     | 1.46e+03 |
| time/              |          |
|    episodes        | 920      |
|    fps             | 13       |
|    time_elapsed    | 55179    |
|    total timesteps | 740176   |
| train/             |          |
|    actor_loss      | -135     |
|    critic_loss     | 11.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 735175   |
---------------------------------
Num timesteps: 742000
Best mean reward: 1745.38 - Last mean reward per episode: 1437.87
---------------------------------
| forward_vel        | 1.15     |
| reward             | 1.23     |
| reward_contact     | -0.00107 |
| reward_ctrl        | -0.92    |
| reward_position    | 2.03e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 930      |
|    ep_rew_mean     | 1.44e+03 |
| time/              |          |
|    episodes        | 924      |
|    fps             | 13       |
|    time_elapsed    | 55345    |
|    total timesteps | 742507   |
| train/             |          |
|    actor_loss      | -134     |
|    critic_loss     | 18.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 737505   |
---------------------------------
Num timesteps: 744000
Best mean reward: 1745.38 - Last mean reward per episode: 1437.37
Num timesteps: 746000
Best mean reward: 1745.38 - Last mean reward per episode: 1436.62
---------------------------------
| forward_vel        | 1.16     |
| reward             | 1.24     |
| reward_contact     | -0.00101 |
| reward_ctrl        | -0.918   |
| reward_position    | 2.03e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 930      |
|    ep_rew_mean     | 1.44e+03 |
| time/              |          |
|    episodes        | 928      |
|    fps             | 13       |
|    time_elapsed    | 55618    |
|    total timesteps | 746507   |
| train/             |          |
|    actor_loss      | -149     |
|    critic_loss     | 7.37     |
|    learning_rate   | 0.001    |
|    n_updates       | 741505   |
---------------------------------
Num timesteps: 748000
Best mean reward: 1745.38 - Last mean reward per episode: 1444.23
Num timesteps: 750000
Best mean reward: 1745.38 - Last mean reward per episode: 1446.36
---------------------------------
| forward_vel        | 1.16     |
| reward             | 1.25     |
| reward_contact     | -0.00107 |
| reward_ctrl        | -0.908   |
| reward_position    | 2.03e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 933      |
|    ep_rew_mean     | 1.45e+03 |
| time/              |          |
|    episodes        | 932      |
|    fps             | 13       |
|    time_elapsed    | 55869    |
|    total timesteps | 750156   |
| train/             |          |
|    actor_loss      | -141     |
|    critic_loss     | 16.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 745155   |
---------------------------------
Num timesteps: 752000
Best mean reward: 1745.38 - Last mean reward per episode: 1450.81
Num timesteps: 754000
Best mean reward: 1745.38 - Last mean reward per episode: 1464.48
---------------------------------
| forward_vel        | 1.17     |
| reward             | 1.29     |
| reward_contact     | -0.00111 |
| reward_ctrl        | -0.879   |
| reward_position    | 2.02e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 942      |
|    ep_rew_mean     | 1.46e+03 |
| time/              |          |
|    episodes        | 936      |
|    fps             | 13       |
|    time_elapsed    | 56143    |
|    total timesteps | 754127   |
| train/             |          |
|    actor_loss      | -139     |
|    critic_loss     | 6.87     |
|    learning_rate   | 0.001    |
|    n_updates       | 749125   |
---------------------------------
Num timesteps: 756000
Best mean reward: 1745.38 - Last mean reward per episode: 1459.38
---------------------------------
| forward_vel        | 1.16     |
| reward             | 1.29     |
| reward_contact     | -0.00114 |
| reward_ctrl        | -0.868   |
| reward_position    | 2.02e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 932      |
|    ep_rew_mean     | 1.46e+03 |
| time/              |          |
|    episodes        | 940      |
|    fps             | 13       |
|    time_elapsed    | 56356    |
|    total timesteps | 757158   |
| train/             |          |
|    actor_loss      | -139     |
|    critic_loss     | 10.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 752155   |
---------------------------------
Num timesteps: 758000
Best mean reward: 1745.38 - Last mean reward per episode: 1455.92
Num timesteps: 760000
Best mean reward: 1745.38 - Last mean reward per episode: 1443.63
---------------------------------
| forward_vel        | 1.18     |
| reward             | 1.31     |
| reward_contact     | -0.00112 |
| reward_ctrl        | -0.873   |
| reward_position    | 0.000588 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 932      |
|    ep_rew_mean     | 1.45e+03 |
| time/              |          |
|    episodes        | 944      |
|    fps             | 13       |
|    time_elapsed    | 56637    |
|    total timesteps | 761158   |
| train/             |          |
|    actor_loss      | -141     |
|    critic_loss     | 11.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 756155   |
---------------------------------
Num timesteps: 762000
Best mean reward: 1745.38 - Last mean reward per episode: 1448.65
Num timesteps: 764000
Best mean reward: 1745.38 - Last mean reward per episode: 1454.57
---------------------------------
| forward_vel        | 1.19     |
| reward             | 1.32     |
| reward_contact     | -0.00103 |
| reward_ctrl        | -0.874   |
| reward_position    | 0.000588 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 932      |
|    ep_rew_mean     | 1.45e+03 |
| time/              |          |
|    episodes        | 948      |
|    fps             | 13       |
|    time_elapsed    | 56916    |
|    total timesteps | 765158   |
| train/             |          |
|    actor_loss      | -138     |
|    critic_loss     | 12.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 760155   |
---------------------------------
Num timesteps: 766000
Best mean reward: 1745.38 - Last mean reward per episode: 1445.41
Num timesteps: 768000
Best mean reward: 1745.38 - Last mean reward per episode: 1449.36
----------------------------------
| forward_vel        | 1.19      |
| reward             | 1.31      |
| reward_contact     | -0.000926 |
| reward_ctrl        | -0.876    |
| reward_position    | 0.000588  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 937       |
|    ep_rew_mean     | 1.45e+03  |
| time/              |           |
|    episodes        | 952       |
|    fps             | 13        |
|    time_elapsed    | 57170     |
|    total timesteps | 768799    |
| train/             |           |
|    actor_loss      | -139      |
|    critic_loss     | 10.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 763795    |
----------------------------------
Num timesteps: 770000
Best mean reward: 1745.38 - Last mean reward per episode: 1448.07
Num timesteps: 772000
Best mean reward: 1745.38 - Last mean reward per episode: 1445.46
----------------------------------
| forward_vel        | 1.19      |
| reward             | 1.32      |
| reward_contact     | -0.000918 |
| reward_ctrl        | -0.868    |
| reward_position    | 0.000588  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 930       |
|    ep_rew_mean     | 1.45e+03  |
| time/              |           |
|    episodes        | 956       |
|    fps             | 13        |
|    time_elapsed    | 57402     |
|    total timesteps | 772114    |
| train/             |           |
|    actor_loss      | -142      |
|    critic_loss     | 21        |
|    learning_rate   | 0.001     |
|    n_updates       | 767110    |
----------------------------------
Num timesteps: 774000
Best mean reward: 1745.38 - Last mean reward per episode: 1444.95
----------------------------------
| forward_vel        | 1.18      |
| reward             | 1.29      |
| reward_contact     | -0.000964 |
| reward_ctrl        | -0.897    |
| reward_position    | 0.000588  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 924       |
|    ep_rew_mean     | 1.44e+03  |
| time/              |           |
|    episodes        | 960       |
|    fps             | 13        |
|    time_elapsed    | 57636     |
|    total timesteps | 775454    |
| train/             |           |
|    actor_loss      | -144      |
|    critic_loss     | 11.3      |
|    learning_rate   | 0.001     |
|    n_updates       | 770450    |
----------------------------------
Num timesteps: 776000
Best mean reward: 1745.38 - Last mean reward per episode: 1438.13
Num timesteps: 778000
Best mean reward: 1745.38 - Last mean reward per episode: 1439.10
---------------------------------
| forward_vel        | 1.18     |
| reward             | 1.27     |
| reward_contact     | -0.00101 |
| reward_ctrl        | -0.906   |
| reward_position    | 0.000576 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 932      |
|    ep_rew_mean     | 1.46e+03 |
| time/              |          |
|    episodes        | 964      |
|    fps             | 13       |
|    time_elapsed    | 57931    |
|    total timesteps | 779454   |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 17.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 774450   |
---------------------------------
Num timesteps: 780000
Best mean reward: 1745.38 - Last mean reward per episode: 1457.92
Num timesteps: 782000
Best mean reward: 1745.38 - Last mean reward per episode: 1461.67
---------------------------------
| forward_vel        | 1.21     |
| reward             | 1.3      |
| reward_contact     | -0.00108 |
| reward_ctrl        | -0.912   |
| reward_position    | 0.000576 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 927      |
|    ep_rew_mean     | 1.47e+03 |
| time/              |          |
|    episodes        | 968      |
|    fps             | 13       |
|    time_elapsed    | 58184    |
|    total timesteps | 782969   |
| train/             |          |
|    actor_loss      | -140     |
|    critic_loss     | 10.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 777965   |
---------------------------------
Num timesteps: 784000
Best mean reward: 1745.38 - Last mean reward per episode: 1466.59
---------------------------------
| forward_vel        | 1.24     |
| reward             | 1.32     |
| reward_contact     | -0.00111 |
| reward_ctrl        | -0.914   |
| reward_position    | 0.000576 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 1.46e+03 |
| time/              |          |
|    episodes        | 972      |
|    fps             | 13       |
|    time_elapsed    | 58348    |
|    total timesteps | 785485   |
| train/             |          |
|    actor_loss      | -143     |
|    critic_loss     | 13.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 780480   |
---------------------------------
Num timesteps: 786000
Best mean reward: 1745.38 - Last mean reward per episode: 1459.12
Num timesteps: 788000
Best mean reward: 1745.38 - Last mean reward per episode: 1459.27
---------------------------------
| forward_vel        | 1.22     |
| reward             | 1.29     |
| reward_contact     | -0.00108 |
| reward_ctrl        | -0.928   |
| reward_position    | 0.000576 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 1.46e+03 |
| time/              |          |
|    episodes        | 976      |
|    fps             | 13       |
|    time_elapsed    | 58625    |
|    total timesteps | 789485   |
| train/             |          |
|    actor_loss      | -141     |
|    critic_loss     | 9.06     |
|    learning_rate   | 0.001    |
|    n_updates       | 784480   |
---------------------------------
Num timesteps: 790000
Best mean reward: 1745.38 - Last mean reward per episode: 1457.23
Num timesteps: 792000
Best mean reward: 1745.38 - Last mean reward per episode: 1453.10
---------------------------------
| forward_vel        | 1.25     |
| reward             | 1.31     |
| reward_contact     | -0.00104 |
| reward_ctrl        | -0.936   |
| reward_position    | 0.000576 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 916      |
|    ep_rew_mean     | 1.46e+03 |
| time/              |          |
|    episodes        | 980      |
|    fps             | 13       |
|    time_elapsed    | 58845    |
|    total timesteps | 792847   |
| train/             |          |
|    actor_loss      | -145     |
|    critic_loss     | 10.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 787845   |
---------------------------------
Num timesteps: 794000
Best mean reward: 1745.38 - Last mean reward per episode: 1460.39
Num timesteps: 796000
Best mean reward: 1745.38 - Last mean reward per episode: 1468.67
----------------------------------
| forward_vel        | 1.28      |
| reward             | 1.36      |
| reward_contact     | -0.000943 |
| reward_ctrl        | -0.915    |
| reward_position    | 0.000576  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 916       |
|    ep_rew_mean     | 1.47e+03  |
| time/              |           |
|    episodes        | 984       |
|    fps             | 13        |
|    time_elapsed    | 59119     |
|    total timesteps | 796847    |
| train/             |           |
|    actor_loss      | -143      |
|    critic_loss     | 11.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 791845    |
----------------------------------
Num timesteps: 798000
Best mean reward: 1745.38 - Last mean reward per episode: 1476.25
Num timesteps: 800000
Best mean reward: 1745.38 - Last mean reward per episode: 1482.13
----------------------------------
| forward_vel        | 1.25      |
| reward             | 1.34      |
| reward_contact     | -0.000909 |
| reward_ctrl        | -0.915    |
| reward_position    | 0.000576  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 917       |
|    ep_rew_mean     | 1.48e+03  |
| time/              |           |
|    episodes        | 988       |
|    fps             | 13        |
|    time_elapsed    | 59378     |
|    total timesteps | 800752    |
| train/             |           |
|    actor_loss      | -144      |
|    critic_loss     | 8.8       |
|    learning_rate   | 0.001     |
|    n_updates       | 795750    |
----------------------------------
Num timesteps: 802000
Best mean reward: 1745.38 - Last mean reward per episode: 1469.74
----------------------------------
| forward_vel        | 1.28      |
| reward             | 1.36      |
| reward_contact     | -0.000889 |
| reward_ctrl        | -0.915    |
| reward_position    | 0.00132   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 909       |
|    ep_rew_mean     | 1.48e+03  |
| time/              |           |
|    episodes        | 992       |
|    fps             | 13        |
|    time_elapsed    | 59610     |
|    total timesteps | 803868    |
| train/             |           |
|    actor_loss      | -137      |
|    critic_loss     | 21.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 798865    |
----------------------------------
Num timesteps: 804000
Best mean reward: 1745.38 - Last mean reward per episode: 1482.40
Num timesteps: 806000
Best mean reward: 1745.38 - Last mean reward per episode: 1483.46
----------------------------------
| forward_vel        | 1.25      |
| reward             | 1.34      |
| reward_contact     | -0.000914 |
| reward_ctrl        | -0.911    |
| reward_position    | 0.00132   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 912       |
|    ep_rew_mean     | 1.49e+03  |
| time/              |           |
|    episodes        | 996       |
|    fps             | 13        |
|    time_elapsed    | 59910     |
|    total timesteps | 807868    |
| train/             |           |
|    actor_loss      | -143      |
|    critic_loss     | 8.6       |
|    learning_rate   | 0.001     |
|    n_updates       | 802865    |
----------------------------------
Num timesteps: 808000
Best mean reward: 1745.38 - Last mean reward per episode: 1493.04
Num timesteps: 810000
Best mean reward: 1745.38 - Last mean reward per episode: 1482.95
----------------------------------
| forward_vel        | 1.27      |
| reward             | 1.36      |
| reward_contact     | -0.000958 |
| reward_ctrl        | -0.908    |
| reward_position    | 0.00132   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 903       |
|    ep_rew_mean     | 1.48e+03  |
| time/              |           |
|    episodes        | 1000      |
|    fps             | 13        |
|    time_elapsed    | 60140     |
|    total timesteps | 810985    |
| train/             |           |
|    actor_loss      | -143      |
|    critic_loss     | 10.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 805980    |
----------------------------------
Num timesteps: 812000
Best mean reward: 1745.38 - Last mean reward per episode: 1480.52
Num timesteps: 814000
Best mean reward: 1745.38 - Last mean reward per episode: 1480.42
----------------------------------
| forward_vel        | 1.27      |
| reward             | 1.34      |
| reward_contact     | -0.000963 |
| reward_ctrl        | -0.93     |
| reward_position    | 0.00132   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 903       |
|    ep_rew_mean     | 1.48e+03  |
| time/              |           |
|    episodes        | 1004      |
|    fps             | 13        |
|    time_elapsed    | 60453     |
|    total timesteps | 814985    |
| train/             |           |
|    actor_loss      | -141      |
|    critic_loss     | 10.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 809980    |
----------------------------------
Num timesteps: 816000
Best mean reward: 1745.38 - Last mean reward per episode: 1479.93
Num timesteps: 818000
Best mean reward: 1745.38 - Last mean reward per episode: 1484.18
----------------------------------
| forward_vel        | 1.26      |
| reward             | 1.34      |
| reward_contact     | -0.000998 |
| reward_ctrl        | -0.913    |
| reward_position    | 0.00132   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 903       |
|    ep_rew_mean     | 1.48e+03  |
| time/              |           |
|    episodes        | 1008      |
|    fps             | 13        |
|    time_elapsed    | 60753     |
|    total timesteps | 818985    |
| train/             |           |
|    actor_loss      | -143      |
|    critic_loss     | 16.2      |
|    learning_rate   | 0.001     |
|    n_updates       | 813980    |
----------------------------------
Num timesteps: 820000
Best mean reward: 1745.38 - Last mean reward per episode: 1480.38
Num timesteps: 822000
Best mean reward: 1745.38 - Last mean reward per episode: 1489.77
---------------------------------
| forward_vel        | 1.27     |
| reward             | 1.37     |
| reward_contact     | -0.00113 |
| reward_ctrl        | -0.904   |
| reward_position    | 0.00132  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 904      |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1012     |
|    fps             | 13       |
|    time_elapsed    | 61042    |
|    total timesteps | 822985   |
| train/             |          |
|    actor_loss      | -147     |
|    critic_loss     | 9.3      |
|    learning_rate   | 0.001    |
|    n_updates       | 817980   |
---------------------------------
Num timesteps: 824000
Best mean reward: 1745.38 - Last mean reward per episode: 1500.09
Num timesteps: 826000
Best mean reward: 1745.38 - Last mean reward per episode: 1500.27
---------------------------------
| forward_vel        | 1.27     |
| reward             | 1.38     |
| reward_contact     | -0.00114 |
| reward_ctrl        | -0.891   |
| reward_position    | 0.00132  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 905      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1016     |
|    fps             | 13       |
|    time_elapsed    | 61329    |
|    total timesteps | 826985   |
| train/             |          |
|    actor_loss      | -148     |
|    critic_loss     | 7.75     |
|    learning_rate   | 0.001    |
|    n_updates       | 821980   |
---------------------------------
Num timesteps: 828000
Best mean reward: 1745.38 - Last mean reward per episode: 1516.18
Num timesteps: 830000
Best mean reward: 1745.38 - Last mean reward per episode: 1512.76
---------------------------------
| forward_vel        | 1.26     |
| reward             | 1.4      |
| reward_contact     | -0.00121 |
| reward_ctrl        | -0.868   |
| reward_position    | 0.00132  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 908      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1020     |
|    fps             | 13       |
|    time_elapsed    | 61616    |
|    total timesteps | 830985   |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 6.72     |
|    learning_rate   | 0.001    |
|    n_updates       | 825980   |
---------------------------------
Num timesteps: 832000
Best mean reward: 1745.38 - Last mean reward per episode: 1523.40
Num timesteps: 834000
Best mean reward: 1745.38 - Last mean reward per episode: 1531.21
---------------------------------
| forward_vel        | 1.24     |
| reward             | 1.38     |
| reward_contact     | -0.00129 |
| reward_ctrl        | -0.866   |
| reward_position    | 0.00132  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 919      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1024     |
|    fps             | 13       |
|    time_elapsed    | 61860    |
|    total timesteps | 834378   |
| train/             |          |
|    actor_loss      | -144     |
|    critic_loss     | 7.8      |
|    learning_rate   | 0.001    |
|    n_updates       | 829375   |
---------------------------------
Num timesteps: 836000
Best mean reward: 1745.38 - Last mean reward per episode: 1519.69
---------------------------------
| forward_vel        | 1.25     |
| reward             | 1.38     |
| reward_contact     | -0.00129 |
| reward_ctrl        | -0.869   |
| reward_position    | 0.00132  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 910      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1028     |
|    fps             | 13       |
|    time_elapsed    | 62080    |
|    total timesteps | 837460   |
| train/             |          |
|    actor_loss      | -141     |
|    critic_loss     | 9.39     |
|    learning_rate   | 0.001    |
|    n_updates       | 832455   |
---------------------------------
Num timesteps: 838000
Best mean reward: 1745.38 - Last mean reward per episode: 1520.31
Num timesteps: 840000
Best mean reward: 1745.38 - Last mean reward per episode: 1514.44
---------------------------------
| forward_vel        | 1.21     |
| reward             | 1.35     |
| reward_contact     | -0.00132 |
| reward_ctrl        | -0.859   |
| reward_position    | 0.00132  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 913      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1032     |
|    fps             | 13       |
|    time_elapsed    | 62364    |
|    total timesteps | 841460   |
| train/             |          |
|    actor_loss      | -149     |
|    critic_loss     | 18.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 836455   |
---------------------------------
Num timesteps: 842000
Best mean reward: 1745.38 - Last mean reward per episode: 1520.33
Num timesteps: 844000
Best mean reward: 1745.38 - Last mean reward per episode: 1522.53
---------------------------------
| forward_vel        | 1.2      |
| reward             | 1.35     |
| reward_contact     | -0.00131 |
| reward_ctrl        | -0.85    |
| reward_position    | 0.00132  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 913      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1036     |
|    fps             | 13       |
|    time_elapsed    | 62643    |
|    total timesteps | 845460   |
| train/             |          |
|    actor_loss      | -145     |
|    critic_loss     | 11.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 840455   |
---------------------------------
Num timesteps: 846000
Best mean reward: 1745.38 - Last mean reward per episode: 1522.71
Num timesteps: 848000
Best mean reward: 1745.38 - Last mean reward per episode: 1523.37
---------------------------------
| forward_vel        | 1.21     |
| reward             | 1.34     |
| reward_contact     | -0.0013  |
| reward_ctrl        | -0.873   |
| reward_position    | 0.00132  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 914      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1040     |
|    fps             | 13       |
|    time_elapsed    | 62862    |
|    total timesteps | 848569   |
| train/             |          |
|    actor_loss      | -150     |
|    critic_loss     | 9.53     |
|    learning_rate   | 0.001    |
|    n_updates       | 843565   |
---------------------------------
Num timesteps: 850000
Best mean reward: 1745.38 - Last mean reward per episode: 1519.25
---------------------------------
| forward_vel        | 1.21     |
| reward             | 1.34     |
| reward_contact     | -0.00136 |
| reward_ctrl        | -0.87    |
| reward_position    | 0.00075  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 907      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1044     |
|    fps             | 13       |
|    time_elapsed    | 63108    |
|    total timesteps | 851849   |
| train/             |          |
|    actor_loss      | -146     |
|    critic_loss     | 13       |
|    learning_rate   | 0.001    |
|    n_updates       | 846845   |
---------------------------------
Num timesteps: 852000
Best mean reward: 1745.38 - Last mean reward per episode: 1526.73
Num timesteps: 854000
Best mean reward: 1745.38 - Last mean reward per episode: 1512.07
---------------------------------
| forward_vel        | 1.21     |
| reward             | 1.31     |
| reward_contact     | -0.00141 |
| reward_ctrl        | -0.9     |
| reward_position    | 0.00075  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 900      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1048     |
|    fps             | 13       |
|    time_elapsed    | 63328    |
|    total timesteps | 855156   |
| train/             |          |
|    actor_loss      | -146     |
|    critic_loss     | 9.77     |
|    learning_rate   | 0.001    |
|    n_updates       | 850155   |
---------------------------------
Num timesteps: 856000
Best mean reward: 1745.38 - Last mean reward per episode: 1525.85
Num timesteps: 858000
Best mean reward: 1745.38 - Last mean reward per episode: 1522.55
---------------------------------
| forward_vel        | 1.2      |
| reward             | 1.32     |
| reward_contact     | -0.00145 |
| reward_ctrl        | -0.881   |
| reward_position    | 0.00075  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 904      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1052     |
|    fps             | 13       |
|    time_elapsed    | 63608    |
|    total timesteps | 859156   |
| train/             |          |
|    actor_loss      | -146     |
|    critic_loss     | 9.95     |
|    learning_rate   | 0.001    |
|    n_updates       | 854155   |
---------------------------------
Num timesteps: 860000
Best mean reward: 1745.38 - Last mean reward per episode: 1526.95
Num timesteps: 862000
Best mean reward: 1745.38 - Last mean reward per episode: 1528.61
---------------------------------
| forward_vel        | 1.22     |
| reward             | 1.35     |
| reward_contact     | -0.00144 |
| reward_ctrl        | -0.876   |
| reward_position    | 0.00075  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 910      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1056     |
|    fps             | 13       |
|    time_elapsed    | 63875    |
|    total timesteps | 863156   |
| train/             |          |
|    actor_loss      | -143     |
|    critic_loss     | 8.36     |
|    learning_rate   | 0.001    |
|    n_updates       | 858155   |
---------------------------------
Num timesteps: 864000
Best mean reward: 1745.38 - Last mean reward per episode: 1535.85
Num timesteps: 866000
Best mean reward: 1745.38 - Last mean reward per episode: 1533.58
---------------------------------
| forward_vel        | 1.21     |
| reward             | 1.34     |
| reward_contact     | -0.00147 |
| reward_ctrl        | -0.872   |
| reward_position    | 0.00075  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 917      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1060     |
|    fps             | 13       |
|    time_elapsed    | 64134    |
|    total timesteps | 867156   |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 7.46     |
|    learning_rate   | 0.001    |
|    n_updates       | 862155   |
---------------------------------
Num timesteps: 868000
Best mean reward: 1745.38 - Last mean reward per episode: 1530.11
Num timesteps: 870000
Best mean reward: 1745.38 - Last mean reward per episode: 1529.98
---------------------------------
| forward_vel        | 1.23     |
| reward             | 1.36     |
| reward_contact     | -0.00143 |
| reward_ctrl        | -0.863   |
| reward_position    | 0.00075  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 910      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1064     |
|    fps             | 13       |
|    time_elapsed    | 64350    |
|    total timesteps | 870460   |
| train/             |          |
|    actor_loss      | -143     |
|    critic_loss     | 13.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 865455   |
---------------------------------
Num timesteps: 872000
Best mean reward: 1745.38 - Last mean reward per episode: 1524.40
---------------------------------
| forward_vel        | 1.19     |
| reward             | 1.33     |
| reward_contact     | -0.00141 |
| reward_ctrl        | -0.862   |
| reward_position    | 0.00075  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 907      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1068     |
|    fps             | 13       |
|    time_elapsed    | 64560    |
|    total timesteps | 873683   |
| train/             |          |
|    actor_loss      | -148     |
|    critic_loss     | 24.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 868680   |
---------------------------------
Num timesteps: 874000
Best mean reward: 1745.38 - Last mean reward per episode: 1520.47
Num timesteps: 876000
Best mean reward: 1745.38 - Last mean reward per episode: 1521.48
---------------------------------
| forward_vel        | 1.17     |
| reward             | 1.32     |
| reward_contact     | -0.00143 |
| reward_ctrl        | -0.851   |
| reward_position    | 0.00075  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1072     |
|    fps             | 13       |
|    time_elapsed    | 64832    |
|    total timesteps | 877683   |
| train/             |          |
|    actor_loss      | -146     |
|    critic_loss     | 19.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 872680   |
---------------------------------
Num timesteps: 878000
Best mean reward: 1745.38 - Last mean reward per episode: 1543.29
Num timesteps: 880000
Best mean reward: 1745.38 - Last mean reward per episode: 1541.85
---------------------------------
| forward_vel        | 1.15     |
| reward             | 1.31     |
| reward_contact     | -0.00148 |
| reward_ctrl        | -0.84    |
| reward_position    | 0.00075  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    episodes        | 1076     |
|    fps             | 13       |
|    time_elapsed    | 65094    |
|    total timesteps | 881683   |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 15.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 876680   |
---------------------------------
Num timesteps: 882000
Best mean reward: 1745.38 - Last mean reward per episode: 1546.95
Num timesteps: 884000
Best mean reward: 1745.38 - Last mean reward per episode: 1543.05
---------------------------------
| forward_vel        | 1.13     |
| reward             | 1.29     |
| reward_contact     | -0.00149 |
| reward_ctrl        | -0.844   |
| reward_position    | 0.00075  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 928      |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    episodes        | 1080     |
|    fps             | 13       |
|    time_elapsed    | 65369    |
|    total timesteps | 885683   |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 19.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 880680   |
---------------------------------
Num timesteps: 886000
Best mean reward: 1745.38 - Last mean reward per episode: 1548.53
Num timesteps: 888000
Best mean reward: 1745.38 - Last mean reward per episode: 1551.14
---------------------------------
| forward_vel        | 1.11     |
| reward             | 1.27     |
| reward_contact     | -0.00152 |
| reward_ctrl        | -0.837   |
| reward_position    | 0.00075  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 921      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1084     |
|    fps             | 13       |
|    time_elapsed    | 65584    |
|    total timesteps | 888909   |
| train/             |          |
|    actor_loss      | -149     |
|    critic_loss     | 19       |
|    learning_rate   | 0.001    |
|    n_updates       | 883905   |
---------------------------------
Num timesteps: 890000
Best mean reward: 1745.38 - Last mean reward per episode: 1535.80
Num timesteps: 892000
Best mean reward: 1745.38 - Last mean reward per episode: 1536.14
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.3      |
| reward_contact     | -0.00146 |
| reward_ctrl        | -0.834   |
| reward_position    | 0.00075  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1088     |
|    fps             | 13       |
|    time_elapsed    | 65850    |
|    total timesteps | 892909   |
| train/             |          |
|    actor_loss      | -146     |
|    critic_loss     | 16       |
|    learning_rate   | 0.001    |
|    n_updates       | 887905   |
---------------------------------
Num timesteps: 894000
Best mean reward: 1745.38 - Last mean reward per episode: 1519.68
Num timesteps: 896000
Best mean reward: 1745.38 - Last mean reward per episode: 1539.59
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.26     |
| reward_contact     | -0.00144 |
| reward_ctrl        | -0.874   |
| reward_position    | 5.33e-07 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1092     |
|    fps             | 13       |
|    time_elapsed    | 66066    |
|    total timesteps | 896103   |
| train/             |          |
|    actor_loss      | -141     |
|    critic_loss     | 17       |
|    learning_rate   | 0.001    |
|    n_updates       | 891100   |
---------------------------------
Num timesteps: 898000
Best mean reward: 1745.38 - Last mean reward per episode: 1537.60
Num timesteps: 900000
Best mean reward: 1745.38 - Last mean reward per episode: 1533.54
---------------------------------
| forward_vel        | 1.16     |
| reward             | 1.29     |
| reward_contact     | -0.00138 |
| reward_ctrl        | -0.863   |
| reward_position    | 5.33e-07 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1096     |
|    fps             | 13       |
|    time_elapsed    | 66334    |
|    total timesteps | 900103   |
| train/             |          |
|    actor_loss      | -145     |
|    critic_loss     | 10.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 895100   |
---------------------------------
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.25     |
| reward_contact     | -0.00136 |
| reward_ctrl        | -0.886   |
| reward_position    | 4.65e-07 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 905      |
|    ep_rew_mean     | 1.51e+03 |
| time/              |          |
|    episodes        | 1100     |
|    fps             | 13       |
|    time_elapsed    | 66428    |
|    total timesteps | 901490   |
| train/             |          |
|    actor_loss      | -144     |
|    critic_loss     | 20.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 896485   |
---------------------------------
Num timesteps: 902000
Best mean reward: 1745.38 - Last mean reward per episode: 1507.66
Num timesteps: 904000
Best mean reward: 1745.38 - Last mean reward per episode: 1508.26
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.26     |
| reward_contact     | -0.00134 |
| reward_ctrl        | -0.877   |
| reward_position    | 4.65e-07 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 905      |
|    ep_rew_mean     | 1.51e+03 |
| time/              |          |
|    episodes        | 1104     |
|    fps             | 13       |
|    time_elapsed    | 66698    |
|    total timesteps | 905490   |
| train/             |          |
|    actor_loss      | -152     |
|    critic_loss     | 21.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 900485   |
---------------------------------
Num timesteps: 906000
Best mean reward: 1745.38 - Last mean reward per episode: 1505.42
Num timesteps: 908000
Best mean reward: 1745.38 - Last mean reward per episode: 1498.85
---------------------------------
| forward_vel        | 1.13     |
| reward             | 1.24     |
| reward_contact     | -0.00129 |
| reward_ctrl        | -0.887   |
| reward_position    | 4.65e-07 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 897      |
|    ep_rew_mean     | 1.48e+03 |
| time/              |          |
|    episodes        | 1108     |
|    fps             | 13       |
|    time_elapsed    | 66922    |
|    total timesteps | 908688   |
| train/             |          |
|    actor_loss      | -149     |
|    critic_loss     | 9.54     |
|    learning_rate   | 0.001    |
|    n_updates       | 903685   |
---------------------------------
Num timesteps: 910000
Best mean reward: 1745.38 - Last mean reward per episode: 1481.60
Num timesteps: 912000
Best mean reward: 1745.38 - Last mean reward per episode: 1479.79
---------------------------------
| forward_vel        | 1.17     |
| reward             | 1.27     |
| reward_contact     | -0.00115 |
| reward_ctrl        | -0.897   |
| reward_position    | 4.65e-07 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 897      |
|    ep_rew_mean     | 1.48e+03 |
| time/              |          |
|    episodes        | 1112     |
|    fps             | 13       |
|    time_elapsed    | 67199    |
|    total timesteps | 912688   |
| train/             |          |
|    actor_loss      | -148     |
|    critic_loss     | 10.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 907685   |
---------------------------------
Num timesteps: 914000
Best mean reward: 1745.38 - Last mean reward per episode: 1477.25
Num timesteps: 916000
Best mean reward: 1745.38 - Last mean reward per episode: 1471.21
---------------------------------
| forward_vel        | 1.19     |
| reward             | 1.31     |
| reward_contact     | -0.00116 |
| reward_ctrl        | -0.881   |
| reward_position    | 4.65e-07 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 894      |
|    ep_rew_mean     | 1.47e+03 |
| time/              |          |
|    episodes        | 1116     |
|    fps             | 13       |
|    time_elapsed    | 67447    |
|    total timesteps | 916341   |
| train/             |          |
|    actor_loss      | -146     |
|    critic_loss     | 12.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 911340   |
---------------------------------
Num timesteps: 918000
Best mean reward: 1745.38 - Last mean reward per episode: 1468.88
Num timesteps: 920000
Best mean reward: 1745.38 - Last mean reward per episode: 1460.55
---------------------------------
| forward_vel        | 1.18     |
| reward             | 1.29     |
| reward_contact     | -0.00129 |
| reward_ctrl        | -0.889   |
| reward_position    | 4.65e-07 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 894      |
|    ep_rew_mean     | 1.46e+03 |
| time/              |          |
|    episodes        | 1120     |
|    fps             | 13       |
|    time_elapsed    | 67718    |
|    total timesteps | 920341   |
| train/             |          |
|    actor_loss      | -149     |
|    critic_loss     | 13.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 915340   |
---------------------------------
Num timesteps: 922000
Best mean reward: 1745.38 - Last mean reward per episode: 1475.78
---------------------------------
| forward_vel        | 1.18     |
| reward             | 1.28     |
| reward_contact     | -0.00136 |
| reward_ctrl        | -0.899   |
| reward_position    | 4.65e-07 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 896      |
|    ep_rew_mean     | 1.48e+03 |
| time/              |          |
|    episodes        | 1124     |
|    fps             | 13       |
|    time_elapsed    | 67965    |
|    total timesteps | 923979   |
| train/             |          |
|    actor_loss      | -147     |
|    critic_loss     | 14.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 918975   |
---------------------------------
Num timesteps: 924000
Best mean reward: 1745.38 - Last mean reward per episode: 1475.90
Num timesteps: 926000
Best mean reward: 1745.38 - Last mean reward per episode: 1488.91
---------------------------------
| forward_vel        | 1.18     |
| reward             | 1.3      |
| reward_contact     | -0.00139 |
| reward_ctrl        | -0.88    |
| reward_position    | 4.25e-09 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 905      |
|    ep_rew_mean     | 1.48e+03 |
| time/              |          |
|    episodes        | 1128     |
|    fps             | 13       |
|    time_elapsed    | 68237    |
|    total timesteps | 927979   |
| train/             |          |
|    actor_loss      | -151     |
|    critic_loss     | 8.89     |
|    learning_rate   | 0.001    |
|    n_updates       | 922975   |
---------------------------------
Num timesteps: 928000
Best mean reward: 1745.38 - Last mean reward per episode: 1482.74
Num timesteps: 930000
Best mean reward: 1745.38 - Last mean reward per episode: 1493.99
---------------------------------
| forward_vel        | 1.21     |
| reward             | 1.34     |
| reward_contact     | -0.00131 |
| reward_ctrl        | -0.873   |
| reward_position    | 4.25e-09 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 904      |
|    ep_rew_mean     | 1.48e+03 |
| time/              |          |
|    episodes        | 1132     |
|    fps             | 13       |
|    time_elapsed    | 68498    |
|    total timesteps | 931813   |
| train/             |          |
|    actor_loss      | -149     |
|    critic_loss     | 15.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 926810   |
---------------------------------
Num timesteps: 932000
Best mean reward: 1745.38 - Last mean reward per episode: 1479.91
Num timesteps: 934000
Best mean reward: 1745.38 - Last mean reward per episode: 1480.94
---------------------------------
| forward_vel        | 1.2      |
| reward             | 1.3      |
| reward_contact     | -0.0013  |
| reward_ctrl        | -0.893   |
| reward_position    | 4.25e-09 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 904      |
|    ep_rew_mean     | 1.48e+03 |
| time/              |          |
|    episodes        | 1136     |
|    fps             | 13       |
|    time_elapsed    | 68782    |
|    total timesteps | 935813   |
| train/             |          |
|    actor_loss      | -148     |
|    critic_loss     | 11       |
|    learning_rate   | 0.001    |
|    n_updates       | 930810   |
---------------------------------
Num timesteps: 936000
Best mean reward: 1745.38 - Last mean reward per episode: 1479.77
Num timesteps: 938000
Best mean reward: 1745.38 - Last mean reward per episode: 1476.27
---------------------------------
| forward_vel        | 1.17     |
| reward             | 1.29     |
| reward_contact     | -0.00127 |
| reward_ctrl        | -0.875   |
| reward_position    | 1.83e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 912      |
|    ep_rew_mean     | 1.48e+03 |
| time/              |          |
|    episodes        | 1140     |
|    fps             | 13       |
|    time_elapsed    | 69045    |
|    total timesteps | 939813   |
| train/             |          |
|    actor_loss      | -147     |
|    critic_loss     | 14.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 934810   |
---------------------------------
Num timesteps: 940000
Best mean reward: 1745.38 - Last mean reward per episode: 1483.29
Num timesteps: 942000
Best mean reward: 1745.38 - Last mean reward per episode: 1490.15
---------------------------------
| forward_vel        | 1.16     |
| reward             | 1.29     |
| reward_contact     | -0.00129 |
| reward_ctrl        | -0.864   |
| reward_position    | 1.83e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 920      |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    episodes        | 1144     |
|    fps             | 13       |
|    time_elapsed    | 69311    |
|    total timesteps | 943813   |
| train/             |          |
|    actor_loss      | -147     |
|    critic_loss     | 23.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 938810   |
---------------------------------
Num timesteps: 944000
Best mean reward: 1745.38 - Last mean reward per episode: 1488.13
Num timesteps: 946000
Best mean reward: 1745.38 - Last mean reward per episode: 1487.67
---------------------------------
| forward_vel        | 1.15     |
| reward             | 1.31     |
| reward_contact     | -0.00124 |
| reward_ctrl        | -0.841   |
| reward_position    | 1.83e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 919      |
|    ep_rew_mean     | 1.48e+03 |
| time/              |          |
|    episodes        | 1148     |
|    fps             | 13       |
|    time_elapsed    | 69531    |
|    total timesteps | 947081   |
| train/             |          |
|    actor_loss      | -153     |
|    critic_loss     | 8.88     |
|    learning_rate   | 0.001    |
|    n_updates       | 942080   |
---------------------------------
Num timesteps: 948000
Best mean reward: 1745.38 - Last mean reward per episode: 1479.66
Num timesteps: 950000
Best mean reward: 1745.38 - Last mean reward per episode: 1497.56
---------------------------------
| forward_vel        | 1.15     |
| reward             | 1.3      |
| reward_contact     | -0.0013  |
| reward_ctrl        | -0.845   |
| reward_position    | 1.83e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 919      |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    episodes        | 1152     |
|    fps             | 13       |
|    time_elapsed    | 69813    |
|    total timesteps | 951081   |
| train/             |          |
|    actor_loss      | -150     |
|    critic_loss     | 16.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 946080   |
---------------------------------
Num timesteps: 952000
Best mean reward: 1745.38 - Last mean reward per episode: 1494.45
Num timesteps: 954000
Best mean reward: 1745.38 - Last mean reward per episode: 1496.13
---------------------------------
| forward_vel        | 1.12     |
| reward             | 1.25     |
| reward_contact     | -0.00131 |
| reward_ctrl        | -0.872   |
| reward_position    | 1.83e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 918      |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    episodes        | 1156     |
|    fps             | 13       |
|    time_elapsed    | 70074    |
|    total timesteps | 954926   |
| train/             |          |
|    actor_loss      | -151     |
|    critic_loss     | 16.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 949925   |
---------------------------------
Num timesteps: 956000
Best mean reward: 1745.38 - Last mean reward per episode: 1491.35
Num timesteps: 958000
Best mean reward: 1745.38 - Last mean reward per episode: 1496.66
---------------------------------
| forward_vel        | 1.13     |
| reward             | 1.26     |
| reward_contact     | -0.00122 |
| reward_ctrl        | -0.873   |
| reward_position    | 1.83e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 918      |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    episodes        | 1160     |
|    fps             | 13       |
|    time_elapsed    | 70341    |
|    total timesteps | 958926   |
| train/             |          |
|    actor_loss      | -151     |
|    critic_loss     | 14.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 953925   |
---------------------------------
Num timesteps: 960000
Best mean reward: 1745.38 - Last mean reward per episode: 1498.82
Num timesteps: 962000
Best mean reward: 1745.38 - Last mean reward per episode: 1496.74
---------------------------------
| forward_vel        | 1.1      |
| reward             | 1.23     |
| reward_contact     | -0.00123 |
| reward_ctrl        | -0.871   |
| reward_position    | 1.83e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 925      |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    episodes        | 1164     |
|    fps             | 13       |
|    time_elapsed    | 70601    |
|    total timesteps | 962926   |
| train/             |          |
|    actor_loss      | -148     |
|    critic_loss     | 7.81     |
|    learning_rate   | 0.001    |
|    n_updates       | 957925   |
---------------------------------
Num timesteps: 964000
Best mean reward: 1745.38 - Last mean reward per episode: 1492.09
Num timesteps: 966000
Best mean reward: 1745.38 - Last mean reward per episode: 1495.92
---------------------------------
| forward_vel        | 1.09     |
| reward             | 1.2      |
| reward_contact     | -0.00124 |
| reward_ctrl        | -0.89    |
| reward_position    | 1.83e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 932      |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1168     |
|    fps             | 13       |
|    time_elapsed    | 70868    |
|    total timesteps | 966926   |
| train/             |          |
|    actor_loss      | -147     |
|    critic_loss     | 15.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 961925   |
---------------------------------
Num timesteps: 968000
Best mean reward: 1745.38 - Last mean reward per episode: 1495.67
Num timesteps: 970000
Best mean reward: 1745.38 - Last mean reward per episode: 1497.85
---------------------------------
| forward_vel        | 1.11     |
| reward             | 1.21     |
| reward_contact     | -0.00122 |
| reward_ctrl        | -0.895   |
| reward_position    | 1.83e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 932      |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1172     |
|    fps             | 13       |
|    time_elapsed    | 71155    |
|    total timesteps | 970926   |
| train/             |          |
|    actor_loss      | -153     |
|    critic_loss     | 7.52     |
|    learning_rate   | 0.001    |
|    n_updates       | 965925   |
---------------------------------
Num timesteps: 972000
Best mean reward: 1745.38 - Last mean reward per episode: 1490.82
Num timesteps: 974000
Best mean reward: 1745.38 - Last mean reward per episode: 1490.88
---------------------------------
| forward_vel        | 1.12     |
| reward             | 1.23     |
| reward_contact     | -0.00119 |
| reward_ctrl        | -0.89    |
| reward_position    | 1.83e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 924      |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    episodes        | 1176     |
|    fps             | 13       |
|    time_elapsed    | 71367    |
|    total timesteps | 974045   |
| train/             |          |
|    actor_loss      | -151     |
|    critic_loss     | 13.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 969040   |
---------------------------------
Num timesteps: 976000
Best mean reward: 1745.38 - Last mean reward per episode: 1483.12
Num timesteps: 978000
Best mean reward: 1745.38 - Last mean reward per episode: 1499.36
---------------------------------
| forward_vel        | 1.11     |
| reward             | 1.23     |
| reward_contact     | -0.00113 |
| reward_ctrl        | -0.882   |
| reward_position    | 1.83e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 924      |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    episodes        | 1180     |
|    fps             | 13       |
|    time_elapsed    | 71626    |
|    total timesteps | 978045   |
| train/             |          |
|    actor_loss      | -151     |
|    critic_loss     | 19.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 973040   |
---------------------------------
Num timesteps: 980000
Best mean reward: 1745.38 - Last mean reward per episode: 1474.58
---------------------------------
| forward_vel        | 1.12     |
| reward             | 1.22     |
| reward_contact     | -0.00116 |
| reward_ctrl        | -0.902   |
| reward_position    | 1.83e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 918      |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    episodes        | 1184     |
|    fps             | 13       |
|    time_elapsed    | 71798    |
|    total timesteps | 980706   |
| train/             |          |
|    actor_loss      | -152     |
|    critic_loss     | 12.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 975705   |
---------------------------------
Num timesteps: 982000
Best mean reward: 1745.38 - Last mean reward per episode: 1475.12
---------------------------------
| forward_vel        | 1.12     |
| reward             | 1.22     |
| reward_contact     | -0.00119 |
| reward_ctrl        | -0.903   |
| reward_position    | 0.000763 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 906      |
|    ep_rew_mean     | 1.47e+03 |
| time/              |          |
|    episodes        | 1188     |
|    fps             | 13       |
|    time_elapsed    | 71977    |
|    total timesteps | 983495   |
| train/             |          |
|    actor_loss      | -153     |
|    critic_loss     | 12.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 978490   |
---------------------------------
Num timesteps: 984000
Best mean reward: 1745.38 - Last mean reward per episode: 1473.40
Num timesteps: 986000
Best mean reward: 1745.38 - Last mean reward per episode: 1482.02
---------------------------------
| forward_vel        | 1.14     |
| reward             | 1.26     |
| reward_contact     | -0.00123 |
| reward_ctrl        | -0.88    |
| reward_position    | 0.000763 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 914      |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    episodes        | 1192     |
|    fps             | 13       |
|    time_elapsed    | 72236    |
|    total timesteps | 987495   |
| train/             |          |
|    actor_loss      | -149     |
|    critic_loss     | 23.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 982490   |
---------------------------------
Num timesteps: 988000
Best mean reward: 1745.38 - Last mean reward per episode: 1470.49
Num timesteps: 990000
Best mean reward: 1745.38 - Last mean reward per episode: 1473.47
---------------------------------
| forward_vel        | 1.16     |
| reward             | 1.28     |
| reward_contact     | -0.00129 |
| reward_ctrl        | -0.885   |
| reward_position    | 0.000765 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 904      |
|    ep_rew_mean     | 1.47e+03 |
| time/              |          |
|    episodes        | 1196     |
|    fps             | 13       |
|    time_elapsed    | 72436    |
|    total timesteps | 990516   |
| train/             |          |
|    actor_loss      | -150     |
|    critic_loss     | 15.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 985515   |
---------------------------------
Num timesteps: 992000
Best mean reward: 1745.38 - Last mean reward per episode: 1488.34
---------------------------------
| forward_vel        | 1.16     |
| reward             | 1.29     |
| reward_contact     | -0.00135 |
| reward_ctrl        | -0.865   |
| reward_position    | 0.000765 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 921      |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1200     |
|    fps             | 13       |
|    time_elapsed    | 72640    |
|    total timesteps | 993589   |
| train/             |          |
|    actor_loss      | -151     |
|    critic_loss     | 17.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 988585   |
---------------------------------
Num timesteps: 994000
Best mean reward: 1745.38 - Last mean reward per episode: 1486.88
Num timesteps: 996000
Best mean reward: 1745.38 - Last mean reward per episode: 1480.84
---------------------------------
| forward_vel        | 1.2      |
| reward             | 1.35     |
| reward_contact     | -0.0013  |
| reward_ctrl        | -0.855   |
| reward_position    | 0.00268  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 913      |
|    ep_rew_mean     | 1.48e+03 |
| time/              |          |
|    episodes        | 1204     |
|    fps             | 13       |
|    time_elapsed    | 72852    |
|    total timesteps | 996773   |
| train/             |          |
|    actor_loss      | -150     |
|    critic_loss     | 17.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 991770   |
---------------------------------
Num timesteps: 998000
Best mean reward: 1745.38 - Last mean reward per episode: 1469.63
---------------------------------
| forward_vel        | 1.25     |
| reward             | 1.41     |
| reward_contact     | -0.00128 |
| reward_ctrl        | -0.838   |
| reward_position    | 0.00312  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 912      |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    episodes        | 1208     |
|    fps             | 13       |
|    time_elapsed    | 73056    |
|    total timesteps | 999852   |
| train/             |          |
|    actor_loss      | -148     |
|    critic_loss     | 14.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 994850   |
---------------------------------
Num timesteps: 1000000
Best mean reward: 1745.38 - Last mean reward per episode: 1490.05
Num timesteps: 1002000
Best mean reward: 1745.38 - Last mean reward per episode: 1489.66
---------------------------------
| forward_vel        | 1.23     |
| reward             | 1.39     |
| reward_contact     | -0.0013  |
| reward_ctrl        | -0.835   |
| reward_position    | 0.00312  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 912      |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1212     |
|    fps             | 13       |
|    time_elapsed    | 73340    |
|    total timesteps | 1003852  |
| train/             |          |
|    actor_loss      | -152     |
|    critic_loss     | 10.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 998850   |
---------------------------------
Num timesteps: 1004000
Best mean reward: 1745.38 - Last mean reward per episode: 1496.05
Num timesteps: 1006000
Best mean reward: 1745.38 - Last mean reward per episode: 1492.55
---------------------------------
| forward_vel        | 1.22     |
| reward             | 1.39     |
| reward_contact     | -0.00133 |
| reward_ctrl        | -0.833   |
| reward_position    | 0.00312  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 911      |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1216     |
|    fps             | 13       |
|    time_elapsed    | 73577    |
|    total timesteps | 1007423  |
| train/             |          |
|    actor_loss      | -147     |
|    critic_loss     | 38.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1002420  |
---------------------------------
Num timesteps: 1008000
Best mean reward: 1745.38 - Last mean reward per episode: 1498.73
Num timesteps: 1010000
Best mean reward: 1745.38 - Last mean reward per episode: 1499.92
---------------------------------
| forward_vel        | 1.22     |
| reward             | 1.4      |
| reward_contact     | -0.00117 |
| reward_ctrl        | -0.823   |
| reward_position    | 0.00312  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 911      |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1220     |
|    fps             | 13       |
|    time_elapsed    | 73893    |
|    total timesteps | 1011423  |
| train/             |          |
|    actor_loss      | -151     |
|    critic_loss     | 13.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1006420  |
---------------------------------
Num timesteps: 1012000
Best mean reward: 1745.38 - Last mean reward per episode: 1502.75
Num timesteps: 1014000
Best mean reward: 1745.38 - Last mean reward per episode: 1500.65
---------------------------------
| forward_vel        | 1.22     |
| reward             | 1.42     |
| reward_contact     | -0.00115 |
| reward_ctrl        | -0.802   |
| reward_position    | 0.00312  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 914      |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1224     |
|    fps             | 13       |
|    time_elapsed    | 74172    |
|    total timesteps | 1015423  |
| train/             |          |
|    actor_loss      | -153     |
|    critic_loss     | 10.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1010420  |
---------------------------------
Num timesteps: 1016000
Best mean reward: 1745.38 - Last mean reward per episode: 1504.48
Num timesteps: 1018000
Best mean reward: 1745.38 - Last mean reward per episode: 1509.49
---------------------------------
| forward_vel        | 1.23     |
| reward             | 1.42     |
| reward_contact     | -0.00117 |
| reward_ctrl        | -0.815   |
| reward_position    | 0.00312  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 914      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1228     |
|    fps             | 13       |
|    time_elapsed    | 74451    |
|    total timesteps | 1019423  |
| train/             |          |
|    actor_loss      | -147     |
|    critic_loss     | 11.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1014420  |
---------------------------------
Num timesteps: 1020000
Best mean reward: 1745.38 - Last mean reward per episode: 1518.59
Num timesteps: 1022000
Best mean reward: 1745.38 - Last mean reward per episode: 1516.57
---------------------------------
| forward_vel        | 1.21     |
| reward             | 1.36     |
| reward_contact     | -0.00121 |
| reward_ctrl        | -0.851   |
| reward_position    | 0.00312  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 914      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1232     |
|    fps             | 13       |
|    time_elapsed    | 74730    |
|    total timesteps | 1023256  |
| train/             |          |
|    actor_loss      | -149     |
|    critic_loss     | 15       |
|    learning_rate   | 0.001    |
|    n_updates       | 1018255  |
---------------------------------
Num timesteps: 1024000
Best mean reward: 1745.38 - Last mean reward per episode: 1521.88
Num timesteps: 1026000
Best mean reward: 1745.38 - Last mean reward per episode: 1520.63
---------------------------------
| forward_vel        | 1.23     |
| reward             | 1.38     |
| reward_contact     | -0.00121 |
| reward_ctrl        | -0.854   |
| reward_position    | 0.00312  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1236     |
|    fps             | 13       |
|    time_elapsed    | 74989    |
|    total timesteps | 1026675  |
| train/             |          |
|    actor_loss      | -148     |
|    critic_loss     | 53.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 1021670  |
---------------------------------
Num timesteps: 1028000
Best mean reward: 1745.38 - Last mean reward per episode: 1520.62
Num timesteps: 1030000
Best mean reward: 1745.38 - Last mean reward per episode: 1534.60
---------------------------------
| forward_vel        | 1.26     |
| reward             | 1.41     |
| reward_contact     | -0.00121 |
| reward_ctrl        | -0.852   |
| reward_position    | 0.00311  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1240     |
|    fps             | 13       |
|    time_elapsed    | 75272    |
|    total timesteps | 1030675  |
| train/             |          |
|    actor_loss      | -155     |
|    critic_loss     | 13       |
|    learning_rate   | 0.001    |
|    n_updates       | 1025670  |
---------------------------------
Num timesteps: 1032000
Best mean reward: 1745.38 - Last mean reward per episode: 1542.78
Num timesteps: 1034000
Best mean reward: 1745.38 - Last mean reward per episode: 1540.84
---------------------------------
| forward_vel        | 1.25     |
| reward             | 1.4      |
| reward_contact     | -0.00122 |
| reward_ctrl        | -0.846   |
| reward_position    | 0.00311  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1244     |
|    fps             | 13       |
|    time_elapsed    | 75553    |
|    total timesteps | 1034675  |
| train/             |          |
|    actor_loss      | -152     |
|    critic_loss     | 11.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1029670  |
---------------------------------
Num timesteps: 1036000
Best mean reward: 1745.38 - Last mean reward per episode: 1541.49
Num timesteps: 1038000
Best mean reward: 1745.38 - Last mean reward per episode: 1542.07
---------------------------------
| forward_vel        | 1.25     |
| reward             | 1.4      |
| reward_contact     | -0.00124 |
| reward_ctrl        | -0.858   |
| reward_position    | 0.00311  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 916      |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    episodes        | 1248     |
|    fps             | 13       |
|    time_elapsed    | 75832    |
|    total timesteps | 1038675  |
| train/             |          |
|    actor_loss      | -154     |
|    critic_loss     | 10.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1033670  |
---------------------------------
Num timesteps: 1040000
Best mean reward: 1745.38 - Last mean reward per episode: 1548.29
Num timesteps: 1042000
Best mean reward: 1745.38 - Last mean reward per episode: 1548.72
---------------------------------
| forward_vel        | 1.29     |
| reward             | 1.44     |
| reward_contact     | -0.00119 |
| reward_ctrl        | -0.855   |
| reward_position    | 0.00311  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 916      |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    episodes        | 1252     |
|    fps             | 13       |
|    time_elapsed    | 76111    |
|    total timesteps | 1042675  |
| train/             |          |
|    actor_loss      | -151     |
|    critic_loss     | 13       |
|    learning_rate   | 0.001    |
|    n_updates       | 1037670  |
---------------------------------
Num timesteps: 1044000
Best mean reward: 1745.38 - Last mean reward per episode: 1539.03
---------------------------------
| forward_vel        | 1.33     |
| reward             | 1.47     |
| reward_contact     | -0.00113 |
| reward_ctrl        | -0.857   |
| reward_position    | 0.00311  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1256     |
|    fps             | 13       |
|    time_elapsed    | 76237    |
|    total timesteps | 1044427  |
| train/             |          |
|    actor_loss      | -146     |
|    critic_loss     | 16.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1039425  |
---------------------------------
Num timesteps: 1046000
Best mean reward: 1745.38 - Last mean reward per episode: 1526.70
Num timesteps: 1048000
Best mean reward: 1745.38 - Last mean reward per episode: 1526.82
---------------------------------
| forward_vel        | 1.36     |
| reward             | 1.53     |
| reward_contact     | -0.00112 |
| reward_ctrl        | -0.845   |
| reward_position    | 0.0105   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1260     |
|    fps             | 13       |
|    time_elapsed    | 76516    |
|    total timesteps | 1048427  |
| train/             |          |
|    actor_loss      | -152     |
|    critic_loss     | 17.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1043425  |
---------------------------------
Num timesteps: 1050000
Best mean reward: 1745.38 - Last mean reward per episode: 1522.81
---------------------------------
| forward_vel        | 1.39     |
| reward             | 1.54     |
| reward_contact     | -0.00112 |
| reward_ctrl        | -0.865   |
| reward_position    | 0.0105   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 884      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1264     |
|    fps             | 13       |
|    time_elapsed    | 76727    |
|    total timesteps | 1051361  |
| train/             |          |
|    actor_loss      | -154     |
|    critic_loss     | 36.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 1046360  |
---------------------------------
Num timesteps: 1052000
Best mean reward: 1745.38 - Last mean reward per episode: 1527.01
Num timesteps: 1054000
Best mean reward: 1745.38 - Last mean reward per episode: 1542.80
---------------------------------
| forward_vel        | 1.42     |
| reward             | 1.58     |
| reward_contact     | -0.00108 |
| reward_ctrl        | -0.841   |
| reward_position    | 0.0105   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 876      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1268     |
|    fps             | 13       |
|    time_elapsed    | 76944    |
|    total timesteps | 1054484  |
| train/             |          |
|    actor_loss      | -159     |
|    critic_loss     | 30.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1049480  |
---------------------------------
Num timesteps: 1056000
Best mean reward: 1745.38 - Last mean reward per episode: 1526.15
---------------------------------
| forward_vel        | 1.43     |
| reward             | 1.6      |
| reward_contact     | -0.00108 |
| reward_ctrl        | -0.837   |
| reward_position    | 0.0105   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1272     |
|    fps             | 13       |
|    time_elapsed    | 77183    |
|    total timesteps | 1057850  |
| train/             |          |
|    actor_loss      | -154     |
|    critic_loss     | 7.44     |
|    learning_rate   | 0.001    |
|    n_updates       | 1052845  |
---------------------------------
Num timesteps: 1058000
Best mean reward: 1745.38 - Last mean reward per episode: 1517.88
Num timesteps: 1060000
Best mean reward: 1745.38 - Last mean reward per episode: 1522.63
---------------------------------
| forward_vel        | 1.46     |
| reward             | 1.64     |
| reward_contact     | -0.00105 |
| reward_ctrl        | -0.828   |
| reward_position    | 0.0105   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 873      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1276     |
|    fps             | 13       |
|    time_elapsed    | 77430    |
|    total timesteps | 1061366  |
| train/             |          |
|    actor_loss      | -155     |
|    critic_loss     | 9.67     |
|    learning_rate   | 0.001    |
|    n_updates       | 1056365  |
---------------------------------
Num timesteps: 1062000
Best mean reward: 1745.38 - Last mean reward per episode: 1527.70
Num timesteps: 1064000
Best mean reward: 1745.38 - Last mean reward per episode: 1505.45
---------------------------------
| forward_vel        | 1.47     |
| reward             | 1.64     |
| reward_contact     | -0.00106 |
| reward_ctrl        | -0.848   |
| reward_position    | 0.0117   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 865      |
|    ep_rew_mean     | 1.51e+03 |
| time/              |          |
|    episodes        | 1280     |
|    fps             | 13       |
|    time_elapsed    | 77649    |
|    total timesteps | 1064552  |
| train/             |          |
|    actor_loss      | -159     |
|    critic_loss     | 10.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 1059550  |
---------------------------------
Num timesteps: 1066000
Best mean reward: 1745.38 - Last mean reward per episode: 1517.77
---------------------------------
| forward_vel        | 1.49     |
| reward             | 1.66     |
| reward_contact     | -0.00103 |
| reward_ctrl        | -0.84    |
| reward_position    | 0.0121   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 862      |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1284     |
|    fps             | 13       |
|    time_elapsed    | 77810    |
|    total timesteps | 1066862  |
| train/             |          |
|    actor_loss      | -155     |
|    critic_loss     | 12.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1061860  |
---------------------------------
Num timesteps: 1068000
Best mean reward: 1745.38 - Last mean reward per episode: 1504.58
Num timesteps: 1070000
Best mean reward: 1745.38 - Last mean reward per episode: 1513.18
---------------------------------
| forward_vel        | 1.46     |
| reward             | 1.65     |
| reward_contact     | -0.00109 |
| reward_ctrl        | -0.822   |
| reward_position    | 0.0113   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 868      |
|    ep_rew_mean     | 1.51e+03 |
| time/              |          |
|    episodes        | 1288     |
|    fps             | 13       |
|    time_elapsed    | 78079    |
|    total timesteps | 1070343  |
| train/             |          |
|    actor_loss      | -155     |
|    critic_loss     | 8.11     |
|    learning_rate   | 0.001    |
|    n_updates       | 1065340  |
---------------------------------
Num timesteps: 1072000
Best mean reward: 1745.38 - Last mean reward per episode: 1511.32
Num timesteps: 1074000
Best mean reward: 1745.38 - Last mean reward per episode: 1500.52
---------------------------------
| forward_vel        | 1.45     |
| reward             | 1.62     |
| reward_contact     | -0.00101 |
| reward_ctrl        | -0.835   |
| reward_position    | 0.0113   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 867      |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1292     |
|    fps             | 13       |
|    time_elapsed    | 78350    |
|    total timesteps | 1074214  |
| train/             |          |
|    actor_loss      | -158     |
|    critic_loss     | 11.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1069210  |
---------------------------------
Num timesteps: 1076000
Best mean reward: 1745.38 - Last mean reward per episode: 1514.94
---------------------------------
| forward_vel        | 1.44     |
| reward             | 1.6      |
| reward_contact     | -0.00101 |
| reward_ctrl        | -0.847   |
| reward_position    | 0.0113   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1296     |
|    fps             | 13       |
|    time_elapsed    | 78566    |
|    total timesteps | 1077454  |
| train/             |          |
|    actor_loss      | -162     |
|    critic_loss     | 11.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 1072450  |
---------------------------------
Num timesteps: 1078000
Best mean reward: 1745.38 - Last mean reward per episode: 1501.05
Num timesteps: 1080000
Best mean reward: 1745.38 - Last mean reward per episode: 1504.02
----------------------------------
| forward_vel        | 1.44      |
| reward             | 1.6       |
| reward_contact     | -0.000957 |
| reward_ctrl        | -0.847    |
| reward_position    | 0.0113    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 879       |
|    ep_rew_mean     | 1.53e+03  |
| time/              |           |
|    episodes        | 1300      |
|    fps             | 13        |
|    time_elapsed    | 78835     |
|    total timesteps | 1081454   |
| train/             |           |
|    actor_loss      | -151      |
|    critic_loss     | 10.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 1076450   |
----------------------------------
Num timesteps: 1082000
Best mean reward: 1745.38 - Last mean reward per episode: 1527.69
Num timesteps: 1084000
Best mean reward: 1745.38 - Last mean reward per episode: 1543.81
---------------------------------
| forward_vel        | 1.38     |
| reward             | 1.53     |
| reward_contact     | -0.00102 |
| reward_ctrl        | -0.861   |
| reward_position    | 0.00941  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 885      |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    episodes        | 1304     |
|    fps             | 13       |
|    time_elapsed    | 79103    |
|    total timesteps | 1085250  |
| train/             |          |
|    actor_loss      | -160     |
|    critic_loss     | 8.46     |
|    learning_rate   | 0.001    |
|    n_updates       | 1080245  |
---------------------------------
Num timesteps: 1086000
Best mean reward: 1745.38 - Last mean reward per episode: 1546.08
Num timesteps: 1088000
Best mean reward: 1745.38 - Last mean reward per episode: 1551.59
---------------------------------
| forward_vel        | 1.37     |
| reward             | 1.5      |
| reward_contact     | -0.00111 |
| reward_ctrl        | -0.873   |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 889      |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    episodes        | 1308     |
|    fps             | 13       |
|    time_elapsed    | 79346    |
|    total timesteps | 1088717  |
| train/             |          |
|    actor_loss      | -160     |
|    critic_loss     | 10.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 1083715  |
---------------------------------
Num timesteps: 1090000
Best mean reward: 1745.38 - Last mean reward per episode: 1546.66
Num timesteps: 1092000
Best mean reward: 1745.38 - Last mean reward per episode: 1541.80
---------------------------------
| forward_vel        | 1.33     |
| reward             | 1.46     |
| reward_contact     | -0.00114 |
| reward_ctrl        | -0.882   |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 889      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1312     |
|    fps             | 13       |
|    time_elapsed    | 79639    |
|    total timesteps | 1092717  |
| train/             |          |
|    actor_loss      | -159     |
|    critic_loss     | 14.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1087715  |
---------------------------------
Num timesteps: 1094000
Best mean reward: 1745.38 - Last mean reward per episode: 1540.84
Num timesteps: 1096000
Best mean reward: 1745.38 - Last mean reward per episode: 1538.57
---------------------------------
| forward_vel        | 1.32     |
| reward             | 1.44     |
| reward_contact     | -0.00117 |
| reward_ctrl        | -0.88    |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 891      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1316     |
|    fps             | 13       |
|    time_elapsed    | 79913    |
|    total timesteps | 1096555  |
| train/             |          |
|    actor_loss      | -162     |
|    critic_loss     | 7.71     |
|    learning_rate   | 0.001    |
|    n_updates       | 1091550  |
---------------------------------
Num timesteps: 1098000
Best mean reward: 1745.38 - Last mean reward per episode: 1535.58
---------------------------------
| forward_vel        | 1.33     |
| reward             | 1.46     |
| reward_contact     | -0.00115 |
| reward_ctrl        | -0.882   |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 883      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1320     |
|    fps             | 13       |
|    time_elapsed    | 80140    |
|    total timesteps | 1099702  |
| train/             |          |
|    actor_loss      | -162     |
|    critic_loss     | 6.68     |
|    learning_rate   | 0.001    |
|    n_updates       | 1094700  |
---------------------------------
Num timesteps: 1100000
Best mean reward: 1745.38 - Last mean reward per episode: 1535.11
Num timesteps: 1102000
Best mean reward: 1745.38 - Last mean reward per episode: 1518.55
---------------------------------
| forward_vel        | 1.36     |
| reward             | 1.5      |
| reward_contact     | -0.00103 |
| reward_ctrl        | -0.873   |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1324     |
|    fps             | 13       |
|    time_elapsed    | 80391    |
|    total timesteps | 1103118  |
| train/             |          |
|    actor_loss      | -166     |
|    critic_loss     | 40.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1098115  |
---------------------------------
Num timesteps: 1104000
Best mean reward: 1745.38 - Last mean reward per episode: 1518.07
Num timesteps: 1106000
Best mean reward: 1745.38 - Last mean reward per episode: 1523.50
---------------------------------
| forward_vel        | 1.33     |
| reward             | 1.46     |
| reward_contact     | -0.00113 |
| reward_ctrl        | -0.872   |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 1.51e+03 |
| time/              |          |
|    episodes        | 1328     |
|    fps             | 13       |
|    time_elapsed    | 80680    |
|    total timesteps | 1107118  |
| train/             |          |
|    actor_loss      | -163     |
|    critic_loss     | 10.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1102115  |
---------------------------------
Num timesteps: 1108000
Best mean reward: 1745.38 - Last mean reward per episode: 1513.79
Num timesteps: 1110000
Best mean reward: 1745.38 - Last mean reward per episode: 1522.36
---------------------------------
| forward_vel        | 1.36     |
| reward             | 1.53     |
| reward_contact     | -0.00111 |
| reward_ctrl        | -0.839   |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 879      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1332     |
|    fps             | 13       |
|    time_elapsed    | 80968    |
|    total timesteps | 1111118  |
| train/             |          |
|    actor_loss      | -163     |
|    critic_loss     | 10.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 1106115  |
---------------------------------
Num timesteps: 1112000
Best mean reward: 1745.38 - Last mean reward per episode: 1515.92
Num timesteps: 1114000
Best mean reward: 1745.38 - Last mean reward per episode: 1523.29
---------------------------------
| forward_vel        | 1.35     |
| reward             | 1.53     |
| reward_contact     | -0.00111 |
| reward_ctrl        | -0.835   |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 884      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1336     |
|    fps             | 13       |
|    time_elapsed    | 81263    |
|    total timesteps | 1115118  |
| train/             |          |
|    actor_loss      | -163     |
|    critic_loss     | 9.35     |
|    learning_rate   | 0.001    |
|    n_updates       | 1110115  |
---------------------------------
Num timesteps: 1116000
Best mean reward: 1745.38 - Last mean reward per episode: 1529.57
Num timesteps: 1118000
Best mean reward: 1745.38 - Last mean reward per episode: 1528.66
---------------------------------
| forward_vel        | 1.34     |
| reward             | 1.48     |
| reward_contact     | -0.00112 |
| reward_ctrl        | -0.87    |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 884      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1340     |
|    fps             | 13       |
|    time_elapsed    | 81553    |
|    total timesteps | 1119118  |
| train/             |          |
|    actor_loss      | -157     |
|    critic_loss     | 6.3      |
|    learning_rate   | 0.001    |
|    n_updates       | 1114115  |
---------------------------------
Num timesteps: 1120000
Best mean reward: 1745.38 - Last mean reward per episode: 1534.60
Num timesteps: 1122000
Best mean reward: 1745.38 - Last mean reward per episode: 1531.32
---------------------------------
| forward_vel        | 1.37     |
| reward             | 1.49     |
| reward_contact     | -0.00107 |
| reward_ctrl        | -0.88    |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 884      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1344     |
|    fps             | 13       |
|    time_elapsed    | 81839    |
|    total timesteps | 1123118  |
| train/             |          |
|    actor_loss      | -164     |
|    critic_loss     | 16.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1118115  |
---------------------------------
Num timesteps: 1124000
Best mean reward: 1745.38 - Last mean reward per episode: 1541.05
Num timesteps: 1126000
Best mean reward: 1745.38 - Last mean reward per episode: 1544.80
---------------------------------
| forward_vel        | 1.35     |
| reward             | 1.48     |
| reward_contact     | -0.00109 |
| reward_ctrl        | -0.877   |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 884      |
|    ep_rew_mean     | 1.56e+03 |
| time/              |          |
|    episodes        | 1348     |
|    fps             | 13       |
|    time_elapsed    | 82113    |
|    total timesteps | 1127118  |
| train/             |          |
|    actor_loss      | -168     |
|    critic_loss     | 41.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1122115  |
---------------------------------
Num timesteps: 1128000
Best mean reward: 1745.38 - Last mean reward per episode: 1559.55
Num timesteps: 1130000
Best mean reward: 1745.38 - Last mean reward per episode: 1552.46
---------------------------------
| forward_vel        | 1.32     |
| reward             | 1.44     |
| reward_contact     | -0.0011  |
| reward_ctrl        | -0.884   |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 884      |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    episodes        | 1352     |
|    fps             | 13       |
|    time_elapsed    | 82393    |
|    total timesteps | 1131118  |
| train/             |          |
|    actor_loss      | -162     |
|    critic_loss     | 22.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 1126115  |
---------------------------------
Num timesteps: 1132000
Best mean reward: 1745.38 - Last mean reward per episode: 1553.45
Num timesteps: 1134000
Best mean reward: 1745.38 - Last mean reward per episode: 1571.49
---------------------------------
| forward_vel        | 1.29     |
| reward             | 1.44     |
| reward_contact     | -0.00123 |
| reward_ctrl        | -0.864   |
| reward_position    | 0.00897  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 907      |
|    ep_rew_mean     | 1.6e+03  |
| time/              |          |
|    episodes        | 1356     |
|    fps             | 13       |
|    time_elapsed    | 82678    |
|    total timesteps | 1135118  |
| train/             |          |
|    actor_loss      | -166     |
|    critic_loss     | 14.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 1130115  |
---------------------------------
Num timesteps: 1136000
Best mean reward: 1745.38 - Last mean reward per episode: 1595.76
Num timesteps: 1138000
Best mean reward: 1745.38 - Last mean reward per episode: 1585.43
---------------------------------
| forward_vel        | 1.27     |
| reward             | 1.41     |
| reward_contact     | -0.00124 |
| reward_ctrl        | -0.865   |
| reward_position    | 0.00157  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 902      |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    episodes        | 1360     |
|    fps             | 13       |
|    time_elapsed    | 82929    |
|    total timesteps | 1138620  |
| train/             |          |
|    actor_loss      | -160     |
|    critic_loss     | 17.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1133615  |
---------------------------------
Num timesteps: 1140000
Best mean reward: 1745.38 - Last mean reward per episode: 1582.62
Num timesteps: 1142000
Best mean reward: 1745.38 - Last mean reward per episode: 1596.31
---------------------------------
| forward_vel        | 1.25     |
| reward             | 1.39     |
| reward_contact     | -0.00124 |
| reward_ctrl        | -0.859   |
| reward_position    | 0.00157  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 913      |
|    ep_rew_mean     | 1.6e+03  |
| time/              |          |
|    episodes        | 1364     |
|    fps             | 13       |
|    time_elapsed    | 83216    |
|    total timesteps | 1142620  |
| train/             |          |
|    actor_loss      | -167     |
|    critic_loss     | 16.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 1137615  |
---------------------------------
Num timesteps: 1144000
Best mean reward: 1745.38 - Last mean reward per episode: 1594.10
Num timesteps: 1146000
Best mean reward: 1745.38 - Last mean reward per episode: 1595.73
---------------------------------
| forward_vel        | 1.25     |
| reward             | 1.4      |
| reward_contact     | -0.00125 |
| reward_ctrl        | -0.857   |
| reward_position    | 0.00157  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 921      |
|    ep_rew_mean     | 1.61e+03 |
| time/              |          |
|    episodes        | 1368     |
|    fps             | 13       |
|    time_elapsed    | 83501    |
|    total timesteps | 1146620  |
| train/             |          |
|    actor_loss      | -164     |
|    critic_loss     | 17       |
|    learning_rate   | 0.001    |
|    n_updates       | 1141615  |
---------------------------------
Num timesteps: 1148000
Best mean reward: 1745.38 - Last mean reward per episode: 1601.38
Num timesteps: 1150000
Best mean reward: 1745.38 - Last mean reward per episode: 1604.64
---------------------------------
| forward_vel        | 1.24     |
| reward             | 1.38     |
| reward_contact     | -0.0013  |
| reward_ctrl        | -0.861   |
| reward_position    | 0.00157  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 928      |
|    ep_rew_mean     | 1.61e+03 |
| time/              |          |
|    episodes        | 1372     |
|    fps             | 13       |
|    time_elapsed    | 83784    |
|    total timesteps | 1150620  |
| train/             |          |
|    actor_loss      | -160     |
|    critic_loss     | 11.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1145615  |
---------------------------------
Num timesteps: 1152000
Best mean reward: 1745.38 - Last mean reward per episode: 1586.09
---------------------------------
| forward_vel        | 1.24     |
| reward             | 1.36     |
| reward_contact     | -0.00136 |
| reward_ctrl        | -0.883   |
| reward_position    | 0.003    |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 913      |
|    ep_rew_mean     | 1.59e+03 |
| time/              |          |
|    episodes        | 1376     |
|    fps             | 13       |
|    time_elapsed    | 83933    |
|    total timesteps | 1152702  |
| train/             |          |
|    actor_loss      | -167     |
|    critic_loss     | 10.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 1147700  |
---------------------------------
Num timesteps: 1154000
Best mean reward: 1745.38 - Last mean reward per episode: 1595.22
---------------------------------
| forward_vel        | 1.24     |
| reward             | 1.34     |
| reward_contact     | -0.00138 |
| reward_ctrl        | -0.902   |
| reward_position    | 0.00177  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    episodes        | 1380     |
|    fps             | 13       |
|    time_elapsed    | 84129    |
|    total timesteps | 1155475  |
| train/             |          |
|    actor_loss      | -161     |
|    critic_loss     | 25.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1150470  |
---------------------------------
Num timesteps: 1156000
Best mean reward: 1745.38 - Last mean reward per episode: 1562.58
Num timesteps: 1158000
Best mean reward: 1745.38 - Last mean reward per episode: 1576.31
---------------------------------
| forward_vel        | 1.21     |
| reward             | 1.3      |
| reward_contact     | -0.0014  |
| reward_ctrl        | -0.925   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 917      |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    episodes        | 1384     |
|    fps             | 13       |
|    time_elapsed    | 84345    |
|    total timesteps | 1158527  |
| train/             |          |
|    actor_loss      | -165     |
|    critic_loss     | 7.18     |
|    learning_rate   | 0.001    |
|    n_updates       | 1153525  |
---------------------------------
Num timesteps: 1160000
Best mean reward: 1745.38 - Last mean reward per episode: 1578.56
Num timesteps: 1162000
Best mean reward: 1745.38 - Last mean reward per episode: 1581.80
---------------------------------
| forward_vel        | 1.21     |
| reward             | 1.29     |
| reward_contact     | -0.0014  |
| reward_ctrl        | -0.932   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 919      |
|    ep_rew_mean     | 1.59e+03 |
| time/              |          |
|    episodes        | 1388     |
|    fps             | 13       |
|    time_elapsed    | 84608    |
|    total timesteps | 1162255  |
| train/             |          |
|    actor_loss      | -162     |
|    critic_loss     | 10.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1157250  |
---------------------------------
Num timesteps: 1164000
Best mean reward: 1745.38 - Last mean reward per episode: 1588.22
Num timesteps: 1166000
Best mean reward: 1745.38 - Last mean reward per episode: 1606.98
---------------------------------
| forward_vel        | 1.19     |
| reward             | 1.29     |
| reward_contact     | -0.00151 |
| reward_ctrl        | -0.915   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 920      |
|    ep_rew_mean     | 1.61e+03 |
| time/              |          |
|    episodes        | 1392     |
|    fps             | 13       |
|    time_elapsed    | 84890    |
|    total timesteps | 1166255  |
| train/             |          |
|    actor_loss      | -166     |
|    critic_loss     | 11.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 1161250  |
---------------------------------
Num timesteps: 1168000
Best mean reward: 1745.38 - Last mean reward per episode: 1606.43
Num timesteps: 1170000
Best mean reward: 1745.38 - Last mean reward per episode: 1623.28
---------------------------------
| forward_vel        | 1.18     |
| reward             | 1.29     |
| reward_contact     | -0.00148 |
| reward_ctrl        | -0.9     |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 928      |
|    ep_rew_mean     | 1.62e+03 |
| time/              |          |
|    episodes        | 1396     |
|    fps             | 13       |
|    time_elapsed    | 85169    |
|    total timesteps | 1170255  |
| train/             |          |
|    actor_loss      | -167     |
|    critic_loss     | 12.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1165250  |
---------------------------------
Num timesteps: 1172000
Best mean reward: 1745.38 - Last mean reward per episode: 1605.63
---------------------------------
| forward_vel        | 1.2      |
| reward             | 1.28     |
| reward_contact     | -0.00156 |
| reward_ctrl        | -0.933   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 915      |
|    ep_rew_mean     | 1.6e+03  |
| time/              |          |
|    episodes        | 1400     |
|    fps             | 13       |
|    time_elapsed    | 85356    |
|    total timesteps | 1172943  |
| train/             |          |
|    actor_loss      | -167     |
|    critic_loss     | 6.81     |
|    learning_rate   | 0.001    |
|    n_updates       | 1167940  |
---------------------------------
Num timesteps: 1174000
Best mean reward: 1745.38 - Last mean reward per episode: 1603.69
Num timesteps: 1176000
Best mean reward: 1745.38 - Last mean reward per episode: 1597.85
---------------------------------
| forward_vel        | 1.22     |
| reward             | 1.31     |
| reward_contact     | -0.00155 |
| reward_ctrl        | -0.921   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 911      |
|    ep_rew_mean     | 1.59e+03 |
| time/              |          |
|    episodes        | 1404     |
|    fps             | 13       |
|    time_elapsed    | 85595    |
|    total timesteps | 1176375  |
| train/             |          |
|    actor_loss      | -166     |
|    critic_loss     | 9.54     |
|    learning_rate   | 0.001    |
|    n_updates       | 1171370  |
---------------------------------
Num timesteps: 1178000
Best mean reward: 1745.38 - Last mean reward per episode: 1597.08
---------------------------------
| forward_vel        | 1.24     |
| reward             | 1.33     |
| reward_contact     | -0.00149 |
| reward_ctrl        | -0.923   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 911      |
|    ep_rew_mean     | 1.6e+03  |
| time/              |          |
|    episodes        | 1408     |
|    fps             | 13       |
|    time_elapsed    | 85832    |
|    total timesteps | 1179812  |
| train/             |          |
|    actor_loss      | -164     |
|    critic_loss     | 10.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 1174810  |
---------------------------------
Num timesteps: 1180000
Best mean reward: 1745.38 - Last mean reward per episode: 1599.63
Num timesteps: 1182000
Best mean reward: 1745.38 - Last mean reward per episode: 1610.85
---------------------------------
| forward_vel        | 1.26     |
| reward             | 1.36     |
| reward_contact     | -0.00141 |
| reward_ctrl        | -0.918   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 1.61e+03 |
| time/              |          |
|    episodes        | 1412     |
|    fps             | 13       |
|    time_elapsed    | 86060    |
|    total timesteps | 1183636  |
| train/             |          |
|    actor_loss      | -171     |
|    critic_loss     | 16.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1178635  |
---------------------------------
Num timesteps: 1184000
Best mean reward: 1745.38 - Last mean reward per episode: 1609.67
Num timesteps: 1186000
Best mean reward: 1745.38 - Last mean reward per episode: 1612.93
---------------------------------
| forward_vel        | 1.27     |
| reward             | 1.37     |
| reward_contact     | -0.00144 |
| reward_ctrl        | -0.918   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 902      |
|    ep_rew_mean     | 1.61e+03 |
| time/              |          |
|    episodes        | 1416     |
|    fps             | 13       |
|    time_elapsed    | 86208    |
|    total timesteps | 1186741  |
| train/             |          |
|    actor_loss      | -163     |
|    critic_loss     | 7.86     |
|    learning_rate   | 0.001    |
|    n_updates       | 1181740  |
---------------------------------
Num timesteps: 1188000
Best mean reward: 1745.38 - Last mean reward per episode: 1607.31
Num timesteps: 1190000
Best mean reward: 1745.38 - Last mean reward per episode: 1608.12
---------------------------------
| forward_vel        | 1.27     |
| reward             | 1.34     |
| reward_contact     | -0.00144 |
| reward_ctrl        | -0.938   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 904      |
|    ep_rew_mean     | 1.61e+03 |
| time/              |          |
|    episodes        | 1420     |
|    fps             | 13       |
|    time_elapsed    | 86368    |
|    total timesteps | 1190092  |
| train/             |          |
|    actor_loss      | -168     |
|    critic_loss     | 13.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1185090  |
---------------------------------
Num timesteps: 1192000
Best mean reward: 1745.38 - Last mean reward per episode: 1625.59
Num timesteps: 1194000
Best mean reward: 1745.38 - Last mean reward per episode: 1634.82
---------------------------------
| forward_vel        | 1.27     |
| reward             | 1.35     |
| reward_contact     | -0.00146 |
| reward_ctrl        | -0.94    |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 910      |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    episodes        | 1424     |
|    fps             | 13       |
|    time_elapsed    | 86558    |
|    total timesteps | 1194092  |
| train/             |          |
|    actor_loss      | -167     |
|    critic_loss     | 12.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1189090  |
---------------------------------
Num timesteps: 1196000
Best mean reward: 1745.38 - Last mean reward per episode: 1637.59
Num timesteps: 1198000
Best mean reward: 1745.38 - Last mean reward per episode: 1647.41
---------------------------------
| forward_vel        | 1.3      |
| reward             | 1.38     |
| reward_contact     | -0.00136 |
| reward_ctrl        | -0.931   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 910      |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    episodes        | 1428     |
|    fps             | 13       |
|    time_elapsed    | 86747    |
|    total timesteps | 1198092  |
| train/             |          |
|    actor_loss      | -162     |
|    critic_loss     | 9.74     |
|    learning_rate   | 0.001    |
|    n_updates       | 1193090  |
---------------------------------
Num timesteps: 1200000
Best mean reward: 1745.38 - Last mean reward per episode: 1646.87
---------------------------------
| forward_vel        | 1.26     |
| reward             | 1.35     |
| reward_contact     | -0.00146 |
| reward_ctrl        | -0.933   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 905      |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    episodes        | 1432     |
|    fps             | 13       |
|    time_elapsed    | 86914    |
|    total timesteps | 1201626  |
| train/             |          |
|    actor_loss      | -168     |
|    critic_loss     | 19.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1196625  |
---------------------------------
Num timesteps: 1202000
Best mean reward: 1745.38 - Last mean reward per episode: 1642.37
Num timesteps: 1204000
Best mean reward: 1745.38 - Last mean reward per episode: 1627.50
---------------------------------
| forward_vel        | 1.26     |
| reward             | 1.33     |
| reward_contact     | -0.00144 |
| reward_ctrl        | -0.941   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 903      |
|    ep_rew_mean     | 1.62e+03 |
| time/              |          |
|    episodes        | 1436     |
|    fps             | 13       |
|    time_elapsed    | 87091    |
|    total timesteps | 1205378  |
| train/             |          |
|    actor_loss      | -159     |
|    critic_loss     | 13       |
|    learning_rate   | 0.001    |
|    n_updates       | 1200375  |
---------------------------------
Num timesteps: 1206000
Best mean reward: 1745.38 - Last mean reward per episode: 1624.69
Num timesteps: 1208000
Best mean reward: 1745.38 - Last mean reward per episode: 1626.97
---------------------------------
| forward_vel        | 1.3      |
| reward             | 1.39     |
| reward_contact     | -0.00141 |
| reward_ctrl        | -0.927   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 903      |
|    ep_rew_mean     | 1.63e+03 |
| time/              |          |
|    episodes        | 1440     |
|    fps             | 13       |
|    time_elapsed    | 87278    |
|    total timesteps | 1209378  |
| train/             |          |
|    actor_loss      | -164     |
|    critic_loss     | 35.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1204375  |
---------------------------------
Num timesteps: 1210000
Best mean reward: 1745.38 - Last mean reward per episode: 1631.17
Num timesteps: 1212000
Best mean reward: 1745.38 - Last mean reward per episode: 1591.89
---------------------------------
| forward_vel        | 1.3      |
| reward             | 1.37     |
| reward_contact     | -0.00138 |
| reward_ctrl        | -0.938   |
| reward_position    | 0.0164   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 897      |
|    ep_rew_mean     | 1.59e+03 |
| time/              |          |
|    episodes        | 1444     |
|    fps             | 13       |
|    time_elapsed    | 87436    |
|    total timesteps | 1212803  |
| train/             |          |
|    actor_loss      | -170     |
|    critic_loss     | 16.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1207800  |
---------------------------------
Num timesteps: 1214000
Best mean reward: 1745.38 - Last mean reward per episode: 1592.57
---------------------------------
| forward_vel        | 1.32     |
| reward             | 1.41     |
| reward_contact     | -0.00136 |
| reward_ctrl        | -0.929   |
| reward_position    | 0.0174   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 887      |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    episodes        | 1448     |
|    fps             | 13       |
|    time_elapsed    | 87573    |
|    total timesteps | 1215835  |
| train/             |          |
|    actor_loss      | -166     |
|    critic_loss     | 11.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 1210830  |
---------------------------------
Num timesteps: 1216000
Best mean reward: 1745.38 - Last mean reward per episode: 1575.93
Num timesteps: 1218000
Best mean reward: 1745.38 - Last mean reward per episode: 1576.93
---------------------------------
| forward_vel        | 1.33     |
| reward             | 1.41     |
| reward_contact     | -0.0013  |
| reward_ctrl        | -0.938   |
| reward_position    | 0.0174   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 880      |
|    ep_rew_mean     | 1.57e+03 |
| time/              |          |
|    episodes        | 1452     |
|    fps             | 13       |
|    time_elapsed    | 87723    |
|    total timesteps | 1219154  |
| train/             |          |
|    actor_loss      | -166     |
|    critic_loss     | 22.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 1214150  |
---------------------------------
Num timesteps: 1220000
Best mean reward: 1745.38 - Last mean reward per episode: 1567.44
Num timesteps: 1222000
Best mean reward: 1745.38 - Last mean reward per episode: 1548.50
---------------------------------
| forward_vel        | 1.33     |
| reward             | 1.37     |
| reward_contact     | -0.0012  |
| reward_ctrl        | -0.969   |
| reward_position    | 0.0174   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 872      |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    episodes        | 1456     |
|    fps             | 13       |
|    time_elapsed    | 87866    |
|    total timesteps | 1222355  |
| train/             |          |
|    actor_loss      | -165     |
|    critic_loss     | 9.32     |
|    learning_rate   | 0.001    |
|    n_updates       | 1217350  |
---------------------------------
Num timesteps: 1224000
Best mean reward: 1745.38 - Last mean reward per episode: 1544.48
Num timesteps: 1226000
Best mean reward: 1745.38 - Last mean reward per episode: 1551.84
---------------------------------
| forward_vel        | 1.34     |
| reward             | 1.38     |
| reward_contact     | -0.00123 |
| reward_ctrl        | -0.97    |
| reward_position    | 0.0174   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 1.56e+03 |
| time/              |          |
|    episodes        | 1460     |
|    fps             | 13       |
|    time_elapsed    | 88043    |
|    total timesteps | 1226355  |
| train/             |          |
|    actor_loss      | -168     |
|    critic_loss     | 11.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1221350  |
---------------------------------
Num timesteps: 1228000
Best mean reward: 1745.38 - Last mean reward per episode: 1554.90
Num timesteps: 1230000
Best mean reward: 1745.38 - Last mean reward per episode: 1555.04
---------------------------------
| forward_vel        | 1.37     |
| reward             | 1.41     |
| reward_contact     | -0.00119 |
| reward_ctrl        | -0.972   |
| reward_position    | 0.0174   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 875      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1464     |
|    fps             | 13       |
|    time_elapsed    | 88209    |
|    total timesteps | 1230105  |
| train/             |          |
|    actor_loss      | -166     |
|    critic_loss     | 15.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1225100  |
---------------------------------
Num timesteps: 1232000
Best mean reward: 1745.38 - Last mean reward per episode: 1544.98
Num timesteps: 1234000
Best mean reward: 1745.38 - Last mean reward per episode: 1540.81
---------------------------------
| forward_vel        | 1.33     |
| reward             | 1.35     |
| reward_contact     | -0.00128 |
| reward_ctrl        | -1       |
| reward_position    | 0.0174   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 875      |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    episodes        | 1468     |
|    fps             | 13       |
|    time_elapsed    | 88385    |
|    total timesteps | 1234105  |
| train/             |          |
|    actor_loss      | -165     |
|    critic_loss     | 7.75     |
|    learning_rate   | 0.001    |
|    n_updates       | 1229100  |
---------------------------------
Num timesteps: 1236000
Best mean reward: 1745.38 - Last mean reward per episode: 1534.80
---------------------------------
| forward_vel        | 1.34     |
| reward             | 1.34     |
| reward_contact     | -0.00125 |
| reward_ctrl        | -1.02    |
| reward_position    | 0.0174   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 867      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1472     |
|    fps             | 13       |
|    time_elapsed    | 88528    |
|    total timesteps | 1237366  |
| train/             |          |
|    actor_loss      | -160     |
|    critic_loss     | 10.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1232365  |
---------------------------------
Num timesteps: 1238000
Best mean reward: 1745.38 - Last mean reward per episode: 1520.98
---------------------------------
| forward_vel        | 1.33     |
| reward             | 1.31     |
| reward_contact     | -0.00127 |
| reward_ctrl        | -1.04    |
| reward_position    | 0.0169   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 870      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1476     |
|    fps             | 13       |
|    time_elapsed    | 88631    |
|    total timesteps | 1239704  |
| train/             |          |
|    actor_loss      | -164     |
|    critic_loss     | 17.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1234700  |
---------------------------------
Num timesteps: 1240000
Best mean reward: 1745.38 - Last mean reward per episode: 1535.90
Num timesteps: 1242000
Best mean reward: 1745.38 - Last mean reward per episode: 1523.50
---------------------------------
| forward_vel        | 1.38     |
| reward             | 1.38     |
| reward_contact     | -0.00125 |
| reward_ctrl        | -1.01    |
| reward_position    | 0.0168   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 866      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1480     |
|    fps             | 13       |
|    time_elapsed    | 88735    |
|    total timesteps | 1242074  |
| train/             |          |
|    actor_loss      | -171     |
|    critic_loss     | 7.79     |
|    learning_rate   | 0.001    |
|    n_updates       | 1237070  |
---------------------------------
Num timesteps: 1244000
Best mean reward: 1745.38 - Last mean reward per episode: 1556.20
Num timesteps: 1246000
Best mean reward: 1745.38 - Last mean reward per episode: 1558.24
---------------------------------
| forward_vel        | 1.38     |
| reward             | 1.39     |
| reward_contact     | -0.00124 |
| reward_ctrl        | -0.994   |
| reward_position    | 0.0019   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 875      |
|    ep_rew_mean     | 1.57e+03 |
| time/              |          |
|    episodes        | 1484     |
|    fps             | 14       |
|    time_elapsed    | 88910    |
|    total timesteps | 1246074  |
| train/             |          |
|    actor_loss      | -168     |
|    critic_loss     | 55.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1241070  |
---------------------------------
Num timesteps: 1248000
Best mean reward: 1745.38 - Last mean reward per episode: 1570.87
Num timesteps: 1250000
Best mean reward: 1745.38 - Last mean reward per episode: 1579.45
---------------------------------
| forward_vel        | 1.4      |
| reward             | 1.4      |
| reward_contact     | -0.00119 |
| reward_ctrl        | -0.996   |
| reward_position    | 0.0019   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 878      |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    episodes        | 1488     |
|    fps             | 14       |
|    time_elapsed    | 89086    |
|    total timesteps | 1250074  |
| train/             |          |
|    actor_loss      | -171     |
|    critic_loss     | 16.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 1245070  |
---------------------------------
Num timesteps: 1252000
Best mean reward: 1745.38 - Last mean reward per episode: 1584.11
Num timesteps: 1254000
Best mean reward: 1745.38 - Last mean reward per episode: 1587.61
---------------------------------
| forward_vel        | 1.42     |
| reward             | 1.44     |
| reward_contact     | -0.00108 |
| reward_ctrl        | -0.984   |
| reward_position    | 0.0019   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 878      |
|    ep_rew_mean     | 1.59e+03 |
| time/              |          |
|    episodes        | 1492     |
|    fps             | 14       |
|    time_elapsed    | 89262    |
|    total timesteps | 1254074  |
| train/             |          |
|    actor_loss      | -167     |
|    critic_loss     | 15.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 1249070  |
---------------------------------
Num timesteps: 1256000
Best mean reward: 1745.38 - Last mean reward per episode: 1585.08
Num timesteps: 1258000
Best mean reward: 1745.38 - Last mean reward per episode: 1587.96
---------------------------------
| forward_vel        | 1.44     |
| reward             | 1.45     |
| reward_contact     | -0.00114 |
| reward_ctrl        | -0.995   |
| reward_position    | 0.0019   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 878      |
|    ep_rew_mean     | 1.59e+03 |
| time/              |          |
|    episodes        | 1496     |
|    fps             | 14       |
|    time_elapsed    | 89438    |
|    total timesteps | 1258074  |
| train/             |          |
|    actor_loss      | -164     |
|    critic_loss     | 15.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1253070  |
---------------------------------
Num timesteps: 1260000
Best mean reward: 1745.38 - Last mean reward per episode: 1586.26
---------------------------------
| forward_vel        | 1.43     |
| reward             | 1.45     |
| reward_contact     | -0.00105 |
| reward_ctrl        | -0.982   |
| reward_position    | 0.0019   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 879      |
|    ep_rew_mean     | 1.59e+03 |
| time/              |          |
|    episodes        | 1500     |
|    fps             | 14       |
|    time_elapsed    | 89560    |
|    total timesteps | 1260820  |
| train/             |          |
|    actor_loss      | -172     |
|    critic_loss     | 37.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1255815  |
---------------------------------
Num timesteps: 1262000
Best mean reward: 1745.38 - Last mean reward per episode: 1585.94
Num timesteps: 1264000
Best mean reward: 1745.38 - Last mean reward per episode: 1575.10
---------------------------------
| forward_vel        | 1.42     |
| reward             | 1.46     |
| reward_contact     | -0.00103 |
| reward_ctrl        | -0.964   |
| reward_position    | 0.0019   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 876      |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    episodes        | 1504     |
|    fps             | 14       |
|    time_elapsed    | 89700    |
|    total timesteps | 1264001  |
| train/             |          |
|    actor_loss      | -170     |
|    critic_loss     | 21       |
|    learning_rate   | 0.001    |
|    n_updates       | 1259000  |
---------------------------------
Num timesteps: 1266000
Best mean reward: 1745.38 - Last mean reward per episode: 1577.81
---------------------------------
| forward_vel        | 1.41     |
| reward             | 1.42     |
| reward_contact     | -0.00101 |
| reward_ctrl        | -0.987   |
| reward_position    | 0.0019   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 875      |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    episodes        | 1508     |
|    fps             | 14       |
|    time_elapsed    | 89846    |
|    total timesteps | 1267333  |
| train/             |          |
|    actor_loss      | -171     |
|    critic_loss     | 11.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 1262330  |
---------------------------------
Num timesteps: 1268000
Best mean reward: 1745.38 - Last mean reward per episode: 1576.94
Num timesteps: 1270000
Best mean reward: 1745.38 - Last mean reward per episode: 1574.52
---------------------------------
| forward_vel        | 1.39     |
| reward             | 1.36     |
| reward_contact     | -0.00107 |
| reward_ctrl        | -1.02    |
| reward_position    | 0.0019   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 870      |
|    ep_rew_mean     | 1.57e+03 |
| time/              |          |
|    episodes        | 1512     |
|    fps             | 14       |
|    time_elapsed    | 89992    |
|    total timesteps | 1270653  |
| train/             |          |
|    actor_loss      | -170     |
|    critic_loss     | 20.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1265650  |
---------------------------------
Num timesteps: 1272000
Best mean reward: 1745.38 - Last mean reward per episode: 1574.99
Num timesteps: 1274000
Best mean reward: 1745.38 - Last mean reward per episode: 1569.79
---------------------------------
| forward_vel        | 1.36     |
| reward             | 1.33     |
| reward_contact     | -0.00108 |
| reward_ctrl        | -1.04    |
| reward_position    | 0.0019   |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    episodes        | 1516     |
|    fps             | 14       |
|    time_elapsed    | 90157    |
|    total timesteps | 1274442  |
| train/             |          |
|    actor_loss      | -169     |
|    critic_loss     | 14.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1269440  |
---------------------------------
Num timesteps: 1276000
Best mean reward: 1745.38 - Last mean reward per episode: 1564.88
----------------------------------
| forward_vel        | 1.37      |
| reward             | 1.35      |
| reward_contact     | -0.000995 |
| reward_ctrl        | -1.02     |
| reward_position    | 0.0019    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 877       |
|    ep_rew_mean     | 1.56e+03  |
| time/              |           |
|    episodes        | 1520      |
|    fps             | 14        |
|    time_elapsed    | 90306     |
|    total timesteps | 1277841   |
| train/             |           |
|    actor_loss      | -174      |
|    critic_loss     | 8.83      |
|    learning_rate   | 0.001     |
|    n_updates       | 1272840   |
----------------------------------
Num timesteps: 1278000
Best mean reward: 1745.38 - Last mean reward per episode: 1563.90
Num timesteps: 1280000
Best mean reward: 1745.38 - Last mean reward per episode: 1543.25
----------------------------------
| forward_vel        | 1.39      |
| reward             | 1.36      |
| reward_contact     | -0.000995 |
| reward_ctrl        | -1.03     |
| reward_position    | 0.0019    |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 869       |
|    ep_rew_mean     | 1.54e+03  |
| time/              |           |
|    episodes        | 1524      |
|    fps             | 14        |
|    time_elapsed    | 90442     |
|    total timesteps | 1280949   |
| train/             |           |
|    actor_loss      | -172      |
|    critic_loss     | 22        |
|    learning_rate   | 0.001     |
|    n_updates       | 1275945   |
----------------------------------
Num timesteps: 1282000
Best mean reward: 1745.38 - Last mean reward per episode: 1539.03
Num timesteps: 1284000
Best mean reward: 1745.38 - Last mean reward per episode: 1523.86
----------------------------------
| forward_vel        | 1.4       |
| reward             | 1.36      |
| reward_contact     | -0.000997 |
| reward_ctrl        | -1.04     |
| reward_position    | 0.00192   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 859       |
|    ep_rew_mean     | 1.53e+03  |
| time/              |           |
|    episodes        | 1528      |
|    fps             | 14        |
|    time_elapsed    | 90576     |
|    total timesteps | 1284008   |
| train/             |           |
|    actor_loss      | -166      |
|    critic_loss     | 8.28      |
|    learning_rate   | 0.001     |
|    n_updates       | 1279005   |
----------------------------------
Num timesteps: 1286000
Best mean reward: 1745.38 - Last mean reward per episode: 1500.91
----------------------------------
| forward_vel        | 1.39      |
| reward             | 1.33      |
| reward_contact     | -0.000902 |
| reward_ctrl        | -1.06     |
| reward_position    | 0.00196   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 860       |
|    ep_rew_mean     | 1.51e+03  |
| time/              |           |
|    episodes        | 1532      |
|    fps             | 14        |
|    time_elapsed    | 90735     |
|    total timesteps | 1287664   |
| train/             |           |
|    actor_loss      | -168      |
|    critic_loss     | 8.28      |
|    learning_rate   | 0.001     |
|    n_updates       | 1282660   |
----------------------------------
Num timesteps: 1288000
Best mean reward: 1745.38 - Last mean reward per episode: 1506.26
Num timesteps: 1290000
Best mean reward: 1745.38 - Last mean reward per episode: 1504.81
----------------------------------
| forward_vel        | 1.42      |
| reward             | 1.34      |
| reward_contact     | -0.000923 |
| reward_ctrl        | -1.07     |
| reward_position    | 0.00196   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 848       |
|    ep_rew_mean     | 1.51e+03  |
| time/              |           |
|    episodes        | 1536      |
|    fps             | 14        |
|    time_elapsed    | 90847     |
|    total timesteps | 1290227   |
| train/             |           |
|    actor_loss      | -173      |
|    critic_loss     | 15        |
|    learning_rate   | 0.001     |
|    n_updates       | 1285225   |
----------------------------------
Num timesteps: 1292000
Best mean reward: 1745.38 - Last mean reward per episode: 1505.20
----------------------------------
| forward_vel        | 1.4       |
| reward             | 1.34      |
| reward_contact     | -0.000923 |
| reward_ctrl        | -1.05     |
| reward_position    | 0.00196   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 846       |
|    ep_rew_mean     | 1.5e+03   |
| time/              |           |
|    episodes        | 1540      |
|    fps             | 14        |
|    time_elapsed    | 91011     |
|    total timesteps | 1293974   |
| train/             |           |
|    actor_loss      | -175      |
|    critic_loss     | 12.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1288970   |
----------------------------------
Num timesteps: 1294000
Best mean reward: 1745.38 - Last mean reward per episode: 1498.42
Num timesteps: 1296000
Best mean reward: 1745.38 - Last mean reward per episode: 1536.35
---------------------------------
| forward_vel        | 1.39     |
| reward             | 1.34     |
| reward_contact     | -0.00097 |
| reward_ctrl        | -1.05    |
| reward_position    | 0.00196  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 852      |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    episodes        | 1544     |
|    fps             | 14       |
|    time_elapsed    | 91184    |
|    total timesteps | 1297974  |
| train/             |          |
|    actor_loss      | -173     |
|    critic_loss     | 9.5      |
|    learning_rate   | 0.001    |
|    n_updates       | 1292970  |
---------------------------------
Num timesteps: 1298000
Best mean reward: 1745.38 - Last mean reward per episode: 1544.57
Num timesteps: 1300000
Best mean reward: 1745.38 - Last mean reward per episode: 1541.27
----------------------------------
| forward_vel        | 1.4       |
| reward             | 1.34      |
| reward_contact     | -0.000949 |
| reward_ctrl        | -1.06     |
| reward_position    | 0.000964  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 861       |
|    ep_rew_mean     | 1.55e+03  |
| time/              |           |
|    episodes        | 1548      |
|    fps             | 14        |
|    time_elapsed    | 91356     |
|    total timesteps | 1301974   |
| train/             |           |
|    actor_loss      | -174      |
|    critic_loss     | 9.52      |
|    learning_rate   | 0.001     |
|    n_updates       | 1296970   |
----------------------------------
Num timesteps: 1302000
Best mean reward: 1745.38 - Last mean reward per episode: 1553.73
----------------------------------
| forward_vel        | 1.4       |
| reward             | 1.34      |
| reward_contact     | -0.000949 |
| reward_ctrl        | -1.07     |
| reward_position    | 0.000967  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 848       |
|    ep_rew_mean     | 1.53e+03  |
| time/              |           |
|    episodes        | 1552      |
|    fps             | 14        |
|    time_elapsed    | 91442     |
|    total timesteps | 1303948   |
| train/             |           |
|    actor_loss      | -172      |
|    critic_loss     | 9.82      |
|    learning_rate   | 0.001     |
|    n_updates       | 1298945   |
----------------------------------
Num timesteps: 1304000
Best mean reward: 1745.38 - Last mean reward per episode: 1529.52
Num timesteps: 1306000
Best mean reward: 1745.38 - Last mean reward per episode: 1531.65
----------------------------------
| forward_vel        | 1.42      |
| reward             | 1.36      |
| reward_contact     | -0.000979 |
| reward_ctrl        | -1.06     |
| reward_position    | 0.000968  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 846       |
|    ep_rew_mean     | 1.53e+03  |
| time/              |           |
|    episodes        | 1556      |
|    fps             | 14        |
|    time_elapsed    | 91574     |
|    total timesteps | 1307004   |
| train/             |           |
|    actor_loss      | -174      |
|    critic_loss     | 17.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1302000   |
----------------------------------
Num timesteps: 1308000
Best mean reward: 1745.38 - Last mean reward per episode: 1533.03
Num timesteps: 1310000
Best mean reward: 1745.38 - Last mean reward per episode: 1522.20
----------------------------------
| forward_vel        | 1.41      |
| reward             | 1.35      |
| reward_contact     | -0.000929 |
| reward_ctrl        | -1.06     |
| reward_position    | 0.000968  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 846       |
|    ep_rew_mean     | 1.53e+03  |
| time/              |           |
|    episodes        | 1560      |
|    fps             | 14        |
|    time_elapsed    | 91747     |
|    total timesteps | 1311004   |
| train/             |           |
|    actor_loss      | -175      |
|    critic_loss     | 16.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1306000   |
----------------------------------
Num timesteps: 1312000
Best mean reward: 1745.38 - Last mean reward per episode: 1528.75
Num timesteps: 1314000
Best mean reward: 1745.38 - Last mean reward per episode: 1538.25
----------------------------------
| forward_vel        | 1.39      |
| reward             | 1.34      |
| reward_contact     | -0.000944 |
| reward_ctrl        | -1.05     |
| reward_position    | 0.000968  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 847       |
|    ep_rew_mean     | 1.55e+03  |
| time/              |           |
|    episodes        | 1564      |
|    fps             | 14        |
|    time_elapsed    | 91912     |
|    total timesteps | 1314847   |
| train/             |           |
|    actor_loss      | -173      |
|    critic_loss     | 17.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1309845   |
----------------------------------
Num timesteps: 1316000
Best mean reward: 1745.38 - Last mean reward per episode: 1547.20
Num timesteps: 1318000
Best mean reward: 1745.38 - Last mean reward per episode: 1551.93
----------------------------------
| forward_vel        | 1.42      |
| reward             | 1.39      |
| reward_contact     | -0.000887 |
| reward_ctrl        | -1.03     |
| reward_position    | 0.000968  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 841       |
|    ep_rew_mean     | 1.54e+03  |
| time/              |           |
|    episodes        | 1568      |
|    fps             | 14        |
|    time_elapsed    | 92058     |
|    total timesteps | 1318233   |
| train/             |           |
|    actor_loss      | -177      |
|    critic_loss     | 25.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1313230   |
----------------------------------
Num timesteps: 1320000
Best mean reward: 1745.38 - Last mean reward per episode: 1545.31
----------------------------------
| forward_vel        | 1.41      |
| reward             | 1.4       |
| reward_contact     | -0.000857 |
| reward_ctrl        | -1.01     |
| reward_position    | 0.000968  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 841       |
|    ep_rew_mean     | 1.55e+03  |
| time/              |           |
|    episodes        | 1572      |
|    fps             | 14        |
|    time_elapsed    | 92222     |
|    total timesteps | 1321422   |
| train/             |           |
|    actor_loss      | -175      |
|    critic_loss     | 9.3       |
|    learning_rate   | 0.001     |
|    n_updates       | 1316420   |
----------------------------------
Num timesteps: 1322000
Best mean reward: 1745.38 - Last mean reward per episode: 1545.82
Num timesteps: 1324000
Best mean reward: 1745.38 - Last mean reward per episode: 1558.72
----------------------------------
| forward_vel        | 1.38      |
| reward             | 1.38      |
| reward_contact     | -0.000814 |
| reward_ctrl        | -1        |
| reward_position    | 6.7e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 853       |
|    ep_rew_mean     | 1.55e+03  |
| time/              |           |
|    episodes        | 1576      |
|    fps             | 14        |
|    time_elapsed    | 92503     |
|    total timesteps | 1324981   |
| train/             |           |
|    actor_loss      | -172      |
|    critic_loss     | 15.7      |
|    learning_rate   | 0.001     |
|    n_updates       | 1319980   |
----------------------------------
Num timesteps: 1326000
Best mean reward: 1745.38 - Last mean reward per episode: 1551.74
Num timesteps: 1328000
Best mean reward: 1745.38 - Last mean reward per episode: 1580.88
----------------------------------
| forward_vel        | 1.34      |
| reward             | 1.36      |
| reward_contact     | -0.000819 |
| reward_ctrl        | -0.98     |
| reward_position    | 6.7e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 869       |
|    ep_rew_mean     | 1.58e+03  |
| time/              |           |
|    episodes        | 1580      |
|    fps             | 14        |
|    time_elapsed    | 92776     |
|    total timesteps | 1328981   |
| train/             |           |
|    actor_loss      | -169      |
|    critic_loss     | 17        |
|    learning_rate   | 0.001     |
|    n_updates       | 1323980   |
----------------------------------
Num timesteps: 1330000
Best mean reward: 1745.38 - Last mean reward per episode: 1582.59
Num timesteps: 1332000
Best mean reward: 1745.38 - Last mean reward per episode: 1577.30
----------------------------------
| forward_vel        | 1.32      |
| reward             | 1.34      |
| reward_contact     | -0.000816 |
| reward_ctrl        | -0.983    |
| reward_position    | 6.7e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 869       |
|    ep_rew_mean     | 1.57e+03  |
| time/              |           |
|    episodes        | 1584      |
|    fps             | 14        |
|    time_elapsed    | 93040     |
|    total timesteps | 1332981   |
| train/             |           |
|    actor_loss      | -175      |
|    critic_loss     | 48.7      |
|    learning_rate   | 0.001     |
|    n_updates       | 1327980   |
----------------------------------
Num timesteps: 1334000
Best mean reward: 1745.38 - Last mean reward per episode: 1575.50
Num timesteps: 1336000
Best mean reward: 1745.38 - Last mean reward per episode: 1557.48
----------------------------------
| forward_vel        | 1.32      |
| reward             | 1.32      |
| reward_contact     | -0.000845 |
| reward_ctrl        | -0.993    |
| reward_position    | 6.7e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 869       |
|    ep_rew_mean     | 1.56e+03  |
| time/              |           |
|    episodes        | 1588      |
|    fps             | 14        |
|    time_elapsed    | 93337     |
|    total timesteps | 1336981   |
| train/             |           |
|    actor_loss      | -169      |
|    critic_loss     | 21.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 1331980   |
----------------------------------
Num timesteps: 1338000
Best mean reward: 1745.38 - Last mean reward per episode: 1556.04
Num timesteps: 1340000
Best mean reward: 1745.38 - Last mean reward per episode: 1548.83
----------------------------------
| forward_vel        | 1.34      |
| reward             | 1.33      |
| reward_contact     | -0.000887 |
| reward_ctrl        | -1        |
| reward_position    | 6.7e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 865       |
|    ep_rew_mean     | 1.55e+03  |
| time/              |           |
|    episodes        | 1592      |
|    fps             | 14        |
|    time_elapsed    | 93591     |
|    total timesteps | 1340554   |
| train/             |           |
|    actor_loss      | -174      |
|    critic_loss     | 10.7      |
|    learning_rate   | 0.001     |
|    n_updates       | 1335550   |
----------------------------------
Num timesteps: 1342000
Best mean reward: 1745.38 - Last mean reward per episode: 1553.58
Num timesteps: 1344000
Best mean reward: 1745.38 - Last mean reward per episode: 1553.26
---------------------------------
| forward_vel        | 1.33     |
| reward             | 1.32     |
| reward_contact     | -0.00085 |
| reward_ctrl        | -1       |
| reward_position    | 6.7e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 865      |
|    ep_rew_mean     | 1.56e+03 |
| time/              |          |
|    episodes        | 1596     |
|    fps             | 14       |
|    time_elapsed    | 93881    |
|    total timesteps | 1344554  |
| train/             |          |
|    actor_loss      | -174     |
|    critic_loss     | 9.62     |
|    learning_rate   | 0.001    |
|    n_updates       | 1339550  |
---------------------------------
Num timesteps: 1346000
Best mean reward: 1745.38 - Last mean reward per episode: 1568.06
Num timesteps: 1348000
Best mean reward: 1745.38 - Last mean reward per episode: 1581.08
---------------------------------
| forward_vel        | 1.33     |
| reward             | 1.35     |
| reward_contact     | -0.00085 |
| reward_ctrl        | -0.984   |
| reward_position    | 6.7e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    episodes        | 1600     |
|    fps             | 14       |
|    time_elapsed    | 94194    |
|    total timesteps | 1348554  |
| train/             |          |
|    actor_loss      | -176     |
|    critic_loss     | 7.12     |
|    learning_rate   | 0.001    |
|    n_updates       | 1343550  |
---------------------------------
Num timesteps: 1350000
Best mean reward: 1745.38 - Last mean reward per episode: 1575.88
Num timesteps: 1352000
Best mean reward: 1745.38 - Last mean reward per episode: 1596.75
----------------------------------
| forward_vel        | 1.33      |
| reward             | 1.35      |
| reward_contact     | -0.000843 |
| reward_ctrl        | -0.983    |
| reward_position    | 6.7e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 880       |
|    ep_rew_mean     | 1.6e+03   |
| time/              |           |
|    episodes        | 1604      |
|    fps             | 14        |
|    time_elapsed    | 94438     |
|    total timesteps | 1352024   |
| train/             |           |
|    actor_loss      | -173      |
|    critic_loss     | 14.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1347020   |
----------------------------------
Num timesteps: 1354000
Best mean reward: 1745.38 - Last mean reward per episode: 1605.97
Num timesteps: 1356000
Best mean reward: 1745.38 - Last mean reward per episode: 1611.04
----------------------------------
| forward_vel        | 1.36      |
| reward             | 1.39      |
| reward_contact     | -0.000849 |
| reward_ctrl        | -0.971    |
| reward_position    | 6.7e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 887       |
|    ep_rew_mean     | 1.61e+03  |
| time/              |           |
|    episodes        | 1608      |
|    fps             | 14        |
|    time_elapsed    | 94726     |
|    total timesteps | 1356024   |
| train/             |           |
|    actor_loss      | -171      |
|    critic_loss     | 16.5      |
|    learning_rate   | 0.001     |
|    n_updates       | 1351020   |
----------------------------------
Num timesteps: 1358000
Best mean reward: 1745.38 - Last mean reward per episode: 1609.67
----------------------------------
| forward_vel        | 1.36      |
| reward             | 1.41      |
| reward_contact     | -0.000808 |
| reward_ctrl        | -0.956    |
| reward_position    | 6.7e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 882       |
|    ep_rew_mean     | 1.6e+03   |
| time/              |           |
|    episodes        | 1612      |
|    fps             | 14        |
|    time_elapsed    | 94947     |
|    total timesteps | 1358826   |
| train/             |           |
|    actor_loss      | -164      |
|    critic_loss     | 17.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 1353825   |
----------------------------------
Num timesteps: 1360000
Best mean reward: 1745.38 - Last mean reward per episode: 1600.09
----------------------------------
| forward_vel        | 1.41      |
| reward             | 1.44      |
| reward_contact     | -0.000778 |
| reward_ctrl        | -0.966    |
| reward_position    | 6.7e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 874       |
|    ep_rew_mean     | 1.59e+03  |
| time/              |           |
|    episodes        | 1616      |
|    fps             | 14        |
|    time_elapsed    | 95164     |
|    total timesteps | 1361841   |
| train/             |           |
|    actor_loss      | -181      |
|    critic_loss     | 38.2      |
|    learning_rate   | 0.001     |
|    n_updates       | 1356840   |
----------------------------------
Num timesteps: 1362000
Best mean reward: 1745.38 - Last mean reward per episode: 1588.75
Num timesteps: 1364000
Best mean reward: 1745.38 - Last mean reward per episode: 1624.44
---------------------------------
| forward_vel        | 1.44     |
| reward             | 1.47     |
| reward_contact     | -0.0008  |
| reward_ctrl        | -0.974   |
| reward_position    | 6.7e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 880      |
|    ep_rew_mean     | 1.63e+03 |
| time/              |          |
|    episodes        | 1620     |
|    fps             | 14       |
|    time_elapsed    | 95446    |
|    total timesteps | 1365841  |
| train/             |          |
|    actor_loss      | -168     |
|    critic_loss     | 15.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1360840  |
---------------------------------
Num timesteps: 1366000
Best mean reward: 1745.38 - Last mean reward per episode: 1629.70
Num timesteps: 1368000
Best mean reward: 1745.38 - Last mean reward per episode: 1638.63
----------------------------------
| forward_vel        | 1.43      |
| reward             | 1.44      |
| reward_contact     | -0.000857 |
| reward_ctrl        | -0.984    |
| reward_position    | 6.7e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 885       |
|    ep_rew_mean     | 1.65e+03  |
| time/              |           |
|    episodes        | 1624      |
|    fps             | 14        |
|    time_elapsed    | 95725     |
|    total timesteps | 1369453   |
| train/             |           |
|    actor_loss      | -177      |
|    critic_loss     | 20.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 1364450   |
----------------------------------
Num timesteps: 1370000
Best mean reward: 1745.38 - Last mean reward per episode: 1645.16
Num timesteps: 1372000
Best mean reward: 1745.38 - Last mean reward per episode: 1653.90
----------------------------------
| forward_vel        | 1.41      |
| reward             | 1.43      |
| reward_contact     | -0.000864 |
| reward_ctrl        | -0.982    |
| reward_position    | 5.01e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 893       |
|    ep_rew_mean     | 1.65e+03  |
| time/              |           |
|    episodes        | 1628      |
|    fps             | 14        |
|    time_elapsed    | 96003     |
|    total timesteps | 1373276   |
| train/             |           |
|    actor_loss      | -175      |
|    critic_loss     | 47.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 1368275   |
----------------------------------
Num timesteps: 1374000
Best mean reward: 1745.38 - Last mean reward per episode: 1662.73
Num timesteps: 1376000
Best mean reward: 1745.38 - Last mean reward per episode: 1665.52
----------------------------------
| forward_vel        | 1.47      |
| reward             | 1.5       |
| reward_contact     | -0.000842 |
| reward_ctrl        | -0.967    |
| reward_position    | 4.21e-06  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 891       |
|    ep_rew_mean     | 1.65e+03  |
| time/              |           |
|    episodes        | 1632      |
|    fps             | 14        |
|    time_elapsed    | 96250     |
|    total timesteps | 1376745   |
| train/             |           |
|    actor_loss      | -173      |
|    critic_loss     | 13.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1371740   |
----------------------------------
Num timesteps: 1378000
Best mean reward: 1745.38 - Last mean reward per episode: 1643.70
Num timesteps: 1380000
Best mean reward: 1745.38 - Last mean reward per episode: 1666.75
---------------------------------
| forward_vel        | 1.44     |
| reward             | 1.48     |
| reward_contact     | -0.00085 |
| reward_ctrl        | -0.96    |
| reward_position    | 4.21e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 900      |
|    ep_rew_mean     | 1.67e+03 |
| time/              |          |
|    episodes        | 1636     |
|    fps             | 14       |
|    time_elapsed    | 96528    |
|    total timesteps | 1380184  |
| train/             |          |
|    actor_loss      | -176     |
|    critic_loss     | 17.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1375180  |
---------------------------------
Num timesteps: 1382000
Best mean reward: 1745.38 - Last mean reward per episode: 1653.73
Num timesteps: 1384000
Best mean reward: 1745.38 - Last mean reward per episode: 1658.07
----------------------------------
| forward_vel        | 1.44      |
| reward             | 1.46      |
| reward_contact     | -0.000886 |
| reward_ctrl        | -0.976    |
| reward_position    | 4.21e-06  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 902       |
|    ep_rew_mean     | 1.66e+03  |
| time/              |           |
|    episodes        | 1640      |
|    fps             | 14        |
|    time_elapsed    | 96829     |
|    total timesteps | 1384184   |
| train/             |           |
|    actor_loss      | -178      |
|    critic_loss     | 58.2      |
|    learning_rate   | 0.001     |
|    n_updates       | 1379180   |
----------------------------------
Num timesteps: 1386000
Best mean reward: 1745.38 - Last mean reward per episode: 1655.61
----------------------------------
| forward_vel        | 1.44      |
| reward             | 1.48      |
| reward_contact     | -0.000829 |
| reward_ctrl        | -0.964    |
| reward_position    | 4.21e-06  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 898       |
|    ep_rew_mean     | 1.65e+03  |
| time/              |           |
|    episodes        | 1644      |
|    fps             | 14        |
|    time_elapsed    | 97104     |
|    total timesteps | 1387770   |
| train/             |           |
|    actor_loss      | -174      |
|    critic_loss     | 29.3      |
|    learning_rate   | 0.001     |
|    n_updates       | 1382765   |
----------------------------------
Num timesteps: 1388000
Best mean reward: 1745.38 - Last mean reward per episode: 1650.49
Num timesteps: 1390000
Best mean reward: 1745.38 - Last mean reward per episode: 1647.56
----------------------------------
| forward_vel        | 1.41      |
| reward             | 1.44      |
| reward_contact     | -0.000821 |
| reward_ctrl        | -0.973    |
| reward_position    | 4.21e-06  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 893       |
|    ep_rew_mean     | 1.65e+03  |
| time/              |           |
|    episodes        | 1648      |
|    fps             | 14        |
|    time_elapsed    | 97384     |
|    total timesteps | 1391258   |
| train/             |           |
|    actor_loss      | -171      |
|    critic_loss     | 12.9      |
|    learning_rate   | 0.001     |
|    n_updates       | 1386255   |
----------------------------------
Num timesteps: 1392000
Best mean reward: 1745.38 - Last mean reward per episode: 1634.91
Num timesteps: 1394000
Best mean reward: 1745.38 - Last mean reward per episode: 1673.00
----------------------------------
| forward_vel        | 1.42      |
| reward             | 1.45      |
| reward_contact     | -0.000821 |
| reward_ctrl        | -0.963    |
| reward_position    | 1.66e-06  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 903       |
|    ep_rew_mean     | 1.67e+03  |
| time/              |           |
|    episodes        | 1652      |
|    fps             | 14        |
|    time_elapsed    | 97595     |
|    total timesteps | 1394216   |
| train/             |           |
|    actor_loss      | -179      |
|    critic_loss     | 15.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 1389215   |
----------------------------------
Num timesteps: 1396000
Best mean reward: 1745.38 - Last mean reward per episode: 1672.59
----------------------------------
| forward_vel        | 1.42      |
| reward             | 1.48      |
| reward_contact     | -0.000763 |
| reward_ctrl        | -0.931    |
| reward_position    | 3.76e-16  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 903       |
|    ep_rew_mean     | 1.68e+03  |
| time/              |           |
|    episodes        | 1656      |
|    fps             | 14        |
|    time_elapsed    | 97847     |
|    total timesteps | 1397315   |
| train/             |           |
|    actor_loss      | -178      |
|    critic_loss     | 8.83      |
|    learning_rate   | 0.001     |
|    n_updates       | 1392310   |
----------------------------------
Num timesteps: 1398000
Best mean reward: 1745.38 - Last mean reward per episode: 1681.36
Num timesteps: 1400000
Best mean reward: 1745.38 - Last mean reward per episode: 1694.09
----------------------------------
| forward_vel        | 1.4       |
| reward             | 1.46      |
| reward_contact     | -0.000854 |
| reward_ctrl        | -0.944    |
| reward_position    | 5.18e-16  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 903       |
|    ep_rew_mean     | 1.66e+03  |
| time/              |           |
|    episodes        | 1660      |
|    fps             | 14        |
|    time_elapsed    | 98146     |
|    total timesteps | 1401315   |
| train/             |           |
|    actor_loss      | -174      |
|    critic_loss     | 7.39      |
|    learning_rate   | 0.001     |
|    n_updates       | 1396310   |
----------------------------------
Num timesteps: 1402000
Best mean reward: 1745.38 - Last mean reward per episode: 1659.04
Num timesteps: 1404000
Best mean reward: 1745.38 - Last mean reward per episode: 1646.24
----------------------------------
| forward_vel        | 1.4       |
| reward             | 1.42      |
| reward_contact     | -0.000837 |
| reward_ctrl        | -0.982    |
| reward_position    | 5.18e-16  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 898       |
|    ep_rew_mean     | 1.64e+03  |
| time/              |           |
|    episodes        | 1664      |
|    fps             | 14        |
|    time_elapsed    | 98394     |
|    total timesteps | 1404644   |
| train/             |           |
|    actor_loss      | -183      |
|    critic_loss     | 8.53      |
|    learning_rate   | 0.001     |
|    n_updates       | 1399640   |
----------------------------------
Num timesteps: 1406000
Best mean reward: 1745.38 - Last mean reward per episode: 1637.27
----------------------------------
| forward_vel        | 1.4       |
| reward             | 1.4       |
| reward_contact     | -0.000876 |
| reward_ctrl        | -0.996    |
| reward_position    | 5.18e-16  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 890       |
|    ep_rew_mean     | 1.63e+03  |
| time/              |           |
|    episodes        | 1668      |
|    fps             | 14        |
|    time_elapsed    | 98605     |
|    total timesteps | 1407252   |
| train/             |           |
|    actor_loss      | -179      |
|    critic_loss     | 11.7      |
|    learning_rate   | 0.001     |
|    n_updates       | 1402250   |
----------------------------------
Num timesteps: 1408000
Best mean reward: 1745.38 - Last mean reward per episode: 1623.32
Num timesteps: 1410000
Best mean reward: 1745.38 - Last mean reward per episode: 1626.81
----------------------------------
| forward_vel        | 1.4       |
| reward             | 1.41      |
| reward_contact     | -0.000881 |
| reward_ctrl        | -0.992    |
| reward_position    | 9.76e-09  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 893       |
|    ep_rew_mean     | 1.64e+03  |
| time/              |           |
|    episodes        | 1672      |
|    fps             | 14        |
|    time_elapsed    | 98861     |
|    total timesteps | 1410686   |
| train/             |           |
|    actor_loss      | -184      |
|    critic_loss     | 15.9      |
|    learning_rate   | 0.001     |
|    n_updates       | 1405685   |
----------------------------------
Num timesteps: 1412000
Best mean reward: 1745.38 - Last mean reward per episode: 1651.50
Num timesteps: 1414000
Best mean reward: 1745.38 - Last mean reward per episode: 1661.22
----------------------------------
| forward_vel        | 1.43      |
| reward             | 1.46      |
| reward_contact     | -0.000851 |
| reward_ctrl        | -0.961    |
| reward_position    | 9.76e-09  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 897       |
|    ep_rew_mean     | 1.67e+03  |
| time/              |           |
|    episodes        | 1676      |
|    fps             | 14        |
|    time_elapsed    | 99175     |
|    total timesteps | 1414686   |
| train/             |           |
|    actor_loss      | -178      |
|    critic_loss     | 11.5      |
|    learning_rate   | 0.001     |
|    n_updates       | 1409685   |
----------------------------------
Num timesteps: 1416000
Best mean reward: 1745.38 - Last mean reward per episode: 1672.84
----------------------------------
| forward_vel        | 1.45      |
| reward             | 1.46      |
| reward_contact     | -0.000853 |
| reward_ctrl        | -0.993    |
| reward_position    | 9.76e-09  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 885       |
|    ep_rew_mean     | 1.65e+03  |
| time/              |           |
|    episodes        | 1680      |
|    fps             | 14        |
|    time_elapsed    | 99386     |
|    total timesteps | 1417463   |
| train/             |           |
|    actor_loss      | -181      |
|    critic_loss     | 8.62      |
|    learning_rate   | 0.001     |
|    n_updates       | 1412460   |
----------------------------------
Num timesteps: 1418000
Best mean reward: 1745.38 - Last mean reward per episode: 1654.97
Num timesteps: 1420000
Best mean reward: 1745.38 - Last mean reward per episode: 1659.98
----------------------------------
| forward_vel        | 1.46      |
| reward             | 1.46      |
| reward_contact     | -0.000887 |
| reward_ctrl        | -0.994    |
| reward_position    | 9.76e-09  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 885       |
|    ep_rew_mean     | 1.67e+03  |
| time/              |           |
|    episodes        | 1684      |
|    fps             | 14        |
|    time_elapsed    | 99684     |
|    total timesteps | 1421463   |
| train/             |           |
|    actor_loss      | -181      |
|    critic_loss     | 18.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 1416460   |
----------------------------------
Num timesteps: 1422000
Best mean reward: 1745.38 - Last mean reward per episode: 1665.09
Num timesteps: 1424000
Best mean reward: 1745.38 - Last mean reward per episode: 1648.01
----------------------------------
| forward_vel        | 1.43      |
| reward             | 1.45      |
| reward_contact     | -0.000827 |
| reward_ctrl        | -0.978    |
| reward_position    | 9.76e-09  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 885       |
|    ep_rew_mean     | 1.66e+03  |
| time/              |           |
|    episodes        | 1688      |
|    fps             | 14        |
|    time_elapsed    | 100000    |
|    total timesteps | 1425463   |
| train/             |           |
|    actor_loss      | -180      |
|    critic_loss     | 11.2      |
|    learning_rate   | 0.001     |
|    n_updates       | 1420460   |
----------------------------------
Num timesteps: 1426000
Best mean reward: 1745.38 - Last mean reward per episode: 1664.52
----------------------------------
| forward_vel        | 1.43      |
| reward             | 1.46      |
| reward_contact     | -0.000786 |
| reward_ctrl        | -0.976    |
| reward_position    | 9.76e-09  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 872       |
|    ep_rew_mean     | 1.64e+03  |
| time/              |           |
|    episodes        | 1692      |
|    fps             | 14        |
|    time_elapsed    | 100169    |
|    total timesteps | 1427792   |
| train/             |           |
|    actor_loss      | -183      |
|    critic_loss     | 40.9      |
|    learning_rate   | 0.001     |
|    n_updates       | 1422790   |
----------------------------------
Num timesteps: 1428000
Best mean reward: 1745.38 - Last mean reward per episode: 1643.45
Num timesteps: 1430000
Best mean reward: 1745.38 - Last mean reward per episode: 1625.04
----------------------------------
| forward_vel        | 1.43      |
| reward             | 1.46      |
| reward_contact     | -0.000794 |
| reward_ctrl        | -0.965    |
| reward_position    | 9.76e-09  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 872       |
|    ep_rew_mean     | 1.62e+03  |
| time/              |           |
|    episodes        | 1696      |
|    fps             | 14        |
|    time_elapsed    | 100478    |
|    total timesteps | 1431792   |
| train/             |           |
|    actor_loss      | -181      |
|    critic_loss     | 9.94      |
|    learning_rate   | 0.001     |
|    n_updates       | 1426790   |
----------------------------------
Num timesteps: 1432000
Best mean reward: 1745.38 - Last mean reward per episode: 1622.05
Num timesteps: 1434000
Best mean reward: 1745.38 - Last mean reward per episode: 1620.43
----------------------------------
| forward_vel        | 1.43      |
| reward             | 1.46      |
| reward_contact     | -0.000854 |
| reward_ctrl        | -0.968    |
| reward_position    | 9.76e-09  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 872       |
|    ep_rew_mean     | 1.62e+03  |
| time/              |           |
|    episodes        | 1700      |
|    fps             | 14        |
|    time_elapsed    | 100800    |
|    total timesteps | 1435792   |
| train/             |           |
|    actor_loss      | -180      |
|    critic_loss     | 15.2      |
|    learning_rate   | 0.001     |
|    n_updates       | 1430790   |
----------------------------------
Num timesteps: 1436000
Best mean reward: 1745.38 - Last mean reward per episode: 1611.25
----------------------------------
| forward_vel        | 1.43      |
| reward             | 1.44      |
| reward_contact     | -0.000833 |
| reward_ctrl        | -0.995    |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 859       |
|    ep_rew_mean     | 1.58e+03  |
| time/              |           |
|    episodes        | 1704      |
|    fps             | 14        |
|    time_elapsed    | 100954    |
|    total timesteps | 1437948   |
| train/             |           |
|    actor_loss      | -179      |
|    critic_loss     | 13.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1432945   |
----------------------------------
Num timesteps: 1438000
Best mean reward: 1745.38 - Last mean reward per episode: 1576.68
Num timesteps: 1440000
Best mean reward: 1745.38 - Last mean reward per episode: 1556.72
----------------------------------
| forward_vel        | 1.39      |
| reward             | 1.35      |
| reward_contact     | -0.000841 |
| reward_ctrl        | -1.04     |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 854       |
|    ep_rew_mean     | 1.52e+03  |
| time/              |           |
|    episodes        | 1708      |
|    fps             | 14        |
|    time_elapsed    | 101239    |
|    total timesteps | 1441418   |
| train/             |           |
|    actor_loss      | -181      |
|    critic_loss     | 21.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 1436415   |
----------------------------------
Num timesteps: 1442000
Best mean reward: 1745.38 - Last mean reward per episode: 1523.08
Num timesteps: 1444000
Best mean reward: 1745.38 - Last mean reward per episode: 1526.33
----------------------------------
| forward_vel        | 1.43      |
| reward             | 1.39      |
| reward_contact     | -0.000838 |
| reward_ctrl        | -1.03     |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 860       |
|    ep_rew_mean     | 1.53e+03  |
| time/              |           |
|    episodes        | 1712      |
|    fps             | 14        |
|    time_elapsed    | 101498    |
|    total timesteps | 1444873   |
| train/             |           |
|    actor_loss      | -184      |
|    critic_loss     | 29.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 1439870   |
----------------------------------
Num timesteps: 1446000
Best mean reward: 1745.38 - Last mean reward per episode: 1517.45
Num timesteps: 1448000
Best mean reward: 1745.38 - Last mean reward per episode: 1525.53
----------------------------------
| forward_vel        | 1.38      |
| reward             | 1.35      |
| reward_contact     | -0.000847 |
| reward_ctrl        | -1.03     |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 864       |
|    ep_rew_mean     | 1.53e+03  |
| time/              |           |
|    episodes        | 1716      |
|    fps             | 14        |
|    time_elapsed    | 101756    |
|    total timesteps | 1448199   |
| train/             |           |
|    actor_loss      | -185      |
|    critic_loss     | 24.2      |
|    learning_rate   | 0.001     |
|    n_updates       | 1443195   |
----------------------------------
Num timesteps: 1450000
Best mean reward: 1745.38 - Last mean reward per episode: 1493.34
----------------------------------
| forward_vel        | 1.37      |
| reward             | 1.35      |
| reward_contact     | -0.000819 |
| reward_ctrl        | -1.02     |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 844       |
|    ep_rew_mean     | 1.48e+03  |
| time/              |           |
|    episodes        | 1720      |
|    fps             | 14        |
|    time_elapsed    | 101919    |
|    total timesteps | 1450250   |
| train/             |           |
|    actor_loss      | -182      |
|    critic_loss     | 11.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1445245   |
----------------------------------
Num timesteps: 1452000
Best mean reward: 1745.38 - Last mean reward per episode: 1488.71
Num timesteps: 1454000
Best mean reward: 1745.38 - Last mean reward per episode: 1482.69
----------------------------------
| forward_vel        | 1.33      |
| reward             | 1.3       |
| reward_contact     | -0.000864 |
| reward_ctrl        | -1.03     |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 848       |
|    ep_rew_mean     | 1.48e+03  |
| time/              |           |
|    episodes        | 1724      |
|    fps             | 14        |
|    time_elapsed    | 102228    |
|    total timesteps | 1454250   |
| train/             |           |
|    actor_loss      | -179      |
|    critic_loss     | 24.7      |
|    learning_rate   | 0.001     |
|    n_updates       | 1449245   |
----------------------------------
Num timesteps: 1456000
Best mean reward: 1745.38 - Last mean reward per episode: 1492.99
Num timesteps: 1458000
Best mean reward: 1745.38 - Last mean reward per episode: 1488.00
----------------------------------
| forward_vel        | 1.35      |
| reward             | 1.32      |
| reward_contact     | -0.000807 |
| reward_ctrl        | -1.02     |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 850       |
|    ep_rew_mean     | 1.49e+03  |
| time/              |           |
|    episodes        | 1728      |
|    fps             | 14        |
|    time_elapsed    | 102550    |
|    total timesteps | 1458250   |
| train/             |           |
|    actor_loss      | -183      |
|    critic_loss     | 13.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 1453245   |
----------------------------------
Num timesteps: 1460000
Best mean reward: 1745.38 - Last mean reward per episode: 1499.22
Num timesteps: 1462000
Best mean reward: 1745.38 - Last mean reward per episode: 1506.60
---------------------------------
| forward_vel        | 1.34     |
| reward             | 1.32     |
| reward_contact     | -0.00084 |
| reward_ctrl        | -1.02    |
| reward_position    | 2.53e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 855      |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1732     |
|    fps             | 14       |
|    time_elapsed    | 102828   |
|    total timesteps | 1462250  |
| train/             |          |
|    actor_loss      | -182     |
|    critic_loss     | 18.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1457245  |
---------------------------------
Num timesteps: 1464000
Best mean reward: 1745.38 - Last mean reward per episode: 1534.05
Num timesteps: 1466000
Best mean reward: 1745.38 - Last mean reward per episode: 1522.21
----------------------------------
| forward_vel        | 1.35      |
| reward             | 1.35      |
| reward_contact     | -0.000859 |
| reward_ctrl        | -0.994    |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 861       |
|    ep_rew_mean     | 1.53e+03  |
| time/              |           |
|    episodes        | 1736      |
|    fps             | 14        |
|    time_elapsed    | 103109    |
|    total timesteps | 1466250   |
| train/             |           |
|    actor_loss      | -186      |
|    critic_loss     | 15.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 1461245   |
----------------------------------
Num timesteps: 1468000
Best mean reward: 1745.38 - Last mean reward per episode: 1547.61
----------------------------------
| forward_vel        | 1.38      |
| reward             | 1.38      |
| reward_contact     | -0.000847 |
| reward_ctrl        | -0.99     |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 856       |
|    ep_rew_mean     | 1.54e+03  |
| time/              |           |
|    episodes        | 1740      |
|    fps             | 14        |
|    time_elapsed    | 103358    |
|    total timesteps | 1469802   |
| train/             |           |
|    actor_loss      | -173      |
|    critic_loss     | 44.5      |
|    learning_rate   | 0.001     |
|    n_updates       | 1464800   |
----------------------------------
Num timesteps: 1470000
Best mean reward: 1745.38 - Last mean reward per episode: 1540.51
Num timesteps: 1472000
Best mean reward: 1745.38 - Last mean reward per episode: 1524.91
----------------------------------
| forward_vel        | 1.4       |
| reward             | 1.42      |
| reward_contact     | -0.000875 |
| reward_ctrl        | -0.985    |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 851       |
|    ep_rew_mean     | 1.53e+03  |
| time/              |           |
|    episodes        | 1744      |
|    fps             | 14        |
|    time_elapsed    | 103576    |
|    total timesteps | 1472886   |
| train/             |           |
|    actor_loss      | -178      |
|    critic_loss     | 8.87      |
|    learning_rate   | 0.001     |
|    n_updates       | 1467885   |
----------------------------------
Num timesteps: 1474000
Best mean reward: 1745.38 - Last mean reward per episode: 1526.14
Num timesteps: 1476000
Best mean reward: 1745.38 - Last mean reward per episode: 1522.76
----------------------------------
| forward_vel        | 1.4       |
| reward             | 1.41      |
| reward_contact     | -0.000902 |
| reward_ctrl        | -0.989    |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 852       |
|    ep_rew_mean     | 1.52e+03  |
| time/              |           |
|    episodes        | 1748      |
|    fps             | 14        |
|    time_elapsed    | 103828    |
|    total timesteps | 1476409   |
| train/             |           |
|    actor_loss      | -180      |
|    critic_loss     | 11.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 1471405   |
----------------------------------
Num timesteps: 1478000
Best mean reward: 1745.38 - Last mean reward per episode: 1537.51
Num timesteps: 1480000
Best mean reward: 1745.38 - Last mean reward per episode: 1537.26
----------------------------------
| forward_vel        | 1.44      |
| reward             | 1.44      |
| reward_contact     | -0.000962 |
| reward_ctrl        | -1        |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 862       |
|    ep_rew_mean     | 1.54e+03  |
| time/              |           |
|    episodes        | 1752      |
|    fps             | 14        |
|    time_elapsed    | 104115    |
|    total timesteps | 1480409   |
| train/             |           |
|    actor_loss      | -177      |
|    critic_loss     | 12        |
|    learning_rate   | 0.001     |
|    n_updates       | 1475405   |
----------------------------------
Num timesteps: 1482000
Best mean reward: 1745.38 - Last mean reward per episode: 1540.18
----------------------------------
| forward_vel        | 1.43      |
| reward             | 1.41      |
| reward_contact     | -0.000962 |
| reward_ctrl        | -1.02     |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 858       |
|    ep_rew_mean     | 1.52e+03  |
| time/              |           |
|    episodes        | 1756      |
|    fps             | 14        |
|    time_elapsed    | 104311    |
|    total timesteps | 1483155   |
| train/             |           |
|    actor_loss      | -176      |
|    critic_loss     | 11.5      |
|    learning_rate   | 0.001     |
|    n_updates       | 1478150   |
----------------------------------
Num timesteps: 1484000
Best mean reward: 1745.38 - Last mean reward per episode: 1522.93
Num timesteps: 1486000
Best mean reward: 1745.38 - Last mean reward per episode: 1544.85
----------------------------------
| forward_vel        | 1.44      |
| reward             | 1.43      |
| reward_contact     | -0.000887 |
| reward_ctrl        | -1.01     |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 853       |
|    ep_rew_mean     | 1.55e+03  |
| time/              |           |
|    episodes        | 1760      |
|    fps             | 14        |
|    time_elapsed    | 104555    |
|    total timesteps | 1486608   |
| train/             |           |
|    actor_loss      | -176      |
|    critic_loss     | 12.9      |
|    learning_rate   | 0.001     |
|    n_updates       | 1481605   |
----------------------------------
Num timesteps: 1488000
Best mean reward: 1745.38 - Last mean reward per episode: 1557.58
Num timesteps: 1490000
Best mean reward: 1745.38 - Last mean reward per episode: 1555.40
----------------------------------
| forward_vel        | 1.44      |
| reward             | 1.45      |
| reward_contact     | -0.000928 |
| reward_ctrl        | -0.991    |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 860       |
|    ep_rew_mean     | 1.56e+03  |
| time/              |           |
|    episodes        | 1764      |
|    fps             | 14        |
|    time_elapsed    | 104840    |
|    total timesteps | 1490608   |
| train/             |           |
|    actor_loss      | -185      |
|    critic_loss     | 21        |
|    learning_rate   | 0.001     |
|    n_updates       | 1485605   |
----------------------------------
Num timesteps: 1492000
Best mean reward: 1745.38 - Last mean reward per episode: 1574.28
Num timesteps: 1494000
Best mean reward: 1745.38 - Last mean reward per episode: 1571.92
----------------------------------
| forward_vel        | 1.44      |
| reward             | 1.46      |
| reward_contact     | -0.000888 |
| reward_ctrl        | -0.984    |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 873       |
|    ep_rew_mean     | 1.59e+03  |
| time/              |           |
|    episodes        | 1768      |
|    fps             | 14        |
|    time_elapsed    | 105117    |
|    total timesteps | 1494529   |
| train/             |           |
|    actor_loss      | -181      |
|    critic_loss     | 33.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 1489525   |
----------------------------------
Num timesteps: 1496000
Best mean reward: 1745.38 - Last mean reward per episode: 1599.86
Num timesteps: 1498000
Best mean reward: 1745.38 - Last mean reward per episode: 1570.03
----------------------------------
| forward_vel        | 1.45      |
| reward             | 1.43      |
| reward_contact     | -0.000865 |
| reward_ctrl        | -1.02     |
| reward_position    | 2.53e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 877       |
|    ep_rew_mean     | 1.57e+03  |
| time/              |           |
|    episodes        | 1772      |
|    fps             | 14        |
|    time_elapsed    | 105388    |
|    total timesteps | 1498417   |
| train/             |           |
|    actor_loss      | -179      |
|    critic_loss     | 8.18      |
|    learning_rate   | 0.001     |
|    n_updates       | 1493415   |
----------------------------------
Num timesteps: 1500000
Best mean reward: 1745.38 - Last mean reward per episode: 1571.97
Num timesteps: 1502000
Best mean reward: 1745.38 - Last mean reward per episode: 1544.97
----------------------------------
| forward_vel        | 1.45      |
| reward             | 1.38      |
| reward_contact     | -0.000989 |
| reward_ctrl        | -1.07     |
| reward_position    | 3.75e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 877       |
|    ep_rew_mean     | 1.54e+03  |
| time/              |           |
|    episodes        | 1776      |
|    fps             | 14        |
|    time_elapsed    | 105667    |
|    total timesteps | 1502417   |
| train/             |           |
|    actor_loss      | -177      |
|    critic_loss     | 57.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1497415   |
----------------------------------
Num timesteps: 1504000
Best mean reward: 1745.38 - Last mean reward per episode: 1543.73
----------------------------------
| forward_vel        | 1.44      |
| reward             | 1.39      |
| reward_contact     | -0.000969 |
| reward_ctrl        | -1.06     |
| reward_position    | 3.75e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 883       |
|    ep_rew_mean     | 1.55e+03  |
| time/              |           |
|    episodes        | 1780      |
|    fps             | 14        |
|    time_elapsed    | 105904    |
|    total timesteps | 1505804   |
| train/             |           |
|    actor_loss      | -175      |
|    critic_loss     | 32.7      |
|    learning_rate   | 0.001     |
|    n_updates       | 1500800   |
----------------------------------
Num timesteps: 1506000
Best mean reward: 1745.38 - Last mean reward per episode: 1553.95
Num timesteps: 1508000
Best mean reward: 1745.38 - Last mean reward per episode: 1554.04
----------------------------------
| forward_vel        | 1.45      |
| reward             | 1.4       |
| reward_contact     | -0.000999 |
| reward_ctrl        | -1.05     |
| reward_position    | 3.75e-05  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 883       |
|    ep_rew_mean     | 1.55e+03  |
| time/              |           |
|    episodes        | 1784      |
|    fps             | 14        |
|    time_elapsed    | 106185    |
|    total timesteps | 1509804   |
| train/             |           |
|    actor_loss      | -178      |
|    critic_loss     | 16.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 1504800   |
----------------------------------
Num timesteps: 1510000
Best mean reward: 1745.38 - Last mean reward per episode: 1550.76
Num timesteps: 1512000
Best mean reward: 1745.38 - Last mean reward per episode: 1550.12
---------------------------------
| forward_vel        | 1.48     |
| reward             | 1.4      |
| reward_contact     | -0.00102 |
| reward_ctrl        | -1.07    |
| reward_position    | 3.75e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 875      |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    episodes        | 1788     |
|    fps             | 14       |
|    time_elapsed    | 106408   |
|    total timesteps | 1512969  |
| train/             |          |
|    actor_loss      | -181     |
|    critic_loss     | 10.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1507965  |
---------------------------------
Num timesteps: 1514000
Best mean reward: 1745.38 - Last mean reward per episode: 1531.72
Num timesteps: 1516000
Best mean reward: 1745.38 - Last mean reward per episode: 1547.94
---------------------------------
| forward_vel        | 1.46     |
| reward             | 1.37     |
| reward_contact     | -0.00102 |
| reward_ctrl        | -1.09    |
| reward_position    | 3.75e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 883      |
|    ep_rew_mean     | 1.57e+03 |
| time/              |          |
|    episodes        | 1792     |
|    fps             | 14       |
|    time_elapsed    | 106626   |
|    total timesteps | 1516064  |
| train/             |          |
|    actor_loss      | -181     |
|    critic_loss     | 14.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1511060  |
---------------------------------
Num timesteps: 1518000
Best mean reward: 1745.38 - Last mean reward per episode: 1558.97
---------------------------------
| forward_vel        | 1.45     |
| reward             | 1.32     |
| reward_contact     | -0.00107 |
| reward_ctrl        | -1.13    |
| reward_position    | 3.75e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 1.56e+03 |
| time/              |          |
|    episodes        | 1796     |
|    fps             | 14       |
|    time_elapsed    | 106808   |
|    total timesteps | 1518696  |
| train/             |          |
|    actor_loss      | -181     |
|    critic_loss     | 13.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1513695  |
---------------------------------
Num timesteps: 1520000
Best mean reward: 1745.38 - Last mean reward per episode: 1553.01
Num timesteps: 1522000
Best mean reward: 1745.38 - Last mean reward per episode: 1555.03
---------------------------------
| forward_vel        | 1.44     |
| reward             | 1.32     |
| reward_contact     | -0.00104 |
| reward_ctrl        | -1.13    |
| reward_position    | 3.75e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 1.56e+03 |
| time/              |          |
|    episodes        | 1800     |
|    fps             | 14       |
|    time_elapsed    | 107084   |
|    total timesteps | 1522696  |
| train/             |          |
|    actor_loss      | -177     |
|    critic_loss     | 9.98     |
|    learning_rate   | 0.001    |
|    n_updates       | 1517695  |
---------------------------------
Num timesteps: 1524000
Best mean reward: 1745.38 - Last mean reward per episode: 1566.62
Num timesteps: 1526000
Best mean reward: 1745.38 - Last mean reward per episode: 1583.37
---------------------------------
| forward_vel        | 1.44     |
| reward             | 1.32     |
| reward_contact     | -0.00109 |
| reward_ctrl        | -1.12    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 881      |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    episodes        | 1804     |
|    fps             | 14       |
|    time_elapsed    | 107313   |
|    total timesteps | 1526046  |
| train/             |          |
|    actor_loss      | -175     |
|    critic_loss     | 24.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1521045  |
---------------------------------
Num timesteps: 1528000
Best mean reward: 1745.38 - Last mean reward per episode: 1580.97
Num timesteps: 1530000
Best mean reward: 1745.38 - Last mean reward per episode: 1627.15
---------------------------------
| forward_vel        | 1.48     |
| reward             | 1.4      |
| reward_contact     | -0.00111 |
| reward_ctrl        | -1.08    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 886      |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    episodes        | 1808     |
|    fps             | 14       |
|    time_elapsed    | 107590   |
|    total timesteps | 1530046  |
| train/             |          |
|    actor_loss      | -177     |
|    critic_loss     | 20.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1525045  |
---------------------------------
Num timesteps: 1532000
Best mean reward: 1745.38 - Last mean reward per episode: 1631.07
Num timesteps: 1534000
Best mean reward: 1745.38 - Last mean reward per episode: 1645.01
---------------------------------
| forward_vel        | 1.45     |
| reward             | 1.37     |
| reward_contact     | -0.00109 |
| reward_ctrl        | -1.08    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 892      |
|    ep_rew_mean     | 1.65e+03 |
| time/              |          |
|    episodes        | 1812     |
|    fps             | 14       |
|    time_elapsed    | 107871   |
|    total timesteps | 1534046  |
| train/             |          |
|    actor_loss      | -177     |
|    critic_loss     | 9.35     |
|    learning_rate   | 0.001    |
|    n_updates       | 1529045  |
---------------------------------
Num timesteps: 1536000
Best mean reward: 1745.38 - Last mean reward per episode: 1662.28
Num timesteps: 1538000
Best mean reward: 1745.38 - Last mean reward per episode: 1675.69
---------------------------------
| forward_vel        | 1.47     |
| reward             | 1.39     |
| reward_contact     | -0.00113 |
| reward_ctrl        | -1.07    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 898      |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    episodes        | 1816     |
|    fps             | 14       |
|    time_elapsed    | 108152   |
|    total timesteps | 1538046  |
| train/             |          |
|    actor_loss      | -174     |
|    critic_loss     | 26.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1533045  |
---------------------------------
Num timesteps: 1540000
Best mean reward: 1745.38 - Last mean reward per episode: 1686.12
---------------------------------
| forward_vel        | 1.47     |
| reward             | 1.4      |
| reward_contact     | -0.00115 |
| reward_ctrl        | -1.07    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 911      |
|    ep_rew_mean     | 1.7e+03  |
| time/              |          |
|    episodes        | 1820     |
|    fps             | 14       |
|    time_elapsed    | 108386   |
|    total timesteps | 1541357  |
| train/             |          |
|    actor_loss      | -179     |
|    critic_loss     | 30.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1536355  |
---------------------------------
Num timesteps: 1542000
Best mean reward: 1745.38 - Last mean reward per episode: 1700.41
Num timesteps: 1544000
Best mean reward: 1745.38 - Last mean reward per episode: 1705.53
---------------------------------
| forward_vel        | 1.5      |
| reward             | 1.44     |
| reward_contact     | -0.00102 |
| reward_ctrl        | -1.06    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 905      |
|    ep_rew_mean     | 1.7e+03  |
| time/              |          |
|    episodes        | 1824     |
|    fps             | 14       |
|    time_elapsed    | 108626   |
|    total timesteps | 1544740  |
| train/             |          |
|    actor_loss      | -173     |
|    critic_loss     | 13.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1539735  |
---------------------------------
Num timesteps: 1546000
Best mean reward: 1745.38 - Last mean reward per episode: 1699.20
Num timesteps: 1548000
Best mean reward: 1745.38 - Last mean reward per episode: 1690.90
---------------------------------
| forward_vel        | 1.49     |
| reward             | 1.42     |
| reward_contact     | -0.00102 |
| reward_ctrl        | -1.07    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 899      |
|    ep_rew_mean     | 1.69e+03 |
| time/              |          |
|    episodes        | 1828     |
|    fps             | 14       |
|    time_elapsed    | 108865   |
|    total timesteps | 1548123  |
| train/             |          |
|    actor_loss      | -182     |
|    critic_loss     | 21.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1543120  |
---------------------------------
Num timesteps: 1550000
Best mean reward: 1745.38 - Last mean reward per episode: 1692.58
Num timesteps: 1552000
Best mean reward: 1745.38 - Last mean reward per episode: 1689.30
---------------------------------
| forward_vel        | 1.46     |
| reward             | 1.4      |
| reward_contact     | -0.00108 |
| reward_ctrl        | -1.06    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 899      |
|    ep_rew_mean     | 1.66e+03 |
| time/              |          |
|    episodes        | 1832     |
|    fps             | 14       |
|    time_elapsed    | 109147   |
|    total timesteps | 1552123  |
| train/             |          |
|    actor_loss      | -177     |
|    critic_loss     | 17.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 1547120  |
---------------------------------
Num timesteps: 1554000
Best mean reward: 1745.38 - Last mean reward per episode: 1662.11
Num timesteps: 1556000
Best mean reward: 1745.38 - Last mean reward per episode: 1677.27
---------------------------------
| forward_vel        | 1.46     |
| reward             | 1.37     |
| reward_contact     | -0.00109 |
| reward_ctrl        | -1.09    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 899      |
|    ep_rew_mean     | 1.67e+03 |
| time/              |          |
|    episodes        | 1836     |
|    fps             | 14       |
|    time_elapsed    | 109430   |
|    total timesteps | 1556123  |
| train/             |          |
|    actor_loss      | -176     |
|    critic_loss     | 129      |
|    learning_rate   | 0.001    |
|    n_updates       | 1551120  |
---------------------------------
Num timesteps: 1558000
Best mean reward: 1745.38 - Last mean reward per episode: 1628.90
---------------------------------
| forward_vel        | 1.42     |
| reward             | 1.29     |
| reward_contact     | -0.00108 |
| reward_ctrl        | -1.12    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 898      |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    episodes        | 1840     |
|    fps             | 14       |
|    time_elapsed    | 109678   |
|    total timesteps | 1559614  |
| train/             |          |
|    actor_loss      | -180     |
|    critic_loss     | 16.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1554610  |
---------------------------------
Num timesteps: 1560000
Best mean reward: 1745.38 - Last mean reward per episode: 1642.79
Num timesteps: 1562000
Best mean reward: 1745.38 - Last mean reward per episode: 1656.14
---------------------------------
| forward_vel        | 1.37     |
| reward             | 1.24     |
| reward_contact     | -0.00114 |
| reward_ctrl        | -1.13    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 907      |
|    ep_rew_mean     | 1.65e+03 |
| time/              |          |
|    episodes        | 1844     |
|    fps             | 14       |
|    time_elapsed    | 109987   |
|    total timesteps | 1563614  |
| train/             |          |
|    actor_loss      | -177     |
|    critic_loss     | 41.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1558610  |
---------------------------------
Num timesteps: 1564000
Best mean reward: 1745.38 - Last mean reward per episode: 1653.56
Num timesteps: 1566000
Best mean reward: 1745.38 - Last mean reward per episode: 1670.28
---------------------------------
| forward_vel        | 1.4      |
| reward             | 1.26     |
| reward_contact     | -0.00115 |
| reward_ctrl        | -1.13    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 912      |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    episodes        | 1848     |
|    fps             | 14       |
|    time_elapsed    | 110296   |
|    total timesteps | 1567614  |
| train/             |          |
|    actor_loss      | -175     |
|    critic_loss     | 47.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1562610  |
---------------------------------
Num timesteps: 1568000
Best mean reward: 1745.38 - Last mean reward per episode: 1669.11
Num timesteps: 1570000
Best mean reward: 1745.38 - Last mean reward per episode: 1662.86
---------------------------------
| forward_vel        | 1.35     |
| reward             | 1.24     |
| reward_contact     | -0.00114 |
| reward_ctrl        | -1.12    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 905      |
|    ep_rew_mean     | 1.66e+03 |
| time/              |          |
|    episodes        | 1852     |
|    fps             | 14       |
|    time_elapsed    | 110531   |
|    total timesteps | 1570948  |
| train/             |          |
|    actor_loss      | -178     |
|    critic_loss     | 26.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1565945  |
---------------------------------
Num timesteps: 1572000
Best mean reward: 1745.38 - Last mean reward per episode: 1665.57
Num timesteps: 1574000
Best mean reward: 1745.38 - Last mean reward per episode: 1667.49
---------------------------------
| forward_vel        | 1.34     |
| reward             | 1.21     |
| reward_contact     | -0.00119 |
| reward_ctrl        | -1.13    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 911      |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    episodes        | 1856     |
|    fps             | 14       |
|    time_elapsed    | 110766   |
|    total timesteps | 1574257  |
| train/             |          |
|    actor_loss      | -186     |
|    critic_loss     | 33.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 1569255  |
---------------------------------
Num timesteps: 1576000
Best mean reward: 1745.38 - Last mean reward per episode: 1688.77
Num timesteps: 1578000
Best mean reward: 1745.38 - Last mean reward per episode: 1667.54
---------------------------------
| forward_vel        | 1.34     |
| reward             | 1.21     |
| reward_contact     | -0.00121 |
| reward_ctrl        | -1.13    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 916      |
|    ep_rew_mean     | 1.67e+03 |
| time/              |          |
|    episodes        | 1860     |
|    fps             | 14       |
|    time_elapsed    | 111052   |
|    total timesteps | 1578257  |
| train/             |          |
|    actor_loss      | -185     |
|    critic_loss     | 17.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 1573255  |
---------------------------------
Num timesteps: 1580000
Best mean reward: 1745.38 - Last mean reward per episode: 1670.86
---------------------------------
| forward_vel        | 1.35     |
| reward             | 1.25     |
| reward_contact     | -0.00114 |
| reward_ctrl        | -1.1     |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 907      |
|    ep_rew_mean     | 1.66e+03 |
| time/              |          |
|    episodes        | 1864     |
|    fps             | 14       |
|    time_elapsed    | 111266   |
|    total timesteps | 1581269  |
| train/             |          |
|    actor_loss      | -180     |
|    critic_loss     | 12.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1576265  |
---------------------------------
Num timesteps: 1582000
Best mean reward: 1745.38 - Last mean reward per episode: 1658.96
Num timesteps: 1584000
Best mean reward: 1745.38 - Last mean reward per episode: 1656.22
---------------------------------
| forward_vel        | 1.34     |
| reward             | 1.25     |
| reward_contact     | -0.00108 |
| reward_ctrl        | -1.09    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 907      |
|    ep_rew_mean     | 1.66e+03 |
| time/              |          |
|    episodes        | 1868     |
|    fps             | 14       |
|    time_elapsed    | 111552   |
|    total timesteps | 1585269  |
| train/             |          |
|    actor_loss      | -175     |
|    critic_loss     | 47.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 1580265  |
---------------------------------
Num timesteps: 1586000
Best mean reward: 1745.38 - Last mean reward per episode: 1657.65
Num timesteps: 1588000
Best mean reward: 1745.38 - Last mean reward per episode: 1657.96
---------------------------------
| forward_vel        | 1.35     |
| reward             | 1.28     |
| reward_contact     | -0.00111 |
| reward_ctrl        | -1.07    |
| reward_position    | 1.23e-05 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    episodes        | 1872     |
|    fps             | 14       |
|    time_elapsed    | 111838   |
|    total timesteps | 1589269  |
| train/             |          |
|    actor_loss      | -173     |
|    critic_loss     | 12.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1584265  |
---------------------------------
Num timesteps: 1590000
Best mean reward: 1745.38 - Last mean reward per episode: 1684.36
Num timesteps: 1592000
Best mean reward: 1745.38 - Last mean reward per episode: 1670.50
---------------------------------
| forward_vel        | 1.35     |
| reward             | 1.28     |
| reward_contact     | -0.00106 |
| reward_ctrl        | -1.07    |
| reward_position    | 6.1e-10  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    episodes        | 1876     |
|    fps             | 14       |
|    time_elapsed    | 112126   |
|    total timesteps | 1593269  |
| train/             |          |
|    actor_loss      | -179     |
|    critic_loss     | 11.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1588265  |
---------------------------------
Num timesteps: 1594000
Best mean reward: 1745.38 - Last mean reward per episode: 1679.99
Num timesteps: 1596000
Best mean reward: 1745.38 - Last mean reward per episode: 1682.98
---------------------------------
| forward_vel        | 1.36     |
| reward             | 1.3      |
| reward_contact     | -0.00111 |
| reward_ctrl        | -1.06    |
| reward_position    | 6.1e-10  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 906      |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    episodes        | 1880     |
|    fps             | 14       |
|    time_elapsed    | 112354   |
|    total timesteps | 1596432  |
| train/             |          |
|    actor_loss      | -179     |
|    critic_loss     | 25.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1591430  |
---------------------------------
Num timesteps: 1598000
Best mean reward: 1745.38 - Last mean reward per episode: 1665.26
---------------------------------
| forward_vel        | 1.37     |
| reward             | 1.27     |
| reward_contact     | -0.00111 |
| reward_ctrl        | -1.09    |
| reward_position    | 6.1e-10  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 899      |
|    ep_rew_mean     | 1.66e+03 |
| time/              |          |
|    episodes        | 1884     |
|    fps             | 14       |
|    time_elapsed    | 112589   |
|    total timesteps | 1599721  |
| train/             |          |
|    actor_loss      | -173     |
|    critic_loss     | 22.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 1594720  |
---------------------------------
Num timesteps: 1600000
Best mean reward: 1745.38 - Last mean reward per episode: 1663.19
Num timesteps: 1602000
Best mean reward: 1745.38 - Last mean reward per episode: 1679.40
---------------------------------
| forward_vel        | 1.38     |
| reward             | 1.3      |
| reward_contact     | -0.00109 |
| reward_ctrl        | -1.08    |
| reward_position    | 6.1e-10  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 908      |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    episodes        | 1888     |
|    fps             | 14       |
|    time_elapsed    | 112877   |
|    total timesteps | 1603721  |
| train/             |          |
|    actor_loss      | -175     |
|    critic_loss     | 16.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1598720  |
---------------------------------
Num timesteps: 1604000
Best mean reward: 1745.38 - Last mean reward per episode: 1684.25
Num timesteps: 1606000
Best mean reward: 1745.38 - Last mean reward per episode: 1697.52
---------------------------------
| forward_vel        | 1.41     |
| reward             | 1.33     |
| reward_contact     | -0.00104 |
| reward_ctrl        | -1.08    |
| reward_position    | 6.1e-10  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 917      |
|    ep_rew_mean     | 1.69e+03 |
| time/              |          |
|    episodes        | 1892     |
|    fps             | 14       |
|    time_elapsed    | 113164   |
|    total timesteps | 1607721  |
| train/             |          |
|    actor_loss      | -176     |
|    critic_loss     | 16       |
|    learning_rate   | 0.001    |
|    n_updates       | 1602720  |
---------------------------------
Num timesteps: 1608000
Best mean reward: 1745.38 - Last mean reward per episode: 1689.94
Num timesteps: 1610000
Best mean reward: 1745.38 - Last mean reward per episode: 1700.63
----------------------------------
| forward_vel        | 1.43      |
| reward             | 1.39      |
| reward_contact     | -0.000978 |
| reward_ctrl        | -1.04     |
| reward_position    | 0.000122  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 920       |
|    ep_rew_mean     | 1.7e+03   |
| time/              |           |
|    episodes        | 1896      |
|    fps             | 14        |
|    time_elapsed    | 113384    |
|    total timesteps | 1610737   |
| train/             |           |
|    actor_loss      | -171      |
|    critic_loss     | 17.7      |
|    learning_rate   | 0.001     |
|    n_updates       | 1605735   |
----------------------------------
Num timesteps: 1612000
Best mean reward: 1745.38 - Last mean reward per episode: 1699.57
Num timesteps: 1614000
Best mean reward: 1745.38 - Last mean reward per episode: 1694.35
----------------------------------
| forward_vel        | 1.43      |
| reward             | 1.35      |
| reward_contact     | -0.000974 |
| reward_ctrl        | -1.07     |
| reward_position    | 0.000122  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 916       |
|    ep_rew_mean     | 1.7e+03   |
| time/              |           |
|    episodes        | 1900      |
|    fps             | 14        |
|    time_elapsed    | 113642    |
|    total timesteps | 1614293   |
| train/             |           |
|    actor_loss      | -176      |
|    critic_loss     | 11.2      |
|    learning_rate   | 0.001     |
|    n_updates       | 1609290   |
----------------------------------
Num timesteps: 1616000
Best mean reward: 1745.38 - Last mean reward per episode: 1705.85
Num timesteps: 1618000
Best mean reward: 1745.38 - Last mean reward per episode: 1711.20
----------------------------------
| forward_vel        | 1.45      |
| reward             | 1.39      |
| reward_contact     | -0.000907 |
| reward_ctrl        | -1.06     |
| reward_position    | 0.000122  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 922       |
|    ep_rew_mean     | 1.73e+03  |
| time/              |           |
|    episodes        | 1904      |
|    fps             | 14        |
|    time_elapsed    | 113934    |
|    total timesteps | 1618293   |
| train/             |           |
|    actor_loss      | -176      |
|    critic_loss     | 9.18      |
|    learning_rate   | 0.001     |
|    n_updates       | 1613290   |
----------------------------------
Num timesteps: 1620000
Best mean reward: 1745.38 - Last mean reward per episode: 1727.87
Num timesteps: 1622000
Best mean reward: 1745.38 - Last mean reward per episode: 1732.30
----------------------------------
| forward_vel        | 1.44      |
| reward             | 1.4       |
| reward_contact     | -0.000931 |
| reward_ctrl        | -1.04     |
| reward_position    | 0.000122  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 922       |
|    ep_rew_mean     | 1.73e+03  |
| time/              |           |
|    episodes        | 1908      |
|    fps             | 14        |
|    time_elapsed    | 114225    |
|    total timesteps | 1622293   |
| train/             |           |
|    actor_loss      | -181      |
|    critic_loss     | 44.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1617290   |
----------------------------------
Num timesteps: 1624000
Best mean reward: 1745.38 - Last mean reward per episode: 1742.15
Num timesteps: 1626000
Best mean reward: 1745.38 - Last mean reward per episode: 1740.61
----------------------------------
| forward_vel        | 1.46      |
| reward             | 1.42      |
| reward_contact     | -0.000924 |
| reward_ctrl        | -1.03     |
| reward_position    | 0.000122  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 922       |
|    ep_rew_mean     | 1.74e+03  |
| time/              |           |
|    episodes        | 1912      |
|    fps             | 14        |
|    time_elapsed    | 114514    |
|    total timesteps | 1626293   |
| train/             |           |
|    actor_loss      | -178      |
|    critic_loss     | 19.2      |
|    learning_rate   | 0.001     |
|    n_updates       | 1621290   |
----------------------------------
Num timesteps: 1628000
Best mean reward: 1745.38 - Last mean reward per episode: 1739.80
Num timesteps: 1630000
Best mean reward: 1745.38 - Last mean reward per episode: 1727.85
----------------------------------
| forward_vel        | 1.45      |
| reward             | 1.38      |
| reward_contact     | -0.000855 |
| reward_ctrl        | -1.07     |
| reward_position    | 0.000122  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 922       |
|    ep_rew_mean     | 1.73e+03  |
| time/              |           |
|    episodes        | 1916      |
|    fps             | 14        |
|    time_elapsed    | 114812    |
|    total timesteps | 1630293   |
| train/             |           |
|    actor_loss      | -180      |
|    critic_loss     | 16.9      |
|    learning_rate   | 0.001     |
|    n_updates       | 1625290   |
----------------------------------
Num timesteps: 1632000
Best mean reward: 1745.38 - Last mean reward per episode: 1725.01
----------------------------------
| forward_vel        | 1.44      |
| reward             | 1.36      |
| reward_contact     | -0.000892 |
| reward_ctrl        | -1.07     |
| reward_position    | 0.000122  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 921       |
|    ep_rew_mean     | 1.72e+03  |
| time/              |           |
|    episodes        | 1920      |
|    fps             | 14        |
|    time_elapsed    | 115056    |
|    total timesteps | 1633506   |
| train/             |           |
|    actor_loss      | -185      |
|    critic_loss     | 20.5      |
|    learning_rate   | 0.001     |
|    n_updates       | 1628505   |
----------------------------------
Num timesteps: 1634000
Best mean reward: 1745.38 - Last mean reward per episode: 1723.26
Num timesteps: 1636000
Best mean reward: 1745.38 - Last mean reward per episode: 1696.52
----------------------------------
| forward_vel        | 1.45      |
| reward             | 1.34      |
| reward_contact     | -0.000913 |
| reward_ctrl        | -1.11     |
| reward_position    | 0.000122  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 913       |
|    ep_rew_mean     | 1.71e+03  |
| time/              |           |
|    episodes        | 1924      |
|    fps             | 14        |
|    time_elapsed    | 115247    |
|    total timesteps | 1636065   |
| train/             |           |
|    actor_loss      | -178      |
|    critic_loss     | 25.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1631060   |
----------------------------------
Num timesteps: 1638000
Best mean reward: 1745.38 - Last mean reward per episode: 1721.51
----------------------------------
| forward_vel        | 1.47      |
| reward             | 1.36      |
| reward_contact     | -0.000913 |
| reward_ctrl        | -1.1      |
| reward_position    | 0.000122  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 919       |
|    ep_rew_mean     | 1.72e+03  |
| time/              |           |
|    episodes        | 1928      |
|    fps             | 14        |
|    time_elapsed    | 115589    |
|    total timesteps | 1639986   |
| train/             |           |
|    actor_loss      | -182      |
|    critic_loss     | 41.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1634985   |
----------------------------------
Num timesteps: 1640000
Best mean reward: 1745.38 - Last mean reward per episode: 1724.62
Num timesteps: 1642000
Best mean reward: 1745.38 - Last mean reward per episode: 1724.58
----------------------------------
| forward_vel        | 1.48      |
| reward             | 1.38      |
| reward_contact     | -0.000826 |
| reward_ctrl        | -1.1      |
| reward_position    | 0.000122  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 914       |
|    ep_rew_mean     | 1.75e+03  |
| time/              |           |
|    episodes        | 1932      |
|    fps             | 14        |
|    time_elapsed    | 115886    |
|    total timesteps | 1643569   |
| train/             |           |
|    actor_loss      | -181      |
|    critic_loss     | 17.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1638565   |
----------------------------------
Num timesteps: 1644000
Best mean reward: 1745.38 - Last mean reward per episode: 1751.54
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2832.6832543000005, 30.22887689028137)
Num timesteps: 1646000
Best mean reward: 1751.54 - Last mean reward per episode: 1863.62
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2813.872796, 72.53243554767084)
----------------------------------
| forward_vel        | 1.72      |
| reward             | 1.79      |
| reward_contact     | -0.000686 |
| reward_ctrl        | -0.923    |
| reward_position    | 0.000122  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 913       |
|    ep_rew_mean     | 1.74e+03  |
| time/              |           |
|    episodes        | 1936      |
|    fps             | 14        |
|    time_elapsed    | 116914    |
|    total timesteps | 1647865   |
| train/             |           |
|    actor_loss      | -179      |
|    critic_loss     | 35        |
|    learning_rate   | 0.001     |
|    n_updates       | 1642860   |
----------------------------------
Num timesteps: 1648000
Best mean reward: 1863.62 - Last mean reward per episode: 1968.13
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2727.2897997, 40.110836406390895)
Num timesteps: 1650000
Best mean reward: 1968.13 - Last mean reward per episode: 2064.26
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2828.4691558, 45.22376653875761)
Num timesteps: 1652000
Best mean reward: 2064.26 - Last mean reward per episode: 2202.40
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2712.3191397999994, 35.55195290691919)
----------------------------------
| forward_vel        | 1.87      |
| reward             | 2.07      |
| reward_contact     | -0.000771 |
| reward_ctrl        | -0.804    |
| reward_position    | 0.000122  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 918       |
|    ep_rew_mean     | 1.75e+03  |
| time/              |           |
|    episodes        | 1940      |
|    fps             | 13        |
|    time_elapsed    | 118175    |
|    total timesteps | 1652000   |
| train/             |           |
|    actor_loss      | -180      |
|    critic_loss     | 18.9      |
|    learning_rate   | 0.001     |
|    n_updates       | 1646995   |
----------------------------------
Num timesteps: 1654000
Best mean reward: 2202.40 - Last mean reward per episode: 2277.44
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2801.9353718, 15.088410661941925)
---------------------------------
| forward_vel        | 1.95     |
| reward             | 2.26     |
| reward_contact     | -0.00106 |
| reward_ctrl        | -0.686   |
| reward_position    | 6.76e-09 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 1.73e+03 |
| time/              |          |
|    episodes        | 1944     |
|    fps             | 13       |
|    time_elapsed    | 118708   |
|    total timesteps | 1655365  |
| train/             |          |
|    actor_loss      | -181     |
|    critic_loss     | 12.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 1650360  |
---------------------------------
Num timesteps: 1656000
Best mean reward: 2277.44 - Last mean reward per episode: 2364.52
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2494.0278235, 826.3779952551654)
Num timesteps: 1658000
Best mean reward: 2364.52 - Last mean reward per episode: 2418.96
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2571.5994044, 805.4962977924752)
Num timesteps: 1660000
Best mean reward: 2418.96 - Last mean reward per episode: 2519.27
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2862.99882, 33.66766994371868)
----------------------------------
| forward_vel        | 2.08      |
| reward             | 2.52      |
| reward_contact     | -0.000943 |
| reward_ctrl        | -0.563    |
| reward_position    | 2.53e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 909       |
|    ep_rew_mean     | 1.72e+03  |
| time/              |           |
|    episodes        | 1948      |
|    fps             | 13        |
|    time_elapsed    | 119804    |
|    total timesteps | 1660000   |
| train/             |           |
|    actor_loss      | -176      |
|    critic_loss     | 14        |
|    learning_rate   | 0.001     |
|    n_updates       | 1654995   |
----------------------------------
Num timesteps: 1662000
Best mean reward: 2519.27 - Last mean reward per episode: 2531.59
Saving new best model to rl/out_dir/models/exp66/best_model.zip
(2711.2717771000002, 709.3355600204262)
----------------------------------
| forward_vel        | 2.08      |
| reward             | 2.51      |
| reward_contact     | -0.000836 |
| reward_ctrl        | -0.572    |
| reward_position    | 2.53e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 906       |
|    ep_rew_mean     | 1.72e+03  |
| time/              |           |
|    episodes        | 1952      |
|    fps             | 13        |
|    time_elapsed    | 120308    |
|    total timesteps | 1663589   |
| train/             |           |
|    actor_loss      | -172      |
|    critic_loss     | 64.5      |
|    learning_rate   | 0.001     |
|    n_updates       | 1658585   |
----------------------------------
Num timesteps: 1664000
Best mean reward: 2531.59 - Last mean reward per episode: 2511.86
Num timesteps: 1666000
Best mean reward: 2531.59 - Last mean reward per episode: 2493.87
----------------------------------
| forward_vel        | 2.04      |
| reward             | 2.45      |
| reward_contact     | -0.000866 |
| reward_ctrl        | -0.59     |
| reward_position    | 2.53e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 908       |
|    ep_rew_mean     | 1.72e+03  |
| time/              |           |
|    episodes        | 1956      |
|    fps             | 13        |
|    time_elapsed    | 120564    |
|    total timesteps | 1667149   |
| train/             |           |
|    actor_loss      | -183      |
|    critic_loss     | 13.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1662145   |
----------------------------------
Num timesteps: 1668000
Best mean reward: 2531.59 - Last mean reward per episode: 2486.67
Num timesteps: 1670000
Best mean reward: 2531.59 - Last mean reward per episode: 2472.93
----------------------------------
| forward_vel        | 2.02      |
| reward             | 2.41      |
| reward_contact     | -0.000862 |
| reward_ctrl        | -0.61     |
| reward_position    | 2.53e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 908       |
|    ep_rew_mean     | 1.75e+03  |
| time/              |           |
|    episodes        | 1960      |
|    fps             | 13        |
|    time_elapsed    | 120848    |
|    total timesteps | 1671101   |
| train/             |           |
|    actor_loss      | -188      |
|    critic_loss     | 12.3      |
|    learning_rate   | 0.001     |
|    n_updates       | 1666100   |
----------------------------------
Num timesteps: 1672000
Best mean reward: 2531.59 - Last mean reward per episode: 2460.26
Num timesteps: 1674000
Best mean reward: 2531.59 - Last mean reward per episode: 2448.00
----------------------------------
| forward_vel        | 1.97      |
| reward             | 2.35      |
| reward_contact     | -0.000909 |
| reward_ctrl        | -0.627    |
| reward_position    | 2.53e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 915       |
|    ep_rew_mean     | 1.76e+03  |
| time/              |           |
|    episodes        | 1964      |
|    fps             | 13        |
|    time_elapsed    | 121109    |
|    total timesteps | 1674784   |
| train/             |           |
|    actor_loss      | -184      |
|    critic_loss     | 13.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1669780   |
----------------------------------
Num timesteps: 1676000
Best mean reward: 2531.59 - Last mean reward per episode: 2414.23
Num timesteps: 1678000
Best mean reward: 2531.59 - Last mean reward per episode: 2430.78
----------------------------------
| forward_vel        | 1.96      |
| reward             | 2.32      |
| reward_contact     | -0.000904 |
| reward_ctrl        | -0.642    |
| reward_position    | 1.85e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 915       |
|    ep_rew_mean     | 1.76e+03  |
| time/              |           |
|    episodes        | 1968      |
|    fps             | 13        |
|    time_elapsed    | 121395    |
|    total timesteps | 1678784   |
| train/             |           |
|    actor_loss      | -184      |
|    critic_loss     | 15.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1673780   |
----------------------------------
Num timesteps: 1680000
Best mean reward: 2531.59 - Last mean reward per episode: 2429.14
Num timesteps: 1682000
Best mean reward: 2531.59 - Last mean reward per episode: 2394.12
----------------------------------
| forward_vel        | 1.95      |
| reward             | 2.3       |
| reward_contact     | -0.000883 |
| reward_ctrl        | -0.649    |
| reward_position    | 1.85e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 915       |
|    ep_rew_mean     | 1.75e+03  |
| time/              |           |
|    episodes        | 1972      |
|    fps             | 13        |
|    time_elapsed    | 121682    |
|    total timesteps | 1682784   |
| train/             |           |
|    actor_loss      | -178      |
|    critic_loss     | 18.5      |
|    learning_rate   | 0.001     |
|    n_updates       | 1677780   |
----------------------------------
Num timesteps: 1684000
Best mean reward: 2531.59 - Last mean reward per episode: 2380.30
Num timesteps: 1686000
Best mean reward: 2531.59 - Last mean reward per episode: 2364.73
----------------------------------
| forward_vel        | 1.92      |
| reward             | 2.27      |
| reward_contact     | -0.000909 |
| reward_ctrl        | -0.65     |
| reward_position    | 1.85e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 915       |
|    ep_rew_mean     | 1.79e+03  |
| time/              |           |
|    episodes        | 1976      |
|    fps             | 13        |
|    time_elapsed    | 121970    |
|    total timesteps | 1686784   |
| train/             |           |
|    actor_loss      | -171      |
|    critic_loss     | 25.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 1681780   |
----------------------------------
Num timesteps: 1688000
Best mean reward: 2531.59 - Last mean reward per episode: 2348.05
Num timesteps: 1690000
Best mean reward: 2531.59 - Last mean reward per episode: 2340.68
----------------------------------
| forward_vel        | 1.9       |
| reward             | 2.23      |
| reward_contact     | -0.000789 |
| reward_ctrl        | -0.67     |
| reward_position    | 1.85e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 916       |
|    ep_rew_mean     | 1.79e+03  |
| time/              |           |
|    episodes        | 1980      |
|    fps             | 13        |
|    time_elapsed    | 122208    |
|    total timesteps | 1690109   |
| train/             |           |
|    actor_loss      | -182      |
|    critic_loss     | 11        |
|    learning_rate   | 0.001     |
|    n_updates       | 1685105   |
----------------------------------
Num timesteps: 1692000
Best mean reward: 2531.59 - Last mean reward per episode: 2272.80
----------------------------------
| forward_vel        | 1.89      |
| reward             | 2.19      |
| reward_contact     | -0.000639 |
| reward_ctrl        | -0.705    |
| reward_position    | 1.85e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 906       |
|    ep_rew_mean     | 1.77e+03  |
| time/              |           |
|    episodes        | 1984      |
|    fps             | 13        |
|    time_elapsed    | 122375    |
|    total timesteps | 1692410   |
| train/             |           |
|    actor_loss      | -181      |
|    critic_loss     | 28.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1687405   |
----------------------------------
Num timesteps: 1694000
Best mean reward: 2531.59 - Last mean reward per episode: 2234.76
----------------------------------
| forward_vel        | 1.86      |
| reward             | 2.13      |
| reward_contact     | -0.000666 |
| reward_ctrl        | -0.729    |
| reward_position    | 1.85e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 891       |
|    ep_rew_mean     | 1.74e+03  |
| time/              |           |
|    episodes        | 1988      |
|    fps             | 13        |
|    time_elapsed    | 122554    |
|    total timesteps | 1694908   |
| train/             |           |
|    actor_loss      | -176      |
|    critic_loss     | 24.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1689905   |
----------------------------------
Num timesteps: 1696000
Best mean reward: 2531.59 - Last mean reward per episode: 2201.51
Num timesteps: 1698000
Best mean reward: 2531.59 - Last mean reward per episode: 2201.58
----------------------------------
| forward_vel        | 1.84      |
| reward             | 2.1       |
| reward_contact     | -0.000679 |
| reward_ctrl        | -0.734    |
| reward_position    | 1.85e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 891       |
|    ep_rew_mean     | 1.75e+03  |
| time/              |           |
|    episodes        | 1992      |
|    fps             | 13        |
|    time_elapsed    | 122839    |
|    total timesteps | 1698908   |
| train/             |           |
|    actor_loss      | -183      |
|    critic_loss     | 31.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 1693905   |
----------------------------------
Num timesteps: 1700000
Best mean reward: 2531.59 - Last mean reward per episode: 2196.96
Num timesteps: 1702000
Best mean reward: 2531.59 - Last mean reward per episode: 2170.75
----------------------------------
| forward_vel        | 1.84      |
| reward             | 2.09      |
| reward_contact     | -0.000619 |
| reward_ctrl        | -0.754    |
| reward_position    | 1.85e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 895       |
|    ep_rew_mean     | 1.76e+03  |
| time/              |           |
|    episodes        | 1996      |
|    fps             | 13        |
|    time_elapsed    | 123077    |
|    total timesteps | 1702265   |
| train/             |           |
|    actor_loss      | -172      |
|    critic_loss     | 15.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1697260   |
----------------------------------
Num timesteps: 1704000
Best mean reward: 2531.59 - Last mean reward per episode: 2150.79
Num timesteps: 1706000
Best mean reward: 2531.59 - Last mean reward per episode: 2135.32
----------------------------------
| forward_vel        | 1.77      |
| reward             | 2         |
| reward_contact     | -0.000669 |
| reward_ctrl        | -0.776    |
| reward_position    | 1.85e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 899       |
|    ep_rew_mean     | 1.77e+03  |
| time/              |           |
|    episodes        | 2000      |
|    fps             | 13        |
|    time_elapsed    | 123361    |
|    total timesteps | 1706257   |
| train/             |           |
|    actor_loss      | -178      |
|    critic_loss     | 24.9      |
|    learning_rate   | 0.001     |
|    n_updates       | 1701255   |
----------------------------------
Num timesteps: 1708000
Best mean reward: 2531.59 - Last mean reward per episode: 2116.20
Num timesteps: 1710000
Best mean reward: 2531.59 - Last mean reward per episode: 2105.10
----------------------------------
| forward_vel        | 1.72      |
| reward             | 1.91      |
| reward_contact     | -0.000653 |
| reward_ctrl        | -0.804    |
| reward_position    | 1.85e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 899       |
|    ep_rew_mean     | 1.75e+03  |
| time/              |           |
|    episodes        | 2004      |
|    fps             | 13        |
|    time_elapsed    | 123644    |
|    total timesteps | 1710257   |
| train/             |           |
|    actor_loss      | -182      |
|    critic_loss     | 37.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1705255   |
----------------------------------
Num timesteps: 1712000
Best mean reward: 2531.59 - Last mean reward per episode: 2096.62
---------------------------------
| forward_vel        | 1.7      |
| reward             | 1.91     |
| reward_contact     | -0.00068 |
| reward_ctrl        | -0.791   |
| reward_position    | 1.85e-08 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 894      |
|    ep_rew_mean     | 1.74e+03 |
| time/              |          |
|    episodes        | 2008     |
|    fps             | 13       |
|    time_elapsed    | 123896   |
|    total timesteps | 1713770  |
| train/             |          |
|    actor_loss      | -181     |
|    critic_loss     | 37.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1708765  |
---------------------------------
Num timesteps: 1714000
Best mean reward: 2531.59 - Last mean reward per episode: 2084.77
Num timesteps: 1716000
Best mean reward: 2531.59 - Last mean reward per episode: 2060.61
---------------------------------
| forward_vel        | 1.69     |
| reward             | 1.86     |
| reward_contact     | -0.00071 |
| reward_ctrl        | -0.832   |
| reward_position    | 1.85e-08 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 888      |
|    ep_rew_mean     | 1.73e+03 |
| time/              |          |
|    episodes        | 2012     |
|    fps             | 13       |
|    time_elapsed    | 124138   |
|    total timesteps | 1717132  |
| train/             |          |
|    actor_loss      | -180     |
|    critic_loss     | 10       |
|    learning_rate   | 0.001    |
|    n_updates       | 1712130  |
---------------------------------
Num timesteps: 1718000
Best mean reward: 2531.59 - Last mean reward per episode: 2045.18
Num timesteps: 1720000
Best mean reward: 2531.59 - Last mean reward per episode: 2047.96
---------------------------------
| forward_vel        | 1.68     |
| reward             | 1.83     |
| reward_contact     | -0.00071 |
| reward_ctrl        | -0.844   |
| reward_position    | 4.75e-12 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 883      |
|    ep_rew_mean     | 1.73e+03 |
| time/              |          |
|    episodes        | 2016     |
|    fps             | 13       |
|    time_elapsed    | 124392   |
|    total timesteps | 1720676  |
| train/             |          |
|    actor_loss      | -186     |
|    critic_loss     | 13.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1715675  |
---------------------------------
Num timesteps: 1722000
Best mean reward: 2531.59 - Last mean reward per episode: 2043.30
Num timesteps: 1724000
Best mean reward: 2531.59 - Last mean reward per episode: 2063.55
----------------------------------
| forward_vel        | 1.66      |
| reward             | 1.83      |
| reward_contact     | -0.000738 |
| reward_ctrl        | -0.835    |
| reward_position    | 2.33e-28  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 891       |
|    ep_rew_mean     | 1.77e+03  |
| time/              |           |
|    episodes        | 2020      |
|    fps             | 13        |
|    time_elapsed    | 124681    |
|    total timesteps | 1724676   |
| train/             |           |
|    actor_loss      | -186      |
|    critic_loss     | 13.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 1719675   |
----------------------------------
Num timesteps: 1726000
Best mean reward: 2531.59 - Last mean reward per episode: 2050.84
Num timesteps: 1728000
Best mean reward: 2531.59 - Last mean reward per episode: 2037.71
---------------------------------
| forward_vel        | 1.65     |
| reward             | 1.8      |
| reward_contact     | -0.00074 |
| reward_ctrl        | -0.849   |
| reward_position    | 2.33e-28 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 906      |
|    ep_rew_mean     | 1.8e+03  |
| time/              |          |
|    episodes        | 2024     |
|    fps             | 13       |
|    time_elapsed    | 124971   |
|    total timesteps | 1728676  |
| train/             |          |
|    actor_loss      | -174     |
|    critic_loss     | 16.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1723675  |
---------------------------------
Num timesteps: 1730000
Best mean reward: 2531.59 - Last mean reward per episode: 2015.67
Num timesteps: 1732000
Best mean reward: 2531.59 - Last mean reward per episode: 2005.20
----------------------------------
| forward_vel        | 1.6       |
| reward             | 1.7       |
| reward_contact     | -0.000911 |
| reward_ctrl        | -0.894    |
| reward_position    | 2.33e-28  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 906       |
|    ep_rew_mean     | 1.79e+03  |
| time/              |           |
|    episodes        | 2028      |
|    fps             | 13        |
|    time_elapsed    | 125262    |
|    total timesteps | 1732676   |
| train/             |           |
|    actor_loss      | -173      |
|    critic_loss     | 23.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 1727675   |
----------------------------------
Num timesteps: 1734000
Best mean reward: 2531.59 - Last mean reward per episode: 1968.35
----------------------------------
| forward_vel        | 1.59      |
| reward             | 1.66      |
| reward_contact     | -0.000881 |
| reward_ctrl        | -0.925    |
| reward_position    | 2.33e-28  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 901       |
|    ep_rew_mean     | 1.77e+03  |
| time/              |           |
|    episodes        | 2032      |
|    fps             | 13        |
|    time_elapsed    | 125483    |
|    total timesteps | 1735725   |
| train/             |           |
|    actor_loss      | -185      |
|    critic_loss     | 13.9      |
|    learning_rate   | 0.001     |
|    n_updates       | 1730720   |
----------------------------------
Num timesteps: 1736000
Best mean reward: 2531.59 - Last mean reward per episode: 1951.45
Num timesteps: 1738000
Best mean reward: 2531.59 - Last mean reward per episode: 1931.44
----------------------------------
| forward_vel        | 1.56      |
| reward             | 1.62      |
| reward_contact     | -0.000913 |
| reward_ctrl        | -0.936    |
| reward_position    | 2.33e-28  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 902       |
|    ep_rew_mean     | 1.78e+03  |
| time/              |           |
|    episodes        | 2036      |
|    fps             | 13        |
|    time_elapsed    | 125775    |
|    total timesteps | 1739725   |
| train/             |           |
|    actor_loss      | -177      |
|    critic_loss     | 36        |
|    learning_rate   | 0.001     |
|    n_updates       | 1734720   |
----------------------------------
Num timesteps: 1740000
Best mean reward: 2531.59 - Last mean reward per episode: 1889.78
----------------------------------
| forward_vel        | 1.54      |
| reward             | 1.6       |
| reward_contact     | -0.000973 |
| reward_ctrl        | -0.944    |
| reward_position    | 9.89e-07  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 884       |
|    ep_rew_mean     | 1.76e+03  |
| time/              |           |
|    episodes        | 2040      |
|    fps             | 13        |
|    time_elapsed    | 125935    |
|    total timesteps | 1741930   |
| train/             |           |
|    actor_loss      | -180      |
|    critic_loss     | 16.3      |
|    learning_rate   | 0.001     |
|    n_updates       | 1736925   |
----------------------------------
Num timesteps: 1742000
Best mean reward: 2531.59 - Last mean reward per episode: 1874.35
Num timesteps: 1744000
Best mean reward: 2531.59 - Last mean reward per episode: 1854.80
----------------------------------
| forward_vel        | 1.52      |
| reward             | 1.54      |
| reward_contact     | -0.000984 |
| reward_ctrl        | -0.972    |
| reward_position    | 9.89e-07  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 894       |
|    ep_rew_mean     | 1.79e+03  |
| time/              |           |
|    episodes        | 2044      |
|    fps             | 13        |
|    time_elapsed    | 126227    |
|    total timesteps | 1745930   |
| train/             |           |
|    actor_loss      | -183      |
|    critic_loss     | 18        |
|    learning_rate   | 0.001     |
|    n_updates       | 1740925   |
----------------------------------
Num timesteps: 1746000
Best mean reward: 2531.59 - Last mean reward per episode: 1832.04
Num timesteps: 1748000
Best mean reward: 2531.59 - Last mean reward per episode: 1792.04
---------------------------------
| forward_vel        | 1.44     |
| reward             | 1.44     |
| reward_contact     | -0.00106 |
| reward_ctrl        | -0.998   |
| reward_position    | 9.89e-07 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 889      |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    episodes        | 2048     |
|    fps             | 13       |
|    time_elapsed    | 126486   |
|    total timesteps | 1749474  |
| train/             |          |
|    actor_loss      | -181     |
|    critic_loss     | 46       |
|    learning_rate   | 0.001    |
|    n_updates       | 1744470  |
---------------------------------
Num timesteps: 1750000
Best mean reward: 2531.59 - Last mean reward per episode: 1754.72
Num timesteps: 1752000
Best mean reward: 2531.59 - Last mean reward per episode: 1746.50
---------------------------------
| forward_vel        | 1.4      |
| reward             | 1.38     |
| reward_contact     | -0.00107 |
| reward_ctrl        | -1.02    |
| reward_position    | 7.2e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 889      |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    episodes        | 2052     |
|    fps             | 13       |
|    time_elapsed    | 126723   |
|    total timesteps | 1752491  |
| train/             |          |
|    actor_loss      | -181     |
|    critic_loss     | 20.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1747490  |
---------------------------------
Num timesteps: 1754000
Best mean reward: 2531.59 - Last mean reward per episode: 1756.74
---------------------------------
| forward_vel        | 1.39     |
| reward             | 1.37     |
| reward_contact     | -0.00109 |
| reward_ctrl        | -1.03    |
| reward_position    | 7.2e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 887      |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    episodes        | 2056     |
|    fps             | 13       |
|    time_elapsed    | 126975   |
|    total timesteps | 1755856  |
| train/             |          |
|    actor_loss      | -176     |
|    critic_loss     | 17.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1750855  |
---------------------------------
Num timesteps: 1756000
Best mean reward: 2531.59 - Last mean reward per episode: 1749.89
Num timesteps: 1758000
Best mean reward: 2531.59 - Last mean reward per episode: 1749.85
---------------------------------
| forward_vel        | 1.37     |
| reward             | 1.35     |
| reward_contact     | -0.00111 |
| reward_ctrl        | -1.02    |
| reward_position    | 7.2e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 888      |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    episodes        | 2060     |
|    fps             | 13       |
|    time_elapsed    | 127271   |
|    total timesteps | 1759856  |
| train/             |          |
|    actor_loss      | -177     |
|    critic_loss     | 28.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 1754855  |
---------------------------------
Num timesteps: 1760000
Best mean reward: 2531.59 - Last mean reward per episode: 1746.72
Num timesteps: 1762000
Best mean reward: 2531.59 - Last mean reward per episode: 1740.21
---------------------------------
| forward_vel        | 1.37     |
| reward             | 1.35     |
| reward_contact     | -0.00108 |
| reward_ctrl        | -1.02    |
| reward_position    | 7.2e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 886      |
|    ep_rew_mean     | 1.74e+03 |
| time/              |          |
|    episodes        | 2064     |
|    fps             | 13       |
|    time_elapsed    | 127533   |
|    total timesteps | 1763424  |
| train/             |          |
|    actor_loss      | -173     |
|    critic_loss     | 50.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1758420  |
---------------------------------
Num timesteps: 1764000
Best mean reward: 2531.59 - Last mean reward per episode: 1738.28
Num timesteps: 1766000
Best mean reward: 2531.59 - Last mean reward per episode: 1741.67
---------------------------------
| forward_vel        | 1.36     |
| reward             | 1.36     |
| reward_contact     | -0.00103 |
| reward_ctrl        | -1       |
| reward_position    | 7.2e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 886      |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    episodes        | 2068     |
|    fps             | 13       |
|    time_elapsed    | 127830   |
|    total timesteps | 1767424  |
| train/             |          |
|    actor_loss      | -173     |
|    critic_loss     | 16.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1762420  |
---------------------------------
Num timesteps: 1768000
Best mean reward: 2531.59 - Last mean reward per episode: 1725.35
----------------------------------
| forward_vel        | 1.38      |
| reward             | 1.37      |
| reward_contact     | -0.000979 |
| reward_ctrl        | -1        |
| reward_position    | 7.2e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 868       |
|    ep_rew_mean     | 1.72e+03  |
| time/              |           |
|    episodes        | 2072      |
|    fps             | 13        |
|    time_elapsed    | 127986    |
|    total timesteps | 1769537   |
| train/             |           |
|    actor_loss      | -180      |
|    critic_loss     | 23        |
|    learning_rate   | 0.001     |
|    n_updates       | 1764535   |
----------------------------------
Num timesteps: 1770000
Best mean reward: 2531.59 - Last mean reward per episode: 1718.00
Num timesteps: 1772000
Best mean reward: 2531.59 - Last mean reward per episode: 1711.43
----------------------------------
| forward_vel        | 1.36      |
| reward             | 1.34      |
| reward_contact     | -0.000976 |
| reward_ctrl        | -1.01     |
| reward_position    | 7.2e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 865       |
|    ep_rew_mean     | 1.71e+03  |
| time/              |           |
|    episodes        | 2076      |
|    fps             | 13        |
|    time_elapsed    | 128260    |
|    total timesteps | 1773239   |
| train/             |           |
|    actor_loss      | -174      |
|    critic_loss     | 10.9      |
|    learning_rate   | 0.001     |
|    n_updates       | 1768235   |
----------------------------------
Num timesteps: 1774000
Best mean reward: 2531.59 - Last mean reward per episode: 1705.43
Num timesteps: 1776000
Best mean reward: 2531.59 - Last mean reward per episode: 1703.43
---------------------------------
| forward_vel        | 1.35     |
| reward             | 1.33     |
| reward_contact     | -0.001   |
| reward_ctrl        | -1.02    |
| reward_position    | 7.2e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 1.71e+03 |
| time/              |          |
|    episodes        | 2080     |
|    fps             | 13       |
|    time_elapsed    | 128539   |
|    total timesteps | 1776973  |
| train/             |          |
|    actor_loss      | -176     |
|    critic_loss     | 19.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1771970  |
---------------------------------
Num timesteps: 1778000
Best mean reward: 2531.59 - Last mean reward per episode: 1712.05
Num timesteps: 1780000
Best mean reward: 2531.59 - Last mean reward per episode: 1748.05
---------------------------------
| forward_vel        | 1.33     |
| reward             | 1.32     |
| reward_contact     | -0.00102 |
| reward_ctrl        | -1.01    |
| reward_position    | 7.2e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 886      |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    episodes        | 2084     |
|    fps             | 13       |
|    time_elapsed    | 128836   |
|    total timesteps | 1780973  |
| train/             |          |
|    actor_loss      | -179     |
|    critic_loss     | 14.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1775970  |
---------------------------------
Num timesteps: 1782000
Best mean reward: 2531.59 - Last mean reward per episode: 1751.44
Num timesteps: 1784000
Best mean reward: 2531.59 - Last mean reward per episode: 1752.16
----------------------------------
| forward_vel        | 1.32      |
| reward             | 1.32      |
| reward_contact     | -0.000976 |
| reward_ctrl        | -0.998    |
| reward_position    | 7.2e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 898       |
|    ep_rew_mean     | 1.76e+03  |
| time/              |           |
|    episodes        | 2088      |
|    fps             | 13        |
|    time_elapsed    | 129111    |
|    total timesteps | 1784674   |
| train/             |           |
|    actor_loss      | -186      |
|    critic_loss     | 16.3      |
|    learning_rate   | 0.001     |
|    n_updates       | 1779670   |
----------------------------------
Num timesteps: 1786000
Best mean reward: 2531.59 - Last mean reward per episode: 1749.78
----------------------------------
| forward_vel        | 1.34      |
| reward             | 1.37      |
| reward_contact     | -0.000963 |
| reward_ctrl        | -0.974    |
| reward_position    | 7.2e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 890       |
|    ep_rew_mean     | 1.76e+03  |
| time/              |           |
|    episodes        | 2092      |
|    fps             | 13        |
|    time_elapsed    | 129354    |
|    total timesteps | 1787918   |
| train/             |           |
|    actor_loss      | -179      |
|    critic_loss     | 24.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1782915   |
----------------------------------
Num timesteps: 1788000
Best mean reward: 2531.59 - Last mean reward per episode: 1755.55
Num timesteps: 1790000
Best mean reward: 2531.59 - Last mean reward per episode: 1768.69
---------------------------------
| forward_vel        | 1.32     |
| reward             | 1.36     |
| reward_contact     | -0.001   |
| reward_ctrl        | -0.964   |
| reward_position    | 7.2e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 893      |
|    ep_rew_mean     | 1.77e+03 |
| time/              |          |
|    episodes        | 2096     |
|    fps             | 13       |
|    time_elapsed    | 129628   |
|    total timesteps | 1791570  |
| train/             |          |
|    actor_loss      | -173     |
|    critic_loss     | 13.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1786565  |
---------------------------------
Num timesteps: 1792000
Best mean reward: 2531.59 - Last mean reward per episode: 1765.66
Num timesteps: 1794000
Best mean reward: 2531.59 - Last mean reward per episode: 1762.41
----------------------------------
| forward_vel        | 1.37      |
| reward             | 1.41      |
| reward_contact     | -0.000913 |
| reward_ctrl        | -0.952    |
| reward_position    | 7.2e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 882       |
|    ep_rew_mean     | 1.75e+03  |
| time/              |           |
|    episodes        | 2100      |
|    fps             | 13        |
|    time_elapsed    | 129846    |
|    total timesteps | 1794463   |
| train/             |           |
|    actor_loss      | -180      |
|    critic_loss     | 17.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 1789460   |
----------------------------------
Num timesteps: 1796000
Best mean reward: 2531.59 - Last mean reward per episode: 1738.66
----------------------------------
| forward_vel        | 1.43      |
| reward             | 1.47      |
| reward_contact     | -0.000902 |
| reward_ctrl        | -0.96     |
| reward_position    | 7.2e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 872       |
|    ep_rew_mean     | 1.74e+03  |
| time/              |           |
|    episodes        | 2104      |
|    fps             | 13        |
|    time_elapsed    | 130073    |
|    total timesteps | 1797469   |
| train/             |           |
|    actor_loss      | -182      |
|    critic_loss     | 14.7      |
|    learning_rate   | 0.001     |
|    n_updates       | 1792465   |
----------------------------------
Num timesteps: 1798000
Best mean reward: 2531.59 - Last mean reward per episode: 1739.24
Num timesteps: 1800000
Best mean reward: 2531.59 - Last mean reward per episode: 1729.01
----------------------------------
| forward_vel        | 1.44      |
| reward             | 1.48      |
| reward_contact     | -0.000888 |
| reward_ctrl        | -0.962    |
| reward_position    | 7.2e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 870       |
|    ep_rew_mean     | 1.73e+03  |
| time/              |           |
|    episodes        | 2108      |
|    fps             | 13        |
|    time_elapsed    | 130323    |
|    total timesteps | 1800750   |
| train/             |           |
|    actor_loss      | -181      |
|    critic_loss     | 13.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1795745   |
----------------------------------
Num timesteps: 1802000
Best mean reward: 2531.59 - Last mean reward per episode: 1726.88
Num timesteps: 1804000
Best mean reward: 2531.59 - Last mean reward per episode: 1737.33
----------------------------------
| forward_vel        | 1.42      |
| reward             | 1.48      |
| reward_contact     | -0.000948 |
| reward_ctrl        | -0.945    |
| reward_position    | 7.2e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 876       |
|    ep_rew_mean     | 1.74e+03  |
| time/              |           |
|    episodes        | 2112      |
|    fps             | 13        |
|    time_elapsed    | 130625    |
|    total timesteps | 1804750   |
| train/             |           |
|    actor_loss      | -182      |
|    critic_loss     | 21.3      |
|    learning_rate   | 0.001     |
|    n_updates       | 1799745   |
----------------------------------
Num timesteps: 1806000
Best mean reward: 2531.59 - Last mean reward per episode: 1740.96
Num timesteps: 1808000
Best mean reward: 2531.59 - Last mean reward per episode: 1750.61
---------------------------------
| forward_vel        | 1.39     |
| reward             | 1.45     |
| reward_contact     | -0.001   |
| reward_ctrl        | -0.941   |
| reward_position    | 7.2e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 881      |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    episodes        | 2116     |
|    fps             | 13       |
|    time_elapsed    | 130925   |
|    total timesteps | 1808750  |
| train/             |          |
|    actor_loss      | -177     |
|    critic_loss     | 36.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1803745  |
---------------------------------
Num timesteps: 1810000
Best mean reward: 2531.59 - Last mean reward per episode: 1743.96
----------------------------------
| forward_vel        | 1.37      |
| reward             | 1.43      |
| reward_contact     | -0.000972 |
| reward_ctrl        | -0.937    |
| reward_position    | 7.2e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 871       |
|    ep_rew_mean     | 1.68e+03  |
| time/              |           |
|    episodes        | 2120      |
|    fps             | 13        |
|    time_elapsed    | 131153    |
|    total timesteps | 1811780   |
| train/             |           |
|    actor_loss      | -183      |
|    critic_loss     | 25.7      |
|    learning_rate   | 0.001     |
|    n_updates       | 1806775   |
----------------------------------
Num timesteps: 1812000
Best mean reward: 2531.59 - Last mean reward per episode: 1681.15
Num timesteps: 1814000
Best mean reward: 2531.59 - Last mean reward per episode: 1676.81
---------------------------------
| forward_vel        | 1.35     |
| reward             | 1.39     |
| reward_contact     | -0.00098 |
| reward_ctrl        | -0.953   |
| reward_position    | 7.2e-05  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 871      |
|    ep_rew_mean     | 1.66e+03 |
| time/              |          |
|    episodes        | 2124     |
|    fps             | 13       |
|    time_elapsed    | 131453   |
|    total timesteps | 1815780  |
| train/             |          |
|    actor_loss      | -184     |
|    critic_loss     | 12.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1810775  |
---------------------------------
Num timesteps: 1816000
Best mean reward: 2531.59 - Last mean reward per episode: 1657.53
Num timesteps: 1818000
Best mean reward: 2531.59 - Last mean reward per episode: 1624.95
----------------------------------
| forward_vel        | 1.36      |
| reward             | 1.42      |
| reward_contact     | -0.000857 |
| reward_ctrl        | -0.938    |
| reward_position    | 7.2e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 871       |
|    ep_rew_mean     | 1.63e+03  |
| time/              |           |
|    episodes        | 2128      |
|    fps             | 13        |
|    time_elapsed    | 131753    |
|    total timesteps | 1819780   |
| train/             |           |
|    actor_loss      | -178      |
|    critic_loss     | 12.3      |
|    learning_rate   | 0.001     |
|    n_updates       | 1814775   |
----------------------------------
Num timesteps: 1820000
Best mean reward: 2531.59 - Last mean reward per episode: 1633.83
Num timesteps: 1822000
Best mean reward: 2531.59 - Last mean reward per episode: 1623.24
----------------------------------
| forward_vel        | 1.34      |
| reward             | 1.41      |
| reward_contact     | -0.000827 |
| reward_ctrl        | -0.925    |
| reward_position    | 7.2e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 864       |
|    ep_rew_mean     | 1.62e+03  |
| time/              |           |
|    episodes        | 2132      |
|    fps             | 13        |
|    time_elapsed    | 131930    |
|    total timesteps | 1822133   |
| train/             |           |
|    actor_loss      | -189      |
|    critic_loss     | 24        |
|    learning_rate   | 0.001     |
|    n_updates       | 1817130   |
----------------------------------
Num timesteps: 1824000
Best mean reward: 2531.59 - Last mean reward per episode: 1620.34
Num timesteps: 1826000
Best mean reward: 2531.59 - Last mean reward per episode: 1617.97
----------------------------------
| forward_vel        | 1.33      |
| reward             | 1.38      |
| reward_contact     | -0.000851 |
| reward_ctrl        | -0.942    |
| reward_position    | 7.2e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 864       |
|    ep_rew_mean     | 1.62e+03  |
| time/              |           |
|    episodes        | 2136      |
|    fps             | 13        |
|    time_elapsed    | 132230    |
|    total timesteps | 1826133   |
| train/             |           |
|    actor_loss      | -172      |
|    critic_loss     | 18.5      |
|    learning_rate   | 0.001     |
|    n_updates       | 1821130   |
----------------------------------
Num timesteps: 1828000
Best mean reward: 2531.59 - Last mean reward per episode: 1635.30
----------------------------------
| forward_vel        | 1.36      |
| reward             | 1.41      |
| reward_contact     | -0.000795 |
| reward_ctrl        | -0.948    |
| reward_position    | 7.1e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 875       |
|    ep_rew_mean     | 1.62e+03  |
| time/              |           |
|    episodes        | 2140      |
|    fps             | 13        |
|    time_elapsed    | 132473    |
|    total timesteps | 1829385   |
| train/             |           |
|    actor_loss      | -175      |
|    critic_loss     | 17.7      |
|    learning_rate   | 0.001     |
|    n_updates       | 1824380   |
----------------------------------
Num timesteps: 1830000
Best mean reward: 2531.59 - Last mean reward per episode: 1622.51
Num timesteps: 1832000
Best mean reward: 2531.59 - Last mean reward per episode: 1619.58
----------------------------------
| forward_vel        | 1.36      |
| reward             | 1.42      |
| reward_contact     | -0.000794 |
| reward_ctrl        | -0.931    |
| reward_position    | 7.1e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 873       |
|    ep_rew_mean     | 1.62e+03  |
| time/              |           |
|    episodes        | 2144      |
|    fps             | 13        |
|    time_elapsed    | 132763    |
|    total timesteps | 1833238   |
| train/             |           |
|    actor_loss      | -174      |
|    critic_loss     | 26.3      |
|    learning_rate   | 0.001     |
|    n_updates       | 1828235   |
----------------------------------
Num timesteps: 1834000
Best mean reward: 2531.59 - Last mean reward per episode: 1620.84
Num timesteps: 1836000
Best mean reward: 2531.59 - Last mean reward per episode: 1647.66
----------------------------------
| forward_vel        | 1.41      |
| reward             | 1.49      |
| reward_contact     | -0.000748 |
| reward_ctrl        | -0.923    |
| reward_position    | 7.1e-05   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 872       |
|    ep_rew_mean     | 1.65e+03  |
| time/              |           |
|    episodes        | 2148      |
|    fps             | 13        |
|    time_elapsed    | 133022    |
|    total timesteps | 1836666   |
| train/             |           |
|    actor_loss      | -181      |
|    critic_loss     | 27.9      |
|    learning_rate   | 0.001     |
|    n_updates       | 1831665   |
----------------------------------
Num timesteps: 1838000
Best mean reward: 2531.59 - Last mean reward per episode: 1654.98
Num timesteps: 1840000
Best mean reward: 2531.59 - Last mean reward per episode: 1677.02
----------------------------------
| forward_vel        | 1.42      |
| reward             | 1.5       |
| reward_contact     | -0.000762 |
| reward_ctrl        | -0.921    |
| reward_position    | 2.42e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 882       |
|    ep_rew_mean     | 1.68e+03  |
| time/              |           |
|    episodes        | 2152      |
|    fps             | 13        |
|    time_elapsed    | 133323    |
|    total timesteps | 1840666   |
| train/             |           |
|    actor_loss      | -189      |
|    critic_loss     | 16.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1835665   |
----------------------------------
Num timesteps: 1842000
Best mean reward: 2531.59 - Last mean reward per episode: 1664.04
Num timesteps: 1844000
Best mean reward: 2531.59 - Last mean reward per episode: 1665.59
----------------------------------
| forward_vel        | 1.45      |
| reward             | 1.54      |
| reward_contact     | -0.000768 |
| reward_ctrl        | -0.91     |
| reward_position    | 2.42e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 882       |
|    ep_rew_mean     | 1.68e+03  |
| time/              |           |
|    episodes        | 2156      |
|    fps             | 13        |
|    time_elapsed    | 133578    |
|    total timesteps | 1844063   |
| train/             |           |
|    actor_loss      | -174      |
|    critic_loss     | 15.7      |
|    learning_rate   | 0.001     |
|    n_updates       | 1839060   |
----------------------------------
Num timesteps: 1846000
Best mean reward: 2531.59 - Last mean reward per episode: 1683.68
----------------------------------
| forward_vel        | 1.49      |
| reward             | 1.57      |
| reward_contact     | -0.000757 |
| reward_ctrl        | -0.914    |
| reward_position    | 2.42e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 874       |
|    ep_rew_mean     | 1.66e+03  |
| time/              |           |
|    episodes        | 2160      |
|    fps             | 13        |
|    time_elapsed    | 133819    |
|    total timesteps | 1847277   |
| train/             |           |
|    actor_loss      | -179      |
|    critic_loss     | 41.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 1842275   |
----------------------------------
Num timesteps: 1848000
Best mean reward: 2531.59 - Last mean reward per episode: 1664.48
Num timesteps: 1850000
Best mean reward: 2531.59 - Last mean reward per episode: 1667.17
---------------------------------
| forward_vel        | 1.5      |
| reward             | 1.56     |
| reward_contact     | -0.0008  |
| reward_ctrl        | -0.933   |
| reward_position    | 2.42e-08 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 879      |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    episodes        | 2164     |
|    fps             | 13       |
|    time_elapsed    | 134119   |
|    total timesteps | 1851277  |
| train/             |          |
|    actor_loss      | -189     |
|    critic_loss     | 58.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 1846275  |
---------------------------------
Num timesteps: 1852000
Best mean reward: 2531.59 - Last mean reward per episode: 1682.18
Num timesteps: 1854000
Best mean reward: 2531.59 - Last mean reward per episode: 1679.22
----------------------------------
| forward_vel        | 1.49      |
| reward             | 1.55      |
| reward_contact     | -0.000866 |
| reward_ctrl        | -0.939    |
| reward_position    | 2.42e-08  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 879       |
|    ep_rew_mean     | 1.68e+03  |
| time/              |           |
|    episodes        | 2168      |
|    fps             | 13        |
|    time_elapsed    | 134421    |
|    total timesteps | 1855277   |
| train/             |           |
|    actor_loss      | -187      |
|    critic_loss     | 11.6      |
|    learning_rate   | 0.001     |
|    n_updates       | 1850275   |
----------------------------------
Num timesteps: 1856000
Best mean reward: 2531.59 - Last mean reward per episode: 1678.82
Num timesteps: 1858000
Best mean reward: 2531.59 - Last mean reward per episode: 1701.99
----------------------------------
| forward_vel        | 1.46      |
| reward             | 1.53      |
| reward_contact     | -0.000953 |
| reward_ctrl        | -0.936    |
| reward_position    | 1.19e-12  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 889       |
|    ep_rew_mean     | 1.7e+03   |
| time/              |           |
|    episodes        | 2172      |
|    fps             | 13        |
|    time_elapsed    | 134661    |
|    total timesteps | 1858444   |
| train/             |           |
|    actor_loss      | -184      |
|    critic_loss     | 11.9      |
|    learning_rate   | 0.001     |
|    n_updates       | 1853440   |
----------------------------------
Num timesteps: 1860000
Best mean reward: 2531.59 - Last mean reward per episode: 1699.25
----------------------------------
| forward_vel        | 1.49      |
| reward             | 1.55      |
| reward_contact     | -0.000961 |
| reward_ctrl        | -0.938    |
| reward_position    | 1.19e-12  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 878       |
|    ep_rew_mean     | 1.69e+03  |
| time/              |           |
|    episodes        | 2176      |
|    fps             | 13        |
|    time_elapsed    | 134859    |
|    total timesteps | 1861045   |
| train/             |           |
|    actor_loss      | -188      |
|    critic_loss     | 24.4      |
|    learning_rate   | 0.001     |
|    n_updates       | 1856040   |
----------------------------------
Num timesteps: 1862000
Best mean reward: 2531.59 - Last mean reward per episode: 1691.79
Num timesteps: 1864000
Best mean reward: 2531.59 - Last mean reward per episode: 1676.04
----------------------------------
| forward_vel        | 1.49      |
| reward             | 1.55      |
| reward_contact     | -0.000958 |
| reward_ctrl        | -0.941    |
| reward_position    | 1.19e-12  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 872       |
|    ep_rew_mean     | 1.68e+03  |
| time/              |           |
|    episodes        | 2180      |
|    fps             | 13        |
|    time_elapsed    | 135097    |
|    total timesteps | 1864177   |
| train/             |           |
|    actor_loss      | -183      |
|    critic_loss     | 25.2      |
|    learning_rate   | 0.001     |
|    n_updates       | 1859175   |
----------------------------------
Num timesteps: 1866000
Best mean reward: 2531.59 - Last mean reward per episode: 1669.87
Num timesteps: 1868000
Best mean reward: 2531.59 - Last mean reward per episode: 1672.11
----------------------------------
| forward_vel        | 1.49      |
| reward             | 1.56      |
| reward_contact     | -0.000963 |
| reward_ctrl        | -0.929    |
| reward_position    | 1.19e-12  |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 872       |
|    ep_rew_mean     | 1.67e+03  |
| time/              |           |
|    episodes        | 2184      |
|    fps             | 13        |
|    time_elapsed    | 135401    |
|    total timesteps | 1868155   |
| train/             |           |
|    actor_loss      | -183      |
|    critic_loss     | 8.58      |
|    learning_rate   | 0.001     |
|    n_updates       | 1863150   |
----------------------------------
Num timesteps: 1870000
Best mean reward: 2531.59 - Last mean reward per episode: 1666.71
---------------------------------
| forward_vel        | 1.5      |
| reward             | 1.57     |
| reward_contact     | -0.001   |
| reward_ctrl        | -0.936   |
| reward_position    | 1.19e-12 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 870      |
|    ep_rew_mean     | 1.67e+03 |
| time/              |          |
|    episodes        | 2188     |
|    fps             | 13       |
|    time_elapsed    | 135667   |
|    total timesteps | 1871677  |
| train/             |          |
|    actor_loss      | -182     |
|    critic_loss     | 18.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1866675  |
---------------------------------
Num timesteps: 1872000
Best mean reward: 2531.59 - Last mean reward per episode: 1668.96
Num timesteps: 1874000
Best mean reward: 2531.59 - Last mean reward per episode: 1677.10
---------------------------------
| forward_vel        | 1.5      |
| reward             | 1.54     |
| reward_contact     | -0.00104 |
| reward_ctrl        | -0.955   |
| reward_position    | 1.19e-12 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 878      |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    episodes        | 2192     |
|    fps             | 13       |
|    time_elapsed    | 135971   |
|    total timesteps | 1875677  |
| train/             |          |
|    actor_loss      | -180     |
|    critic_loss     | 23.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1870675  |
---------------------------------
Num timesteps: 1876000
Best mean reward: 2531.59 - Last mean reward per episode: 1675.68
Num timesteps: 1878000
Best mean reward: 2531.59 - Last mean reward per episode: 1665.61
---------------------------------
| forward_vel        | 1.47     |
| reward             | 1.49     |
| reward_contact     | -0.00105 |
| reward_ctrl        | -0.987   |
| reward_position    | 1.19e-12 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 875      |
|    ep_rew_mean     | 1.67e+03 |
| time/              |          |
|    episodes        | 2196     |
|    fps             | 13       |
|    time_elapsed    | 136233   |
|    total timesteps | 1879112  |
| train/             |          |
|    actor_loss      | -184     |
|    critic_loss     | 13.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1874110  |
---------------------------------
Num timesteps: 1880000
Best mean reward: 2531.59 - Last mean reward per episode: 1665.15
Num timesteps: 1882000
Best mean reward: 2531.59 - Last mean reward per episode: 1672.67
---------------------------------
| forward_vel        | 1.48     |
| reward             | 1.51     |
| reward_contact     | -0.00109 |
| reward_ctrl        | -0.968   |
| reward_position    | 1.19e-12 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 886      |
|    ep_rew_mean     | 1.69e+03 |
| time/              |          |
|    episodes        | 2200     |
|    fps             | 13       |
|    time_elapsed    | 136539   |
|    total timesteps | 1883112  |
| train/             |          |
|    actor_loss      | -185     |
|    critic_loss     | 16.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 1878110  |
---------------------------------
Num timesteps: 1884000
Best mean reward: 2531.59 - Last mean reward per episode: 1692.27
Num timesteps: 1886000
Best mean reward: 2531.59 - Last mean reward per episode: 1694.41
---------------------------------
| forward_vel        | 1.46     |
| reward             | 1.52     |
| reward_contact     | -0.0011  |
| reward_ctrl        | -0.941   |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 887      |
|    ep_rew_mean     | 1.7e+03  |
| time/              |          |
|    episodes        | 2204     |
|    fps             | 13       |
|    time_elapsed    | 136772   |
|    total timesteps | 1886191  |
| train/             |          |
|    actor_loss      | -179     |
|    critic_loss     | 20.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1881190  |
---------------------------------
Num timesteps: 1888000
Best mean reward: 2531.59 - Last mean reward per episode: 1698.45
Num timesteps: 1890000
Best mean reward: 2531.59 - Last mean reward per episode: 1701.95
---------------------------------
| forward_vel        | 1.44     |
| reward             | 1.49     |
| reward_contact     | -0.0011  |
| reward_ctrl        | -0.954   |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 894      |
|    ep_rew_mean     | 1.7e+03  |
| time/              |          |
|    episodes        | 2208     |
|    fps             | 13       |
|    time_elapsed    | 137079   |
|    total timesteps | 1890191  |
| train/             |          |
|    actor_loss      | -186     |
|    critic_loss     | 24.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1885190  |
---------------------------------
Num timesteps: 1892000
Best mean reward: 2531.59 - Last mean reward per episode: 1702.85
Num timesteps: 1894000
Best mean reward: 2531.59 - Last mean reward per episode: 1705.84
---------------------------------
| forward_vel        | 1.45     |
| reward             | 1.49     |
| reward_contact     | -0.0011  |
| reward_ctrl        | -0.956   |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 894      |
|    ep_rew_mean     | 1.7e+03  |
| time/              |          |
|    episodes        | 2212     |
|    fps             | 13       |
|    time_elapsed    | 137384   |
|    total timesteps | 1894191  |
| train/             |          |
|    actor_loss      | -184     |
|    critic_loss     | 34.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1889190  |
---------------------------------
---------------------------------
| forward_vel        | 1.45     |
| reward             | 1.46     |
| reward_contact     | -0.00107 |
| reward_ctrl        | -0.985   |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 871      |
|    ep_rew_mean     | 1.66e+03 |
| time/              |          |
|    episodes        | 2216     |
|    fps             | 13       |
|    time_elapsed    | 137509   |
|    total timesteps | 1895845  |
| train/             |          |
|    actor_loss      | -180     |
|    critic_loss     | 20.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 1890840  |
---------------------------------
Num timesteps: 1896000
Best mean reward: 2531.59 - Last mean reward per episode: 1659.76
Num timesteps: 1898000
Best mean reward: 2531.59 - Last mean reward per episode: 1675.54
---------------------------------
| forward_vel        | 1.5      |
| reward             | 1.5      |
| reward_contact     | -0.00101 |
| reward_ctrl        | -0.997   |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 879      |
|    ep_rew_mean     | 1.71e+03 |
| time/              |          |
|    episodes        | 2220     |
|    fps             | 13       |
|    time_elapsed    | 137804   |
|    total timesteps | 1899712  |
| train/             |          |
|    actor_loss      | -191     |
|    critic_loss     | 14       |
|    learning_rate   | 0.001    |
|    n_updates       | 1894710  |
---------------------------------
Num timesteps: 1900000
Best mean reward: 2531.59 - Last mean reward per episode: 1713.41
Num timesteps: 1902000
Best mean reward: 2531.59 - Last mean reward per episode: 1715.27
---------------------------------
| forward_vel        | 1.48     |
| reward             | 1.47     |
| reward_contact     | -0.00104 |
| reward_ctrl        | -1.01    |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 879      |
|    ep_rew_mean     | 1.74e+03 |
| time/              |          |
|    episodes        | 2224     |
|    fps             | 13       |
|    time_elapsed    | 138109   |
|    total timesteps | 1903712  |
| train/             |          |
|    actor_loss      | -187     |
|    critic_loss     | 24.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1898710  |
---------------------------------
Num timesteps: 1904000
Best mean reward: 2531.59 - Last mean reward per episode: 1735.84
Num timesteps: 1906000
Best mean reward: 2531.59 - Last mean reward per episode: 1760.33
---------------------------------
| forward_vel        | 1.5      |
| reward             | 1.5      |
| reward_contact     | -0.001   |
| reward_ctrl        | -0.997   |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 874      |
|    ep_rew_mean     | 1.76e+03 |
| time/              |          |
|    episodes        | 2228     |
|    fps             | 13       |
|    time_elapsed    | 138375   |
|    total timesteps | 1907212  |
| train/             |          |
|    actor_loss      | -188     |
|    critic_loss     | 34.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1902210  |
---------------------------------
Num timesteps: 1908000
Best mean reward: 2531.59 - Last mean reward per episode: 1756.64
Num timesteps: 1910000
Best mean reward: 2531.59 - Last mean reward per episode: 1764.90
---------------------------------
| forward_vel        | 1.52     |
| reward             | 1.51     |
| reward_contact     | -0.001   |
| reward_ctrl        | -1       |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 891      |
|    ep_rew_mean     | 1.78e+03 |
| time/              |          |
|    episodes        | 2232     |
|    fps             | 13       |
|    time_elapsed    | 138681   |
|    total timesteps | 1911212  |
| train/             |          |
|    actor_loss      | -182     |
|    critic_loss     | 14.9     |
|    learning_rate   | 0.001    |
|    n_updates       | 1906210  |
---------------------------------
Num timesteps: 1912000
Best mean reward: 2531.59 - Last mean reward per episode: 1763.14
Num timesteps: 1914000
Best mean reward: 2531.59 - Last mean reward per episode: 1757.58
---------------------------------
| forward_vel        | 1.49     |
| reward             | 1.45     |
| reward_contact     | -0.00109 |
| reward_ctrl        | -1.04    |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 883      |
|    ep_rew_mean     | 1.76e+03 |
| time/              |          |
|    episodes        | 2236     |
|    fps             | 13       |
|    time_elapsed    | 138931   |
|    total timesteps | 1914469  |
| train/             |          |
|    actor_loss      | -187     |
|    critic_loss     | 44.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 1909465  |
---------------------------------
Num timesteps: 1916000
Best mean reward: 2531.59 - Last mean reward per episode: 1760.65
Num timesteps: 1918000
Best mean reward: 2531.59 - Last mean reward per episode: 1767.25
---------------------------------
| forward_vel        | 1.48     |
| reward             | 1.45     |
| reward_contact     | -0.00112 |
| reward_ctrl        | -1.03    |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 890      |
|    ep_rew_mean     | 1.79e+03 |
| time/              |          |
|    episodes        | 2240     |
|    fps             | 13       |
|    time_elapsed    | 139237   |
|    total timesteps | 1918425  |
| train/             |          |
|    actor_loss      | -193     |
|    critic_loss     | 36.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1913420  |
---------------------------------
Num timesteps: 1920000
Best mean reward: 2531.59 - Last mean reward per episode: 1784.40
---------------------------------
| forward_vel        | 1.49     |
| reward             | 1.46     |
| reward_contact     | -0.00109 |
| reward_ctrl        | -1.03    |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 888      |
|    ep_rew_mean     | 1.78e+03 |
| time/              |          |
|    episodes        | 2244     |
|    fps             | 13       |
|    time_elapsed    | 139515   |
|    total timesteps | 1921992  |
| train/             |          |
|    actor_loss      | -184     |
|    critic_loss     | 26.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1916990  |
---------------------------------
Num timesteps: 1922000
Best mean reward: 2531.59 - Last mean reward per episode: 1782.16
Num timesteps: 1924000
Best mean reward: 2531.59 - Last mean reward per episode: 1755.10
---------------------------------
| forward_vel        | 1.49     |
| reward             | 1.45     |
| reward_contact     | -0.00106 |
| reward_ctrl        | -1.04    |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 878      |
|    ep_rew_mean     | 1.76e+03 |
| time/              |          |
|    episodes        | 2248     |
|    fps             | 13       |
|    time_elapsed    | 139702   |
|    total timesteps | 1924440  |
| train/             |          |
|    actor_loss      | -180     |
|    critic_loss     | 17       |
|    learning_rate   | 0.001    |
|    n_updates       | 1919435  |
---------------------------------
Num timesteps: 1926000
Best mean reward: 2531.59 - Last mean reward per episode: 1748.70
---------------------------------
| forward_vel        | 1.48     |
| reward             | 1.43     |
| reward_contact     | -0.00104 |
| reward_ctrl        | -1.05    |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 871      |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    episodes        | 2252     |
|    fps             | 13       |
|    time_elapsed    | 139960   |
|    total timesteps | 1927809  |
| train/             |          |
|    actor_loss      | -179     |
|    critic_loss     | 26.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 1922805  |
---------------------------------
Num timesteps: 1928000
Best mean reward: 2531.59 - Last mean reward per episode: 1748.29
Num timesteps: 1930000
Best mean reward: 2531.59 - Last mean reward per episode: 1756.17
---------------------------------
| forward_vel        | 1.46     |
| reward             | 1.42     |
| reward_contact     | -0.00104 |
| reward_ctrl        | -1.04    |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    episodes        | 2256     |
|    fps             | 13       |
|    time_elapsed    | 140263   |
|    total timesteps | 1931809  |
| train/             |          |
|    actor_loss      | -190     |
|    critic_loss     | 18.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 1926805  |
---------------------------------
Num timesteps: 1932000
Best mean reward: 2531.59 - Last mean reward per episode: 1754.16
Num timesteps: 1934000
Best mean reward: 2531.59 - Last mean reward per episode: 1751.23
---------------------------------
| forward_vel        | 1.45     |
| reward             | 1.41     |
| reward_contact     | -0.0011  |
| reward_ctrl        | -1.05    |
| reward_position    | 1.41e-06 |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 885      |
|    ep_rew_mean     | 1.77e+03 |
| time/              |          |
|    episodes        | 2260     |
|    fps             | 13       |
|    time_elapsed    | 140573   |
|    total timesteps | 1935809  |
| train/             |          |
|    actor_loss      | -185     |
|    critic_loss     | 16       |
|    learning_rate   | 0.001    |
|    n_updates       | 1930805  |
---------------------------------
Num timesteps: 1936000
Best mean reward: 2531.59 - Last mean reward per episode: 1769.91
Num timesteps: 1938000
Best mean reward: 2531.59 - Last mean reward per episode: 1737.08
---------------------------------
| forward_vel        | 1.47     |
| reward             | 1.44     |
| reward_contact     | -0.00104 |
| reward_ctrl        | -1.03    |
| reward_position    | 2.1e-06  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 868      |
|    ep_rew_mean     | 1.73e+03 |
| time/              |          |
|    episodes        | 2264     |
|    fps             | 13       |
|    time_elapsed    | 140750   |
|    total timesteps | 1938127  |
| train/             |          |
|    actor_loss      | -177     |
|    critic_loss     | 16.3     |
|    learning_rate   | 0.001    |
|    n_updates       | 1933125  |
---------------------------------
Num timesteps: 1940000
Best mean reward: 2531.59 - Last mean reward per episode: 1736.16
---------------------------------
| forward_vel        | 1.5      |
| reward             | 1.48     |
| reward_contact     | -0.00101 |
| reward_ctrl        | -1.02    |
| reward_position    | 2.1e-06  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 866      |
|    ep_rew_mean     | 1.73e+03 |
| time/              |          |
|    episodes        | 2268     |
|    fps             | 13       |
|    time_elapsed    | 141034   |
|    total timesteps | 1941870  |
| train/             |          |
|    actor_loss      | -193     |
|    critic_loss     | 25.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 1936865  |
---------------------------------
Num timesteps: 1942000
Best mean reward: 2531.59 - Last mean reward per episode: 1734.10
Num timesteps: 1944000
Best mean reward: 2531.59 - Last mean reward per episode: 1744.90
----------------------------------
| forward_vel        | 1.53      |
| reward             | 1.5       |
| reward_contact     | -0.000987 |
| reward_ctrl        | -1.03     |
| reward_position    | 2.1e-06   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 874       |
|    ep_rew_mean     | 1.75e+03  |
| time/              |           |
|    episodes        | 2272      |
|    fps             | 13        |
|    time_elapsed    | 141338    |
|    total timesteps | 1945870   |
| train/             |           |
|    actor_loss      | -182      |
|    critic_loss     | 48.8      |
|    learning_rate   | 0.001     |
|    n_updates       | 1940865   |
----------------------------------
Num timesteps: 1946000
Best mean reward: 2531.59 - Last mean reward per episode: 1745.42
Num timesteps: 1948000
Best mean reward: 2531.59 - Last mean reward per episode: 1757.85
---------------------------------
| forward_vel        | 1.52     |
| reward             | 1.48     |
| reward_contact     | -0.00101 |
| reward_ctrl        | -1.04    |
| reward_position    | 2.1e-06  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 888      |
|    ep_rew_mean     | 1.77e+03 |
| time/              |          |
|    episodes        | 2276     |
|    fps             | 13       |
|    time_elapsed    | 141642   |
|    total timesteps | 1949870  |
| train/             |          |
|    actor_loss      | -192     |
|    critic_loss     | 14.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1944865  |
---------------------------------
Num timesteps: 1950000
Best mean reward: 2531.59 - Last mean reward per episode: 1769.40
Num timesteps: 1952000
Best mean reward: 2531.59 - Last mean reward per episode: 1770.30
---------------------------------
| forward_vel        | 1.52     |
| reward             | 1.47     |
| reward_contact     | -0.00102 |
| reward_ctrl        | -1.04    |
| reward_position    | 2.1e-06  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 897      |
|    ep_rew_mean     | 1.79e+03 |
| time/              |          |
|    episodes        | 2280     |
|    fps             | 13       |
|    time_elapsed    | 141947   |
|    total timesteps | 1953870  |
| train/             |          |
|    actor_loss      | -186     |
|    critic_loss     | 26.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1948865  |
---------------------------------
Num timesteps: 1954000
Best mean reward: 2531.59 - Last mean reward per episode: 1790.03
Num timesteps: 1956000
Best mean reward: 2531.59 - Last mean reward per episode: 1793.10
---------------------------------
| forward_vel        | 1.51     |
| reward             | 1.44     |
| reward_contact     | -0.00106 |
| reward_ctrl        | -1.07    |
| reward_position    | 2.1e-06  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 892      |
|    ep_rew_mean     | 1.78e+03 |
| time/              |          |
|    episodes        | 2284     |
|    fps             | 13       |
|    time_elapsed    | 142209   |
|    total timesteps | 1957328  |
| train/             |          |
|    actor_loss      | -179     |
|    critic_loss     | 27.4     |
|    learning_rate   | 0.001    |
|    n_updates       | 1952325  |
---------------------------------
Num timesteps: 1958000
Best mean reward: 2531.59 - Last mean reward per episode: 1776.28
Num timesteps: 1960000
Best mean reward: 2531.59 - Last mean reward per episode: 1780.76
----------------------------------
| forward_vel        | 1.54      |
| reward             | 1.46      |
| reward_contact     | -0.000979 |
| reward_ctrl        | -1.08     |
| reward_position    | 2.1e-06   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 896       |
|    ep_rew_mean     | 1.79e+03  |
| time/              |           |
|    episodes        | 2288      |
|    fps             | 13        |
|    time_elapsed    | 142507    |
|    total timesteps | 1961274   |
| train/             |           |
|    actor_loss      | -188      |
|    critic_loss     | 22.9      |
|    learning_rate   | 0.001     |
|    n_updates       | 1956270   |
----------------------------------
Num timesteps: 1962000
Best mean reward: 2531.59 - Last mean reward per episode: 1794.31
Num timesteps: 1964000
Best mean reward: 2531.59 - Last mean reward per episode: 1794.91
---------------------------------
| forward_vel        | 1.52     |
| reward             | 1.44     |
| reward_contact     | -0.00097 |
| reward_ctrl        | -1.08    |
| reward_position    | 2.1e-06  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 896      |
|    ep_rew_mean     | 1.79e+03 |
| time/              |          |
|    episodes        | 2292     |
|    fps             | 13       |
|    time_elapsed    | 142811   |
|    total timesteps | 1965274  |
| train/             |          |
|    actor_loss      | -189     |
|    critic_loss     | 25.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1960270  |
---------------------------------
Num timesteps: 1966000
Best mean reward: 2531.59 - Last mean reward per episode: 1793.54
Num timesteps: 1968000
Best mean reward: 2531.59 - Last mean reward per episode: 1803.95
----------------------------------
| forward_vel        | 1.54      |
| reward             | 1.47      |
| reward_contact     | -0.000972 |
| reward_ctrl        | -1.06     |
| reward_position    | 2.1e-06   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 900       |
|    ep_rew_mean     | 1.81e+03  |
| time/              |           |
|    episodes        | 2296      |
|    fps             | 13        |
|    time_elapsed    | 143102    |
|    total timesteps | 1969088   |
| train/             |           |
|    actor_loss      | -187      |
|    critic_loss     | 12.5      |
|    learning_rate   | 0.001     |
|    n_updates       | 1964085   |
----------------------------------
Num timesteps: 1970000
Best mean reward: 2531.59 - Last mean reward per episode: 1813.24
Num timesteps: 1972000
Best mean reward: 2531.59 - Last mean reward per episode: 1810.75
----------------------------------
| forward_vel        | 1.52      |
| reward             | 1.44      |
| reward_contact     | -0.000941 |
| reward_ctrl        | -1.08     |
| reward_position    | 2.1e-06   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 900       |
|    ep_rew_mean     | 1.81e+03  |
| time/              |           |
|    episodes        | 2300      |
|    fps             | 13        |
|    time_elapsed    | 143408    |
|    total timesteps | 1973088   |
| train/             |           |
|    actor_loss      | -194      |
|    critic_loss     | 130       |
|    learning_rate   | 0.001     |
|    n_updates       | 1968085   |
----------------------------------
Num timesteps: 1974000
Best mean reward: 2531.59 - Last mean reward per episode: 1795.68
Num timesteps: 1976000
Best mean reward: 2531.59 - Last mean reward per episode: 1813.68
----------------------------------
| forward_vel        | 1.51      |
| reward             | 1.44      |
| reward_contact     | -0.000998 |
| reward_ctrl        | -1.07     |
| reward_position    | 6.9e-07   |
| reward_survive     | 1         |
| rollout/           |           |
|    ep_len_mean     | 901       |
|    ep_rew_mean     | 1.81e+03  |
| time/              |           |
|    episodes        | 2304      |
|    fps             | 13        |
|    time_elapsed    | 143648    |
|    total timesteps | 1976273   |
| train/             |           |
|    actor_loss      | -186      |
|    critic_loss     | 13.1      |
|    learning_rate   | 0.001     |
|    n_updates       | 1971270   |
----------------------------------
Num timesteps: 1978000
Best mean reward: 2531.59 - Last mean reward per episode: 1809.88
Num timesteps: 1980000
Best mean reward: 2531.59 - Last mean reward per episode: 1816.72
---------------------------------
| forward_vel        | 1.52     |
| reward             | 1.46     |
| reward_contact     | -0.00107 |
| reward_ctrl        | -1.06    |
| reward_position    | 6.9e-07  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 901      |
|    ep_rew_mean     | 1.82e+03 |
| time/              |          |
|    episodes        | 2308     |
|    fps             | 13       |
|    time_elapsed    | 143950   |
|    total timesteps | 1980273  |
| train/             |          |
|    actor_loss      | -190     |
|    critic_loss     | 13.8     |
|    learning_rate   | 0.001    |
|    n_updates       | 1975270  |
---------------------------------
Num timesteps: 1982000
Best mean reward: 2531.59 - Last mean reward per episode: 1787.46
---------------------------------
| forward_vel        | 1.56     |
| reward             | 1.5      |
| reward_contact     | -0.00101 |
| reward_ctrl        | -1.06    |
| reward_position    | 6.9e-07  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 887      |
|    ep_rew_mean     | 1.79e+03 |
| time/              |          |
|    episodes        | 2312     |
|    fps             | 13       |
|    time_elapsed    | 144145   |
|    total timesteps | 1982862  |
| train/             |          |
|    actor_loss      | -186     |
|    critic_loss     | 33.6     |
|    learning_rate   | 0.001    |
|    n_updates       | 1977860  |
---------------------------------
Num timesteps: 1984000
Best mean reward: 2531.59 - Last mean reward per episode: 1791.70
Num timesteps: 1986000
Best mean reward: 2531.59 - Last mean reward per episode: 1822.46
---------------------------------
| forward_vel        | 1.58     |
| reward             | 1.56     |
| reward_contact     | -0.00104 |
| reward_ctrl        | -1.02    |
| reward_position    | 6.9e-07  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 910      |
|    ep_rew_mean     | 1.84e+03 |
| time/              |          |
|    episodes        | 2316     |
|    fps             | 13       |
|    time_elapsed    | 144447   |
|    total timesteps | 1986862  |
| train/             |          |
|    actor_loss      | -192     |
|    critic_loss     | 47.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 1981860  |
---------------------------------
Num timesteps: 1988000
Best mean reward: 2531.59 - Last mean reward per episode: 1836.12
Num timesteps: 1990000
Best mean reward: 2531.59 - Last mean reward per episode: 1837.71
---------------------------------
| forward_vel        | 1.58     |
| reward             | 1.56     |
| reward_contact     | -0.00107 |
| reward_ctrl        | -1.02    |
| reward_position    | 6.9e-07  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 912      |
|    ep_rew_mean     | 1.84e+03 |
| time/              |          |
|    episodes        | 2320     |
|    fps             | 13       |
|    time_elapsed    | 144749   |
|    total timesteps | 1990862  |
| train/             |          |
|    actor_loss      | -188     |
|    critic_loss     | 23.5     |
|    learning_rate   | 0.001    |
|    n_updates       | 1985860  |
---------------------------------
Num timesteps: 1992000
Best mean reward: 2531.59 - Last mean reward per episode: 1842.42
Num timesteps: 1994000
Best mean reward: 2531.59 - Last mean reward per episode: 1841.29
---------------------------------
| forward_vel        | 1.57     |
| reward             | 1.56     |
| reward_contact     | -0.00115 |
| reward_ctrl        | -1.01    |
| reward_position    | 6.9e-07  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 906      |
|    ep_rew_mean     | 1.83e+03 |
| time/              |          |
|    episodes        | 2324     |
|    fps             | 13       |
|    time_elapsed    | 145006   |
|    total timesteps | 1994283  |
| train/             |          |
|    actor_loss      | -184     |
|    critic_loss     | 23.1     |
|    learning_rate   | 0.001    |
|    n_updates       | 1989280  |
---------------------------------
Num timesteps: 1996000
Best mean reward: 2531.59 - Last mean reward per episode: 1841.21
---------------------------------
| forward_vel        | 1.6      |
| reward             | 1.59     |
| reward_contact     | -0.00114 |
| reward_ctrl        | -1.01    |
| reward_position    | 6.9e-07  |
| reward_survive     | 1        |
| rollout/           |          |
|    ep_len_mean     | 906      |
|    ep_rew_mean     | 1.84e+03 |
| time/              |          |
|    episodes        | 2328     |
|    fps             | 13       |
|    time_elapsed    | 145272   |
|    total timesteps | 1997840  |
| train/             |          |
|    actor_loss      | -187     |
|    critic_loss     | 62       |
|    learning_rate   | 0.001    |
|    n_updates       | 1992835  |
---------------------------------
/home/shandilya/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() > 0
Num timesteps: 1998000
Best mean reward: 2531.59 - Last mean reward per episode: 1837.98
Num timesteps: 2000000
Best mean reward: 2531.59 - Last mean reward per episode: 1839.53
Traceback (most recent call last):
  File "ddpg.py", line 280, in <module>
    print(stable_baselines3.common.evaluation.evaluate_policy(model_2, env, render=True))
NameError: name 'model_2' is not defined
